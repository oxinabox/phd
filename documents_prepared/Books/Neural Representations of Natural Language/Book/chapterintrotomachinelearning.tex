\documentclass[12pt,parskip]{komatufte}
\include{preamble}
\usepackage{showframe}

\begin{document}
	

\setchapterpreamble{%
	\dictum[J. M. G. ele Lammens, \textit{A Computational Model of Color Perception and Color Naming}, PhD Dissertation, State University of New York, 1994]{%
Whether one sees the artificial neural network technique described below as learning or as optimization depends largely on one's background and one's theoretical likes and dislikes. I will freely use ``learning'' in the remainder of this section because that term is traditionally used in the neural networks literature, but the reader should feel free to substitute ``optimization'' if (s)he finds the other term offensive. Please contact the author for an Emacs lisp function to enforce the usage of choice.%
}}
\chapter{Machine Learning for Representations}\label{sec:machine-learning-for-representations}

%•	Chapter 2: Introduction to machine learning for representations (10 pages)
%o	This chapter can be skipped by readers already familiar with machine learning
%o	This will not be a full introduction to machine learning, which of-course could be an entire book on its own.
%o	It will cover the crucial basic techniques used in the works discussed in part B. The main focus will be on introducing neural networks, going into reasonable detail on hyper-parameters such as activation functions and layer sizes, as well as covering training techniques. 
%o	It will not cover techniques that are special to natural language processing – those will be discussed in chapters 4,5, and 6.


\blindtext
\end{document}