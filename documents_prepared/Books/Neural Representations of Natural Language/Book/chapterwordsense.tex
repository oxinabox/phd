\documentclass[12pt,parskip]{komatufte}
\include{preamble}
\usepackage{tabulary}
\newcolumntype{K}[1]{>{\centering\arraybackslash}p{#1}}
\begin{document}
	
\section{Word Senses}

Words have multiple meanings.
A trivial example of this is 


\aside[lemma/lexeme]{}
\aside[tense]{}
\aside[Part of Speech/POS]{}
\aside[synset]{}
\aside[stem]{}
\aside[synset]{A synset is a set of synonymous words: that is words that have the same meaning}
\aside[gloss]{A gloss is the dictionary entry for a word-sense, it normally includes both the definition and an example of use.
In wordnet each synset shares a common gloss. }



The standard way to assign word senses is via some lexicographical resource.
i.e. a dictionary, or a thesaurus.
There is not a canonical list of word senses that are truly real and consistently defined in English.
Every dictionary is unique, with different definitions and numbers of word senses.
The most commonly used lexicographical resource is WordNet \pcite{miller1995wordnet},
there are several WordNets equivalents in other languages,
as well as the multi-lingual  BabelNet \pcite{navigli2010babelnet}.




\subsection{Word Sense Disambiguation}


\aside[Semantic Syllepsis]{
	Also known as pathological sentences that kill almost all WSD systems.
	Consider the sentence: \natlang{John used to work for the \emph{newspaper} that you are carrying.},
	In this sentence the word newspaper simultaneously have two different meanings: it is both the company, and the object
	As word sense disambiguation systems normally attempt to assign a single sense  to an each word they are unable to handle these sentences.
	Most word sense induction systems can not much better: at best a new sense could be allocated for the join use, which does not correspond to the human notion of the word having two senses for different parts of the sentence.
	Most works on word sense disambiguation outright ignore these sentences, or consider them to be ungrammatical, or incorrect.
	However, they are readily understood and used without thought by most native speakers.
	These constructions are also known as zeugma, although zeugma is itself as highly polysemous word, so its usage varies. 
}



Word sense disambiguation is one of the hardest problems in NLP.
Very few systems significantly out perform the baseline most common sense (MCS).

Progress on the problem is made difficult by several factors.

There are problems with the data available.
The lack of very large scale training corpora rendering fully supervised methods difficult.
The limited testing corpora can result in systems that allow 
Lack of human agreement on the correct sense, resulting in weak ground truth.

There are also issues inherent in the task.
Determining the sense may require very long range information:
for example the information on context may not even be in the same sentence.
It may require knowing the domain of the text, where word sense uses vary between domain.
It may in-fact be intentionally unclear, with multiple correct interpretations, as in a pun.
Or be unintentionally unknowable, due to poor writing style, such that it would confuse any human reader also.





\section{Word Sense Induction}
\section{Word Sense Alignment}



\subsection{Directly Learning Lexical Sense Embeddings}
In this area of research, the induction of word sense embeddings is treated as a supervised, or semi-supervised task, that requires sense labelled corpora for training.

\tcite{iacobacci2015sensembed} use a Continuous Bag of Word language model \parencite{mikolov2013efficient}, using word senses as the labels rather than words.
This is a direct application of word embedding techniques.
To overcome the lack of a large sense labelled corpus, Iacobacci et al. use a 3rd party WSD tool, BabelFly \cite{Moroetal:14tacl}, to add sense annotations to a previously unlabelled corpus. 

\tcite{Chen2014} use a semi-supervised approach to train sense vectors.
They partially disambiguate their training corpus, using initial word sense vectors and WordNet; and use these labels to fine tune their embeddings.
Initially the sense vectors are set as the average of the single sense word embeddings \parencite{mikolov2013efficient} for the words in the WordNet gloss.
This is then also done for the words in a sentence.
The distance between the sentence average and the gloss average is used to perform WSD to label the word sense. Words are only sense labelled when the distance is within a threshold.
The requirement for meeting a threshold in order to add the sense label  decreases the likelihood of training on an incorrect sense label.
This relabelled data is then used as training data, for fine tuning the sense embeddings.


\subsection{Mapping induced senses to lexical senses}\label{mapping}
By defining a stochastic map between the induced and lexical senses, \tcite{agirre2006}, propose a general method for allowing WSI systems to be used for WSD.
Their work was used in SemEval-2007 Task 02 \parencite{SemEval2007WSIandWSD} to evaluate all entries. 
Agirre et al. use a mapping corpus to find the probability of a lexical sense, given the induced sense according to the WSI system.

By exploiting the particular properties of sense embedding based WSI systems we propose a system that can better facilitate the use of this subset of WSI systems for WSD.

\section{Word sense representation (WSR)}
Word sense representation (WSR) is the process by which a variety of representations, for different work senses is generated.
Here we use the term to refer to the supervised case -- that the word senses are labelled in what ever training data is used.
We are concerned with vector representations.

\tcite{iacobacci2015sensembed}

\section{Word sense induction (WSI)}
Word sense induction (WSI) is (for purposes of this discussion) the process of using unsupervised data to discover, (and implect in that task represent) word senses.
We can see this as similar to an unsupervised analogue to WSR.

Most vector WSI and WSR approaches are evaluated on similarity tests.
Like WordSim-353 \cite{WordSim353}, for contextless, or Stanford's Contextual Word Similarities (SCWS) \cite{Huang2012}. This is also how normal Word2Vec variants are often evaluated.


\tcite{pantel2002WSI}

\tcite{Reisinger2010}

\tcite{Huang2012}

\tcite{Chen2014}

\tcite{AdaGrams}



\section{Word sense disambiguation (WSD)}
Word sense disambiguation (WSD) is the process to assign a word sense, to an instance of a word. We use this term primarily in the context of WSD to a sense from a standard sense inventory. Those it is also used 

\tcite{veronis2004hyperlex}
\tcite{pinto2007upv}

\tcite{basile-caputo-semeraro:2014:Coling}

\section{Sense alignment -- going from WSI to WSD}
Here we look at methods that allow induced word senses (from WSI), to be used on WSD tasks.
A WSD task, requires determining which of the standard word-senses a particular example of a word in its context belongs to.
These standard word senses, are from some dictionary (or Sense Inventory) created by 
lexicographers, such as WordNet, BabelNet.

A related task to this word sense alignment is the composite word embedding creation used in similarity Called LocalSim in \textcite{Huang2012} (see above).


\tcite{agirre2006}

\subsubsection{\textcite {pantel2002WSI}}
The method used for evaluation by Pantel et. al. is a form of alignment. I think.
I really haven't manage to wrap my head around it.

\end{document}