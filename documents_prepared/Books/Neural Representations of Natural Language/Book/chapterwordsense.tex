\documentclass[12pt,parskip]{komatufte}
\include{preamble}

\begin{document}
\begin{table}
	\scriptsize
	
	\begin{tabulary}{\textwidth}{|C|K{1cm}|C|C|C|C|C|}
		\hline Type & paper & Input & Output & Technology & Corpora & Evaluation \\ 
		\hline  WSR & \parencite{iacobacci2015sensembed} & Sense-Labelled Corpus  & Standard Sense Embeddings & CBOW H.Softmax & Wikipedia with Babelfly WSD applied & Word Similarity, Analogy  \\ 
		%
		\hline WSI &  \parencite{pantel2002WSI} & POS tagged Corpus  & Induced Sense Clusters & Hierarchical Clustering over usage features & Subset of TREC Newswire collection with MiniParse POS tagging applied an & Agreement with WordNet \\ 
		%
		\hline WSI &  \parencite{Reisinger2010} & Corpus  & Induced Word Vectors & Mixture Model Clustering over weighted unigram context features & Wikipedia, Gigaword & Word Similarity \\
		%
		\hline WSI &  \parencite{Huang2012} & Corpus  & Induced Word Vectors & Neural Network to predict next word; with second stage relabeling of corpus with clusters based on average of words context vectors & Wikipedia & Word Similarity, Word Similarity with context \\
		%
		\hline 
	\end{tabulary} 
\end{table}

\section{Word sense representation (WSR)}
Word sense representation (WSR) is the process by which a variety of representations, for different work senses is generated.
Here we use the term to refer to the supervised case -- that the word senses are labelled in what ever training data is used.
We are concerned with vector representations.

\tcite{iacobacci2015sensembed}

\section{Word sense induction (WSI)}
Word sense induction (WSI) is (for purposes of this discussion) the process of using unsupervised data to discover, (and implect in that task represent) word senses.
We can see this as similar to an unsupervised analogue to WSR.

Most vector WSI and WSR approaches are evaluated on similarity tests.
Like WordSim-353 \cite{WordSim353}, for contextless, or Stanford's Contextual Word Similarities (SCWS) \cite{Huang2012}. This is also how normal Word2Vec variants are often evaluated.


\tcite{pantel2002WSI}

\tcite{Reisinger2010}

\tcite{Huang2012}

\tcite{Chen2014}

\tcite{AdaGrams}

I have AdaGrams running. Running on default settings did not yield a variety of senses from my inspection. I have rerun it using the settings used in the paper now, much better.



\section{Word sense disambiguation (WSD)}
Word sense disambiguation (WSD) is the process to assign a word sense, to an instance of a word. We use this term primarily in the context of WSD to a sense from a standard sense inventory. Those it is also used 

\tcite{veronis2004hyperlex}
\tcite{pinto2007upv}

\tcite{basile-caputo-semeraro:2014:Coling}

\section{Sense alignment -- going from WSI to WSD}
Here we look at methods that allow induced word senses (from WSI), to be used on WSD tasks.
A WSD task, requires determining which of the standard word-senses a particular example of a word in its context belongs to.
These standard word senses, are from some dictionary (or Sense Inventory) created by 
lexicographers, such as WordNet, BabelNet.

A related task to this word sense alignment is the composite word embedding creation used in similarity Called LocalSim in \textcite{Huang2012} (see above).


\tcite{agirre2006}

\subsubsection{\textcite {pantel2002WSI}}
The method used for evaluation by Pantel et. al. is a form of alignment. I think.
I really haven't manage to wrap my head around it.

\end{document}