\documentclass[12pt,parskip]{komatufte}
\include{preamble}


\begin{document}

\loadgeometry{basegeo}
\title{Neural Representations \\of\\ Natural Language}
\author{Lyndon White\\ Roberto Togneri\\ Wei Liu\\ Mohammed Bennamoun}
\publishers{SpringerBriefs in Computer Science}


\maketitle
\tableofcontents

\loadgeometry{contentgeo}
\chapter{Introduction}\label{sec:introduction}
\begin{abstract}
	Chapter 1: Introduction: 2-3 pages
Introduce the book, and the utility of using machine learning for natural language processing
\end{abstract}
\include{chapterintroduction}



\include{chapterintrotomachinelearning}


\include{chapterwordrepr}




\include{chapterwordsense}

\chapter{Sentence Representations and Beyond}\label{sec:sentence-representations-and-beyond}
\begin{abstract}
Chapter 8: Sentence representations and beyond (5-10 pages)
This chapter takes the previous discussion of phrases to the next level: sentences.
This will include discussions of works on recursive structure
As well work leveraging recurrent neural networks.
Methods that do not strongly consider order (including Sum of Word Embeddings; paragraph vectors) will also be discussed here.
Many of these techniques extent to arbitrary length sequences of words.
\end{abstract}


\chapter{Conclusion}\label{sec:conclusion}
\begin{abstract}
Chapter 8: Conclusion (10 pages)
This will conclude the book. 
It will summarise the prior charters
Discuss the progression of the field.
It will discuss the role machine learnt representations have within larger systems.
It will conclude with an outlook on the future.
\end{abstract}


\clearpage
\addcontentsline{toc}{section}{References}
\loadgeometry{basegeo}
\printbibliography

\end{document}
