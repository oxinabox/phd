\documentclass[12pt,parskip]{komatufte}
\include{preamble}


\begin{document}

\loadgeometry{basegeo}
\title{Neural Representations \\of\\ Natural Language}
\author{Lyndon White\\ Roberto Togneri\\ Wei Liu\\ Mohammed Bennamoun}
\publishers{SpringerBriefs in Computer Science}


\maketitle
\tableofcontents

\loadgeometry{contentgeo}
\chapter{Introduction}\label{sec:introduction}
\begin{abstract}
	Chapter 1: Introduction: 2-3 pages
Introduce the book, and the utility of using machine learning for natural language processing
\end{abstract}
\include{chapterintroduction}

%\part{Introduction to the Fields}\label{sec:introduction-to-the-fields}
%Part A: Introductory

\include{chapterintrotomachinelearning}


\chapter{Current Challenges in Natural Language Processing}\label{sec:current-challenges-in-natural-language-processing}
\begin{abstract}
	Chapter 3: Current Challenges in Natural Language Processing (10 pages)
	Whereas chapter 2 introduces the Machine Learning domain, this chapter introduces the Natural Language Processing domain.
	This chapter will cover the current tasks that natural language processing is being deployed for
	It provide forward references to the works (in Part B) that use machine learnt representation to accomplish these tasks
	Particular tasks to be discussed include
	Language Modelling
	Sentiment Analysis
	Image Captioning
	Image generation
	Machine Translation
	Paraphrase and plagiarism detection
	Limited discussion will be presented here on prior, non-machine learning techniques.
\end{abstract}

%\part{Representations}\label{sec:representations}
%Part B: Representations

\include{chapterwordrepr}



\chapter{Word Sense Representations}\label{sec:word-sense-representations}
\begin{abstract}
Chapter 5: Word Sense Representations (5-10 pages)
In this chapter, technologies for representing the multiple meanings of a single word can have will be discussed.
This is a growing area, and is particularly important in languages (including English, but other languages even more so), where polysemous and homonymous words are common.
It leads naturally to the next section on phrase representation. Rather than a single word having many meanings, the next chapter will discuss how a single meaning may take multiple words to express.
\end{abstract}

\include{chapterwordsense}

\chapter{Phrase Representations}\label{sec:phrase-representations}
\begin{abstract}
Chapter 7: Phrase Representations (5-10 pages)
This will cover phrases, 
Phrases range from:
multi-token words: for example: et al, word sense;
to collocations: young adult, 5 year old
to longer sentence clauses: the fast train, once upon a time
\end{abstract}

\chapter{Sentence Representations and Beyond}\label{sec:sentence-representations-and-beyond}
\begin{abstract}
Chapter 8: Sentence representations and beyond (5-10 pages)
This chapter takes the previous discussion of phrases to the next level: sentences.
This will include discussions of works on recursive structure
As well work leveraging recurrent neural networks.
Methods that do not strongly consider order (including Sum of Word Embeddings; paragraph vectors) will also be discussed here.
Many of these techniques extent to arbitrary length sequences of words.
\end{abstract}

\chapter{Character-Based Representations}\label{sec:character-based-representations}
\begin{abstract}
	Chapter 9: Character-Based Representations (5 pages)
This short chapter will discuss some of the recent works which directly modelling only the characters (letter), but using this to accomplish tasks from much larger structures.
Starting from Zhang and LeCunâ€™s Text Understanding from Scratch (2015), and concluding with the very most recent works.
It will draw the book to a close by retouching on many of the tasks more commonly associated with prior sections and will discuss how they are attempted from a fully uninformed system that is learning only from letters.
This is a challenging area with fewer works to be discussed.
\end{abstract}

%\part{Conclusion}\label{part:conclusion}
%Part C: Conclusion
\chapter{Conclusion}\label{sec:conclusion}
\begin{abstract}
Chapter 8: Conclusion (10 pages)
This will conclude the book. 
It will summarise the prior charters
Discuss the progression of the field.
It will discuss the role machine learnt representations have within larger systems.
It will conclude with an outlook on the future.
\end{abstract}


\clearpage
\addcontentsline{toc}{section}{References}
\loadgeometry{basegeo}
\printbibliography

\end{document}
