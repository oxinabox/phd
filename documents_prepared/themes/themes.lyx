#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass scrartcl
\use_default_options true
\begin_modules
theorems-ams
eqs-within-sections
figs-within-sections
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
PhD Themes in Neural NLP
\end_layout

\begin_layout Standard
These three themes are broadened and generalized from discussed topics.
\end_layout

\begin_layout Section
Reversible Phrase and Document Embeddings
\end_layout

\begin_layout Standard
featuring: Re-Synthesis of Text from Vector Representations
\end_layout

\begin_layout Standard
See also: Natural Language Generation (the opposite of natural language
 understanding.)
\end_layout

\begin_layout Subsection
Applications / Possible Tasks/Projects within
\end_layout

\begin_layout Itemize
Summarization of a paragraph into a sentence
\end_layout

\begin_deeper
\begin_layout Itemize
Abstraction summarization
\end_layout

\end_deeper
\begin_layout Itemize
Production of a Short Title, via trade-off function between length and capture
 of meaning
\end_layout

\begin_deeper
\begin_layout Itemize
Again Abstractive summarization
\end_layout

\end_deeper
\begin_layout Itemize
Translation
\end_layout

\begin_deeper
\begin_layout Itemize
Using two stocatically reversible mappings from different language spaces
 into the same Meaning space
\end_layout

\end_deeper
\begin_layout Itemize
Robustness/Flow/Re-Synthesis cross over: Finding corrupted sentences/paragraphs
 and inserting correct word/sentence.
\end_layout

\begin_layout Itemize
The creation of a generative, rather than a discriminative model for phrase
 embeddings.
\end_layout

\begin_layout Subsection
Existing Work
\end_layout

\begin_layout Subsubsection
Single Word Embedding
\end_layout

\begin_layout Standard
The alot of work on Word Embeddings note the existence of linear substructures
 in single-word embeddings for example: 
\begin_inset Formula $v("king")-v("man")+v("woman")$
\end_inset

 has nearest neighbor 
\begin_inset Formula $v("queen")$
\end_inset

.
 The paper which first established this seems to be 
\begin_inset CommandInset citation
LatexCommand cite
key "mikolov2013linguisticsubstructures"

\end_inset

.
 Single word generation is fairly simple via nearest neighbor for word embedding.
\end_layout

\begin_layout Standard
Word Embedding spaces seem to combine syntax and semantics, when combining
 the words from a sentence it would be better to end up in a syntax free
 space.
 
\end_layout

\begin_layout Subsubsection
Summarization
\end_layout

\begin_layout Standard
Notably this would be Abstractive Summarization, of building a model then
 generating text from it.
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand cite
key "Kagebaeck2014"

\end_inset

(on Extractive Multidocument Summarization) using word and phrase embedding
 stated that the authors were not aware of any other papers which used continuou
s vector space models for summarization tasks.
 Which is indicative that this area is not well explored, as summarization
 is a very natural use to put any Re-Synthesis system to.
\end_layout

\begin_layout Subsubsection
Knowledge base systems
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand cite
key "MemoryNN"

\end_inset

 is quiet a compicated system for performing full natural language queries
 with natural language output, and with memorisation.
\end_layout

\begin_layout Standard
It has several componants, notable for this section is the R (Response).
 In most of there examples the response is set up to just returns a single
 word response, but some example are shown where they used a RNN.
 Details are not given, but I believe they used a RNN language model similar
 to 
\begin_inset CommandInset citation
LatexCommand cite
key "mikolov2011RnnLM"

\end_inset

 (which they reference).
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand cite
key "mikolov2011RnnLM"

\end_inset

 does not make use of word embeedings, and is very similar to n-gram based
 model.
\end_layout

\begin_layout Standard
There is also 
\begin_inset CommandInset citation
LatexCommand cite
key "Socher2013TensorReasoning"

\end_inset

, which models word relationships with tensors, in a way a much more advanced
 version of 
\begin_inset CommandInset citation
LatexCommand cite
key "mikolov2013linguisticsubstructures"

\end_inset

, though I have not seen comparasons (They were both presented at the same
 conference I believe).
\end_layout

\begin_layout Section
Extended Meaning Flow/ Discourse Analysis 
\end_layout

\begin_layout Standard
Combining the meaning of multiple sentences, for greater understanding
\end_layout

\begin_layout Subsection
Applications / Possible Tasks/Projects within
\end_layout

\begin_layout Itemize
Source Separation of Transcribed Arguments.
\end_layout

\begin_deeper
\begin_layout Itemize
Could use the Hansard (Parliament Transcriptions).
\end_layout

\end_deeper
\begin_layout Itemize
When an Input to a system can not be reliably resolved (and such a state
 can be detected.), then a system could respond with 
\begin_inset Quotes eld
\end_inset

Could you repeat that in a different way?
\begin_inset Quotes erd
\end_inset

, and then combine the meaning of the multiple inputs to get more confidence.
\end_layout

\begin_layout Itemize
Document Issue detection.
 Eg
\end_layout

\begin_deeper
\begin_layout Itemize
Picking out where paragraphs suddenly change in meaning.
\end_layout

\begin_layout Itemize
Find contradictions
\end_layout

\begin_layout Itemize
Changes in tone/POV/tense
\end_layout

\begin_layout Itemize
Detection of Author change
\end_layout

\end_deeper
\begin_layout Itemize
Summarization (again), 
\end_layout

\begin_deeper
\begin_layout Itemize
via picking out key sentences based on having more semantic similarity to
 the whole document.
 ie Extractive Summarization
\end_layout

\begin_layout Itemize
One particular use of this is extracting summarize from multiple difference
 view points.
\begin_inset CommandInset citation
LatexCommand cite
key "CulturomicOpenProblems"

\end_inset


\end_layout

\end_deeper
\begin_layout Subsection
Existing Work
\end_layout

\begin_layout Standard
In 
\begin_inset CommandInset citation
LatexCommand cite
key "mikolov2012contextRNNLM"

\end_inset

, a RNN Language model is enhanced by using LDA.
\end_layout

\begin_layout Standard
The LDA is uses to calculate the topic of the document seen so far, and
 is presented as an additional input to the RNN Language model.
\end_layout

\begin_layout Standard
In 
\begin_inset CommandInset citation
LatexCommand cite
key "2008findingContradictions"

\end_inset

, text is analised using a dependancy graph based approch, to find contractictio
ns.
\end_layout

\begin_layout Section
Robustness in Understanding
\end_layout

\begin_layout Standard
Handling the problem of incorrect transcription.
\end_layout

\begin_layout Subsection
Existing Work
\end_layout

\begin_layout Subsection
Applications / Possible Tasks/Projects within
\end_layout

\begin_layout Itemize
Enhance Speech Recognition with Meaning Component.
\end_layout

\begin_deeper
\begin_layout Itemize
Modern speech recognition systems (eg Kaldi), combine components that ensure
 that phones combine to make dictionary words, and words combine to grammatical
 sentences.
 Both these are syntactical concerns.
 Added language understanding, would check the semantic concerns.
 Sentences which don't make sense (eg 
\begin_inset Quotes eld
\end_inset

The whale ran down the street
\begin_inset Quotes erd
\end_inset

) could be weighted less likely than others that do (eg 
\begin_inset Quotes eld
\end_inset

The whale ran down the fleet
\begin_inset Quotes erd
\end_inset

).
 Similarly on a paragraph level, sentences which contradict could be weighted
 lower.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "../../Resources/master_bibliography/master"
options "IEEEtran"

\end_inset


\end_layout

\end_body
\end_document
