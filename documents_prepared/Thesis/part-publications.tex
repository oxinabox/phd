\documentclass{book}
\input{preamble}


\begin{document}


\part{Publications}
%
%\chapter{Overview: Contrasting Classical and Neural Representations}
%In the works in this section I contrast classical representation approaches with more modern neural network-based representational approaches.
%
%\Cref{SentVecMeaning} presents an abstract comparison of multiple neural network sentence representations compared to the classical bag of words.
%The core idea of the comparison in \Cref{SentVecMeaning} is to see how easy it is to partition the vector representation space according to the partitioning of natural language space of meaning.
%The natural language space is partitioned by meaning: an equivalent relation of paraphrases is defined, which gives rise to that partitioning.
%The task assesses that by assessing if subsets of the data when represented using a system can be used to train a linear SVM to determine the class (partition) of the held-out phrases.
%Using the conclusion that a good vector representation of sentences results sentences from different paraphrase groups being:
%linearly separable
%
%
%
%The systems evaluated included PV-DM and PV-DBOW.
%The work was done before these systems were discredited, 
%as discussed in \Cref{LR:SenseRep}.
%The results presented in this work supported the findings of the limited value of those systems.




\setchapter{How Well Sentence Embeddings Capture Meaning}
\begin{preamble}
	This paper was presented at the 20th Australasian Document Computing Symposium, in 2015.
\end{preamble}
\input{pubSemSynEvalPaper.tex}


\setchapter{Learning Distributions of Meant Color}
\begin{preamble}
	This paper is currently under review for Computational Linguistics.
\end{preamble}
\includepublication{ColorEst}


\setchapter{Finding Word Sense Embeddings of Known Meanings}
\begin{preamble}
	This paper was presented at the 19th Conference on Intelligent Text Processing and Computational Linguistics, in 2018.
\end{preamble}
\includepublication{RefittingSenses}

\setchapter{Novel Perspective}
\begin{preamble}
	This paper was presented at 56th Annual Meeting of the Association for Computational Linguistics (ACL) in 2018, in the System Demonstrations track.
\end{preamble}
\includepublication{NovelPerspective}
\includepublication{NovelPerspectiveSupp}


\setchapter{Generating BOW from SOWE}
\begin{preamble}
	This paper was presented at the 17th Conference on Intelligent Text Processing and Computational Linguistics, in 2016.
	Where it received the award for best student publication.
\end{preamble}
\includepublication{BOWgen}%{Generating BOW from SOWE}
\includepublication{BOWgenSupp}%{Generating BOW from SOWE: Supplementary Materials}

\setchapter{Generating Sentences from SOWE}
\begin{preamble}
	This paper was presented at the High Dimensional Data Mining Workshop at the IEEE International Conference on Data Mining, in 2016.
\end{preamble}

\includepublication{SOWE2Sent}
\includepublication{SOWE2SentSupp}




\end{document}