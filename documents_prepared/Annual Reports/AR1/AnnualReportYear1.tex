%% LyX 2.1.3 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[english]{article}
\usepackage{standalone}
\usepackage{times}
\usepackage[utf8]{luainputenc}
\usepackage{microtype}
\usepackage{geometry}
\geometry{verbose,tmargin=2.5cm,bmargin=2cm,lmargin=1.5cm,rmargin=1.5cm}
\usepackage[english]{babel}
\usepackage{verbatim}

\usepackage{tikz}
\usetikzlibrary{positioning, fit,arrows,shapes.geometric}
\usetikzlibrary{backgrounds}
\usetikzlibrary{shadows}
\usepgflibrary{shadings}

\usepackage{xcolor}
\usepackage{pgfgantt}


\usepackage[backend=bibtex,
style=verbose,
bibencoding=ascii,
maxcitenames=99,
url=true,
hyperref=true
]{biblatex}
\bibliography{master}
\DeclareFieldFormat{abstract}{\par Abstract: \emph{#1}}
\renewbibmacro*{finentry}{\printfield{abstract}\finentry}

\usepackage{cleveref}

\begin{document}

\title{Annual Report 2015-2016}
\author{Lyndon White}

\maketitle

\section{Summary of Research Progress to Date}

Work has proceeded, without significant deviation from the Project Proposal. All this work has yielded publication, or is pending publication; so in the following sections, I will allow the publications abstracts to describe the work.


\subsection{Semantic Evaluation}
\begin{comment}

An investigation into the semantic constancy was carried out. 
The goal was to find out which methods for sentence embeddings were good
The definition of \emph{good }was made concrete as a specification on the relationship between 
the partitioning of sentence space by meaning,
and the corresponding areas of the vector sentence embedding space.
A good sentence embedding method would exhibit the following factors: All sentences with same meaning go to small area in vector space; The areas should not overlap, and should be separate; the areas should have no twists, bulges, holes, jumps etc.      			
It was noted that these are also the conditions for a classifier to work well.
So a classification task can was used to assess the quality of an embedding method.

For this classification to be done, required the sentences to be grouped into semantically equivalent classes.
This uses the formal definition of semantic equivalence. A pair of sentences are considered semantically equivalent of they exhibit bidirectional entailment.
That is to say, if one being true implies the other is true, and that the reverse also holds. By taking the transitive and symmetric closure of this equivalence relation,
the a set of equivelence classes can be found.\\
This was done to the Microsoft research paraphrase corpus, which contains pairs of paraphrases. 
Some sentences occurred in multiple paraphrase pairs.
Thus the closure yields paraphrase groups of suitable size for evaluation.

However there were very few large paraphrase groups. So for additional verification, a new corpus was constructed.
This was based on the Opinosis corpus of highly redundant product reviews. This required manual grouping.
The new corpus yielded much larger groups, and was more challenging as a evaluation task than the existing corpus.
Both corpora were made available online at: \url{http://white.ucc.asn.au/resources/paraphrase_grouped_corpora/}.

The surprising result was that the simple methods including bag of words, and the mean and sum of word embeddings performing significantly better than the more complex models. This added relevance to the next area of work.

\end{comment}

\subsubsection*{Publications Arising}
This work was accepted into the 20th Australasian Document Computing Symposium (ADCS). Where it was presented as an oral, and as a poster to the combined session with  Australian Linguistic Society (ALS), the Australasian Language Technology Association (ALTA), and the Australian Music Psychology Society (AMPS Inc.).
\vspace{1cm}

\fullcite{White2015SentVecMeaning}


\subsection{Sentence Generation from Sum of Word Embeddings}
\begin{figure}[h!]
	\begin{center}
		\input{block_diagram.tex}	
	\end{center}
	\caption{\label{fig:block} The two step process for generating sentences.}
\end{figure}



\subsubsection*{Publications Arising}
This work was broken into two prepared publications, according to the two steps incolved in the process as shown in \Cref{fig:block}
This covers the first half of going from Sum of word embedding, to a bag of words as a conference paper.


\fullcite{White2015BOWgen}
\vspace{1cm}

The second publication, is currently in late stages editing, and is being prepared as a journal article. This covers the whole work, end to end on generating sentences from sums of word embeddings. This includes utilising the bag of words generation step, and adding the word ordering step.

\fullcite{SOWEgen}
\vspace{1cm}

This work was also presented orally to an informal half-day ``Workshop on Deep Learning for Natural Language Processing'', internally within UWA.


\subsection{Problems (including any change in focus)}
There have not been significant problems this year, and there has been no change in focus.
A minor problem was the lack of LDC resources.
LDC includes many of the standard corpora used for NLP. Access to LDC is on subscription, per calendar year and is several thousand dollars.
During that access period, the corpora can be obtained permanently without additional charge.
We chose to delay acquiring a subscription until the new year, that we might take a full year to select and acquire the most useful resources.
I believe this was the correct choice (and indeed it was at my suggestion). However ideally we would always have had an LDC subscription.
More recently other large resources have become publicly available, which allowed the previous work. 
However, the data from LDC would have made it easier to perform additional validation and benchmarking.
We now have access to LDC.

Early in the candidature, there was a problem with a lack of computational resources.
Solving this was one of the confirmation of candidature tasks.
We now have access to NeCTAR virtual machines.
This is no longer an issue.


\newpage

\section{Completion Plan}
The Gantt Chart showing in \Cref{gantt} is largely unchanged from the that in the project proposal. It shows the tasks remaining to be completed; and the tasks completed. 


\subsection{Tasks Completed (2015-2016)}
As the thesis is by publication, the key progress indicator towards textual completion, in the publications. As mentioned above 1 publication has been completed, 1 accepted, and a third is in the final stages of editing. The numerals in the following section align with the Gannt Chart in  \Cref{gantt}. These publications will form key chapters in the thesis.

\subsubsection*{Semantic Evaluation}
\begin{description}
	\item[1:] \cite{White2015SentVecMeaning} (\textbf{Published}: \citefield{White2015SentVecMeaning}{booktitle}, \citeurl{White2015SentVecMeaning})
\end{description}
\subsubsection*{Sum of Word Embeddings}
\begin{description}
	\item[2:] \cite{White2015BOWgen} (\textbf{Accepted}: 06--Mar--2016 \citefield{White2015BOWgen}{booktitle})
	\item[3:] \cite{SOWEgen} (\textbf{In preparation})
\end{description}


\subsection{Tasks Remaining (2016-2017)}
One change is the removal of the "semisupervised semantics constraints" research task, to  be replaced with a "characteristic vector autoregression" task. This new task has additional clarity on the method being used. As part of the investigations with this method, semi-supervised semantic constraints may be included. Similarly Tree search has been replaced with Structure search -- this is merely a clarification that there may be non-tree structures that form the best representation of sentences.
\subsubsection*{Characteristic Vector Autoregression (Apr 2016--Sep 2016)}
An vector autoregressive (VAR) model is potentially able to model sentence dynamics, as a time series.
Rather than trying to fit a model that described all sentences, one VAR will be trained per sentence.
The VAR parameters (matrices) are then themselves used as a vector space representation -- the characteristic VAR for the sentence.
Potential issues include the question of if sentences have a linear structure, and if they have enough words to be modelled this way.
Solutions such as more advanced VAR (non-linear VAR, structured VAR) may required. Potentially unfixing the word vectors may also useful.
This has some potential, not just as a representation method but as a generative method.
These issues, solutions and uses will be progressively investigated.

\subsubsection*{Structure Search (Oct 2016--Mar 2017)}
A sentence is words arranged into structure. 
Only certain structures are grammatically permitted.
Only certain words can go into each structural slot.
A generative sentence model could be created,
by heuristically ordering the possible structures,
then by assessing the structures by how well words filling that structural slot can be found.
This method would be applied on top of another technique.
Such as that produced by the characteristic vector autoregression.

\begin{figure}[h!]
	\centering
	\resizebox{0.9\textwidth}{!}{\centering
		\input{gantt.tex}
	}
	\caption{\label{gantt} an Updated Gnatt Chart}
\end{figure}




\end{document}
