\RequirePackage{luatex85,shellesc}
\documentclass[dvipsnames]{beamer}
\usepackage[author={Lyndon White}]{pdfcomment}

\usepackage{fancyvrb}

\usepackage{microtype}
\usepackage{adjustbox}
\usepackage{amsmath}

\usepackage[subpreambles=false]{standalone}


\usepackage[at]{easylist}

%\newlength\xunit
\input{brownbeamer}
\setbeamercolor{math text}{fg=bluewrite}
\setbeamercolor{math text displayed}{fg=bluewrite}


\bibliography{master.bib}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{tikz}
\usetikzlibrary{positioning}
\usetikzlibrary{chains}
\usetikzlibrary{decorations.pathmorphing}
\usetikzlibrary{graphs,graphs.standard,graphdrawing,arrows}
\usegdlibrary{layered, trees, force}

\usepackage{graphicx}
\graphicspath{{./figs/}, {./}}
\usepackage[space]{grffile}

\usepackage{trimclip}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% TIKZ stuff

\tikzset{%
	->,
	align=center,
	node distance=30mm, sibling distance=25mm, level distance=40mm,
	every edge/.append style = {thick},
	package/.style={draw, circle, very thick},
	mypackage/.style={package, blue},
	repo/.style={draw, very thick, purple},
	info/.style={Green},
	supports/.style={dotted, very thick},
	indirect/.style={decoration={snake}, decorate, very thick, purple}
}

\newcommand{\pkg}[2][]{\tikzset{#2/.append style={}}; \node[#1,package, #2](#2) {#2.jl}}
\newcommand{\repo}[2][]{\node[#1,repo](#2) {#2}}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\inlinecode}[1]{\mbox{\color{Purple}{\texttt{\detokenize{#1}}}}}
%\newenvironment{code}
%{%BEGIN
%\endgraf\verbatim
%}
%{ % END
%\endverbatim
%}
\DefineVerbatimEnvironment{code}{Verbatim}{obeytabs,tabsize=4,gobble=2}


\newcommand{\datadep}[1]{\inlinecode{datadep"#1"}}

% all notes should just be simple item notes.
% I neither need nor want more functionality
\let\oldnote\note
\renewcommand{\note}{\oldnote[item]}

\renewcommand{\emph}{\alert}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Repeat a slide with a node highlighted
\newcommand{\focusslide}[2]{
	{
	\tikzset{#2/.append style={text=white, font=\bfseries,  fill=bluewrite}}
	\againframe{#1}
	}
}

%%%%%%%%%%%%%%%%%%%%%


\institute{School of Electical, Electronic and Computer Engineering\\The University of Western Australia}
\date{}
\title{DataDeps.jl}
\subtitle{and other foundational tools for data driven research\\(Especially NLP)}
\author{\includegraphics[height=2cm]{juliaml}
	\includegraphics[height=2cm]{juliatext}
	\includegraphics[height=2cm]{juliastring}
	\\
	\vspace{5mm}
	\textbf{Lyndon White}}

\logo{\hfill\includegraphics[scale=0.12]{uwa}\hfill\hspace{0.5cm}}

\begin{document}

%\centering %Center everywhere
\frame{\maketitle}


\begin{frame}{Thanks}
	\begin{description}
		\item[Christof Stocker (@evizero):] Prompted this whole thing with a \emph{discussion} a few years ago; and supported it with \emph{code reviews} and \emph{numerous further discussions}.
		\note{The core of DataDeps.jl really is a generalization of some of the code from MLDatasets.jl}
		\item[Sebastin Santy:] who has spent most of his \emph{GSOC} connecting \emph{repository} APIs to \emph{DataDepsGenerators.jl}.
		\item[Australian Research Council Grants:] DP150102405~and~LP110100050.
	\end{description}
	
\end{frame}
\logo{}

\begin{frame}[label=bigpicture]{Big Picture}
	\centering
	%	〈	llx	〉 〈	lly	〉 〈	urx	〉 〈	ury	〉
	%\resizebox{\textwidth}{!}{\clipbox{190pt 170pt 250pt 0pt}{\input{coreidea.tex}}}
	
	\resizebox{\textwidth}{!}{\begin{tikzpicture}[layered layout, grow'=up,]
	\node[nudge=(left:12mm)](researchcode){Research Code};
	
	\pkg[mypackage, nudge=(right:17mm)]{CorpusLoaders};
	
	\pkg[mypackage]{DataDeps};
	\pkg[mypackage]{DataDepsGenerators};
	%	\pkg[mypackage]{ReferenceTests};
	\pkg[mypackage]{MD5};
	\pkg[]{SHA};
	
	\node(MultiResolutionIterators)[mypackage]{Multi--\\Resolution--\\Iterators.jl};
	
	\pkg[mypackage]{InternedStrings};
	\pkg[]{Strs};
	\pkg[]{CSV};
	
	
	\pkg{MLDatasets};
	%	\pkg[mypackage]{ExpectationStubs};
	\pkg{HTTP};
	\pkg[nudge=(right:15mm)]{WordNet};
	\pkg[mypackage, nudge=(right:4mm)]{Embeddings};
	
	
	\pkg[mypackage]{WordTokenizers};
	\pkg{RevTok};
	
	
	\repo{CRAN};
	\repo{DataDryad};
	\repo{GitHub};
	\repo{European Data Portal};
	\repo[]{Open.Canada.ca};
	\repo{Data.gov};
	\repo{Data.gov.au};
	\repo{DataOne};
	\repo{538};
	\repo{BuzzFeedNews};
	\repo{UCI ML Repository};
	\repo{ArcticDataCenter};
	\repo{KnowledgeNetworkforBiocomplexity};
	\repo{TERN};
	\repo{DataCite};
	\repo{Zenodo};
	\repo{FigShare};
	
	
	\node[sibling distance=0mm](gap){};
	
	\graph{
		(researchcode) <- {(MLDatasets), (Embeddings), (WordNet), (CorpusLoaders)} <- (DataDeps);
		(DataDeps) ->[bend left, looseness=0, in=167, out=0] (researchcode);
		
		
		{(CorpusLoaders) <- {(MultiResolutionIterators), (WordTokenizers), (InternedStrings)}};
		(DataDeps) <- {(HTTP), (SHA)};
		(DataDeps) <-[supports] (MD5);
		
		(DataDeps) <-[indirect] (DataDepsGenerators) <- {
			(GitHub) <- {(538), (BuzzFeedNews)},
			(UCI ML Repository),
			(CRAN) <- {(Open.Canada.ca), (Data.gov.au), (Data.gov), (European Data Portal)},
			(DataCite) <- {(Zenodo), (FigShare)},
			(DataDryad),
			(DataOne) <- {(ArcticDataCenter), (TERN), (KnowledgeNetworkforBiocomplexity)},
		};
		
		(WordTokenizers) <-[supports] (RevTok);
		(InternedStrings) <-> [supports] (Strs);
		(InternedStrings) ->[supports] (CSV);
	};
	\end{tikzpicture}}
\end{frame}




\begin{frame}[label=packages]{Julia Packages}
	\centering
	%	〈	llx	〉 〈	lly	〉 〈	urx	〉 〈	ury	〉
	%\resizebox{\textwidth}{!}{\clipbox{190pt 170pt 250pt 0pt}{\input{coreidea.tex}}}
	
	\resizebox{0.9\textwidth}{!}{\begin{tikzpicture}[layered layout,	grow'=up,]
		\node[nudge=(left:12mm)](researchcode){Research Code};
		
		\pkg[mypackage, nudge=(right:17mm)]{CorpusLoaders};
		
		\pkg[mypackage]{DataDeps};
		\pkg[mypackage]{DataDepsGenerators};
		%	\pkg[mypackage]{ReferenceTests};
		\pkg[mypackage]{MD5};
		\pkg[]{SHA};
		
		\node(MultiResolutionIterators)[mypackage]{Multi--\\Resolution--\\Iterators.jl};
		
		\pkg[mypackage]{InternedStrings};
		\pkg[]{Strs};
		\pkg[]{CSV};
		
		
		\pkg{MLDatasets};
		%	\pkg[mypackage]{ExpectationStubs};
		\pkg{HTTP};
		\pkg[nudge=(right:15mm)]{WordNet};
		\pkg[mypackage, nudge=(right:4mm)]{Embeddings};
		
		
		\pkg[mypackage]{WordTokenizers};
		\pkg{RevTok};
		
		\node[sibling distance=0mm](gap){};
		
		\graph{
			(researchcode) <- {(MLDatasets), (Embeddings), (WordNet), (CorpusLoaders)} <- (DataDeps);
			(DataDeps) ->[bend left, looseness=0, in=167, out=0] (researchcode);
			
			
			{(CorpusLoaders) <- {(MultiResolutionIterators), (WordTokenizers), (InternedStrings)}};
			(DataDeps) <- {(HTTP), (SHA)};
			(DataDeps) <-[supports] (MD5);
			
			(DataDeps) <-[indirect] (DataDepsGenerators);
			
			(WordTokenizers) <-[supports] (RevTok);
			(InternedStrings) <-> [supports] (Strs);
			(InternedStrings) ->[supports] (CSV);
			
		};
		\end{tikzpicture}}
\end{frame}

\begin{frame}[label=datadeps]{DataDeps.jl}
	\centering
		%	〈	llx	〉 〈	lly	〉 〈	urx	〉 〈	ury	〉
%	\resizebox{\textwidth}{!}{\clipbox{190pt 320pt 400pt 0pt}{\input{coreidea.tex}}}
	
\resizebox{\textwidth}{!}{\begin{tikzpicture}[layered layout, grow'=up,]
	\node[](researchcode){Research Code};
	
	
	
	\pkg[mypackage]{DataDeps};
	\pkg[mypackage]{DataDepsGenerators};
	\pkg[mypackage]{MD5};
	\pkg[]{SHA};
	\pkg{HTTP};
		

	\pkg[nudge=(right:40mm)]{WordNet};
	\pkg[mypackage, nudge=(right:50mm)]{CorpusLoaders};
	\pkg[mypackage, nudge=(left:0mm)]{Embeddings};
	\pkg[nudge=(left:10mm)]{MLDatasets};

	
	\graph{
		(researchcode) <- {(MLDatasets), (Embeddings), (WordNet), (CorpusLoaders)} <- (DataDeps);
		(DataDeps) ->[bend left, looseness=0, in=167, out=0] (researchcode);
		
		(DataDeps) <- {(HTTP), (SHA)};
		(DataDeps) <-[supports] (MD5);
		
		(DataDeps) <-[indirect] (DataDepsGenerators);	
	};
	\end{tikzpicture}}
\end{frame}

\begin{frame}[label=datadepsgenerators]{DataDepsGenerators.jl}
	\centering
		%	〈	llx	〉 〈	lly	〉 〈	urx	〉 〈	ury	〉
%	\resizebox{\textwidth}{!}{\clipbox{0pt 0pt 0pt 290pt}{\input{coreidea.tex}}}
\newcommand{\content}{
	\node[layer sep = 5mm](researchcode){Research Code};
	
	\pkg[mypackage, layer sep = 5mm]{DataDeps};
	\pkg[mypackage, layer sep = 25mm]{DataDepsGenerators};
	
	\repo{CRAN};
	\repo{DataDryad};
	\repo{GitHub};
	\repo{European Data Portal};
	\repo[]{Open.Canada.ca};
	\repo{Data.gov};
	\repo{Data.gov.au};
	\repo{DataOne};
	\repo{538};
	\repo{BuzzFeedNews};
	\repo{UCI ML Repository};
	\repo{ArcticDataCenter};
	\repo{KnowledgeNetworkforBiocomplexity};
	\repo{TERN};
	\repo{DataCite};
	\repo{Zenodo};
	\repo{FigShare};
	
	
	\graph{
		(researchcode) <- (DataDeps);
		
		(DataDeps) <-[indirect] (DataDepsGenerators) <- {
			(GitHub) <- {(538), (BuzzFeedNews)},
			(UCI ML Repository),
			(CRAN) <- {(Open.Canada.ca), (Data.gov.au), (Data.gov), (European Data Portal)},
			(DataCite) <- {(Zenodo), (FigShare)},
			(DataDryad),
			(DataOne) <- {(ArcticDataCenter), (TERN), (KnowledgeNetworkforBiocomplexity)},
		};
	};
}

\resizebox{\textwidth}{!}{
	\only<1>{
		\begin{tikzpicture}[layered layout, grow'=up,]
			\content{}
		\end{tikzpicture}
	}
	\only<2>{
		\begin{tikzpicture}[%
			layered layout, grow=left, sibling distance=15mm]
			\content{}
		\end{tikzpicture}
	}
}
\end{frame}

\begin{frame}[label=corpusloaders]{CorpusLoaders.jl}
		%	〈	llx	〉 〈	lly	〉 〈	urx	〉 〈	ury	〉
%	\resizebox{\textwidth}{!}{\clipbox{370pt 310pt 250pt 70pt}{\input{coreidea.tex}}}
\centering
\resizebox{0.7\textwidth}{!}{\begin{tikzpicture}[layered layout,	grow'=up,]
		\node[](researchcode){Research Code};
		
		\pkg[mypackage]{CorpusLoaders};
		
		\pkg[mypackage]{DataDeps};
		
		\tikzset{MultiResolutionIterators/.append style={}};% for focusslide
		\node(MultiResolutionIterators)[mypackage,MultiResolutionIterators]{Multi--\\Resolution--\\Iterators.jl};
		
		\pkg[mypackage]{InternedStrings};
		\pkg[]{Strs};
		\pkg[]{CSV};
		
		
		\pkg[mypackage]{WordTokenizers};
		\pkg{RevTok};
		
		
		\graph{
			(researchcode) <- {(CorpusLoaders)};
			{(CorpusLoaders) <- {(DataDeps), (MultiResolutionIterators), (WordTokenizers), (InternedStrings)}};
			(WordTokenizers) <-[supports] (RevTok);
			(InternedStrings) <-> [supports] (Strs);
			(InternedStrings) ->[supports] (CSV);
		};
		\end{tikzpicture}}
\end{frame}

\begin{frame}{Australia, it is quiet far away}
	\note{Perth is exactly 12 hours out of sync with Boston.}
	\includegraphics[height=0.8\pageheight]{map}
\end{frame}

\begin{frame}[fragile]{Code depends on data\\ Especially research code}
	\begin{easylist}[itemize]
		@ To manage your julia dependencies you use 
		@@ \alert{Pkg}
		@ To manage your binary dependencies you use 
		@@ \alert{BinDeps}, 
		@@ \alert{Conda} etc
		@@ or preferably \alert{BinaryProvider}
	\end{easylist}
\end{frame}


\begin{frame}[fragile]{How are you managing your data dependencies?}
	\vfill
	\begin{easylist}[itemize]
		@ Instructions in the \alert{README.md} \note{I.e. I am not}
		@@ So how does your CI work out? 
		\pause
		@ Sticking a \inlinecode{download} command, in \inlinecode{build.jl} \note{or elsewhere in code}
		@@ So it gets downloaded even if not used? \note{This is particularly problematic for packages that provide access to multiple datasets.}
		\pause
		@ Just putting it in the \alert{git repo}
		@@ I am glad it isn't too large for git.
		\pause
	\end{easylist}
	\vfill
	\centering
	{\Large \alert{These are all options.\\ But can we do better?}}
	\vfill\vfill
\end{frame}

\begin{frame}[fragile]{DataDeps doesn't protect you from \\link breakages.\\ But at least you know when it is broken}
	\begin{easylist}[itemize]
		@ Nothing can truly protect against link-rot
		@@ Not even \emph{DOIs}
		@@ The data must physically exist somewhere on a hard-disk. And someone must be \emph{maintaining}that
		\pause
		@ If you are downloading your data automatically you can check it is still there via \emph{automated testing}
		@@ \emph{TravisCI} and \emph{AppVeyor} offer scheduled testing options.
		\note{Some people say you shouldn't test on your real data, but I say if you can do it without running out of time or disk space, do it. It is easiest.}
		\note{Any tests are better than no tests.}
	\end{easylist}
\end{frame}

\focusslide{datadeps}{DataDeps}

\newcommand{\questionanswer}{\only<1>{Questions}\only<2>{\textbf{Answers}}}
\begin{frame}[fragile]{3 Key \questionanswer{} about Data: \\\#1 Storage Location}
	\begin{easylist}[itemize]
		@ Where do I put it? Should it be on the local disk (small) or the network file-store (slow)? \label{itm:where}
		\only<2>{@@ \color{bluewrite} Anywhere on the DataDeps Load Path will work}
		@ If I move it, am I going to have to reconfigure things?
		\only<2>{@@ \color{bluewrite} Not if you are using a datadep path}
		@ What if I put it all in the git repo?
		\only<2>{@@ \color{bluewrite} git does not like large binary files.\\ 50KB \inlinecode{.csv} is ok; 50MB \inlinecode{.jld} is not.}
	\end{easylist}
\end{frame}

\begin{frame}[fragile]{3 Key \questionanswer{} about Data: \\\#2 Redistribution}

	\begin{easylist}[itemize]
		 @ I don't own this data
		 \only<2>{@@ \color{bluewrite} but it is publicly accessible, right?}
		 @ am I allowed to redistribute it? \label{itm:ownredistribute}
		 \only<2>{@@ \color{bluewrite} IANAL, but linking should be fine.} 
		 @ How will I give credit, and ensure the users know who the original creator was?
		 \only<2>{@@ \color{bluewrite} Tell them with a prompt when it is downloaded}
	\end{easylist}
	\vfill
\end{frame}

\begin{frame}[fragile]{3 Key \questionanswer{} about Data: \\\#3 Replication}
	\begin{easylist}[itemize]
		@ How can I be sure that someone running my code has the same data?
		\only<2>{@@ \color{bluewrite} Make automatic data fetching part of the code}
		@ What if they download the wrong data, or extract it incorrectly?
		\only<2>{@@ \color{bluewrite} They can't make mistakes if it is automated}
		@ What if it gets corrupted or has been modified and I am unaware?
		\only<2>{@@ \color{bluewrite} Filehashs, SHA256, MD5 etc.}
	\end{easylist}
\end{frame}

\begin{frame}[fragile]{DataDeps.jl is for Data with the following properties.}
	\Large
	\begin{columns}
		\begin{column}{0.5\textwidth}
			\structure{DataDeps.jl\\ Requirements\\}
			Static \hspace{1cm}{\small (preferred)}\\
			Public \hspace{1cm}{\small (preferred)}\\
			File-Based\\
			Any Format\\
			Any Size\\
		\end{column}
		\begin{column}{0.5\textwidth}
			\begin{onlyenv}<2> 
				\structure{Static\\}
				No automatic redownloading\\
				Checksum fails\\
				\vspace{1cm}
				\inlinecode{ManualDataDep}\\ or hacks\\
			\end{onlyenv}
			\begin{onlyenv}<3> 
				\structure{Public\\}
				Default \inlinecode{fetch_method} has no inbuilt knowledge of \emph{auth-systems}.\\
				It is just HTTP[/S]\\
				\vspace{1cm}
				\inlinecode{ManualDataDep}\\ or hacks\\
			\end{onlyenv}
			\begin{onlyenv}<4> 
				\structure{File Based\\}
				DataDeps.jl is for files.\\
				\emph{Any Files}\\
				\vspace{1cm}
				If your data is from an API then use it?
				\note{There is normally a good reason why data would only be available via a streaming API}
			\end{onlyenv}
			\begin{onlyenv}<5> 
				\structure{Git\\ Requirements\\}
				Dynamic\\
				Public or Private\\
				File-Based\\
				Plain Text Formats\\
				<50MB\\
			\end{onlyenv}
		\end{column}
	\end{columns}
\end{frame}


\begin{frame}[fragile]{How does DataDeps handle files of Any type ?}
	\centering
	\vfill
	{\Large Answer: It doesn't}\\
	\vfill
	\large
	It is only about getting you the files\\
	How can it know what arcane format you used?\\
	\vfill
	Interpreting that data is left to you and \alert{FileIO.jl} etc
	\note{\emph{Quilt} and \emph{frictionlessdata} work only with tables}
	\vfill
\end{frame}


\begin{frame}[fragile]{\inlinecode{ManualDataDep}, using DataDeps.jl with git and other uses}
	\begin{easylist}[itemize]
		@ A manual datadep registration consists just of a name and a message.
		@ It lets you use \datadep{Paths} for locating data without any automation
		@@ If locating the file fails, it prompts the user with the message to install it. \note{So you can include instruction on how to do it manually}
		\pause
		@ Note that for every package the directory \inlinecode{<PKG>/deps/data} is on the datadeps \alert{load path}
		@@ So for files that a good fit for \alert{git} you can include them in the Repo.
		\pause
		@ Note also this lets you work with dynamic data and private data
		@@ as the syncing mechanism is external to DataDeps.jl	
	\end{easylist}
\end{frame}

\begin{frame}[fragile]{Handling private data, with specific \inlinecode{fetch_method} method}
		\small
		\ttfamily
		\color{Aquamarine}
		using HTTP, OAUTH2\\
		const appid="ProjectXYZ:apps:datadeps:support"
		\color{Magenta}
		function authed\_download(url, local)\\
		\verb!    !authtok = getauthtok("https://evil.eg.au/auth"\\
		\verb!            !ENV["USER\_ID"], appid, !ENV["APPSECRET"])\\
 		\verb!    HTTP.download(url, local, ["Authorization"=>authtok])!\\
 		end\\
		\vspace{0.5em}
		\color{Blue}
		register(DataDep("Secret Science Data",\\
		\color{Green}
		"Evil world domination plans. Do not share."
		\color{Orange}
		\verb|[|"https://evil.eg.au/files/deathray.stl",\\
		\verb| |"https://evil.eg.au/files/EvilLeageOfEvil\_letter.md"\verb|]|\\
		\color{Red}
		"d41d8cd98f00b204e9800998ecf8427e"; \# hash\\
		\color{Purple}
		fetch\_method = authed\_download\\
		\color{Blue}
		))
	
\end{frame}


\begin{frame}{Vabdewakke's 6 Degree's of Replicability}
	\begin{enumerate}
		%\item 0: The results cannot be reproduced by an independent researcher.
		
		\item The results \alert{cannot seem to be} reproduced.
		
		\item The results could be reproduced by, \alert{requiring extreme effort.}
		
		\item The results can be reproduced, \alert{requiring considerable effort.}
		
		\item The results can be easily reproduced with \alert{at most \textbf{15 minutes} of user effort}, requiring some proprietary source packages (MATLAB, etc.).
		
		\item The results can be easily reproduced  with \alert{at most \textbf{15 min} of user effort}, requiring only standard, freely available tools (C compiler, etc.).		
	\end{enumerate}
	\note{Vabdewakke actual has a rating zero for "no, just no can not reproduce."}
	\note{What is the key determining factor here? User effort. How do we get down to 15 minutes of user effort?}
	\citehere{VabdewakkeReproduceableResearch}
\end{frame}


\begin{frame}{What happens when I try and run someone's research code?}
	\begin{tikzpicture}[start chain, node distance=5mm,
		act/.append style ={on chain, join},
		every label/.append style ={draw},
		down/.style = {node distance=10mm, on chain=going below}
	]
		\node[act, label=1min]{Find and \\ Download\\Code};
		\node[act, label=2mins]{Read\\ Enough of \\Readme};
		\node[act, bluewrite, label={[bluewrite]1mins}]{Find and\\Download\\Data};
		\node[act, bluewrite, label={[bluewrite]2mins}]{Workout\\how to\\\inlinecode{tar -xzfetc}};
		
		\begin{scope}[continue chain=going left]
		
		\node[act, bluewrite, down, label={[bluewrite]-90:2mins}]{Workout\\How to tell script\\where data is};	 
		\node[act, label={-90:2mins}]{Setup any \\ software \\ dependencies};
		\node[act, label={2mins}]{Run the code\\ Make sure not crashing};
		\node[act, down, label={-90:3mins}]{Interpret\\Output};
		
		\end{scope}
		
		
		
	\end{tikzpicture}
%	\begin{description}
%		\item[1min] Find the website from the paper, and \alert{download the code}
%		\item[2min] Read enough of the README to get rough bearings
%		\item[\textbf{1min}] Find out where to get the data from and \alert{download the data}
%		\item[\textbf{2min}] Try and remember how to use \inlinecode{tar -xzfvalphabetsoup} etc.
%		\item[\textbf{2min}] Workout how to tell script \alert{where data is} \note{Hardcoded path? Argument?}
%		\item[2min] Setup any software dependencies etc.
%		\item[3min] Run the code and make sure it isn't crashing etc.
%		\item[2min] Interpret the output
%	\end{description}
	\note{I have spent 5 of my 15 valuable minutes faffing around about sorting out the data.}
	\note{I think this timeline is fairly reasonable, of course an ideal julia project with everything already working in CI would do a lot better. But if you've got these steps, your already blocked from CI.}
\end{frame}


\begin{frame}[fragile]{You can't trust hardcoded paths; \\ but they are nice to work with.}
	
	\begin{easylist}[itemize]
		@ Ideally we'ld just use \alert{hard-coded, absolute} paths
		@ Absolute paths work with all \emph{applications}
		@ Hard-coding the paths in code means user doesn't have to input them.
		@ But they \emph{break} if anything is \emph{moved}. \note{relative paths are less so}
	\end{easylist}
\end{frame}

\begin{frame}[fragile]{You could making the path be passed in as an argument. But...}
	
	\begin{easylist}[itemize]
		@ Now user has to be typing it in to run it.
		\note{Recall the valuable time spent to workout how to tell the script where the data is?}
		@ So it is harder to use.
		@ You could include a bash-script that invokes it with the path, but now you're just \emph{hard-coding}it somewhere else
	\end{easylist}
\end{frame}


\begin{frame}[fragile]{\datadep{Census 2018/populations.csv} \\ A path you can trust}
	\begin{easylist}[itemize]
		@ Always resolves to an absolute path to that file
		\note{at runtime}
		@ Even if that means it has to download it first
		@ But before resorting to downloading checks a large number of places
		@@  \inlinecode{<PKG>/deps/data}, 
		@@ \inlinecode{~/.julia/datadeps},
		@@ \inlinecode{/usr/share/datadeps}, etc.
		\note{this is the DataDeps load path}
		\note{The places to check can be configured of course}
		@ You know that if you use a datadep path it will resolve to a file that exists.
	\end{easylist}
\end{frame}

\begin{frame}[fragile]{Automatic fetching is really convenient}
	Some things that have happened to me lately:
	\begin{easylist}[itemize]
		
		@ Supervisor tells me shared workstation hard-drive is dangerously full
		\only<1>{@@ \emph{Delete all of them}}
		\only<1>{@@ knowing that the \emph{ones I am still using} will be fetched as required.}
		\pause
		@ Want to start up copy of work on \emph{another server} to run an extra set of experiments in parallel.
		\only<2>{@@ Literally, just clone the \emph{project repo}}
		\only<2>{@@ the data will \emph{make its own way} there}
		\pause
		@ Realize that I've \emph{modified} one of the data \emph{files by mistake}
		\only<3>{@@ \inlinecode{rm(datadep"Foo", recursive=true)}}
		@@ Next time it is needed a \emph{new copy} will be downloaded.
	\end{easylist}
	
\end{frame}

\begin{frame}[fragile]{What happens when you uses a datadep?}
		\centering
		\resizebox{\textwidth}{!}{
		\begin{tikzpicture}[every text node part/.style={align=center}, auto,node distance=2, ->,
		every edge/.append style={every node/.style={font=\footnotesize}}]
		
		
		\node[blue](start) {\datadep{Name}\\ \textbf{Evaluated}}; 
		
		\node[draw, rectangle, below right= 0.5 of start] (search) {0.\\Search\\ \texttt{Load Path}};
		\node[draw, rectangle, right= of search] (msg) {1.\\Display\\ message};
		\node[draw, rectangle, below right= of msg] (fetch) {2.\\Perform\\ fetch method\\ (download)};
		\node[draw, rectangle, below right= of fetch] (checksum) {3.\\Validate\\ using\\ checksum};
		\node[draw, rectangle, below right= of checksum] (postfetch) {4.\\Perform \\post fetch method\\ e.g. unpack};
		\node[green!60!black, below=of postfetch](end) {\textbf{Local Path}\\ \textbf{Returned}};
		
		\path (start) edge (search);
		\path (search)  edge node[below]{datadep} node[sloped,above]{\textbf{Not Found}}  (msg);
		\path (msg)	edge node[below, sloped]{remote paths} node[above right]{\textbf{Accept}}  (fetch);
		\path (fetch)	edge[below, sloped] node{local paths}  (checksum);
		\path (checksum)	edge node[below, sloped]{local paths} node[above right]{\textbf{Succeeded/Ignored}} (postfetch);
		\path (postfetch)	edge (end);
		
		\path (search.south) edge node[above,right,yshift=0.6cm]{\textbf{Found}} node[below,sloped]{local path} (end.west);
		
		
		\path (checksum.north) edge[bend right] node[above right] {Failed-Retry} (fetch.east);
		
		\node[red, below = 0.5 of msg, yshift=-0.6cm] (err1) {\textbf{Abort}};
		\path (msg) edge node[left]{\textbf{Decline}} (err1);
		
		\node[red, below = 0.5 of checksum, yshift=-0.6cm] (err2) {\textbf{Abort}};
		\path (checksum) edge node[left]{\textbf{Failed}}  (err2);
		\end{tikzpicture}
	}
\end{frame}


\begin{frame}[fragile]{Current Usages of DataDeps.jl}
	\structure{MLDatasets.jl}
	\begin{easylist}[itemize]
		@ Provides easy access to a bunch of ML datasets
		@ \inlinecode{xs, ys = MNIST.traindata()}
		@ Gives you regular julia arrays
	\end{easylist}
	\vfill
	\structure{CorpusLoaders.jl}
	\begin{easylist}[itemize]
	@ Provides easy access to linguistic corpora
	@ \inlinecode{corpus_gen = load(WikiCorpus())}
	@ gives you a multi-resolution iterator
	\end{easylist}	
\end{frame}

\begin{frame}[fragile]{Current Usages of DataDeps.jl}	
	\structure{Embeddings.jl}
	\begin{easylist}[itemize]
		@ Provides access to hundreds of pretrained word~embedding models.
		@ \inlinecode{load_embeddings(FastText_Text{:fr})}
		@ gives you a table of French word embeddings.
	\end{easylist}
	
	\vfill
	\structure{WordNet.jl}
	\begin{easylist}[itemize]
		@ Look up lexical relations and definitions.
		@ \inlinecode{lemma = db['a', "glad"]}
		@ \inlinecode{antonyms(db, synsets(db, lemma)[1])}
	\end{easylist}
\end{frame}


\begin{frame}[fragile]{DataDep Registration Block}
	\small
	\ttfamily
	\color{Blue}
	register(DataDep("DataDepName",\\
	\color{Green}
	"""\\
	Free Text Field Displayed to user before download.\\
	Use to give credit, and tell people about licensing.\\
	Or other messages.\\
	""",\\
	\color{Orange}
	"Download URL",\\
	\color{Red}
	"file hash (will be printed if not provided)";\\
	\color{Purple}
	post\_fetch\_method = function to run on downloaded files\\
	\color{Blue}
	))
	\vfill\vfill\vfill\null
\end{frame}


\begin{frame}[fragile]{ Registration Block Example}
	\small
	\ttfamily
	\color{Blue}
	register(DataDep("WordNet 3.0",\\
		\color{Green}
		"""\\
		Dataset: WordNet 3.0\\
		Website: https://wordnet.princeton.edu/wordnet\\
		\vspace{0.5em}
		George A. Miller (1995). \\
		WordNet: A Lexical Database for English.\\
		Communications of the ACM Vol. 38, No. 11: 39-41.\\
		\vspace{0.5em}
		License:\\
		This software and database is being provided to you,\\
		the LICENSEE, by Princeton University under\\
		the following license...\\
		""",\\
		\color{Orange}
		"http://wordnetcode.princeton.edu/3.0/WNdb-3.0.tar.gz",\\
		\color{Red}
		"658b1ba191f5f98c2e9bae3e25...";\\
		\color{Purple}
		post\_fetch\_method = unpack\\
		\color{Blue}
	))
	\vfill\vfill\vfill\null
\end{frame}

\begin{frame}[fragile]{Registration Block: Recursive Example}
		\ttfamily
		using MD5\\
		\vspace{0.5em}
		\color{Blue}
		register(DataDep("DataDepNameRec",\\
		\color{Green}
		"""\\
		Warning these files are all together 39.8GB\\
		""",\\
		\color{Orange}
		\verb![!"http://example.com/readme.txt",\\
	     \verb!    [!"http://example.com/data1.zip",\\
	      \verb!     !"http://example.com/data2.tar.gz",\\
	     \verb!    ]!\\
		\verb!]!,\\
		\color{Red}
		(md5, "d41d8cd98f00b204e9800998ecf8427e")\\
		\color{Purple}
		post\_fetch\_method = \verb![!identity, unpack\verb!]!\\
		\color{Blue}
		))

	\vfill\vfill\vfill\null
	\note{post fetch method and the checksum are applies recursively.
		The checksum xors the hash it if it is not recursed.
		the post fetch method is applied element-wise.}
	\note{Also you can specify the function used to generate the checksum}
\end{frame}


\focusslide{datadepsgenerators}{DataDepsGenerators}

\begin{frame}[fragile]{Developers still have to write registration blocks}
	\begin{easylist}[itemize]
		@ DataDeps.jl shifts the work from \alert{manually to automatic}
		@ But it still has to be done at once.
		@ Writing a registration block normally means \alert{\mbox{copy-and-pasting}} from a website.
		@@ Even copy pasting a dozen URLs is annoying
		@@ Enough information for \alert{data providence} needs more
	\end{easylist}
\end{frame}


%\newcommand{\datadepsgeneratorsflowcolumn}{}
\begin{frame}[fragile]{}
	\frametitle<1>{For published data this information is available from some API}
	\frametitle<2>{DataDepsGenerators creates static code}
	\begin{columns}
		\begin{column}{0.5\textwidth}
			\only<1>{\begin{itemize}
					\item Title
					\item Author Name
					\item Publication Date
					\item Licensing info
					\item Description
					\item Citation for the linked journal paper
					\item \alert{Download URLs}
					\item \alert{File Hashes}
			\end{itemize}}
			\only<2>{\begin{itemize}
					\vfill
					\item This avoids propagating DataDepsGenerator's many \alert{heavy dependencies}.
					\note{A small bunch of libraries for webscraping and parsing various formats}
					\vfill\vfill\vspace{1cm}
					\item Avoids issue \alert{unstability} of repo APIs/websites
					\vfill
					\note{it breaks if some websites/apis change}
			\end{itemize}}
		\end{column}
		\begin{column}{0.5\textwidth}
			\begin{tikzpicture}[every to/.append style = {ultra thick}]
				\node(indata){Orignal Data};
				\node[draw, below=0.8cm of indata](repo){Repository};
				\node[draw, below=0.8cm of repo](datadepsgen) {DataDepsGenerators.jj};
				\node[draw, below=0.8cm of datadepsgen](datadeps){DataDeps.jl};
				\node(outdata)[below=0.8cm of datadeps]{Data, on your machine};
				
				\draw[bluewrite] (indata) to[right] node {Author uploads} (repo);
				\draw[bluewrite] (repo) to[right] node {Metadata} (datadepsgen);
				\draw[bluewrite] (datadepsgen) to node[xshift=-1mm] {Registration code-block} (datadeps);
				\draw[bluewrite] (datadeps) to node[xshift=2.5mm] {Resolves as required} (outdata);
			\end{tikzpicture}
		\end{column}
	\end{columns}
\end{frame}

\begin{frame}[fragile]{Many datasets have multiple possible APIs}
	For example something that points at \alert{Figshare}\\
	{\small \inlinecode{generate("https://doi.org/10.23640/07243.5525476.v1")}}
	\vfill
	\begin{easylist}[itemize]
		@ It includes a DOI
		@@ DataCite API
		@@ JSON-LD DOI Content Negotiation service
		@ It is a URL
		@@ Embedded JSON-LD element
		@@ FigShare API
		@ Many others will be tried and will error out
	\end{easylist}
	\vfill
	\pdfcomment{Do include the merged output on the next slide when that feature is working}
\end{frame}

\begin{frame}[fragile]{Many datasets have multiple possible APIs}
	For example something points at \alert{DataDryad}\\
	{\small 
		\inlinecode{generate(}\\
		\inlinecode{"http://datadryad.org/resource/doi:10.5061/dryad.gj651")}
	}
	\vfill
	\begin{easylist}[itemize]
		@ DataCite API
		@ JSON-LD DOI Content Negotiation service
		@ Embedded JSON-LD element
		@ DataDryad Webscraper
		@ DataOneV1 API
		@ Many others will be tried and will error out
	\end{easylist}
	\vfill
	\pdfcomment{Do include the merged output on the next slide when that feature is working}
\end{frame}

\begin{frame}{DataDepsGenerators combines all the Metadata Sources}
	\centering
	\resizebox{!}{0.8\pageheight}{\begin{tikzpicture}[layered layout, grow=down,]
		\node(out){Complete Metadata\\For Registration Block};
%		\repo[above right=of out]{DataCite};
%		\repo[above = of out]{Others};
%		\repo[above left=of out]{FigShare};
%		\draw[->] (DataCite) to (out);
%		\draw[->] (FigShare) to (out);
%		\draw[->] (Others) to (out);

		\repo[]{DataCite};
		\repo[]{Others};
		\repo[]{Figshare};
	\graph{
		(out) <- {{Figshare} <- {Has URL[Green], No Paper Ref.[Red]},
			      {Others},
			      (DataCite)<-{Has Paper Ref.[Green],  No URL[Red]}
			    };
	};
	

	\end{tikzpicture}}
\end{frame}
	


\begin{frame}[fragile]{GitHub}
	\begin{easylist}[itemize]
		@ $85 \times 10^6$ repositories 
		@@ Some of them are data, (most are not)
		@@ Not a great place for data, but commonly used 
		@ \alert{BuzzFeedNews}: \note{"Mainstream News, responsible data citizens"}
		@@ 1 Repo per dataset
		@ \alert{fivethirtyeight}: \note{Current Affairs site with serious data bent}
		@@ 1 shared Repo with a folder for each dataset \note{which correpond to stories}
		@ We generate URLs pointing at \alert{\url{cdn.rawgit.com}}
		@@ This is backed by \alert{StackPath CDN}
		@@ It is generated to point at the \alert{latest commit} at generation time
	\end{easylist}
\end{frame}


\begin{frame}[fragile]{DataOne}
	\begin{easylist}[itemize]
		@ Data Observation Network for Earth 
		@@ \alert{\textasciitilde  40} Earth and Environment Science repositories
		@@ $1.2 \times 10^6$ Data Files
		@@ Seems to have iffy metadata, varying between nodes.
	\end{easylist}
\end{frame}

\begin{frame}[fragile]{Others}
	\begin{easylist}[itemize]
		@ DataDryad
		@@ Ecological research data
		@@ $7.1 \times 10^4$ Data Files
		@@ $2.2 \times 10^4$ Data Packages
		@ Figshare
		@@ Mostly Figures and Datasets
		@@ $8 \times 10^5$ Files
		@ UCI ML Repository
		@@ $437$ Datasets
		@@ Very commonly used in benchmarking basic ML
		@@ Awful website, zero API
	\end{easylist}
\end{frame}

\begin{frame}[fragile]{DataCite}
	\begin{easylist}[itemize]
		@ $11 \times 10^6$ DOIs issued 
		@@ Mostly to datasets, though they count also figures as data
		@@ If you have a DOI and it points at data, it is probably from DataCite
		@ Problem is all their metadata is missing download URLs
		@@ So user has to add them manually after
		@ This is effectively the final fallback for anything with a DOI.
	\end{easylist}
\end{frame}

%
%
%\begin{frame}[fragile]{Data Repositories}
%\newcommand{\info}[2][]{node[#1,info](#2) {#2}}
%\resizebox{\textwidth}{!}{\begin{tikzpicture}[%
%		layered layout, grow=left, sibling distance=15mm,
%		info/.style={very thick, green!50!black},
%		]
%
%
%\repo{GitHub};
%\repo{538};
%\repo{BuzzFeedNews};
%
%\graph{
%		(GitHub) <- {
%			{{85 million Repos} %
%				<- {{Some of these contain data} %
%				<- {It is not a great place for data, but it is common}},
%			(538) <- {
%					{Data Science driven Current Affairs site},
%					{Each dataset for each story is a folder},
%			},
%			(BuzzFeedNews) <- {
%				{News Site},
%				{One github repo per dataset for a story},
%			},
%			%{We generate urls pointing at \url{https://cdn.rawgit.com/}} %
%			%	<- {for the lasted commit at generation time},
%		};			
%}; %\graph
%
%\end{tikzpicture}}
%\end{frame}

\begin{frame}{We are now going to take a very short break}
	\centering
	\includegraphics[width=\textwidth]{break}	
\end{frame}

\focusslide{corpusloaders}{CorpusLoaders}
\begin{frame}[fragile]{WordTokenizers.jl}
	\begin{easylist}[itemize]
		@ Not much to say.
		@ Honestly not a lot in it itself.
		@@ Just a couple of parsers for a few formats
		@ Mostly interesting as a vessel for driving its dependencies.
	\end{easylist}
	\vspace{1cm}
	\begin{easylist}[itemize]
		@ Notable differences from MLDatasets.jl
		@@ Everything is lazy-loaded from disk via \inlinecode{Channels}.
		@@ Everything is Multi-Resolution
	\end{easylist}
\end{frame}

\focusslide{corpusloaders}{WordTokenizers}
\begin{frame}[fragile]{WordTokenizers.jl}
	\note{Honestly I stole stuff left, right and center for this.}
	Configurable \inlinecode{tokenize}r and \inlinecode{sentence_segment}er.\\
	Abuses \inlinecode{eval} and \alert{\#265} so that you can change the tokenizer being used globally.\\
	Also compatible with externally defined tokenizers like RevTok.jl.
	\vfill	
	Nabbed the original Penn Tokenizer sed-script.\\
	Wrote some code that converts basic \alert{sed language} into \alert{julia AST}.\\
	Ported some of NLTK's tokenizers into sed.
	\vfill

	\vfill
	Rule-based sentence splitter based on Sampo Pyysalo \& Yoshimasa Tsuruoka's perl script.
	\vfill
	Regex is just really good at working with English.	
\end{frame}

\focusslide{corpusloaders}{InternedStrings}
\begin{frame}[fragile]{InternedStrings.jl: All these duplicate strings are using all my memory}
	\begin{easylist}[itemize]
		@ Strings are immutable, so we only need one copy of each
		@ We can maintain a pool of \inlinecode{WeakRef}s to each string allocated.
		@ \inlinecode{str = intern(str)}
		@@ Add the \inlinecode{str} to the pool if not already
		@@ replace \inlinecode{str} with an element of the pool
		@ Because the pool only has \inlinecode{WeakRef}s strings can still be garbage collected.
	\end{easylist}
\end{frame}

\focusslide{corpusloaders}{MultiResolutionIterators}
\begin{frame}[fragile]{MultiResolutionIterators.jl:\\ The structure of a Corpus}
	\begin{easylist}[itemize]
		@ \alert{Corpus}
		@ made up of: \alert{Documents}
		@ made up of: \alert{Paragraphs}
		@ made up of: \alert{Sentences}
		@ made up of: \alert{Words}  or \alert{Tokens}
		@ made up of: \alert{Letters} or \alert{Characters}
	\end{easylist}
\end{frame}




\def\madeupof{$\blacktriangleright$}
\begin{frame}[fragile]{MultiResolutionIterators.jl: Not everyone wants every level of structure}
	\alert{Full corpus structure} is\\
	Documents \madeupof Paragraphs \madeupof Sentences \madeupof Words \madeupof Letters
	\vfill
	
	A \alert{Corpus Linguist} may want\note{studying word usage}\\
	a stream of: Sentences \madeupof Words
	\vfill
	An \alert{Information Retrieval} researcher may want\\
	a stream of: {Documents} \madeupof {Words}
		
	\vfill
	A \alert{char-RNN} language modeller might just want\\
	a stream of Letters
\end{frame}

\begin{frame}[fragile]{MultiResolutionIterators.jl: example}
	\color{Green}
	\begin{code}
		julia> animal_info = [
		[	["Turtles", "are", "reptiles", "."],
			["They", "have", "shells", "."],
			["They", "live", "in", "the", "water", "."]],
		[	["Cats", "are", "mammals", "."],
			["They", "live", "on", "the", "internet", "."]]
		]
		2-element Array{Array{Array{String,1},1},1}
	\end{code}
	\color{Orange}
	\begin{code}
		julia>  struct AnimalTextIndexer end;
		julia> 	levelname_map(::AnimalTextIndexer) = [
			:documents=>1,
			:sentences=>2,
			:words=>3, :tokens=>3,
			:characters=>4, :letters=>4
		]
	\end{code}

\end{frame}

\newcommand{\ormark}{\vspace{-0.5em}\hfill \textasciitilde{} Or \textasciitilde{} \hfill \null \vspace{-0.5em}}
\begin{frame}[fragile]{Information Retrieval wants\\ {Documents} \madeupof {Words}}
	\color{Purple}
	\small
	\begin{code}
		julia> flatten_levels(animal_info, 2)
	\end{code}
		\ormark{}
	\begin{code}
		julia> flatten_levels(animal_info,
					lvls(indexer, :sentences))
	\end{code}
		\ormark{}
	\begin{code}					
		julia> flatten_levels(animal_info, 
					(!lvls)(indexer, :documents, :words))
	\end{code}
	\color{Green}
	\begin{code}
		julia> full_consolidate(ans)
		
		2-element Array{Array{String,1},1}:
		String["Turtles", "are", ".", ...,  "the", "water", "."]
		String["Cats", "are", ..., "the", "internet", "."]
	\end{code}
\end{frame}

\begin{frame}[fragile]{Char-RNN Topic Modelling wants\\ {Documents} \madeupof {Words}}
	\color{Purple}
	\begin{code}					
		julia> join_levels(animal_info,
					lvls(indexer,Dict(
						:words=>" ",
						:sentences=>" ")
					 )
				)
	\end{code}
	\color{Green}
	\begin{code}	
		julia> full_consolidate(ans)
		
		2-element Array{String,1}:
		"Turtles are reptiles ... They live in the water ."
		"Cats are mammals . They live on the internet ."
	\end{code}
\end{frame}


\begin{frame}[fragile]{MultiResolutionIterators.jl}
	\begin{easylist}[itemize]
		@ Mix and match operations as needed
		@ Easy to define any iterator function to work at levels
		@ Overload \inlinecode{apply} to customize behaviour with particular iterator-types.
	\end{easylist}
	\vspace{1cm}
	E.g. could make \inlinecode{MyVector} eager and type preserving
	via \inlinecode{apply(f, v::MyVector) = MyVector(collect(f(v)))}
		
\end{frame}


\begin{frame}[fragile]{What have we learned?}
	\begin{easylist}[itemize]
	@ Australia: Quiet distant, not near London
	\pause
	@ Data is important
	@ Simplify your data management with DataDeps.jl
	@ Simplify your DataDeps creation with DataDepsGenerators.jl
	\pause
	@ Data is useful for NLP
	@ Packages exist to make working with NLP shaped data easier.
	\end{easylist}
\end{frame}

\againframe{bigpicture}

\section{Appendix/ Spare Rants}

\begin{frame}[fragile]{Why DOI's alone are not the answer to broken dataset links:}
	\small
	\begin{easylist}[itemize]
		@ When we say DOI's are persistent we mean they never expire.
		@@ Unlike web URL, you do not have to pay to renew.
		@@ It won't be sold to someone else. It will always refer to your object.
		@ DOI's point to landing pages, not data/paper downloads
		@@ DOI's have attached metadata, but not direct links to the data (not even DataCite DOIs (yet))
		@ A key reason DOI's don't point data/papers is because not all are available online
		@@ Some obviously are pay walled
		@@ But some can't be digitalized at all. E.g. DOI's have been issued to laboratory samples, or to data centres.		
	\end{easylist}
\end{frame}
\begin{frame}[fragile]{DOI's are not the solution, but they are probably part of the solution}
	\begin{easylist}[itemize]
		@ The landing page is still just a website, it's domain name \alert{can expire}
		@@ The data hosting is can expire (and hard-drives can fail).
		@ Did I mention under normal circumstances you can't go from DOI to data URL at all anyway?
		@ Still persistent metadata is also kind of nice to have
		@@ At least if the data goes down you know what was lost, so we can seek it else-where.
		@ Really, though we need to be applying periodic automatic link checking to all URLs we need not to break.
		@@ DataDeps.jl makes that pretty easy, you can just set it up as part of \inlinecode{runtests.jl} and set Travis or AppVeyor to run scheduled tests.
	\end{easylist}
\end{frame}

\end{document}