\RequirePackage{luatex85,shellesc}
\documentclass[dvipsnames]{beamer}
\usepackage{verbatim}

\usepackage{microtype}
\usepackage{adjustbox}
\usepackage{amsmath}

\usepackage[subpreambles=false]{standalone}


\usepackage[at]{easylist}

%\newlength\xunit
\input{brownbeamer}
\setbeamercolor{math text}{fg=bluewrite}
\setbeamercolor{math text displayed}{fg=bluewrite}


\bibliography{master.bib}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{tikz}
\usetikzlibrary{positioning}
\usetikzlibrary{decorations.pathmorphing}
\usetikzlibrary{graphs,graphs.standard,graphdrawing,arrows}
\usegdlibrary{layered, trees, force}

\usepackage{graphicx}
\graphicspath{{./figs/}, {./}}
\usepackage[space]{grffile}

\usepackage{trimclip}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% TIKZ stuff

\tikzset{%
	->,
	align=center,
	node distance=10cm, sibling distance=25mm, level distance=40mm,
	every edge/.append style = {thick},
	package/.style={draw, circle, very thick},
	mypackage/.style={package, blue},
	repo/.style={draw, very thick, purple},
	supports/.style={dotted, very thick},
	indirect/.style={decoration={snake}, decorate, very thick, purple}
}

\newcommand{\pkg}[2][]{\node[#1,package](#2) {#2.jl}}
\newcommand{\repo}[2][]{\node[#1,repo](#2) {#2}}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\inlinecode}[1]{\mbox{\alert{\texttt{\detokenize{#1}}}}}
\newenvironment{code}
{%BEGIN
\endgraf\verbatim
}
{ % END
\endverbatim
}


\newcommand{\datadep}[1]{\inlinecode{datadep"#1"}}

% all notes should just be simple item notes.
% I neither need nor want more functionality
\let\oldnote\note
\renewcommand{\note}{\oldnote[item]}

\renewcommand{\emph}{\alert}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%


\institute{School of Electical, Electronic and Computer Engineering\\The University of Western Australia}
\date{}
\title{DataDeps.jl}
\subtitle{and other foundational tools for data driven research\\(Especially NLP)}
\author{\includegraphics[height=2cm]{juliaml}
	\includegraphics[height=2cm]{juliatext}
	\includegraphics[height=2cm]{juliastring}
	\\
	\vspace{5mm}
	\textbf{Lyndon White}}

\logo{\hfill\includegraphics[scale=0.12]{uwa}\hfill\hspace{0.5cm}}

\begin{document}

%\centering %Center everywhere
\frame{\maketitle}
\logo{}


\begin{frame}{Big Picture}
	\centering
	%	〈	llx	〉 〈	lly	〉 〈	urx	〉 〈	ury	〉
	%\resizebox{\textwidth}{!}{\clipbox{190pt 170pt 250pt 0pt}{\input{coreidea.tex}}}
	
	\resizebox{\textwidth}{!}{\begin{tikzpicture}[layered layout, grow'=up,]
	\node[nudge=(left:12mm)](researchcode){Research Code};
	
	\pkg[mypackage, nudge=(right:17mm)]{CorpusLoaders};
	
	\pkg[mypackage]{DataDeps};
	\pkg[mypackage]{DataDepsGenerators};
	%	\pkg[mypackage]{ReferenceTests};
	\pkg[mypackage]{MD5};
	\pkg[]{SHA};
	
	\node(MultiResolutionIterators)[mypackage]{Multi--\\Resolution--\\Iterators.jl};
	
	\pkg[mypackage]{InternedStrings};
	\pkg[]{Strs};
	\pkg[]{CSV};
	
	
	\pkg{MLDatasets};
	%	\pkg[mypackage]{ExpectationStubs};
	\pkg{HTTP};
	\pkg[nudge=(right:15mm)]{WordNet};
	\pkg[mypackage, nudge=(right:4mm)]{Embeddings};
	
	
	\pkg[mypackage]{WordTokenizers};
	\pkg{RevTok};
	
	
	\repo{CRAN};
	\repo{DataDryad};
	\repo{GitHub};
	\repo{European Data Portal};
	\repo[]{Open.Canada.ca};
	\repo{Data.gov};
	\repo{Data.gov.au};
	\repo{DataOne};
	\repo{538};
	\repo{BuzzFeedNews};
	\repo{UCI ML Repository};
	\repo{ArcticDataCenter};
	\repo{KnowledgeNetworkforBiocomplexity};
	\repo{TERN};
	\repo{DataCite};
	\repo{Zenodo};
	\repo{FigShare};
	
	
	\node[sibling distance=0mm](gap){};
	
	\graph{
		(researchcode) <- {(MLDatasets), (Embeddings), (WordNet), (CorpusLoaders)} <- (DataDeps);
		(DataDeps) ->[bend left, looseness=0, in=167, out=0] (researchcode);
		
		
		{(CorpusLoaders) <- {(MultiResolutionIterators), (WordTokenizers), (InternedStrings)}};
		(DataDeps) <- {(HTTP), (SHA)};
		(DataDeps) <-[supports] (MD5);
		
		(DataDeps) <-[indirect] (DataDepsGenerators) <- {
			(GitHub) <- {(538), (BuzzFeedNews)},
			(UCI ML Repository),
			(CRAN) <- {(Open.Canada.ca), (Data.gov.au), (Data.gov), (European Data Portal)},
			(DataCite) <- {(Zenodo), (FigShare)},
			(DataDryad),
			(DataOne) <- {(ArcticDataCenter), (TERN), (KnowledgeNetworkforBiocomplexity)},
		};
		
		(WordTokenizers) <-[supports] (RevTok);
		(InternedStrings) <-> [supports] (Strs);
		(InternedStrings) ->[supports] (CSV);
	};
	\end{tikzpicture}}
\end{frame}




\begin{frame}{Julia Packages}
	\centering
	%	〈	llx	〉 〈	lly	〉 〈	urx	〉 〈	ury	〉
	%\resizebox{\textwidth}{!}{\clipbox{190pt 170pt 250pt 0pt}{\input{coreidea.tex}}}
	
	\resizebox{0.9\textwidth}{!}{\begin{tikzpicture}[layered layout,	grow'=up,]
		\node[nudge=(left:12mm)](researchcode){Research Code};
		
		\pkg[mypackage, nudge=(right:17mm)]{CorpusLoaders};
		
		\pkg[mypackage]{DataDeps};
		\pkg[mypackage]{DataDepsGenerators};
		%	\pkg[mypackage]{ReferenceTests};
		\pkg[mypackage]{MD5};
		\pkg[]{SHA};
		
		\node(MultiResolutionIterators)[mypackage]{Multi--\\Resolution--\\Iterators.jl};
		
		\pkg[mypackage]{InternedStrings};
		\pkg[]{Strs};
		\pkg[]{CSV};
		
		
		\pkg{MLDatasets};
		%	\pkg[mypackage]{ExpectationStubs};
		\pkg{HTTP};
		\pkg[nudge=(right:15mm)]{WordNet};
		\pkg[mypackage, nudge=(right:4mm)]{Embeddings};
		
		
		\pkg[mypackage]{WordTokenizers};
		\pkg{RevTok};
		
		\node[sibling distance=0mm](gap){};
		
		\graph{
			(researchcode) <- {(MLDatasets), (Embeddings), (WordNet), (CorpusLoaders)} <- (DataDeps);
			(DataDeps) ->[bend left, looseness=0, in=167, out=0] (researchcode);
			
			
			{(CorpusLoaders) <- {(MultiResolutionIterators), (WordTokenizers), (InternedStrings)}};
			(DataDeps) <- {(HTTP), (SHA)};
			(DataDeps) <-[supports] (MD5);
			
			(DataDeps) <-[indirect] (DataDepsGenerators);
			
			(WordTokenizers) <-[supports] (RevTok);
			(InternedStrings) <-> [supports] (Strs);
			(InternedStrings) ->[supports] (CSV);
			
		};
		\end{tikzpicture}}
\end{frame}

\begin{frame}{DataDeps.jl}
	\centering
		%	〈	llx	〉 〈	lly	〉 〈	urx	〉 〈	ury	〉
%	\resizebox{\textwidth}{!}{\clipbox{190pt 320pt 400pt 0pt}{\input{coreidea.tex}}}
	
\resizebox{\textwidth}{!}{\begin{tikzpicture}[layered layout, grow'=up,]
	\node[](researchcode){Research Code};
	
	
	
	\pkg[mypackage]{DataDeps};
	\pkg[mypackage]{DataDepsGenerators};
	\pkg[mypackage]{MD5};
	\pkg[]{SHA};
	\pkg{HTTP};
		

	\pkg[nudge=(right:40mm)]{WordNet};
	\pkg[mypackage, nudge=(right:50mm)]{CorpusLoaders};
	\pkg[mypackage, nudge=(left:0mm)]{Embeddings};
	\pkg[nudge=(left:10mm)]{MLDatasets};

	
	\graph{
		(researchcode) <- {(MLDatasets), (Embeddings), (WordNet), (CorpusLoaders)} <- (DataDeps);
		(DataDeps) ->[bend left, looseness=0, in=167, out=0] (researchcode);
		
		(DataDeps) <- {(HTTP), (SHA)};
		(DataDeps) <-[supports] (MD5);
		
		(DataDeps) <-[indirect] (DataDepsGenerators);	
	};
	\end{tikzpicture}}
\end{frame}

\begin{frame}{DataDepsGenerators.jl}
	\centering
		%	〈	llx	〉 〈	lly	〉 〈	urx	〉 〈	ury	〉
%	\resizebox{\textwidth}{!}{\clipbox{0pt 0pt 0pt 290pt}{\input{coreidea.tex}}}
\newcommand{\content}{
	\node[layer sep = 5mm](researchcode){Research Code};
	
	\pkg[mypackage, layer sep = 5mm]{DataDeps};
	\pkg[mypackage, layer sep = 25mm]{DataDepsGenerators};
	
	\repo{CRAN};
	\repo{DataDryad};
	\repo{GitHub};
	\repo{European Data Portal};
	\repo[]{Open.Canada.ca};
	\repo{Data.gov};
	\repo{Data.gov.au};
	\repo{DataOne};
	\repo{538};
	\repo{BuzzFeedNews};
	\repo{UCI ML Repository};
	\repo{ArcticDataCenter};
	\repo{KnowledgeNetworkforBiocomplexity};
	\repo{TERN};
	\repo{DataCite};
	\repo{Zenodo};
	\repo{FigShare};
	
	
	\graph{
		(researchcode) <- (DataDeps);
		
		(DataDeps) <-[indirect] (DataDepsGenerators) <- {
			(GitHub) <- {(538), (BuzzFeedNews)},
			(UCI ML Repository),
			(CRAN) <- {(Open.Canada.ca), (Data.gov.au), (Data.gov), (European Data Portal)},
			(DataCite) <- {(Zenodo), (FigShare)},
			(DataDryad),
			(DataOne) <- {(ArcticDataCenter), (TERN), (KnowledgeNetworkforBiocomplexity)},
		};
	};
}

\resizebox{\textwidth}{!}{
	\only<1>{
		\begin{tikzpicture}[layered layout, grow'=up,]
			\content{}
		\end{tikzpicture}
	}
	\only<2>{
		\begin{tikzpicture}[%
			layered layout, grow=left, sibling distance=15mm]
			\content{}
		\end{tikzpicture}
	}
}
\end{frame}

\begin{frame}{CorpusLoaders.jl}
		%	〈	llx	〉 〈	lly	〉 〈	urx	〉 〈	ury	〉
%	\resizebox{\textwidth}{!}{\clipbox{370pt 310pt 250pt 70pt}{\input{coreidea.tex}}}
\centering
\resizebox{0.7\textwidth}{!}{\begin{tikzpicture}[layered layout,	grow'=up,]
		\node[](researchcode){Research Code};
		
		\pkg[mypackage]{CorpusLoaders};
		
		\pkg[mypackage]{DataDeps};
		\node(MultiResolutionIterators)[mypackage]{Multi--\\Resolution--\\Iterators.jl};
		
		\pkg[mypackage]{InternedStrings};
		\pkg[]{Strs};
		\pkg[]{CSV};
		
		
		\pkg[mypackage]{WordTokenizers};
		\pkg{RevTok};
		
		
		\graph{
			(researchcode) <- {(CorpusLoaders)};
			{(CorpusLoaders) <- {(DataDeps), (MultiResolutionIterators), (WordTokenizers), (InternedStrings)}};
			(WordTokenizers) <-[supports] (RevTok);
			(InternedStrings) <-> [supports] (Strs);
			(InternedStrings) ->[supports] (CSV);
		};
		\end{tikzpicture}}
\end{frame}


\begin{frame}{Vabdewakke's 6 Degree's of Replicability}
	\begin{enumerate}
		%\item 0: The results cannot be reproduced by an independent researcher.
		
		\item The results \alert{cannot seem to be} reproduced.
		
		\item The results could be reproduced by, \alert{requiring extreme effort.}
		
		\item The results can be reproduced, \alert{requiring considerable effort.}
		
		\item The results can be easily reproduced with \alert{at most \textbf{15 minutes} of user effort}, requiring some proprietary source packages (MATLAB, etc.).
		
		\item The results can be easily reproduced  with \alert{at most \textbf{15 min} of user effort}, requiring only standard, freely available tools (C compiler, etc.).		
	\end{enumerate}
	\note{Vabdewakke actual has a rating zero for "no, just no can not reproduce."}
	\note{What is the key determining factor here? User effort. How do we get down to 15 minutes of user effort?}
	\citehere{VabdewakkeReproduceableResearch}
\end{frame}


\begin{frame}{What happens when I try and reproduce someone's research code?}
	\begin{description}
		\item[1min] Find the website from the paper, and \alert{download the code}
		\item[2min] Read enough of the README to get rough bearings
		\item[\textbf{1min}] Find out where to get the data from and \alert{download the data}
		\item[\textbf{2min}] Try and remember how to use \inlinecode{tar -xzfvalphabetsoup} etc.
		\item[\textbf{2min}] Workout how to tell script \alert{where data is} \note{Hardcoded path? Argument?}
		\item[2min] Setup any software dependencies etc.
		\item[3min] Run the code and make sure it isn't crashing etc.
		\item[2min] Interpret the output
	\end{description}
	\note{I have spent 5 of my 15 valuable minutes faffing around about sorting out the data.}
	\note{I think this timeline is fairly reasonable, of course an ideal julia project with everything already working in CI would do a lot better. But if you've got these steps, your already blocked from CI.}
\end{frame}


\begin{frame}[fragile]{You can't trust hardcoded paths; \\ but they are nice to work with.}
	
	\begin{easylist}[itemize]
		@ Ideally we'ld just use \alert{hard-coded, absolute} paths
		@ Absolute paths work with all applications
		@ Hard-coding the paths in code means less typing
		@ But they break if anything is moved. \note{relative paths are less so}
		@ Making the path be passed in as an argument to the script solves this
		@@ but now user has to be typing it in to run it.
		@@ So harder to use.
		@@ You could include a bash-script that invokes it with the path, but now you're just hard coding it somewhere else
	\end{easylist}
\end{frame}

\begin{frame}[fragile]{You could making the path be passed in as an argument. But...}
	
	\begin{easylist}[itemize]
		@ Now user has to be typing it in to run it.
		\note{Recall the valuable time spent to workout how to tell the script where the data is?}
		@ So it is harder to use.
		@ You could include a bash-script that invokes it with the path, but now you're just hard-coding it somewhere else
	\end{easylist}
\end{frame}


\begin{frame}[fragile]{\datadep{Census 2018/populations.csv} \\ A path you can trust}
	\begin{easylist}[itemize]
		@ Always resolves to an absolute path to that file
		\note{at runtime}
		@ Even if that means it has to download it first
		@ But before resorting to downloading checks a large number of places
		@@  \inlinecode{<PKG>/deps/data}, 
		@@ \inlinecode{~/.julia/datadeps},
		@@ \inlinecode{/usr/share/datadeps}, etc.
		\note{this is the DataDeps load path}
		\note{The places to check can be configured of course}
		@ You know that if you use a datadep path it will resolve to a file that exists.
	\end{easylist}
\end{frame}


\begin{frame}[fragile]{What happens when you uses a datadep?}
		\center
		\resizebox{0.9\textwidth}{!}{
		\begin{tikzpicture}[every text node part/.style={align=center}, auto,node distance=2, ->,
		every edge/.append style={every node/.style={font=\footnotesize}}]
		
		
		\node[blue](start) {\datadep{Name}\\ \textbf{Evaluated}}; 
		
		\node[draw, rectangle, below right= 0.5 of start] (search) {0.\\Search\\ \texttt{Load Path}};
		\node[draw, rectangle, right= of search] (msg) {1.\\Display\\ message};
		\node[draw, rectangle, below right= of msg] (fetch) {2.\\Perform\\ fetch method\\ (download)};
		\node[draw, rectangle, below right= of fetch] (checksum) {3.\\Validate\\ using\\ checksum};
		\node[draw, rectangle, below right= of checksum] (postfetch) {4.\\Perform \\post fetch method\\ e.g. unpack};
		\node[green!60!black, below=of postfetch](end) {\textbf{Local Path}\\ \textbf{Returned}};
		
		\path (start) edge (search);
		\path (search)  edge node[below]{datadep} node[sloped,above]{\textbf{Not Found}}  (msg);
		\path (msg)	edge node[below, sloped]{remote paths} node[above right]{\textbf{Accept}}  (fetch);
		\path (fetch)	edge[below, sloped] node{local paths}  (checksum);
		\path (checksum)	edge node[below, sloped]{local paths} node[above right]{\textbf{Succeeded/Ignored}} (postfetch);
		\path (postfetch)	edge (end);
		
		\path (search.south) edge node[above,right,yshift=0.6cm]{\textbf{Found}} node[below,sloped]{local path} (end.west);
		
		
		\path (checksum.north) edge[bend right] node[above right] {Failed-Retry} (fetch.east);
		
		\node[red, below = 0.5 of msg, yshift=-0.6cm] (err1) {\textbf{Abort}};
		\path (msg) edge node[left]{\textbf{Decline}} (err1);
		
		\node[red, below = 0.5 of checksum, yshift=-0.6cm] (err2) {\textbf{Abort}};
		\path (checksum) edge node[left]{\textbf{Failed}}  (err2);
		\end{tikzpicture}
	}
\end{frame}


\begin{frame}[fragile]{Current Usages of DataDeps.jl}
	\structure{MLDatasets.jl}
	\begin{easylist}[itemize]
		@ Provides easy access to a bunch of ML datasets
		@ \inlinecode{xs, ys = MNIST.traindata()}
		@ Gives you regular julia arrays
	\end{easylist}
	\vfill
	\structure{CorpusLoaders.jl}
	\begin{easylist}[itemize]
	@ Provides easy access to linguistic corpora
	@ \inlinecode{corpus_gen = load(WikiCorpus())}
	@ gives you a multi-resolution iterator
	\end{easylist}	
\end{frame}

\begin{frame}[fragile]{Current Usages of DataDeps.jl}	
	\structure{Embeddings.jl}
	\begin{easylist}[itemize]
		@ Provides access to hundreds of pretrained word~embedding models.
		@ \inlinecode{load_embeddings(FastText_Text{:fr})}
		@ gives you a table of French word embeddings.
	\end{easylist}
	
	\vfill
	\structure{WordNet.jl}
	\begin{easylist}[itemize]
		@ Look up lexical relations and definitions.
		@ \inlinecode{lemma = db['a', "glad"]}
		@ \inlinecode{antonyms(db, synsets(db, lemma)[1])}
	\end{easylist}
\end{frame}


\begin{frame}[fragile]{DataDep Registration Block}
	\small
	\ttfamily
	\color{Blue}
	register(DataDep("DataDepName",\\
	\color{Green}
	"""\\
	Free Text Field Displayed to user before download.\\
	Use to give credit, and tell people about licensing.\\
	Or other messages.\\
	""",\\
	\color{Orange}
	"Download URL",\\
	\color{Red}
	"file hash (will be printed if not provided)";\\
	\color{Purple}
	post\_fetch\_method = function to run on downloaded files\\
	\color{Blue}
	))
	\vfill\vfill\vfill\null
\end{frame}


\begin{frame}[fragile]{ Registration Block Example}
	\small
	\ttfamily
	\color{Blue}
	register(DataDep("WordNet 3.0",\\
		\color{Green}
		"""\\
		Dataset: WordNet 3.0\\
		Website: https://wordnet.princeton.edu/wordnet\\
		\vspace{0.5em}
		George A. Miller (1995). \\
		WordNet: A Lexical Database for English.\\
		Communications of the ACM Vol. 38, No. 11: 39-41.\\
		\vspace{0.5em}
		License:\\
		This software and database is being provided to you,\\
		the LICENSEE, by Princeton University under\\
		the following license...\\
		""",\\
		\color{Orange}
		"http://wordnetcode.princeton.edu/3.0/WNdb-3.0.tar.gz",\\
		\color{Red}
		"658b1ba191f5f98c2e9bae3e25...";\\
		\color{Purple}
		post\_fetch\_method = unpack\\
		\color{Blue}
	))
	\vfill\vfill\vfill\null
\end{frame}

\begin{frame}[fragile]{Registration Block: Recursive Example}
		\ttfamily
		using MD5\\
		\vspace{0.5em}
		\color{Blue}
		register(DataDep("DataDepNameRec",\\
		\color{Green}
		"""\\
		Warning these files are all together 39.8GB\\
		""",\\
		\color{Orange}
		\verb![!"http://example.com/readme.txt",\\
	     \verb!    [!"http://example.com/data1.zip",\\
	      \verb!     !"http://example.com/data2.tar.gz",\\
	     \verb!    ]!\\
		\verb!]!,\\
		\color{Red}
		(md5, "d41d8cd98f00b204e9800998ecf8427e")\\
		\color{Purple}
		post\_fetch\_method = \verb![!identity, unpack\verb!]!\\
		\color{Blue}
		))

	\vfill\vfill\vfill\null
	\note{post fetch method and the checksum are applies recursively.
		The checksum xors the hash it if it is not recursed.
		the post fetch method is applied element-wise.}
	\note{Also you can specify the function used to generate the checksum}
\end{frame}


\section{DataDepGenerators.jl}

\begin{frame}[fragile]{Developers still have to write registration blocks}
	\begin{easylist}[itemize]
		@ DataDeps.jl shifts the work from \alert{manually to automatic}
		@ But it still has to be done at once.
		@ Writing a registration block normally means \alert{\mbox{copy-and-pasting}} from a website.
		@@ Even copy pasting a dozen URLs is annoying
		@@ Enough information for \alert{data providence} needs more
	\end{easylist}
\end{frame}


%\newcommand{\datadepsgeneratorsflowcolumn}{}
\begin{frame}[fragile]{}
	\frametitle<1>{For published data this information is available from some API}
	\frametitle<2>{DataDepsGenerators creates static code}
	\begin{columns}
		\begin{column}{0.5\textwidth}
			\only<1>{\begin{itemize}
					\item Title
					\item Author Name
					\item Publication Date
					\item Licensing info
					\item Description
					\item Citation for the linked journal paper
					\item \alert{Download URLs}
					\item \alert{File Hashes}
			\end{itemize}}
			\only<2>{\begin{itemize}
					\vfill
					\item This avoids propagating DataDepsGenerator's many \alert{heavy dependencies}.
					\note{A small bunch of libraries for webscraping and parsing various formats}
					\vfill\vfill\vspace{1cm}
					\item Avoids issue \alert{unstability} of repo APIs/websites
					\vfill
					\note{it breaks if some websites/apis change}
			\end{itemize}}
		\end{column}
		\begin{column}{0.5\textwidth}
			\begin{tikzpicture}[every to/.append style = {ultra thick}]
				\node(indata){Orignal Data};
				\node[draw, below=0.8cm of indata](repo){Repository};
				\node[draw, below=0.8cm of repo](datadepsgen) {DataDepsGenerators.jj};
				\node[draw, below=0.8cm of datadepsgen](datadeps){DataDeps.jl};
				\node(outdata)[below=0.8cm of datadeps]{Data, on your machine};
				
				\draw[bluewrite] (indata) to[right] node {Author uploads} (repo);
				\draw[bluewrite] (repo) to[right] node {Metadata} (datadepsgen);
				\draw[bluewrite] (datadepsgen) to node[xshift=-1mm] {Registration code-block} (datadeps);
				\draw[bluewrite] (datadeps) to node[xshift=2.5mm] {Resolves as required} (outdata);
			\end{tikzpicture}
		\end{column}
	\end{columns}
\end{frame}

\begin{frame}[fragile]{Why DOI's alone are not the answer to broken dataset links:}
	\small
	\begin{easylist}[itemize]
		@ When we say DOI's are persistent we mean they never expire.
		@@ Unlike web URL, you do not have to pay to renew.
		@@ It won't be sold to someone else. It will always refer to your object.
		@ DOI's point to landing pages, not data/paper downloads
		@@ DOI's have attached metadata, but not direct links to the data (not even DataCite DOIs (yet))
		@ A key reason DOI's don't point data/papers is because not all are available online
		@@ Some obviously are pay walled
		@@ But some can't be digitalized at all. E.g. DOI's have been issued to laboratory samples, or to data centres.		
	\end{easylist}
\end{frame}
\begin{frame}[fragile]{DOI's are not the solution, but they are probably part of the solution}
	\begin{easylist}[itemize]
		@ The landing page is still just a website, it's domain name \alert{can expire}
		@@ The data hosting is can expire (and hard-drives can fail).
		@ Did I mention under normal circumstances you can't go from DOI to data URL at all anyway?
		@ Still persistent metadata is also kind of nice to have
		@@ At least if the data goes down you know what was lost, so we can seek it else-where.
		@ Really, though we need to be applying periodic automatic link checking to all URLs we need not to break.
		@@ DataDeps.jl makes that pretty easy, you can just set it up as part of \inlinecode{runtests.jl} and set Travis or AppVeyor to run scheduled tests.
	\end{easylist}
\end{frame}


\begin{frame}[fragile]{GitHub}
	\begin{easylist}[itemize]
		@ $85 \times 10^6$ repositories 
		@@ Some of them are data, (most are not)
		@@ Not a great place for data, but commonly used 
		@ \alert{BuzzFeedNews}: \note{"Mainstream News, responsible data citizens"}
		@@ 1 Repo per dataset
		@ \alert{fivethirtyeight}: \note{Current Affairs site with serious data bent}
		@@ 1 shared Repo with a folder for each dataset \note{which correpond to stories}
		@ We generate URLs pointing at \alert{\url{cdn.rawgit.com}}
		@@ This is backed by \alert{StackPath CDN}
		@@ It is generated to point at the \alert{latest commit} at generation time
	\end{easylist}
\end{frame}


\begin{frame}[fragile]{DataOne}
	\begin{easylist}[itemize]
		@ Data Observation Network for Earth 
		@@ \alert{\textasciitilde  40} Earth and Environment Science repositories
		@@ $1.2 \times 10^6$ Data Files
		@@ Seems to have iffy metadata, varying between nodes.
	\end{easylist}
\end{frame}

\begin{frame}[fragile]{Others}
	\begin{easylist}[itemize]
		@ DataDryad
		@@ Ecological research data
		@@ $7.1 \times 10^4$ Data Files
		@@ $2.2 \times 10^4$ Data Packages
		@ Figshare
		@@ Mostly Figures and Datasets
		@@ $8 \times 10^5$ Files
		@ UCI ML Repository
		@@ $437$ Datasets
		@@ Very commonly used in benchmarking basic ML
		@@ Awful website, zero API
	\end{easylist}
\end{frame}

\begin{frame}[fragile]{DataCite}
	\begin{easylist}[itemize]
		@ $11 \times 10^6$ DOIs issued 
		@@ Mostly to datasets, though they count also figures as data
		@@ If you have a DOI and it points at data, it is probably from DataCite
		@ Problem is all their metadata is missing download URLs
		@@ So user has to add them manually after
		@ This is effectively the final fallback for anything with a DOI.
	\end{easylist}
\end{frame}

%
%
%\begin{frame}[fragile]{Data Repositories}
%\newcommand{\info}[2][]{node[#1,info](#2) {#2}}
%\resizebox{\textwidth}{!}{\begin{tikzpicture}[%
%		layered layout, grow=left, sibling distance=15mm,
%		info/.style={very thick, green!50!black},
%		]
%
%
%\repo{GitHub};
%\repo{538};
%\repo{BuzzFeedNews};
%
%\graph{
%		(GitHub) <- {
%			{{85 million Repos} %
%				<- {{Some of these contain data} %
%				<- {It is not a great place for data, but it is common}},
%			(538) <- {
%					{Data Science driven Current Affairs site},
%					{Each dataset for each story is a folder},
%			},
%			(BuzzFeedNews) <- {
%				{News Site},
%				{One github repo per dataset for a story},
%			},
%			%{We generate urls pointing at \url{https://cdn.rawgit.com/}} %
%			%	<- {for the lasted commit at generation time},
%		};			
%}; %\graph
%
%\end{tikzpicture}}
%\end{frame}

\begin{frame}[fragile]{WordTokenizers.jl}
	\note{Honestly I stole stuff left, right and center for this.}
	Configurable \inlinecode{tokenize}r and \inlinecode{sentence_segment}er.\\
	Abuses \inlinecode{eval} and \alert{\#265} so that you can change the tokenizer being used globally.\\
	Also compatible with externally defined tokenizers like RevTok.jl.
	\vfill	
	Nabbed the original Penn Tokenizer sed-script.\\
	Wrote some code that converts basic \alert{sed language} into \alert{julia AST}.\\
	Ported some of NLTK's tokenizers into sed.
	\vfill

	\vfill
	Rule-based sentence splitter based on Sampo Pyysalo \& Yoshimasa Tsuruoka's perl script.
	\vfill
	Regex is just really good at working with English.	
\end{frame}

\begin{frame}[fragile]{InternedStrings.jl: All these duplicate strings are using all my memory}
	\begin{easylist}[itemize]
		@ Strings are immutable, so we only need one copy of each
		@ We can maintain a pool of \inlinecode{WeakRef}s to each string allocated.
		@ \inlinecode{str = intern(str)}
		@@ Add the \inlinecode{str} to the pool if not already
		@@ replace \inlinecode{str} with an element of the pool
		@ Because the pool only has \inlinecode{WeakRef}s strings can still be garbage collected.
	\end{easylist}
\end{frame}

\begin{frame}[fragile]{MultiResolutionIterators.jl:\\ The structure of a Corpus}
	\begin{easylist}[itemize]
		@ \alert{Corpus}
		@ made up of: \alert{Documents}
		@ made up of: \alert{Paragraphs}
		@ made up of: \alert{Sentences}
		@ made up of: \alert{Words}  or \alert{Tokens}
		@ made up of: \alert{Letters} or \alert{Characters}
	\end{easylist}
\end{frame}


\def\madeupof{$\blacktriangleright$}
\begin{frame}[fragile]{MultiResolutionIterators.jl: Not everyone wants every level of structure}
	\alert{Full corpus structure} is\\
	Documents \madeupof Paragraphs \madeupof Sentences \madeupof Words \madeupof Letters
	\vfill
	
	A \alert{Corpus Linguist} may want\note{studying word usage}\\
	a stream of: Sentences \madeupof Words
	\vfill
	An \alert{Information Retrieval} researcher may want\\
	a stream of: {Documents} \madeupof {Words}
		
	\vfill
	A \alert{char-RNN} language modeller might just want\\
	a stream of Letters
\end{frame}





\end{document}