#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass amsart
\use_default_options true
\begin_modules
theorems-ams
eqs-within-sections
figs-within-sections
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
Bettern 2010-13 several papers were published on word embeedings.
\end_layout

\begin_layout Standard
Turen Et Al.
 Corberta and Weston.
\end_layout

\begin_layout Standard
These word embeddings let us represent words as vectors.
\end_layout

\begin_layout Standard
They showed good locally linear properties, turen 2011.
\end_layout

\begin_layout Standard
King - Queen = Man - Woman.
\end_layout

\begin_layout Standard
This is not really as true as alot of literature makes it out to be.
\end_layout

\begin_layout Standard
Turens experiments in 2011, showed it to be true in 47% of cases.
\end_layout

\begin_layout Standard
Which is High, but not enough to show that simple
\end_layout

\begin_layout Standard
addion and subtraction operators on word vectors, can be used as the 
\begin_inset Quotes eld
\end_inset

Semantic Operators
\begin_inset Quotes erd
\end_inset

 which exist between words.
\end_layout

\begin_layout Standard
Socher 2011ish, showed that Recurresive Tensor Neural Networks could do
 this.
\end_layout

\begin_layout Standard
Socher's work overall focusses on veraious forms of Recursive Neural Networks,
\end_layout

\begin_layout Standard
and how they could be combined to encode relationships between words.
\end_layout

\begin_layout Standard
As a effect, ether direct or indirect these methods produced phrase embeddings.
\end_layout

\begin_layout Standard
It was shown that these phrase embeddings exhibit some constency of localising
 meaning (Sorcer 2011?).
\end_layout

\begin_layout Standard
With similar meaning phrases located close together in vector space.
\end_layout

\begin_layout Standard
---
\end_layout

\begin_layout Standard
The earliest work on creating phrase embeddings has always been tied to
 bag of words models,
\end_layout

\begin_layout Standard
such as Latenet Semantic Analysis.
\end_layout

\begin_layout Standard
<<TALK ABOUT THIS HERE>>
\end_layout

\begin_layout Standard
LSA and dervivitives, was the defintion of Vector Models which is referecd
 in most papers published prior to 2010.
\end_layout

\begin_layout Standard
---
\end_layout

\begin_layout Standard
Microsoft research recently looked at a another bag of word based model.
\end_layout

\begin_layout Standard

\end_layout

\end_body
\end_document
