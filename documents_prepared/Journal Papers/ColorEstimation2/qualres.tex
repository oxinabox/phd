\documentclass[11pt,a4paper]{article}
%\usepackage[author={Lyndon}]{pdfcomment}

\usepackage{booktabs}
\usepackage{tikz}
\usepackage{graphicx}
\usepackage[space]{grffile}


\begin{document}
\def\maincolors{%
	brown-orange,
	orange-brown,	
	yellow-orange,
	orange-yellow,
	brownish green,
	greenish brown,
	bluish grey,
	greyish blue,
	pink-purple,
	purple-pink,
	green,
	greenish,
	purple,	
	purplish,
	brown,
	brownish,
	black,
	grey,
	white%
}

\def\oovcolors{
	%	brownish 1Green,
	%	bluish gray,
	1Brown,
	1Green,
	1Purple,
	gray,
	1Gray%
}


\tikzset{lastline/.style={opacity=1}}
\newcommand{\distfigs}[2]{
	\begin{tikzpicture}[defaultfig]%
	\foreach[count=\mdlii from 0] \mdlfile/\mdlname in #1 {%
		\node at (3.1*\mdlii cm, -1cm) {\sffamily \mdlname};%
		\foreach[count=\colii from 0] \colorname in #2 {%
			\xdef\topy{1.1*\colii}
			\node at (3.1*\mdlii cm, \topy cm) %
			{\includegraphics[height=0.95cm]{%
					figs/demo/dist/\mdlfile/\colorname}%
			};%

		}%
		\xdef\topy{\topy+1}
		\node at (3.1*\mdlii cm, -1cm) {\sffamily \mdlname};%
		\node at (3.1*\mdlii cm, \topy) {\sffamily \mdlname};%
	}%
	%

%	\draw[dashed] (1.555, -1.1) -- (1.555, \topy);%
%	\draw[lastline] (3*1.555,-1.1) -- (3*1.555, \topy);%
%	\draw[dashed,lastline] (5*1.555,-1.1) -- (5*1.555, \topy);%
	%
	\end{tikzpicture}%
}%

\subsection{Qualitative Results}\label{sec:qualitative-results}

\newcommand{\pointfigs}[3]{
	\begin{tikzpicture}%
	\foreach[count=\mdlii from 0] \mdlfile/\mdlname in #1 {%
		\node(fig\mdlfile) at (3.1*\mdlii cm, 0) %
		{\includegraphics[height=#3 cm]{%
				figs/demo/point/\mdlfile/#2}%
		};%
		\node[below = -0.7 of fig\mdlfile] {\sffamily \mdlname};%
		\node[above = -0.75 of fig\mdlfile] {\sffamily \mdlname};%
	}%
	\end{tikzpicture}%
}%


\begin{figure}
	\resizebox{\textwidth}{!}{
		\distfigs{{Direct/{Training Data}, Direct-smoothed/{\shortstack{Non-compositional\\ Baseline}}, SOWE/SOWE, CNN/CNN, GRU/GRU, LSTM/LSTM}}{\maincolors}
	%\distfigs{{Direct/{Training Data}, Direct-smoothed/{\shortstack{Non-compositional\\ Baseline}}, GRU/GRU, LSTM/LSTM}}{\maincolors}
	}
	\caption{Some examples of the output distribution estimates from the models trained on the full dataset} \label{fig:distout1}
\end{figure}

\begin{figure}
	\resizebox{\textwidth}{!}{
		\pointfigs{{Direct/{\shortstack{Non-compositional\\ Baseline}}, SOWE/SOWE, CNN/CNN, GRU/GRU, LSTM/LSTM}}{maincolors}{18}
	}
	\caption{Some examples of the output point estimates from the models trained on the full dataset} \label{fig:pointout}
\end{figure}


To get an understanding of the problem and how the models are performing, we consider some of the outputs of the model for particular cases.
\Cref{fig:distout1} shows examples of distribution estimates, and 
\Cref{fig:pointout} shows similar examples for point estimates.
Both  are  taken  from models trained on  the full training dataset.
It can be seen that the models' outputs using term based estimation are generally similar to the non-term-based \empmodel{}, as is intended.
This shows that the models are correctly fitting to estimate the colors.
It can be noted  that  in general the  colors  are  very good, with  only a few marked exceptions,   discussed in the  following sections, particularly around multi-word colors.
To  the naked  eye,  it is hard to to distinguish  between the outputs of the different models.
The general high quality of the estimates aligns with the strong results found in the quantitative evaluations discussed in \Cref{sec:quantitative-results}.
The example shown  in \Cref{fig:distout1,fig:pointout} serve  to indicate that while the  quantitative results do show that some of the models perform better than  others, the  true visual difference is very small.

\subsubsection{On the effects of word-order}
The different input modules have a different capacity to leverage word-order.
This is reflected in \Cref{fig:distout1,fig:pointout},
when considering the pairs of outputs that differ only in word order, such as \natlang{purple-pink} and \natlang{pink-purple}.
The plots presented for the training data and for the \empmodel{} show that such color name pairs are subtly different but similar.
The SOWE model is unable to take into account word order at all, and so produces identical outputs for all orders.
The CNN models produce very similar outputs but not strictly identical -- spotting the difference requires a very close observation.
This is in-line with the different filter sizes allowing the CNN to effectively use n-gram features, and finding that the unigram features are the most useful.
Both RNN models (GRU and LSTM) produce estimated distributions that visibly depend on the order of words.
It seems that the first term dominates the final output: for example \natlang{greenish brown} is more green, and  \natlang{brownish green} is more brown, contrary to the linguistic understanding.
The RNN outputs are more similar to the color described by first term than any later terms.
We can see that the first term is not solely responsible for the final output however, as \natlang{purple-pink}, \natlang{purple} and \natlang{purplish} (tokenized as \natlang{purple}, \natlang{ish}) are all different.
It is surprising that the RNNs outputs  are dominated by the first term and not the latter terms\footnote{So much so that we double checked our implementation to be sure that it wasn't processing the inputs backwards.}.
This shows that they are  functioning to remember the earlier inputs.
However, they are struggling to attribute the significance of the word order.
Linguistically we would expect the last term to be the most significant:
\natlang{greenish brown} is a shade of brown, not green.
This expectation is reflected in the histogram for the training data.
Although, for many of the order swapped colors the training histograms shown are very similar regardless of the order.



\subsubsection{On the smoothness of the distribution estimates}\label{sec:learnedsmoothness}
In \Cref{fig:distout1} it can be seen that the term-based distribution estimation models are much smoother than the corresponding histograms taken from the  training data.
They are not as smooth as the \empmodel{} which explicitly uses KDE.
However, they are much smoother than would be expected, had the output bins been treated independently.
Thus it is clear that the models are learning that adjacent bins should have similar output values.
This is a common feature of all the training data, no matter which color is being described.
This learned effect is in line with the fact that color is continuous, and is only being represented here as discrete.
We note in relation to this learned smoothness: that while the models capture the highly asymmetrical shapes of most distributions well, they do not do well at capturing small dips.
Larger multi-modes as seen in the achromatic colors such as \natlang{white}, \natlang{grey}, \natlang{black}, \natlang{white}, are captured; but smaller dips such as the hue of \natlang{greenish} being more likely to be on either side of the green spectrum are largely filled in.
In general, it seems clear that additional smoothing of the training data is not required for the neural network based models.
This aligns with the results presented in \Cref{sec:smoothed-results}.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\end{document}