\documentclass[11pt,a4paper]{article}
%\usepackage[author={Lyndon}]{pdfcomment}

\usepackage{booktabs}
\usepackage{tikz}
\usepackage{graphicx}
\usepackage[space]{grffile}


\begin{document}
\def\maincolors{%
	brown-orange,
	orange-brown,	
	yellow-orange,
	orange-yellow,
	brownish green,
	greenish brown,
	bluish grey,
	greyish blue,
	pink-purple,
	purple-pink,
	green,
	greenish,
	purple,	
	purplish,
	brown,
	brownish,
	black,
	white,
	grey%
}

\def\oovcolors{
	%	brownish 1Green,
	%	bluish gray,
	1Brown,
	1Green,
	1Purple,
	gray,
	1Gray%
}


\tikzset{lastline/.style={opacity=1}}
\newcommand{\distfigs}[2]{
	\begin{tikzpicture}%
	\foreach[count=\mdlii from 0] \mdlfile/\mdlname in #1 {%
		\node at (3.1*\mdlii cm, -1cm) {\sffamily \mdlname};%
		\foreach[count=\colii from 0] \colorname in #2 {%
			\xdef\topy{1.1*\colii}
			\node at (3.1*\mdlii cm, \topy cm) %
			{\includegraphics[height=0.95cm]{%
					figs/demo/dist/\mdlfile/\colorname}%
			};%

		}%
		\xdef\topy{\topy+1}
		\node at (3.1*\mdlii cm, -1cm) {\sffamily \mdlname};%
		\node at (3.1*\mdlii cm, \topy) {\sffamily \mdlname};%
	}%
	%

%	\draw[dashed] (1.555, -1.1) -- (1.555, \topy);%
%	\draw[lastline] (3*1.555,-1.1) -- (3*1.555, \topy);%
%	\draw[dashed,lastline] (5*1.555,-1.1) -- (5*1.555, \topy);%
	%
	\end{tikzpicture}%
}%

\subsection{Qualitative Results}\label{sec:qualitative-results}

\newcommand{\pointfigs}[3]{
	\begin{tikzpicture}%
	\foreach[count=\mdlii from 0] \mdlfile/\mdlname in #1 {%
		\node(fig\mdlfile) at (3.1*\mdlii cm, 0) %
		{\includegraphics[height=#3 cm]{%
				figs/demo/point/\mdlfile/#2}%
		};%
		\node[below = -0.7 of fig\mdlfile] {\sffamily \mdlname};%
		\node[above = -0.75 of fig\mdlfile] {\sffamily \mdlname};%
	}%
	\end{tikzpicture}%
}%


\begin{figure}
	\resizebox{\textwidth}{!}{
		\distfigs{{Direct/{Training Data}, Direct-smoothed/{\shortstack{Operational \\ Upper-Bound}}, SOWE/SOWE, CNN/CNN, RNN/RNN}}{\maincolors}
	}
	\caption{Some examples of the output distribution estimations from the models trained on the full dataset} \label{fig:distout1}
\end{figure}

\begin{figure}
	\pointfigs{{Direct/{\shortstack{Operational \\ Upper-Bound}}, SOWE/SOWE, CNN/CNN, RNN/RNN}}{maincolors}{18}
	\caption{Some examples of the output point estimates from the models trained on the full dataset} \label{fig:pointout}
\end{figure}


To get an understanding of the problem and how the models are performing, we consider some of the outputs of the model for particular cases.
For models trained on the full dataset \Cref{fig:distout1} shows examples of distribution estimates, and 
\Cref{fig:pointout} shows similar examples for point estimates.
It can be seen that the model's outputs using term based estimations are generally similar to the non-term-based Operational Upper-Bound, as is intended.
This shows models are correctly fitting to estimate the colors.
This aligns with the strong results found in that quantitative evaluations discussed in \Cref{sec:quantitative-results}.

\subsubsection{Qualitative results on word-order}
The different input modules have different capacity to leverage word-order.
This is reflected in \Cref{fig:distout1,fig:pointout},
when considering the pairs of outputs that differ only in word order, such as \natlang{purple-pink} and \natlang{pink-purple}.
The plots presented for the training data and for the Operational Upper-Bound show that such color name pairs are subtly different but similar.
The SOWE model is unable to take into account word order at all, and so produces identical outputs for all orders
The CNN models produce very similar outputs but not strictly identical -- spotting the difference requires very close observation.
This is in-line with the different filter sizes allowing the CNN to use effectively use n-gram features, and finding that the unigram features are the most useful.
The RNN produces the most strikingly different results.
It seems that the first term dominates the final output: \natlang{purple-pink} is more purple, and  \natlang{pink-purple} is more pink.
We can see that the first term is not solely responsible for the final output however, as \natlang{purple-pink}, \natlang{purple} and \natlang{purplish} (tokenized as \natlang{purple}, \natlang{ish}) are all different.
It is surprising that the RNN is dominated by the first term and not the latter terms.\footnote{So much so that we double checked our implementation to be sure it wasn't processing the inputs backwards.}
This shows the GRU is functioning to remember the earlier inputs.
This is happening too strongly however, as it is causing incorrect outputs.


\subsubsection{On smoothness in learned distribution estimates}\label{sec:learnedsmoothness}
In \Cref{fig:distout1} it can be seen that the term-based distribution estimation models are much smoother than the corresponding histograms taken from the  training data.
They are not as smooth as the Operational Upper-Bound which explicitly uses KDE.
However, they are much smoother than would be expected had the output bins been treated independently.
Thus it is clear that the models are learning that adjacent bins should have similar output values.
This is a common feature of all the training data, no matter which color is being described.
This learned effect is in line with the fact that color is continuous, and is only being represented here as discrete.
We note in relation to this learned smoothness: that while the models capture the highly asymmetrical shapes of most distributions well, they do not do well at capturing small dips.
Larger multi-modes as seen in the achromatic colors such as \natlang{white}, \natlang{grey}, \natlang{black}, \natlang{white}, are captured; but smaller dips such as the hue of \natlang{greenish} being most likely to be either side of the green spectrum are largely filled in.
In general, it seems clear that additional smoothing of the training data is not required for the neural network based models.
This aligns with the results presented in \Cref{sec:smoothed-results}.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\end{document}