\documentclass[twocolumn]{article}
%\documentclass{standalone}
\usepackage{verbatim}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{multirow}
\usepackage{resizegather}

\begin{document}
\renewcommand{\s}{w_{\blacktriangleright}}
\renewcommand{\ss}{w_{\triangleright}}
\newcommand{\e}{w_{\triangleleft}}
\newcommand{\ee}{w_{\blacktriangleleft}}
\newcommand{\W}{\mathcal{W}}

\newcommand{\displayunskip}{\vspace{0pt}}

\subsubsection{Notation}
We will write $w_{i}$ to represent a word from the bag \textbf{$\W$} ($w_i\in \W$), with
arbitrarily assigned unique subscripts. Where a word occurs with multiplicity
greater than 1, it is assigned multiple subscripts, and is henceforth treated as a distinct word.

Each vertex is a sequence of two words, $\langle w_{i},w_{j}\rangle\in\W^{2}$.
This is a Markov state, consisting of a word $w_j$ and its predecessor word $w_i$ -- a bigram.

Each edge between two vertices represents a transition from one state to another which forms a trigram.
The start vertex is given by $\langle\s,\ss\rangle$, and the end by $\langle\e,\ee\rangle$. The pseudowords  $\s,\ss,\e,\ee$ are added during the trigram models' training allowing knowledge about the beginning and ending of sentences to be incorporated.

The GA-TSP districts are given by the sets of all states that have
a given word in the first position. The district for word $w_{i}$
is given by $S(w_{i})\subseteq\W^{2}$, defined as $S(w_{i})=\{\langle w_{i},w_{j}\rangle\,\mid \forall w_{j}\in\W\}$. It is required to visit every district, thus it is required to use every word.
With this description, the problem can be formulated as a MIP optimisation problem.


\subsubsection{Optimization Model}
Every MIP problem has a set of variables to optimise, and a cost function that assesses how optimal a given choice of values for that variable is. The cost function for the word ordering problem must represent how unlikely a particular order is. The variables must represent the order taken. The variables are considered as a table ($\tau$) which indicates if a particular transition between states is taken. Note that for any pair of Markov states $\langle w_{a},w_{b}\rangle,\langle w_{c},w_{d}\rangle$ is legal if and only if $b=c$, so we denote legal transitions as $\langle w_{i},w_{j}\rangle \to \langle w_{j},w_{k}\rangle$.
%
Such a transition has cost:
\begin{gather*}
%$
	C[\langle w_{i},w_{j}\rangle,\langle w_{j},w_{k}\rangle]=-\log\left(P(w_{k}|w_{i},w_{j}\rangle\right)
%$.
\end{gather*} 
%
The table of transitions to be optimized is:
\displayunskip
\begin{gather*}
 \tau[\langle w_{i},w_{j}\rangle,\,\langle w_{j},w_{k}\rangle] = %\\
 \begin{cases}
	 \multirow{2}{*}{1} & \mathrm{if\,transition\,from} \\
	 	                & \langle w_{i},w_{j}\rangle \to \langle w_{j},w_{k}\rangle
	 	                   \;\mathrm{ occurs} \\
                     0  & \mathrm{otherwise}
  \end{cases}
\end{gather*}
%
The total cost to be minimized, is given by
\displayunskip
\begin{gather*}
 C_{total}(\tau)= \sum_{\mathrlap{\!\!\!\!\forall w_i,w_j,w_k \in \W^{3}
 	}}
 	\;\tau[\langle w_{i},w_{j}\rangle,\,\langle w_{j},w_{k}\rangle] \cdot C[\langle w_{i},w_{j}\rangle,\,\langle w_{j},w_{k}\rangle]
\end{gather*}


The probability of a particular path (i.e. of a particular ordering)
is thus given by $P(\tau)=e^{-C_{total}(\tau)}$


The word order can be found by following the links. The function 
$f_\tau(n)$ gives the word that, according to $\tau$ occurs in the $n$th position.
\displayunskip
\begin{comment}
\hspace{-1cm} {\mbox{%
\begin{minipage}{\columnwidth + 0.5cm}
	\begin{align*}%
	f_\tau(1)=&\{w_{a}\mid\tau[\langle\s,\ss\rangle,\langle\ss,w_{a}\rangle]=1\}_{1} \\ %
	f_\tau(2)=&\{w_{b}\mid\tau[\langle\ss,f_\tau(1)\rangle,\langle f_\tau(1),w_{b}\rangle]=1\}_{1} \\%
	f_\tau(n)=& \\%
	{}\span\omit $\underset{\:\:\mathrm{when}\;\; n\ge3 \hfill}{\{w_{c}\mid\tau[\langle f_\tau(n{-}2),f_\tau(n{-}1)\rangle,\langle f_\tau(n{-}1),w_{c}\rangle]=1\}_{1}}$ \ \hidewidth%
	\end{align*}
	\null{ }
\end{minipage}}}
\end{comment}
\begin{gather*}
	f_\tau(1)=\{w_{a}\mid w_a\in\W \wedge \tau[\langle\s,\ss\rangle,\langle\ss,w_{a}\rangle]=1\}_{1}
\end{gather*}
\vspace{-14mm}
\begin{gather*}
f_\tau(2)=\{w_{b}\mid  w_b\in\W \wedge  \tau[\langle\ss,f_\tau(1)\rangle,\langle f_\tau(1),w_{b}\rangle]=1\}_{1}
\end{gather*}
\vspace{-14mm}
\begin{gather*}
f_\tau(n)=\underset{\mathrm{when}\;\; n\ge3 \hfill}{\{w_{c}\mid  w_c\in\W \wedge  \tau[\langle f_\tau(n{-}2),f_\tau(n{-}1)\rangle,\langle f_\tau(n{-}1),w_{c}\rangle]=1\}_{1}}
\end{gather*}
%
The notation $\{\cdot\}_{1}$ indicates taking a singleton set's only element.
The constraints on $\tau$ ensure that each set is a singleton.




\subsubsection{Constraints}
The requirements of the problem, place various constraints on to $\tau$:
%
The Markov state must be maintained: $\forall\langle w_{a},w_{b}\rangle,\langle w_{c},w_{b}\rangle\in\W^{2}$:
\begin{equation*}
w_{b}\ne w_{c} \implies \tau[\langle w_{a},w_{b}\rangle,\,\langle w_{c},w_{d}\rangle]=0
\end{equation*}
%
Every node entered must also be exited -- except those at the beginning and end. \\$\forall\langle w_{i},w_{j}\rangle\in\W^{2}\backslash\{\langle\s,\ss\rangle,\langle\e,\ee\rangle\}$: 
\begin{gather*}%
 \sum_{\mathrlap{\!\!\!\!\forall\langle w_{a},w_{b}\rangle\in\W^{2}}}\tau[\langle w_{a},w_{b}\rangle,\langle w_{i},w_{j}\rangle]
=\sum_{\mathrlap{\!\!\!\!\forall\langle w_{c},w_{d}\rangle\in\W^{2}}}\tau[\langle w_{i},w_{j}\rangle,\langle w_{c},w_{d}\rangle]
\end{gather*}
%
Every district must be entered exactly once. i.e. every word must be placed in a single position in the sequence. $\forall w_{i}\in\W\backslash\{\s,\ee\}$:
\displayunskip
\begin{gather*}
\sum_{\mathclap{\forall\langle w_{i},w_{j}\rangle\in S(w_{i}\rangle}}
\sum_{\mathclap{\substack{\; \\ \;\\ \forall\langle w_{a},w_{b}\rangle\in\W^{2}}}}
\tau[\langle w_{a},w_{b}\rangle,\,\langle w_{i},w_{j}\rangle]=1
\end{gather*}

To allow the feasibility checker to detect if ordering the words is
impossible, transitions of zero probability are also forbidden. i.e. if \mbox{$P(w_{n}|w_{n-2},w_{n-1})=0$} then \mbox{$\tau[\langle w_{n-2},w_{n-1}\rangle,\langle w_{n-1},w_{n}\rangle]=0$}.
These transitions, if not expressly forbidden, would never occur in
an optimal solution in any case, as they have infinitely high cost.


\paragraph{Lazy Subtour Elimination Constraints}

The problem as formulated above can be input into a MIPS solver. However, like similar formulations of the travelling salesman problem, some solutions will have subtours.
As is usual callback are used to impose lazy constraints to forbid such solutions at run-time.  
However, the actual formulation of those constraints are different to a typical GA-TSP.

Given a potential solution $\tau$ meeting all other constraints, we proceed as follows.

The core path -- which starts at $\langle\s,\ss\rangle$
and ends at $\langle\e,\ee\rangle$ can be found. This is done
by practically following the links from the start node, and accumulating
them into a set $T\subseteq\W^{2}$

From the core path, the set of words covered is given by $\W_{T}=\{w_{i}\,\mid\,\forall\langle w_{i},w_{j}\rangle\in T\,\}\cup\{\ee\}$.
If $\mathcal{W_{T}}=\W$ then there are no subtours and the core-path
is the complete path. Otherwise, there is a subtour to be eliminated.

If there is a subtour, then a constraint must be
added to eliminate it. The constraint we define is that there must be a connection from at least one of the nodes in the district covered by the core path to
one of the nodes in the districts not covered.

The districts covered by the tour are given by $S_{T}=\bigcup_{w_{t}\in \W_{T}}S(w_{t})$. The subtour elimination constraint is given by 
\displayunskip
\begin{equation*}
  \sum_{\mathclap{\forall\langle w_{t1},w_{t2}\rangle\in S_{T}}}
  \sum_{\mathclap{\substack{\; \\ \;\\ \forall\langle w_{a},w_{b}\rangle\in\W^{2}\backslash S_{T}}}}
  \tau[\langle w_{t1},w_{t2}\rangle,\langle w_{a},w_{b}\rangle]\ge1
\end{equation*}
i.e. there must be a transition from one of the states featuring a
word that is in the core path, to one of the states featuring a word
not covered by the core path.


This formulation around the notion of a core-path that differs this from typical subtour elimination in a GA-TSP. GA-TSP problems are not generally guaranteed to have any nodes which must occur. However, every word ordering problem is guaranteed to have such a node -- the start and end nodes. Being able to identify the core path allows for reasonably simple subtour elimination constraint definition. Other subtour elimination constraints, however, also do exist.


\end{document}

