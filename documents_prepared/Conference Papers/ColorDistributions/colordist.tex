\documentclass[11pt,letterpaper]{article}
\usepackage{ijcnlp2017}
\def\ijcnlppaperid{***} %  Enter the IJCNLP Paper ID here:

%\ijcnlpfinalcopy % Uncomment this line for the final submission:

\usepackage{newtxtext}
\usepackage[author={Lyndon}]{pdfcomment}

\usepackage{booktabs}
\usepackage{pgfplotstable}



\usepackage{tikz}
\usetikzlibrary{positioning, fit,  shapes.geometric}
\usepackage{graphicx}

\graphicspath{{./figs/}, {./}}

\usepackage[subpreambles=false]{standalone}

\usepackage{amsmath}
\usepackage{mathtools}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\usepackage{verbatim}
\usepackage{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\parencite}{\cite}
\newcommand{\textcite}{\newcite}


%opening
\title{Learning Distributions of Meant Color}
\author{}
\date{}


\begin{document}

\maketitle

\begin{abstract}
When a speaker says the name of a color, the color they picture is not necessarily the same color the hearer imagines.
Color is a grounded semantic task, but that grounding is not a single value, but rather a range of possible values that could be meant.
To handle this case, we predict a estimated distribution of values, for any given description.
This work further generalities to predict distributions for multi-word descriptions never scene during training.

\end{abstract}

\section{Introduction}
When a person says \emph{tan} they may mean a number of colors: From the bronze of a tanned sunbather, to the brown of tanned leather. When they say \emph{green} they may mean anything from \emph{aquamarine} to \emph{forest green}; and \emph{forest green} itself may mean the shades of a rain-forest, or of a fir-wood, or of a particular branded crayon the speaker had as a child.
Thus the color can not be deterministically known from the color name.
However, based on the knowledge of the population's use of the words, a probability distribution as to the color intended can be found.
Here we will disregard issues of illumination and perceived color based on context, to focus on the core problem of the color of a single patch.


The mapping from color name to color could be considered a regression problem. Solving to find a function that when input some text such as ``forest green'', outputs a numerical value in a color space such as HSV or RGB.
However, regression discards information about the distribution.
If the distributions in color space were mono-modal
\footnote{It should be understood that in this paper, when say \emph{mono-modal} or \emph{multimodal} it is meant in the sense of the number of peaks in the probability distribution; not in the sense of the number of modalities of the data -- e.g. multimodal audio-visual data.}
 and symmetric with consistently small variance, then considering the problem as regression with noise would be adequate.
If the distribution were multi-model (e.g. a mixture model), or non-symmetric (e.g. a truncated distribution) or with varying and wide variances, then regression is loosing valuable information and is unable to produce a model that aligns well with reality.
At the other end from regression, is classification.
\pdfcomment{Relate this to McMalan and Stone's use of Convex -- Symstric is a stronger requirement than convex, and monomodal suggests that }

A classifier will output probabilities for each of the possible categories an input could belong to.
By dividing color space into threshold bins, where each bin is its own category.
Then by classifying a color, one gets getting probabilities of it laying in each bin. The output of the classifier defines an empirical distribution in color-space.
Basic classification models consider each category as being distinct and unrelated.
However, we know that if a color name has a high probability of corresponding to a particular point in color space, then it should have a similar probability for other points in that neighbourhood -- this is a notion of continuousness.
A variety of approaches called ordinal regression or ordinal classification exist to handle this case, where there is a order to the categories.
However, there is no natural total ordering of colors.
In Hue-Saturation-Value (HSV) color space; we think of the hue channel 
 as being cyclic: \emph{red}, \emph{orange}, \emph{yellow}, \emph{green}, \emph{blue}, \emph{purple}, and back to \emph{red}.
One solution would be to move to a color-space which is orderable in all channels: for example Red-Green-Blue (RGB).
However, some of these space do not well align to human perception; or exhibit strong correlation between the values on different channels.
Further, to handle non-independence of the channels of color space, it is natural to consider the categories as regions of a 2D or 3D space (Much like a 2D histogram) for bins of two or three color space channels at one.
Again, there is no ordering on such multiple dimensional points.
2D and 3D joint distributions are not investigated in this work, but we note that the extension of this work to such cases is trivial.
So classical ordinal classification methods have limited utility on the problem.

We instead look to helping a normal classifier learn the continuous relationship between adjacent bins by enhancing the training data.
Rather than representing each observation as a one-hot output with the hot cell being the bin it lays in, we represent it as a histogram of values for a continuous probability distribution with the expected value being the original value of the observation.
This can be seen as blurring a one-hot representation.
By adding this blur to all observations, it encourages the classifier to learn at lower level the tied value between the adjunct bins.
For representations of the Saturation and Value channels a truncated Gaussian distribution is used for the representation, restricting the value to between 0 and 1.
For the Hue channel wrapped normal distribution is used
\pdfcomment{Workout how to merge this with descetisation section}



\section{Highly multimodal colors}
One of the core motivating factors of this work is to be able to handle the color names which have multiple distinct modes.
That is to say there are distinct peaks of the most likely region in color space.
This is not the solo motivation -- there is also the important factors of knowing the confidence of a particular sample of color-space, and understanding the other factors of the distribution, eg spread and more general shape.
As well as the linguistic interest in how the modifier words influence the colours, and the capacity to combine terms in ways never seen in the training data.
However, a core interest here is in colors with a multi-modal distribution; such colors can not be considered as targets for regression as they do not have a symmetric "noise" variation around their mode.


\newcommand{\multimodalfig}[1]{
\begin{figure}
	\IfFileExists{figs/multimodal/empiri#1.pdf}	%This is Fragile, might need to replace with a condtion based on arguments
	{\includegraphics[width=\columnwidth]{multimodal/empiri#1}}
	{}

	\includegraphics[width=\columnwidth]{multimodal/gru#1}
	
	\caption{\label{fig#1} #1}
\end{figure}
}
	
\multimodalfig{grey}
\multimodalfig{lightgrey}
\multimodalfig{darkgrey}
\multimodalfig{verylightgrey}
\multimodalfig{verydarkgrey}



One such color with a significant bi-modal distribution is ``grey''.
Traditionally, ``grey'' has been considered to be achromatic -- that is to say its hue component does not matter.
However, by looking at the data from the Monroe dataset \parencite{Monroe2010XKCDdataset} in \Cref{figgrey} it can be seen that that a the hue distribution significantly favors blues and reds over greens and purples.
Further, ``light grey'' increases the yellow peak (\Cref{figlightgrey}), and ``dark grey'' (\Cref{figdarkgrey}) increases the ``blue'' peak, while also changing the value dimension, as expected.
Beyond this, there is no empirical data, however, our GRU model suggests that that the distribution for `very light grey'' would be similar to that of ``light grey'' increases the yellow peak (\Cref{figverylightgrey}), and ``dark grey'' (\Cref{figverydarkgrey}), though we note that this extrapolation without training data seems rather loose it's precision.








 
\section{Related Work}

\subsection{Color Naming}
Color naming is the reverse of the task we investigate in this work.
The color naming task takes a point in color-space as in input, and outputs a probability distribution over possible names for that color.
There a several notable recent works on color-naming.
\cite{mcmahan2015bayesian,meomcmahanstone:color} present a full description Bayesian approach, which outputs the probability of a whole description.
\cite{2016arXiv160603821M} presents a per-word LSTM approach, which produces a conditional language model -- sequentially outputting a probability of each word in the description.
\cite{DBLP:journals/corr/KawakamiDRS16} presents a per-character LSTM and Variational Autoencoder approach, which products a conditional character language model -- sequentially outputting a probability of each character in the description.
This work by Kawakami et al, also includes a method for generating colours.

\subsection{Color Generation}
Color generation closely related to the primary task considered here.
The process of going from the name of a color, to an actual color -- a single point in a color space.
\cite{DBLP:journals/corr/KawakamiDRS16} presents a method using RNN, and LSTM, as well as baselines using unigram and bigrams, over characters, to predict a point in \emph{Lab} color space \cite{hunter1958photoelectric}.
Color generation is the single output version of our task of color distribution estimation.

The work we present here, goes beyond just color generation.
As given a color name, we generate probability distributions in color space,
these distributions can be sampled, or the peaks selected, to generate colours.
However, they have further use, as we have the whole distribution.
For example, as a subsystem in image processing, when asked to select the ``dark bluish green'' object, each object can be ranked based on how likely it's color is according to the distribution.
This way if extra information eliminates the most-likely object, the second most likely object can immediately be determined.
Further, as the probability of the color of the object being the color being described by the user input is known, a threshold can be given to report no object found, or to ask for additional confirmation.

Color generation system systems outputting a single color can approximate this by using the distance in color space, from a observed color to the predicted color as a proxy for the probability of the observed color. However, this does not handle asymmetric, or multimodal distributions, nor does it take into account that the range of values reasonable for one color description, often significantly differs in width from that reasonable for another.

\section{Color Identification}

\textcite{DBLP:journals/corr/MonroeHGP17} presents a neural network solution to communication game, where a is presented with three color patchs and ask to descibe one of them, 
such that when the listener is presented with the same color patchs that can select the one the speaker was describing.
In this game, the color descriptions have context, for example the speaker can say ``the darker blue one, not the cyan''.
Both speaker and listener models are trained, using and LSTM based decoder and encoders respectively.
They present several variants of their models, including pragmatic models, and models that combine knowledge.
The base listener model is of particular relevance to the distribution modelling task.
The final time-step of the base listener LSTM produces a 100 dimensional representation of description provided.
From this, a Gaussian distributed score function, over the Fourier-transform based color-space of \textcite{2016arXiv160603821M}.
By normalizing the scores of the three colors the listener is to choose from, the conditional probability of each can be found.
It should be noted that while this method does output a probability distribution, as a by-product of the task
it is Gaussian distributed for all inputs -- both symmetric and mono-modal, albeit in a high-dimensional non-linear color space.
This is a reasonable distribution for use in this color-game, where the speaker is expressly trying to avoid ambiguity,
and where color descriptions can feature reference to other colors in the context.
Without this contextual information in the color-naming, distributions over all colors are required,
and these distributions are not expected to be symmetric in any consistent color space.

\subsection{Image Generation}
\pdfcomment{move to introduction.}
Recent works on image generation produce very impressive images based on sentence inputs\cite{reed2016generative,2015arXiv151102793M}.
These end-to-end systems take in a sentence and synthesize a full image.
They have been demonstrated to be able to generate images taking into account the colors described.
Like color generation, this is a single output, or a sampling of outputs rather than distribution.
These works show that it is possible to encode complex information about color based on the words being used.


\section{Method}

\section{Blurring and Discretization}
To allow the network to readily learn the distribution of the colors we change the problem from a task of learning a conditional continuous distribution to the well-established problem of learning a conditional discrete distribution.
First we add a blur to each observation.
This is done by defining a distribution with expected value equal to the observation,
and with variance defined as a hyper-parameter of our process.
Saturation and Value are given truncated Gaussian distributions.
Hue is given a wrap-around Gaussian \footnote{In implementation, we initially approximated the wrapped normal distribution with a von Mises distribution with support between 0 and 1; however the CDF for this was computationally expensive; so we switched to a truncated Gaussian with the support between -1 and 2, which allowed for very fast implementation by aliasing the memory locations outside the true value's support of 0 to 1. The difference in value is negligible until variance becomes much large than we consider here.}.
To discretize the distribution, we partition the support into a number of equally sized bins -- the resolution of our output.
We then evaluate the cumulative distribution between each bin boundary, resulting in a vector of values between zero and one -- summing to one.
Functionally, this is very similar to converting to a one-hot representation, based on bin boundaries, but with some blurring to shift part of the mass into adjacent indices.



\section{Conditional Independence Assumption}
For HSV colors we make the assumption that given the name of the color, then the distribution of the H, S and V components are independent.
That is to say, we assume that if knowing the value of one component would not inform us as to the value of the other if we already know the name of the color.
This assumption is incorrect, but not as incorrect as might be suspected.

Superficial checks were carried out the the accuracy of this assumption.
The Spearman's correlation on the training data suggests that for over three quarters of all color names, there is only weak to zero pairwise correlation between the H,S, and V components (\mbox{Q3 < 0.20}).
This was the lowest, when compared amongst 16 color spaces RGB, HSV, HSI, HSL, xyY, XYZ, Lab, Luv, LCHab, LCHuv, DIN99, DIN99d, DIN99o, LMS, YIQ, and YCbCr.
However, this measure underestimates correlation for values that have circular relative value, such as hue.
For the investigation here, we consider the conditional independence assumption sufficient.



Note that the evaluation metrics chosen do not assume conditional independence.
Though the models, including the baseline model, do.
Better results may be obtained by outputting a 3D joint distribution.

The assumption is not intrinsic to our method.
The discretization and blurring function identically in 3D joint distribution space,
as in three, 1D independent distribution spaces.
However, the independence assumption significantly decreases the computational requirements.
For $n$ the resolution (number of bins) used in discretization:
Assuming independence allows use to work with 3 output layers, each containing $n$ elements.
Rather than one output layer containing $n_{res}^3$ elements.
This saves a lot of memory during the training.


\section{The Models}

\subsection{GRU Model}

\begin{figure}
	\resizebox{\columnwidth}{!}{\input{./figs/neuralnet}}

	\caption{\label{network}
		The GRU Model for predicting the color-space probability distributions of color.
		The section in the dotted-boxes is repeated for each time step.
		}
\end{figure}

We present a neural network based model, with sequential inputs which predicts the 3 separate output distributions. The general structure of this network is similar to \cite{2016arXiv160603821M}, or to most other word sequence learning models.
It is shown in \Cref{network}.
Each word first is transformed to an embedding representation.
This representation is randomly initialized and is trained with the rest of the network.
The embedding is used as the input for a Gated Recurrent Unit (GRU) \parencite{cho2014properties,chung2014empirical}.
The output of final time-step is feed to a Rectified Linear Unit (ReLU) \parencite{dahl2013reludropout}.
Finally, the this used as the input the three distinct softmax output layers -- one for each of hue, saturation and value.
The network was trained to minimize to sum of the three cross-entropy losses of these output layers.

We choose GRU as the basis of our reused structure in the recurrent network.
GRU has fewer parameters to learn than the more established LSTM.
It has generally been found to preform similarly well to LSTM \parencite{chung2014empirical};
including on the color naming problem \parencite{2016arXiv160603821M}.
The GRU forms the basis of the our sequence-of-terms to color-space-probability- distribution network.



\subsection{Baseline Model}
For comparison we define an additional model based more directly on the training data --  without the machine learning component.
This is a simpler model with no machine learning component.
For this model, we produce the estimated distribution for each color description simply by averaging all of that colors discretized observations.
This features the same blurring, as in the GRU Model.
During our investigations we found that a model based simply taking on the mean would, for some of observations in the development dataset, return a predicted probability of zero.
This causes the perplexity to be undefined ($\infty$ when evaluated using IEEE Floating point math.)
To handle this we apply add-one smoothing to each color names output distribution.
Effectively this is adding an number number of additional training observations for each color name,
corresponding to a one-hot vectors for each output bin.
The result of this is that when the mean over all observations is taken, there a no output bins with a probability mass of zero.
With this smoothing the Baseline model can be used to predict distributions for all color descriptions in the training set.
This is inferior in generalisability to the GRU model, which can handle any combination of tokens from the training set.
However, without the requirement to learn the how the compositional structure of the terms in the color name function, it is a much simpler modeling problem, as such we suggest it is a strong baseline for evaluational.


\section{Experimental Setup}
\subsection{Data Preparation}
We use the Monroe dataset \parencite{Monroe2010XKCDdataset}, as prepared by McMahan and Stone \parencite{mcmahan2015bayesian}.
This data has minor cleaning, and a standard division into test, development, and training partitions.
It is also used by \textcite{2016arXiv160603821M} and \textcite{DBLP:journals/corr/KawakamiDRS16}.
The color space is HSV, with all values between zero and one.
Each is pair with a short name for the color, and provided by participants in the Color Survey.

The text descriptions are loosely tokenized into separate words and affixes.
Beyond simply breaking up a description ``greenish blue'' into words: ``greenish'', ``blue'', we further separate the suffix as it's own token: ``green'', ``ish'', ``blue''.
We separate the ``-ish'' and the ``-y'' suffixes.
This tokenization is achieved through a short list of word replacement rules.
We also separate `-` into a distinct token. ``blue-green'' becomes ``blue'', ``-'', ``green''.
We do not demarcate the beginning or end of the color description with any for of marker token.

The Monroe dataset has 829 unique color descriptions.
Each description has a varying number of observations, where each observation is a pairing of description and a point in HSV space.
Using the tokenization described above, we break each description into between one and four tokens.
This results in a total of 311 unique tokens.

\subsection{Extrapolation Sub-Dataset}
One of the key advantages of our proposed system is its ability to predict the distribution for never before scene descriptions of colors.
For example, based on the learned understanding of ``bright'', from examples like ``bright green'' and ``bright red'', and of ``salmon'', our system can suggest the distribution in color space of ``bright salmon'', even though that color never occurs in the training data.
To evaluate this, we derive a new dataset from Monroe dataset, which we will call the extrapolation sub-dataset.
To define this, we select the rarest 100 color descriptions,
with the restriction that every token in a selected description must still have at least 8 uses in other descriptions.
The selected examples include multi-token descriptions such as: ``"bright yellow green'' and also some single tokens that occur more commonly as modifiers that as stand alone descriptions: ``pale''.
We restrict the original test and development datasets to contain only observations of these selected color descriptions.
Conversely, we remove all observations of these color descriptions from the training set.
This produces a dataset suitable for evaluating the capacity of our model to extrapolate the distributions for color descriptions not seen in training.

\subsection{GRU Model Parameters}
For the GRU model, regardless of output resolution, we use the same network parameters.
Hidden layer size of 128 neuron for all hidden layers, except the embedding layer, which we give 16 neurons to.
These values were found on a coarse search of the hyper parameters using the development portion of the data set with the output resolution being 64 bins.
These parameters were also used for the 256 bin output resolution, to simplify comparison, though we suggest increasing the hidden layer size would give additional benefit for the higher output resolution case.
We note that accuracy continued to improve as  we increased the size of the hidden layers,
however significantly diminishing returns for the increased computational time to work with the larger layers.
We use dropout \parencite{srivastava2014dropout} with a probability of 0.5, on all hidden layers, except the embedding layer.


\subsection{Evaluation Metrics}
We propose two key measures of evaluation: Perplexity, and Mean Squared Error.
The Perplexity allows us to evaluate how well our estimated distribution matches the distribution of the observations in the test set.
Perplexity is commonly used for evaluating language models, however here it is being used to evaluate the discretized distribution.
It can loosely be through of as to how well the model's distribution does compared to a uniform distribution -- which has a perplexity equal to the number of bins.


We define perplexity per channel of the color-space, and also report the geometric mean of the perplexities, to give the perplexity of the whole space.
For $\tau$ the test-set made up of pairs consisting of a textual color name $t$, and color-space observation $(v_{H}, v_{S}, v_{V})$.
We define $p_{c}(v_{c}\mid t)$ giving the predicted probability of the observation $v_{c}$ being the color described by the color name $t$, in the given channel ${c}$.
This is found by determining which of the discretized bins from the model's output the $v_{c}$ would lay in, and giving the probability mass of that bin.
From this perplexity is given by
\[
 PP_{c}(\tau) = 2^{-\left(
 	\displaystyle\frac{1}{|\tau|} 
 	\displaystyle\sum_{\mathclap{\qquad\qquad\quad
	 		\forall(t,(v_{H}, v_{S}, v_{V})) \in \tau}}
 	 \log_2 p_{c}(v_{c}\mid t)\right)}
\]
We also define the over-all perplexity by the geometric mean: 
\[
PP(\tau) = \sqrt[3]{PP_H(\tau)+PP_S(\tau)+PP_V(\tau)}
\]
As the perplexity varies depending on the output resolution,
we will also consider when comparing models of different resolution the standardized value of $\frac{PP_c(\tau)}{n}$, where $n$ is the output resolution of the model.
Using this standardized perplexity, if the model always output a uniform distribution then no matter the output resolution $n$ it would always be true that  $\frac{PP_c(\tau)}{n}=1.0$.
Perplexity is a measure of how well the distribution estimated by the model, matches reality according to the observations in the test set.


As a second measure, we use the mean squared error to peak (MSE).
This is useful in the mono-modal symmetric case, and allows out model to be compared to regression models.
To do this we fine the bin with the highest probability, according to $p_c(v_c\mid t)$ and then convert it's index into the continuous space value at the center of the bins range.
We then find the mean square error in the transitional way, averaging over channels.
That is to say, with the definitions as before:
\[
binpeak_c(t)=\argmax_{1\le i \le n}{p_c\left(\tfrac{i}{n} \mid t\right)}
\]
\[
peak_c(t)=\frac{binpeak(t)}{n} - \frac{1}{2n}
\]
\[
SE(t, (v_{H}, v_{S}, v_{V})) = \frac{1}{3}
	\sum_{\mathclap{\forall d\in{H,S,V}}} (peak_c(t) - v_d)^2
\]
\[
MSE(\tau) =\frac{1}{|\tau|}
	\sum_{\mathclap{\qquad\qquad\quad
		\forall(t,(v_{H}, v_{S}, v_{V})) \in \tau}}
	 SE(t,(v_{H}, v_{S}, v_{V}))
\]

Then we take the mean over each observation in the test set, of the mean of the squared error in each of the dimensions of the color space.
The space that the error is measured in is the 0-1 scaled HSV space that is used in the source dataset.
This measurement of the error to peak is the error that would be obtained if a single color output was required, and that color was chosen in a greedy way.



\section{Results and Discussion}

\subsection{Blurring Level}
The blurring during the discretization serves two related purposes.
It is both used as prior knowledge to be added to the model, and as a tool to enhance learning.
to enhance learning, and as prior knowledge incorporated into the model. 
The prior knowledge it encodes is the understanding that there is a continuous distribution for the likelihood of a color.
That given the probability of one point in color space, then the probability of another point within the neighborhood, is going to be similar.
There are few sharp jumps in probability.
Its second purpose is to help the model learn the existence of neighborhoods.

By blurring the training samples, we inform the model about the nearness of the discretized outputs.
The outputs from softmax output layer are intrinsically unordered and purely categorical.
By adding blurring the training output, we ensure that the network learns the relationship between the nearby output neurons.
Such that when one is activated, neurons representing  adjacent points in colors space are also activated (to a lesser strength).
By adding this to all training terms this information is trained into the model
A nearly equivalent alternative would be to define the same requirement as an additional term in the loss function, similar to L2-regularization, penalizing the networks that have sharp differenced between adjacent neurons.
This would be more difficult to tune.
We suggest that modifying the training data is a more elegant way to train this information into the model.

However, there is a trade-off, in blurring.
Without any blurring, the training data is one-hot encoded, and we do not get the benefits of encoding prior knowledge about smoothness, nor do we help the model effectively learn the relative position of the neurons.
The more blur that is added the more information is added about the structure of the space,
but the less information is available from each training datum about its precise point.
For example if the blurring made the target output have 5 adjacent neurons valued at \texttt{[0.1, 0.2, 0.4, 0.2, 0.1]}, then the loss from the network outputting a distribution shifted one place to the left, is much less than it would be for a less blurred case: \texttt{[0.01, 0.04, 0.9, 0.04, 0.01]}.
Thus the level of blurring is a hyper-parameter that needs to be set.


To determine the blurring level we conducted a hyper-parameter sweep.
We checked a range of values and evaluated on the development dataset.
We evaluated both for the output resolution of 64 and 256, and both on the full distribution estimation task, and the extrapolation task.
We found that best results for was to set the standard deviation of the distributions used in the discretization process to be $\sigma=\frac{1}{2n}$, where $n$ is the output resolution.
We found an exception to this when checking the blurring hyper-parameters the full task at 256 output bins; in this case $\sigma=\frac{1}{4n}$, however the different was very small.
As such in all further investigations we used a blurring with $\sigma=\frac{1}{2n}$ in all desecration, except as noted otherwise.

Decreasing or increasing the standard deviation from this produced higher perplexity and mean squared error to peak on when evaluated on the development datasets.
The blurring of $\sigma=\frac{1}{2n}$, redistributes the probability mass assigned in the discretization, to the surrounding bins.
For a training point that would be at the center of a bin, this roughly corresponds to 68.3\% of the probably mass assigned to the central bin, 15.7\% assigned to the bin on each side, and the remaining 0.3\% distributed to the remaining bins.
However, in general points are not aligned to the center of bins, so they generate asymmetric training cases.
All results presented here are for this value of the blurring hyper parameter.






\subsection{Qualitative Comparison of the Distribution}

\multimodalfig{yellow}
\multimodalfig{greenishyellow}
\multimodalfig{greenish}



Shown in \Cref{figyellow}, \Cref{figgreenishyellow}, \Cref{figgreenish}, and earlier in \Cref{figgrey}, \Cref{figlightgrey}, \Cref{figdarkgrey}, \Cref{figverylightgrey}, \Cref{figverydarkgrey} are side by-side comparisons of the output of the 64 bin GRU model, compared to the Baseline Model, both with blurring factor of $\frac{1}{128}$.
Overall it can be seen the Baseline model is a lot sharper, with more spikes,
where as the GRU model tends to be much smoother, even though both use the same blurring during discretization.
Close together peaks, seem to be leveled out, with the valley between being filled.
It can be noted in \Cref{figyellow}, \Cref{figgreenishyellow}, \Cref{figgreenish}, that small close peaks tend to be smoothed between.
Where-as more separated peaks, as in the hue component in \Cref{figgrey}, \Cref{figlightgrey}, \Cref{figdarkgrey}, \Cref{figverylightgrey}, \Cref{figverydarkgrey}, more distinct peaks remain separate.
We note that smoothing, by partially filling valleys is functionally similar to the fuzzy rectangles used in the input processing of \textcite{mcmahan2015bayesian}.
Also like in their work, this filling in results in ``greenish'' being filled in.

\begin{figure}
	
	\includegraphics[width=\columnwidth]{highresgreenishlowblur}
	\caption{\label{fighighresgreenishlowblur} The distribution output by GRU model with resolution 256, and blurring $\sigma=\frac{1}{8n}$}
\end{figure}
We did find that when the blurring level was made very small, it was possible to see the two peaks in ``greenish''.
This can be seen in \Cref{fighighresgreenishlowblur}.
However, this comes at the cost of overall worse performance, as the model does not learn about the smoothness of the distribution.





To enhance the capacity to model the different ways a word can be used in a color description we suggest a parsing step could be added prior to any modelling.
This would label each token with a linguistic roll.
We suggest that this would improve the capacity of this, and other related models to handle cases such as ``greenish''.
We note the our model currently performs less than ideally for ``greenish'' as an color description on its own -- it should have two peaks on either side of the green hue.
We suggest that this is because the representation for ``greenish'' in the embedding layer is shared both for its use on its own, and for its use as a modifier to other colors -- eg ``greenish blue''.
Making it difficult for the output final layers to determine the shape of the curve when it is used on its own.
By adding additional role labels by a parsing step these cases could be distinguished and given separate representations.

\subsection{Distribution Estimation}
\pgfkeys{/pgf/number format/.cd, fixed relative,precision=4}
\pgfplotstableset{
	col sep=tab,
	header=has colnames,
	ignore chars={"},
	column type={l},
	every head row/.style={before row=\toprule,	after row=\midrule},
	columns/model/.style={string type},
	columns/resolution/.style={column name=$n$},
	columns/perp/.style={column name=$PP$},
	columns/perphue/.style={column name=$PP_{H}$},
	columns/perpsat/.style={column name=$PP_{S}$},
	columns/perpval/.style={column name=$PP_{V}$},
	columns/perpstd/.style={column name=$\frac{PP}{n}$},
	columns/msetopeak/.style={column name=$MSE$}
}

\begin{table*}
	\centering
	%\resizebox{\columnwidth}{!}{
	\pgfplotstabletypeset[
		every row 2 column 7/.style={
			postproc cell content/.style={@cell content/.add={$\bf}{$}}}
		]{results/full.tsv}
	%}
	\caption{\label{tblresfull} The results of evaluation on the full Monroe color dataset. Here $n$ is the output resolution of the model, $PP$ is the perplexity, and $MSE$ is the mean squared error to the peak of the output distribution.}
\end{table*}

The primary task of estimating the distribution in color-space.
The results as showing in \Cref{tblresfull}.
It can be seen that all models perform similarly.
This shows that the GRU model is fitting correctly.
The predictions of the distribution given by the GRU model based on its input sequence of color tokens,
are as reflective of the real uses, as the predictions from the baseline model model based on counting uses of that exact color name.
We note, across all models that the perplexity for the hue channel is much smaller than for the saturation or value channel.
This suggests that in the data there is more consistency in the hue, associated with a color name, than with the 
This aligns with the notion that people describe color primarily with reference to the hue, rather than the chroma or shade.
It also aligns with the notion that how \emph{dark} for example ``dark blue'' is, is not a precise quantity.
%By a small margin the best performing model, in terms of standardised perplexity, was the GRU with resolution 256.
The GRU model performs similarly to similarly to the baseline, when trained on a full set of color terms with all combinations of terms present in the training data.
The key advantage of the GRU model is its ability to predict a distribution for an unseen combination of colors, we evaluate this using the extrapolation task.

\subsection{Extrapolation}

\begin{table*}
	\centering
	%\resizebox{\columnwidth}{!}{
	\pgfplotstabletypeset[
		every row 0 column 0/.style={
			postproc cell content/.style={@cell content/.add={\it}{}}}
		]{results/extrapo.tsv}
	%}
	\caption{\label{tblresextrapo} The results of evaluation on the full Monroe color dataset. Here $n$ is the output resolution of the model, $PP$ is the perplexity, and $MSE$ is the mean squared error to the peak of the output distribution.}
\end{table*}


A core motivation of using the GRU model is its ability to learn to combine tokens in a description in ways not seen in training.
To evaluate how well the model does at predicting distributions,
we compare a GRU model trained Extrapolation dataset, to the models trained on the full set.
Both the non-extrapolating, and extrapolating models are evaluated on the same set of rare color descriptions,
but the non-extrapolating models are also shown these rare descriptions during training.
The extrapolating model has never been trained on these combinations of color terms,
and instead must use the knowledge of how those color terms influence the colors in other cases.

The results for estimating the distributions for the rare color descriptions in the Extrapolation dataset are shown in \Cref{tblresextrapo}.
It can be seen that the Extrapolation is successful, the results on the Extrapolation sub-dataset are similar to the overall results for the whole dataset in \Cref{tblresfull}.
The non-extrapolating results are better than the extrapolation model results.
This is to be expected, as they have the additional training data for the rare terms.
It in interesting that most of the non-extrapolating results for the extrapolation dataset are better than for the overall dataset in \Cref{tblresfull}.
it can be seen in particular that the non-extrapolating GRU models perform better than the non-extrapolating Baseline models.
This suggests that they are successfully able to transfer the knowledge of the tokens used in other contexts, to the rare uses in the extrapolation dataset, and also while benefiting from the small number of examples of use in the fine-tuning using the small number training case for the rare descriptions.
The baseline model is unable to do this, relying only on the small number of training cases for that exact color description.
This in-particular shows for the Baseline with output resolution of 256.
Given the high number of output bins, and the small number of training case, many bins would be empty.
The GRU model can use its knowledge of the terms in other uses to predict the distribution for bins not seen in training.




\section{Conclusion}
We have presented a method for estimating the probably distribution of colors that may be ascribed an input name.
This methods uses a discretization process based on treating each training point as the center of a Gaussian, or wrap-around Gaussian distribution, and finding the CDF for discrete regions of the color-space.
The blurring in the discretized training points helps the model's softmax output to learn a reasonable continuous probability distribution, as approximated using a discrete distribution.
Working with probability distributions, rather than regression to a single color-space point on color, allows for better handling of colors with observed distributions that are asymmetric, wide variance or multimodal in the color-space -- most colors.

The model learns the compositional structure of a color name, which it is able to use to predict distributions for colors not seen given during training.
The input terms learn separate representations, which are together used to estimate the distribution.
For example: the color ``dirty brown'' does not occur in the training data, but there are many used of ``dirt'', the suffix ``y'' and ``brown'' in other combinations.
So the GRU model can estimate a distribution.






\subsection{Future-work}


The discretization process representing a continuous probability distribution as a discrete distribution is pragmatically effective, but unsatisfying.
We suggest there are avenues for advancement here by the extension of \textcite{magdon1998neural} to handle conditional distributions.



\bibliography{master}
\bibliographystyle{ijcnlp2017nourl}

\end{document}
