\documentclass[11pt,letterpaper]{article}
\usepackage{ijcnlp2017}
\def\ijcnlppaperid{***} %  Enter the IJCNLP Paper ID here:

%\ijcnlpfinalcopy % Uncomment this line for the final submission:

\usepackage{newtxtext}
\usepackage[author={Lyndon}]{pdfcomment}

\usepackage{booktabs}
\usepackage{pgfplotstable}



\usepackage{tikz}
\usetikzlibrary{positioning, fit,  shapes.geometric}
\usepackage{graphicx}

\graphicspath{{./figs/}, {./}}

\usepackage[subpreambles=false]{standalone}

\usepackage{amsmath}
\usepackage{mathtools}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

%\usepackage{microtype}
\usepackage{verbatim}
\usepackage{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\parencite}{\cite}
\newcommand{\textcite}{\newcite}


%opening
\title{Learning Distributions of Meant Color}
\author{}
\date{}


\begin{document}

\maketitle

\begin{abstract}
When a speaker says the name of a color, the color they picture is not necessarily the same color the hearer imagines.
Color is a grounded semantic task, but that grounding is not a single value, but rather a range of possible values that could be intended.
To handle this case, we propose a model that given a input color description such as ``light greenish blue'' produces an estimated probability distribution across HSV color space.
This work presents a method for estimating probability distributions, based on samples using a description processes.
Predicting distributions  is useful beyond regressing to a single output for handling cases where the distribution is not simply a true value plus noise, but rather is actual feature of the population's varying conception featuring wide variance, and a potentially multimodal nature.
We demonstrate a GRU-based neural network learning the grounded compositional semantics of the terms used with in a the color description.
By learning per-term, rather than per whole description, the model is able to predict distributions that for combinations of terms that are not seen in the training data.
The ability to predict distributions is useful as a component in human computer interaction systems.


\end{abstract}

\section{Introduction}
When a person says ``tan'' they may mean a number of colors: From the bronze of a tanned sunbather, to the brown of tanned leather.
When they say ``green'' they may mean anything from ``aquamarine'' to ``forest green'';
 and even ``forest green'' itself may mean the shades of a ``rain-forest'', or of a ``fir-wood''.
Thus the color can not be deterministically known from the color name.
However, based on knowledge of the population's use of the words, a probability distribution as to the color intended can be found.
Here issues of illumination and perceived color based on context will be disregarded, to focus on the core problem of the color of a single patch.


Color understanding is a core subtask in natural language understanding.
The color language sub-domain displays many of the same features and difficulties as natural language as a whole.
Every word has shades of meaning.
No one understands colors exactly the same.
Words occupy multiple roles: ``pale'' can be used to describe a all \emph{pale} colors, or as a modifier: ``pale blue''.
Basic colors themselves can act both as modifiers, and as targets: ``blue green''.
Modifiers do not act on all colors constantly.
New color descriptions are brought in from other sources, such as ``salmon'', and ``coral'' which come from the colors of the objects they describe.
We note the noxious examples of ``puke'', ``vomit'' and ``yuck'' which not only are as consistently used as any color like ``bright orange'', but are also examples of nearly perfect synonyms describing the same area in color-space.
Many of the problems of natural language are exemplified in their use in colors.
Recent state of the art systems for image generation has demonstrated their capacity by generating from texts containing complex color descriptions such as ``the flower has petals that 
are bright pinkish purple with white stigma'' \parencite{reed2016generative, 2015arXiv151102793M}.
Understanding color is crucial to understanding language. 


The mapping from color name to color could be considered a regression problem. Solving to find a function that when input some text such as ``forest green'', outputs a numerical value in a color space such as HSV or RGB.
However, regression discards information about the distribution.
If the distributions in color space were mono-modal
\footnote{It should be understood that in this paper, when say \emph{mono-modal} or \emph{multimodal} it is meant in the sense of the number of peaks in the probability distribution; not in the sense of the number of modalities of the data -- e.g. multimodal audio-visual data. 
\textcite{mcmahan2015bayesian} call this convex, we prefer the term multimodal.
	}
 and symmetric with consistently small variance, then considering the problem as regression with noise would be adequate.
If the distribution were multi-model (e.g. a mixture model), or non-symmetric (e.g. a truncated distribution) or with varying and wide variances, then regression is loosing valuable information and is unable to produce a model that aligns well with reality.
At the other end from regression, is classification.

A classifier will output probabilities for each of the possible categories an input could belong to.
By dividing color space into threshold bins, where each bin is its own category.
Then by classifying a color, one gets getting probabilities of it laying in each bin. The output of the classifier defines an empirical distribution in color-space.
Basic classification models consider each category as being distinct and unrelated.
However, we know that if a color name has a high probability of corresponding to a particular point in color space, then it should have a similar probability for other points in that neighborhood -- this is a notion of continuousness.
A variety of approaches called ordinal regression or ordinal classification exist to handle this case, where there is a order to the categories.
However, there is no natural total ordering of colors.
So classical ordinal classification methods have limited utility on the problem.

We instead look to helping a normal classifier learn the continuous relationship between adjacent bins by enhancing the training data through a blurring process.

The core of this work is mapping from natural language space, to color space.
This goes beyond direct one-to-one color generation.
Given a color name, probability distributions in color space is generated.
These distributions can be sampled, or the peaks selected, to generate colors.
However, they have further use, as the whole distribution is known.
For example, as a subsystem in human interfacing image processing, when asked to select the ``dark bluish green'' object, each object can be ranked based on how likely it's color is according to the distribution.
This way if extra information eliminates the most-likely object, the second most likely object can immediately be determined.
Further, as the probability of the color of the object being the color being described by the user input is known, a threshold can be given to report no object found, or to ask for additional confirmation.



\section{Highly multimodal colors}\label{sec:highly-multimodal-colors}
One of the core motivating factors of this work is to be able to handle the color names which have multiple distinct modes.
That is to say there are distinct peaks of the most likely region in color space.
\textcite{mcmahan2015bayesian} identify ``greenish'' as a convex color, i.e. one with a multimodal distribution.
We further identify several others ``purplish grey'', ``purplish'' and ``blueish'' amongst them to varying extents.
Though this is not true for all ``-ish'' colors: ``reddish'', ``orangish'', ``yellowish'' are .
We also note this for shades of grey -- where hue is traditionally considered not to matter.


\newcommand{\multimodalfig}[1]{
\begin{figure}
	\includegraphics[width=\columnwidth]{multimodal/empiri#1}
	\includegraphics[width=\columnwidth]{multimodal/gru#1}	
	\caption{\label{fig#1} #1}
\end{figure}
}

\multimodalfig{grey}
\multimodalfig{lightgrey}
\multimodalfig{darkgrey}


\pdfcomment{TODO: once I work out which images are being kept, give them captions.}

One such color with a significant bi-modal distribution is ``grey''.
Traditionally, ``grey'' has been considered to be achromatic -- that is to say its hue component does not matter.
However, by looking at the data from the Monroe dataset \parencite{Monroe2010XKCDdataset} in \Cref{figgrey} it can be seen that that a the hue distribution significantly favors blues and reds over greens and purples.
Further, ``light grey'' increases the yellow peak (\Cref{figlightgrey}), and ``dark grey'' (\Cref{figdarkgrey}) increases the ``blue'' peak, while also changing the value dimension, as expected.
Other multimodal colors include ``greenish'' which is less likely to be a pure green, than to be on the blue or yellow side of the color; 
and ``purplish grey'' which has a dip at ``magenta``.
These colors are discussed further in \Cref{resultsdistributions}.

A core interest here is in colors with a multi-modal and asymmetric distributions; such colors can not be considered as targets for regression as they do not have a symmetric noise around their mode.
As such they can not be estimated by using distance in color-space as a proxy for the probability of intent.
 
\section{Related Work}

\subsection{Color Naming}
Color naming is the reverse of the task investigated in this work.
The color naming task takes a point in color-space as in input, and outputs a probability distribution over possible names for that color.
There a several notable recent works on color-naming.
\textcite{meomcmahanstone:color} and \textcite{mcmahan2015bayesian} present a full description Bayesian approach, which outputs the probability of a whole description.
\textcite{2016arXiv160603821M} presents a per-word LSTM approach, which produces a conditional language model -- sequentially outputting a probability of each word in the description.
\textcite{DBLP:journals/corr/KawakamiDRS16} presents a per-character LSTM and Variational Autoencoder approach, which products a conditional character language model -- sequentially outputting a probability of each character in the description.
The work by Kawakami et al, also includes a method for generating colors.

\subsection{Color Generation}
Color generation closely related to the primary task considered here.
The process of going from the name of a color, to an actual color -- a single point in a color space.
\textcite{DBLP:journals/corr/KawakamiDRS16} presents a method using RNN, and LSTM, as well as baselines using unigram and bigrams, over characters, to predict a point in \emph{Lab} color space \cite{hunter1958photoelectric}.
Color generation is the single output version of our task of color distribution estimation.


Color generation system systems outputting a single color can approximate a probability distribution by using the distance in color space, from a observed color to the predicted color as a proxy for the probability of the observed color. However, this does not handle asymmetric, or multimodal distributions, nor does it take into account that the range of values reasonable for one color description, often significantly differs in width from that reasonable for another.

\section{Color Identification}

\textcite{DBLP:journals/corr/MonroeHGP17} presents a neural network solution to communication game, where a is presented with three color patches and ask to describe one of them, 
such that when the listener is presented with the same color patches in randomized order they can select the one the speaker was describing.
In this game, the color descriptions have context, for example the speaker can say ``the darker blue one, not the cyan''.
Both speaker and listener models are trained, using and LSTM based decoder and encoders respectively.
They present several variants of their models, including pragmatic models, and models that combine knowledge.
The base listener model is of particular relevance to the distribution modeling task.
The final time-step of the base listener LSTM produces a 100 dimensional representation of description provided.
From this, a Gaussian distributed score function, over the Fourier-transform based color space of \textcite{2016arXiv160603821M}.
By normalizing the scores of the three colors the listener is to choose from, the conditional probability of each can be found.
It should be noted that while this method does output a probability distribution, as a by-product of the task
it is Gaussian distributed for all inputs -- both symmetric and mono-modal, albeit in a high-dimensional non-linear color space.
This is arguably reasonable distribution for use in this color-game, where the speaker is expressly trying to avoid ambiguity,
and where color descriptions can feature reference to other colors in the context.
Without this contextual information in the color-naming, distributions over all colors are required,
and these distributions are not expected to be symmetric in any consistent color space.



\section{Method}

\section{Blurring and Discretization}
To allow the network to readily learn the distribution of the colors the task is changed from learning a conditional continuous distribution to the well-established problem of learning a conditional discrete distribution.
We discretize to a resolutions of 64, and 256 bins per channel.
For the case of 256 bins per channel, there is effectively no information lost in a discretized representation as the original data was collected using a web interface displaying 24 bit color \parencite{Monroe2010XKCDdataset}.
The discretization process is as follows.

First, a blur is added to each observation.
This is done by defining a distribution with expected value equal to the observation,
and with variance defined as a hyper-parameter of our process.
Saturation and Value are given truncated Gaussian distributions.
Hue is given a wrap-around Gaussian \footnote{In implementation, the wrapped normal distribution was initially approximated with a von Mises distribution with support between 0 and 1; however the calculating cumulative distribution for this was computationally expensive; so it was switched to a truncated Gaussian with the support between -1 and 2, which allowed for very fast implementation by aliasing the memory locations outside the true value's support of 0 to 1. The difference in value is negligible until variance becomes much large than is considered here, as the values become zero far before reaching the ends of the extended supports}.
To discretize the distribution, the support is partitioned into a number of equally sized bins.
The cumulative distribution is evaluated between each bin boundary, resulting in a vector of values between zero and one -- summing to one.
Functionally, this is very similar to converting to a one-hot representation, based on bin boundaries, but with some blurring to shift part of the mass into adjacent indices.

The blurring during the discretization encoded the prior knowledge of the smooth relationship between adjacent output bins.
The outputs from softmax output layer are intrinsically unordered and purely categorical, this relationship must be trained into the network.
By blurring all training cases, it ensures that knowledge learned.
This effectively penalizes the network for outputting very different values for adjacent output bins.
A nearly equivalent formulation could be defined for the loss function, were one-hot output encoding used.
The blurring level is effectively a hyper-parameter in training.

There is a trade-off, in blurring level.
With very small blurring level the model is not informed of the smoothness -- there is no penalty for sharp differences.
With high blurring there is less overall penalty for incorrect predictions,
and the model is unable to fit sharper shaped curves.

To determine the blurring level we conducted a coarse hyper-parameter sweep using the development dataset.
Best results were found for were to set the standard deviation of the distributions used in the discretization process to be $\sigma=\frac{1}{2n}$, where $n$ is the output resolution.
The blurring of $\sigma=\frac{1}{2n}$, redistributes the probability mass assigned in the discretization, to the surrounding bins.
For a training point that would be at the center of a bin, this roughly corresponds to 68.3\% of the probably mass assigned to the central bin, 15.7\% assigned to the bin on each side, and the remaining 0.3\% distributed to the remaining bins.
However, in general points are not aligned to the center of bins, so they generate asymmetric training cases.
All results presented here are for this value of the blurring hyper parameter.
Further tuning of this parameter might enable better results -- particularly using different blurring levels for the difference channels.


\section{Conditional Independence Assumption}
For HSV colors we make the assumption that given the name of the color, then the distribution of the H, S and V components are independent.
That is to say, we assume that if knowing the value of one component would not inform us as to the value of the other if we already know the name of the color.
\pdfcomment{I'm not sure about the use of we and us in this sentence}
This assumption is incorrect, but not as incorrect as might be suspected.


Superficial checks were carried out the the accuracy of this assumption.
The Spearman's correlation on the training data suggests that for over three quarters of all color names, there is only weak to zero maximum pairwise absolute correlation between the H,S, and V components (\mbox{Q3 = 0.187}).
However, this measure underestimates correlation for values that have circular relative value, such as hue.
This correlation measure was the lowest by a large margin  when compared amongst 16 color spaces; RGB, HSV, HSI, HSL, xyY, XYZ, CIELab, Luv, LCHab, LCHuv, DIN99, DIN99d, DIN99o, LMS, YIQ, and YCbCr; by a full 100\%.
The table is available in the supplementary materials.
\pdfcomment{TODO: Add the table to the supplementary matrials}
Given the limitations of the evaluation methodology, these results are suggestive, rather than solidly indicative of the degree of correctness of the conditional independence assumption.
For the investigation here, we consider the conditional independence assumption sufficient.

Note that the evaluation metrics chosen do not assume conditional independence.
Though the models, including the baseline model, do.
Better results may be obtained by outputting a 3D joint distribution.

The conditional independence assumption is not intrinsic to our method.
The discretization and blurring function identically in 3D joint distribution space,
as in three, 1D independent distribution spaces.
However, the independence assumption significantly decreases the computational requirements.
Assuming independence allows the model to be defined with 3 output layers each containing $n$ elements, where $n$ is the output resolution (number of bins).
Rather than one output layer containing $n_{res}^3$ elements.
This saves a large amount of memory during the training.


\section{The Models}

\subsection{GRU Model}

\begin{figure}
	\resizebox{\columnwidth}{!}{\input{./figs/neuralnet}}

	\caption{\label{network}
		The GRU Model for predicting the color-space probability distributions of color.
		The section in the dotted-boxes is repeated for each time step.
		}
\end{figure}

We present a neural network based model, with sequential inputs which predicts the 3 separate output distributions. The general structure of this network is similar to \textcite{2016arXiv160603821M}, or indeed to most other word sequence learning models.
It is shown in \Cref{network}.
Each word first is transformed to an embedding representation.
This representation is randomly initialized and is trained with the rest of the network.
The embedding is used as the input for a Gated Recurrent Unit (GRU)  \parencite{cho2014properties,chung2014empirical}.
The output of final time-step is feed to a Rectified Linear Unit (ReLU)  \parencite{dahl2013reludropout}.
Finally, the this used as the input the three distinct softmax output layers -- one for each of hue, saturation and value.
The network was trained to minimize to sum of the three cross-entropy losses of these output layers.
The multiple output layers commonly occur joint learning and related transfer learning problems.
\pdfcomment{I was sure I had a good citation from something by Bengio for this techneque in transfer learning. But I can't seem to find ti}

We choose GRU as the basis of our reused structure in the recurrent network.
GRU has fewer parameters to learn than the more established LSTM.
It has generally been found to preform similarly well to LSTM \parencite{chung2014empirical};
including on the color naming problem \parencite{2016arXiv160603821M}.
The GRU forms the basis of the our sequence-of-terms to color-space-probability- distribution network.



\subsection{Baseline Model}
For comparison we define an additional model based more directly on the training data.
This is a simpler model with no machine learning component.
For this model, the estimated distribution for each color description is produced by averaging all of that colors discretized observations.
This features the same blurring, as in the GRU Model.
During our investigations we found that a model based only taking on the mean would return a predicted probability of zero for some of observations in the development dataset.
This causes the perplexity to be undefined (or $\infty$ when evaluated using IEEE floating point math.)
To handle this add-one smoothing is applied to each output distribution.
Effectively this is adding an number number of additional training observations for each color name,
corresponding to a one-hot vectors for each output bin.
The result of this is that when the mean over all observations is taken, there a no output bins with a probability mass of zero.
The Baseline model can be used to predict distributions for all color descriptions in the training set.
This is inferior in generalisability to the GRU model, which can handle any combination of tokens from the training set.
Without the requirement to learn the how the compositional structure of the terms in the color name function, it is a much simpler modeling problem, as such we suggest it is a strong baseline for evaluational.


\section{Experimental Setup}
\subsection{Data Preparation}
We use the Monroe dataset \parencite{Monroe2010XKCDdataset}, as prepared by McMahan and Stone \parencite{mcmahan2015bayesian}.
This dataset is partitioned into test, development, and training sets; and has had some cleaning from the original data collected by Randell \textcite{Monroe2010XKCDdataset}.
It is also used by Will \textcite{2016arXiv160603821M} and \textcite{DBLP:journals/corr/KawakamiDRS16}.
\pdfcomment{I'm not sure how to make it clear that the two Monroes involved are not the same person.}
The color space is HSV, with all values between zero and one.
Each is pair with a short name for the color, and provided by participants in the Color Survey.

The text descriptions are loosely tokenized into separate words and affixes.
Beyond simply breaking up a description ``greenish blue'' into words: ``greenish'', ``blue'', the suffixes ``-ish'' and ``-y' are also separated at their own tokens: ``green'', ``ish'', ``blue''.
This tokenization is achieved through a short list of word replacement rules.
Hyphens are also treated as their own tokens: ``blue-green'' becomes ``blue'', ``-'', ``green''.
The beginning and end of the color description is not demarcated with any form of marker token.

The Monroe dataset has 829 unique color descriptions.
Each description has a varying number of observations, where each observation is a pairing of description and a point in HSV space.
Using the tokenization described above, each description is split into between one and four tokens.
This results in a total of 311 unique tokens.

\subsection{Extrapolation Sub-Dataset}
One of the key advantages of our proposed system is its ability to predict the distribution for never before scene descriptions of colors.
For example, based on the learned understanding of ``bright'', from examples like ``bright green'' and ``bright red'', and of ``salmon'', our system can suggest the distribution in color space of ``bright salmon'', even though that color never occurs in the training data.
To evaluate this, a new dataset is derived from Monroe dataset, which we will call the extrapolation sub-dataset.
This is defined by selecting the rarest 100 color descriptions,
with the restriction that every token in a selected description must still have at least 8 uses in other descriptions.
The selected examples include multi-token descriptions such as: ``"bright yellow green'' and also some single tokens that occur more commonly as modifiers than as stand-alone descriptions: ``pale''.
The test and development datasets are restricted to contain only observations of these selected color descriptions.
Conversely, the extrapolation training set has no observations of these color descriptions.
This produces a dataset suitable for evaluating the capacity of our model to estimate the distributions for color descriptions not seen in training.

\subsection{GRU Model Parameters}
For the GRU model, regardless of output resolution the same network parameters are used.
All hidden layers have width 128, except the embedding layer with width 16.
These values were found on a coarse search of the hyper parameters using the development portion of the data set with the output resolution being 64 bins.
These parameters were also used for the 256 bin output resolution, to simplify comparison, though we suggest increasing the hidden layer size would give additional benefit for the higher output resolution case.
During the hyper-parameter search, it was noted that the accuracy continued to improve as hidden layer width was increased,
however significantly diminishing returns in terms of training time vs accuracy lead us to limit the hidden layer sizes.
Dropout \parencite{srivastava2014dropout} with a probability of 0.5 was used during training, on all hidden layers, except the embedding layer.


\subsection{Evaluation Metrics}
We propose two key measures of evaluation: Perplexity, and Mean Squared Error.
The Perplexity allows us to evaluate how well our estimated distribution matches the distribution of the observations in the test set.
Perplexity is commonly used for evaluating language models, however here it is being used to evaluate the discretized distribution.
It can loosely be through of as to how well the model's distribution does compared to a uniform distribution -- which has a perplexity equal to the number of bins.


We define perplexity per channel of the color-space, and also report the geometric mean of the perplexities, to give the perplexity of the whole space.
For $\tau$ the test-set made up of pairs consisting of a textual color name $t$, and color-space observation $(v_{H}, v_{S}, v_{V})$.
We define $p_{c}(v_{c}\mid t)$ giving the predicted probability of the observation $v_{c}$ being the color described by the color name $t$, in the given channel ${c}$.
This is found by determining which of the discretized bins from the model's output the $v_{c}$ would lay in, and giving the probability mass of that bin.
From this perplexity is given by
\[
 PP_{c}(\tau) = 2^{-\left(
 	\displaystyle\frac{1}{|\tau|} 
 	\displaystyle\sum_{\mathclap{\qquad\qquad\quad
	 		\forall(t,(v_{H}, v_{S}, v_{V})) \in \tau}}
 	 \log_2 p_{c}(v_{c}\mid t)\right)}
\]
We also define the over-all perplexity by the geometric mean: 
\[
PP(\tau) = \sqrt[3]{PP_H(\tau)+PP_S(\tau)+PP_V(\tau)}
\]
As the perplexity varies depending on the output resolution,
we will also consider when comparing models of different resolution the standardized value of $\frac{PP_c(\tau)}{n}$, where $n$ is the output resolution of the model.
Using this standardized perplexity, if the model always output a uniform distribution then no matter the output resolution $n$ it would always be true that  $\frac{PP_c(\tau)}{n}=1.0$.
Perplexity is a measure of how well the distribution estimated by the model, matches reality according to the observations in the test set.


As a second measure, we use the mean squared error to peak (MSE).
This is useful in the mono-modal symmetric case, and allows out model to be compared to regression models.
To do this, the output bin with the highest probability according to $p_c(v_c\mid t)$ is found and it's index is used to find the into the continuous space value at the center of the bin's range.
The mean square error is found in the transitional way, averaging over the three channels.
That is to say, with the definitions as before:
\[
binpeak_c(t)=\argmax_{1\le i \le n}{p_c\left(\tfrac{i}{n} \mid t\right)}
\]
\[
peak_c(t)=\frac{binpeak(t)}{n} - \frac{1}{2n}
\]
\[
SE(t, (v_{H}, v_{S}, v_{V})) = \frac{1}{3}
	\sum_{\mathclap{\forall d\in{H,S,V}}} (peak_c(t) - v_d)^2
\]
\[
MSE(\tau) =\frac{1}{|\tau|}
	\sum_{\mathclap{\qquad\qquad\quad
		\forall(t,(v_{H}, v_{S}, v_{V})) \in \tau}}
	 SE(t,(v_{H}, v_{S}, v_{V}))
\]

The space that the error is measured in is the 0-1 scaled HSV space that is used in the source dataset.
This measurement of the error to peak is the error that would be obtained if a single color output was required, and that color was chosen in a greedy way.


\subsection{Implementation}
The implementation of the models and all evaluations was made in the julia programming language \parencite{Julia},
using the bindings for TensorFlow \parencite{tensorflow2015-whitepaper}.
The full source code is included in the supplementary materials.

\section{Results and Discussion}
\subsection{Qualitative Comparison of the Distribution}\label{resultsdistributions}

\multimodalfig{yellow}
\multimodalfig{greenishyellow}
\multimodalfig{greenish}
\multimodalfig{purplishgrey}



Shown in \Cref{figyellow}, \Cref{figgreenishyellow}, \Cref{figgreenish}, \Cref{figpurplishgrey}, and earlier in \Cref{figgrey}, \Cref{figlightgrey}, \Cref{figdarkgrey} are side by-side comparisons of the output of the 64 bin GRU model, compared to the Baseline model.
Overall, it can be seen the Baseline model is a lot sharper, with more spikes,
where as the GRU model tends to be much smoother, even though both use the same blurring during discretization.
Close together peaks, seem to be leveled out, with the valley between being filled.
It can be noted in \Cref{figyellow}, \Cref{figgreenishyellow}, \Cref{figgreenish}, that small close peaks tend to be smoothed between.
Where-as more separated peaks, as in the hue component in \Cref{figgrey}, \Cref{figlightgrey}, \Cref{figdarkgrey} more distinct peaks remain separate.
We note that smoothing, by partially filling valleys is functionally similar to the fuzzy rectangles used in the input processing of \textcite{mcmahan2015bayesian}.
Also like in their work, this filling in results in ``greenish'' being filled in.



\begin{figure}
	
	\includegraphics[width=\columnwidth]{highresgreenishlowblur}
	\caption{\label{fighighresgreenishlowblur} The distribution output by GRU model with resolution 256, and blurring $\sigma=\frac{1}{8n}$}
\end{figure}
We did find that when the blurring level was made very small, it was possible to see the two peaks in ``greenish''.
This can be seen in \Cref{fighighresgreenishlowblur}.
However, this comes at the cost of overall worse performance, as the model does not learn about the smoothness of the distribution.





To enhance the capacity to model the different ways a word can be used in a color description we suggest a parsing step could be added prior to any modeling to tag each token with a linguistic role.
We suggest that this would improve the capacity of this, and other related models to handle cases such as ``greenish''.
The two uses of ``greenish'', as a color and as a modifier (e.g. ``greenish blue'') is currently both supported by the same embedding layer representations.
Leaving the output layers to determine the shape of the curve when it is used on its own.
By adding additional role labels by a parsing step these cases could more easily be distinguished and given separate representations.

\subsection{Distribution Estimation}
\pgfkeys{/pgf/number format/.cd, fixed relative,precision=4}
\pgfplotstableset{
	col sep=tab,
	header=has colnames,
	ignore chars={"},
	column type={l},
	every head row/.style={before row=\toprule,	after row=\midrule},
	columns/model/.style={string type},
	columns/resolution/.style={column name=$n$},
	columns/perp/.style={column name=$PP$},
	columns/perphue/.style={column name=$PP_{H}$},
	columns/perpsat/.style={column name=$PP_{S}$},
	columns/perpval/.style={column name=$PP_{V}$},
	columns/perpstd/.style={column name=$\frac{PP}{n}$},
	columns/msetopeak/.style={column name=$MSE$}
}

\begin{table*}
	\centering
	%\resizebox{\columnwidth}{!}{
	\pgfplotstabletypeset[
		every row 2 column 7/.style={
			postproc cell content/.style={@cell content/.add={$\bf}{$}}}
		]{results/full.tsv}
	%}
	\caption{\label{tblresfull} The results of evaluation on the full Monroe color dataset. Here $n$ is the output resolution of the model, $PP$ is the perplexity, and $MSE$ is the mean squared error to the peak of the output distribution.}
\end{table*}

The primary task here is the estimation the distribution in color-space for a given color description.
The results are shown in \Cref{tblresfull}.
It can be seen that all models perform similarly.
This shows that the GRU model is fitting correctly.
The GRU model basing on its input sequence of color tokens,
reflects real use of the terms in the test set; 
equally well as the non-compositional Baseline, that counts exact uses of whole descriptions.
Across all models, the perplexity for the hue channel is much smaller than for the saturation or value channels.
This suggests that in the data there is more consistency in the hue, associated with a color name, than with the 
This aligns with the notion that people describe color primarily with reference to the hue, rather than the shade.
It also aligns with the notion that how \emph{dark} for example ``dark blue'' is, is not a precise quantity.
%By a small margin the best performing model, in terms of standardised perplexity, was the GRU with resolution 256.
The GRU model performs similarly to similarly to the baseline, when trained on a full set of color terms with all combinations of terms present in the training data.
The key advantage of the GRU model is its ability to predict a distribution for an unseen combination of colors, this is evaluated using the extrapolation task.

\subsection{Extrapolation}

\begin{table*}
	\centering
	%\resizebox{\columnwidth}{!}{
	\pgfplotstabletypeset[
		every row 0 column 0/.style={
			postproc cell content/.style={@cell content/.add={\it}{}}}
		]{results/extrapo.tsv}
	%}
	\caption{\label{tblresextrapo} The results of evaluation on the full Monroe color dataset. Here $n$ is the output resolution of the model, $PP$ is the perplexity, and $MSE$ is the mean squared error to the peak of the output distribution.}
\end{table*}


A core motivation of using the GRU mode, over the Baseline, is its ability to learn to combine tokens in a description in ways not seen in training.
To evaluate how well the model does at predicting these distributions,
we compare a GRU model trained on e the extrapolation sub-dataset, to the models trained on the full dataset.
Both the non-extrapolating, and extrapolating models are evaluated on the same set of rare color descriptions,
but the non-extrapolating models are also shown these rare descriptions during training.
The extrapolating model has never been trained on these combinations of color terms,
and instead must use the knowledge of how those color terms influence the colors in other cases.

The results for estimating the distributions for the rare color descriptions in the extrapolation sub-dataset are shown in \Cref{tblresextrapo}.
It can be seen that the extrapolation is successful, the results on the extrapolation sub-dataset are similar to the overall results for the whole dataset in \Cref{tblresfull}.
The non-extrapolating results are better than the extrapolation model results.
This is to be expected, as they have the additional training data for the rare terms.
It in interesting that most of the non-extrapolating results for the extrapolation sub-dataset are better than for the overall dataset in \Cref{tblresfull}.
it can be seen in particular that the non-extrapolating GRU models perform better than the non-extrapolating Baseline models.
This suggests that they are successfully able to transfer the knowledge of the tokens used in other contexts, to the rare uses in the extrapolation sub-dataset, and also while benefiting from the small number of examples of use in the fine-tuning using the small number training case for the rare descriptions.
The baseline model is unable to do this, relying only on the small number of training cases for that exact color description.
This in-particular shows for the Baseline with output resolution of 256.
Given the high number of output bins, and the small number of training case, many bins would be empty.
The GRU model can use its knowledge of the terms in other uses to predict the distribution for bins not seen in training.




\section{Conclusion}
We have presented a method for estimating the probably distribution of colors that may be ascribed an input name.
This methods uses a discretization process based on treating each training point as the center of a Gaussian, or wrap-around Gaussian distribution, and finding the probability distribution for discrete regions of the color-space.
The blurring in the discretized training points helps the model's softmax output to learn a reasonable continuous probability distribution, as approximated using a discrete distribution.
Working with probability distributions, rather than regression to a single color-space point on color, allows for better handling of colors with observed distributions that are asymmetric, wide variance or multimodal in the color-space -- most colors.

The model learns the compositional structure of a color name, which it is able to use to predict distributions for colors not seen given during training.
The input terms learn separate representations, which are together used to estimate the distribution.
For example: the color ``dirty brown'' does not occur in the training data, but there are many used of ``dirt'', the suffix ``y'' and ``brown'' in other combinations.
So the GRU model can estimate a distribution.



\subsection{Future-work}


The discretization process representing a continuous probability distribution as a discrete distribution is pragmatically effective, but unsatisfying.
We suggest there are avenues for advancement here by the extension of \textcite{magdon1998neural} to handle conditional distributions.



\bibliography{master}
\bibliographystyle{ijcnlp2017nourl}

\end{document}
