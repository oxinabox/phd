I feel this is interesting:

 in http://jmlr.org/proceedings/papers/v32/le14.pdf : the paper where PV-DM and PV-DBOW come from,
it is argued that: "The good performance demonstrates the merits of Paragraph Vector in capturing the semantics of paragraphs. In fact, paragraph vectors have the potential to overcome many weaknesses of bag-of-words models"

The URAE paper http://www.socher.org/uploads/Main/SocherHuangPenningtonNgManning_NIPS2011.pdf talks about the model capturing semantic and syntactic information.

This paper: http://cs.umd.edu/~miyyer/pubs/2014_nips_generation.pdf
is based around the principle that "Distributed vector space models have recently shown success at capturing the semantic meanings of words [2, 15, 14], phrases and sentences [18, 16, 12], and even full documents [13,3]"
(It uses an extension of the URAE). If meaning is not being captured this method or any like it can not work on full scale (beyond the  4 word sentences shown on).

The information captured can't be sentence semantics.
It could be syntax, or topic (via word semantics perhaps).
It is definitely good and useful information for the applications in which they are being used practically.
