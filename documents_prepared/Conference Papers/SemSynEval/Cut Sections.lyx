#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
While these models perform very well at related practical tasks, our assessment
 highlights some of their limitations.
 It suggests that calling the vector space the models embed into a syntactic
 space is misleading.
 The space clearly incorporates elements of syntax and word choice, as well
 as meaning.
 This result is not surprising and indeed some papers (including 
\begin_inset CommandInset citation
LatexCommand cite
key "SocherEtAl2011:PoolRAE"

\end_inset

) do refer to the space this way.
 The new method does make its truth substantially clearer.
 Currently methods using sentence embeddings for tasks such as summarization
 and translation are limited.
 Some work in summarization has been done such as 
\begin_inset CommandInset citation
LatexCommand cite
key "yogatamaextractive"

\end_inset

 and in 
\begin_inset CommandInset citation
LatexCommand cite
key "KaagebExtractiveSummaristation"

\end_inset

.
 Current applications of sentence embeddings to translation are ever more
 limited, though word and short-phrase embeddings have been used successfully,
 as in 
\begin_inset CommandInset citation
LatexCommand cite
key "zou2013bilingual"

\end_inset

 and 
\begin_inset CommandInset citation
LatexCommand cite
key "gao2014learning"

\end_inset

.
 Models which perform poorly at sentiment classification, are expected to
 perform poorly at these tasks also.
 This expectation seems partially confirmed by the poor performance of the
 U-RAE in the summarization of 
\begin_inset CommandInset citation
LatexCommand cite
key "KaagebExtractiveSummaristation"

\end_inset

, though the sum of word vectors did not perform significantly better in
 that task.
 Successfully encoding meaning will allow for significant advancements in
 these areas.
\end_layout

\end_body
\end_document
