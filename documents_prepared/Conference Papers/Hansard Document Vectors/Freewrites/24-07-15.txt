Ok,
so here is the idea.

We know from old papers into english that 
context changed with semantic meaning.
Even for anytonyms apparently -- counter intutitively.

However, while that applies to natural sentences,
found in corpora,
it is not a nesciary truth of semantic meaning.
and indeed for familiar words,
we have no issues with them being used out of context.
Say by a person not a native speaker,
or by someone using a particularly arward turn of phrase.

While they may  be uncommon, 
they don't always sound oviously wrong, as otherwise it would be well understood that they do.


So how does this affect machine learning alogirthms?

The equivlence between contextual similarity and semantic meaning is what makes 
most word embeddings work.

Is it what should be making sentence embeddings work?
Perhaps not.


It is theorised that humans learn the meaning of words from context,
just like out word embeddings.


If the syntetically generated sentences were wrong...
Synthetically generated sentences may be unnatural,
but not wrong.

I would like to check if the rareness of similar context for antonyms,
is infact just an artifact of the rareness of similar contexts at all.

As found earlier, nontrivial syntactic structures almost never repeat.
Language is as language does.
