\documentclass[twoside,11pt]{article}
\usepackage{jmlr2e}

%%%%%%%%%%%
%Graphics
\usepackage[dvinames]{xcolor}
\usepackage{graphicx}
\usepackage{tikz}
\usetikzlibrary{positioning,arrows,shapes}
\tikzset{
	every picture/.style={/utils/exec={\sffamily}},
	every matrix/.style={ampersand replacement=\&, rounded corners=10pt},
	every node/.style = {font=\small, inner sep = 3},
	>=latex
}
%%%%%%%%%%%

\usepackage{enumitem}
\setlist{nosep}

\newcommand{\datadep}[1]{\texttt{datadep"{}#1"{}}}


\usepackage{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% Heading arguments are {volume}{year}{pages}{date submitted}{date published}{paper id}{author-full-names}
%\jmlrheading{1}{2000}{1-48}{4/00}{10/00}{meila00a}{Marina Meil\u{a} and Michael I. Jordan}

% Short headings should be running head and authors last names

\ShortHeadings{DataDeps.jl}{White et. al.}
\firstpageno{1}

\begin{document}

\title{DataDeps.jl: Repeatable Data Setup for Reproducible\\ Data Science}
\author{%
	\name Lyndon White \email lyndon.white@research.uwa.edu.au\\
	\name Roberto Togneri \email roberto.togneri@uwa.edu.au\\
	\name Wei Liu \email wei.liu@uwa.edu.au\\
	\name Mohammed Bennamoun \email mohammed.bennamoun@uwa.edu.au\\
	The University of Western Australia 
}
\editor{}


\maketitle

\begin{abstract}
	We present DataDeps.jl: a julia package for the reproducible handling of static datasets to enhance the repeatability of scripts used in the data and computational sciences.
	It is used to automate the data setup part of running software which accompanies a paper to replicate a result.
	This step is commonly done manually, which expends time and allows for confusion.
	This functionality is also useful for other packages which require data to function (e.g. a trained machine learning based model).
	DataDeps.jl simplifies extending research software by automatically managing the dependencies and makes it easier to run another author's code, thus enhancing the reproducibility of data science research.
\end{abstract}

\begin{keywords}
data management;  reproducible science; continuous integration, JuliaLang
\end{keywords}

\section{Introduction}

In the movement for reproducible sciences there have been two key requests upon authors:
\textbf{1.} Make your research code public, \textbf{2.} Make your data public \citep{lookafterdata}.
In practice this alone is not enough to ensure that results can be replicated.
To get another author's code running on a your own computing environment is often non-trivial.
One aspect of this is the data setup step: how to acquire the data, and how to connect it to the code.

DataDeps.jl simplifies the data setup step for software written in Julia \citep{Julia}.
It allows the code to depend on data, and have that data automatically downloaded as required.
DataDeps.jl is a compact tool with a single job, following the unix philosophy of doing one job well.
It increases replicability of any scientific code that uses data.
It provides easy to use methods to orchestrate the data setup thus making it simple ot create software that works on a new system without any user effort.
While it has been argued that the direct replicability of executing the author's code is a poor substitute for independent reproduction \citet{drummond2009replicability},
we maintain that being able to run the original code is important for understanding, for extension, and for future comparisons.


\citet{VabdewakkeReproduceableResearch} distinguishes six degrees of replicability for scientific code.
To achieve either of the two highest levels
requires that ``The results can be easily reproduced by an independent researcher with at most 15 min of user effort''.
It is our experience that one can  expend much of that time just on setting up the data.
This involves reading the instructions, locating the download link, transferring it to the right location, extracting an archive, and identifying how to inform the script as to where the data is located.
These tasks are automatable and therefore should be automated; to save user time and remove the opportunity for mistakes, as per the key practice identified by \citet{10.1371/journal.pbio.1001745} ``let the computer do the work''.

Automating the data setup is part of achieving full automation of the setup in a new environment.
DataDeps.jl handles the data dependencies, while Pkg
 and BinDeps.jl\footnote{\url{https://docs.julialang.org/en/stable/stdlib/pkg/}, \url{https://github.com/JuliaLang/BinDeps.jl}}
 (etc.) handle the software dependencies.
This makes automated testing possible, e.g., using services such as 
TravisCI or AppVeyor.\footnote{\url{https://travis-ci.org/}, \url{https://ci.appveyor.com/}}
Automated testing is already ubiquitous amongst julia users, but rarely for parts where data is involved.
If the full deployment process can be automated, much more testing can be run on a clean continuous integration environment.


\section{DataDeps.jl}
\subsection{Three common issues about research data}\label{sec:issues}
DataDeps.jl is designed around solving common issues researchers have with their file-based data.
The three key problems that it is particularly intended to address are:

\begin{description}
	\item[Storage location:] Where do I put it? \label{itm:where}
	Should it be on the local disk (small) or the network file-store (slow)?
	If I move it, am I going to have to reconfigure things>
	\item[Redistribution:] I don't own this data, am I allowed to redistribute it? \label{itm:ownredistribute} 
	How will I give credit, and ensure the users know who the original creator was?
	\item[Replication:] How can I be sure that someone running my code has the same data?
	What if they download the wrong data, or extract it incorrectly?
	What if it gets corrupted or modified?
\end{description}

\subsection{Similar Tools}
For python: Quilt\footnote{\url{https://github.com/quiltdata/quilt}} is a loosely similar tool.
In contrast to DataDeps.jl quilt uses a centralised data-store, to which users upload the data, and they can then download and install the data as a software package.
Uploading the data to the centralised Quilt data store \textbf{Redistribution} issues are made worse, further it is a single point of failure, that can not be easily replaced.
If the Quilt server goes down all packages depending on quilt break, and it can not be fixed without recreating all of Quilt's  infrastructure
If an original URL referenced using DataDeps.jl goes down, only software using that URL breaks, and it can be fixed by rehosting the data at a new URL and updating.

Quilt does offer a number of advantages over DataDeps.jl:
additional convince methods for the file formats quilt can parse,
and also handling data versioning.
At present DataDeps.jl does not handle versioning, being more focused on static data.

\subsection{Ecosystem}

\begin{figure}
	\centering
	\resizebox{!}{0.15\paperheight}{%
		\begin{tikzpicture}[]
		\node[ellipse, thick, draw, inner sep = 3] (datadeps) {\textbf{DataDeps.jl}};
		\node[matrix, xshift=3cm, below right = 0.5 of datadeps, draw, column sep=15, row sep=7] (datasetpackages) {
			\node{\textbf{Dataset packages}}; \\
			\node[draw,ellipse]{MLDatasets.jl};\\
			\node[draw,ellipse]{CorpusLoaders.jl}; \\
			\node{\phantom{M} \ldots \phantom{M}};\\
		};
		\node[matrix, xshift=-3cm, below left = 0.5 of datadeps, draw, column sep=15] (packages) {
			\node{\textbf{Packages}}; \\
			\node{\textbf{needing data}}; \\
			\node[draw,ellipse]{WordNet.jl}; \\
			\node{\phantom{M} \ldots \phantom{M}};\\
		};
		\node[ellipse, draw, inner sep = 3, below = 3 of datadeps] (researchcode) {Research Scripts/Software};
		
		\path[->,draw] (datadeps) edge node[sloped,above]{raw data} (packages);
		\path[->,draw] (packages) edge node[sloped,above]{functionality} (researchcode);
		
		\path[->,draw] (datadeps) edge[above] node[sloped,above]{raw data} (datasetpackages);
		\path[->,draw] (datasetpackages) edge[above] node[sloped,above, xshift=-0.2cm, yshift=0.1cm]{processed/loaded data} (researchcode);
		
		\path[->,draw] (datadeps) edge node[sloped,above]{raw data} (researchcode);	
		\end{tikzpicture}
	}
	\caption{How DataDeps.jl fits into the package ecosystem around data. The referenced packages currently exist and are using DataDeps.jl.\label{fig:eco}}
\end{figure}

DataDeps.jl is part of a package ecosystem as shown in \Cref{fig:eco}.
DataDeps.jl can be used directly by research software, to access the data they depend upon for e.g. evaluations.
For many standard datasets, packages such as MLDatasets.jl\footnote{\url{https://github.com/JuliaML/MLDatasets.jl}}
 provide more convenient accesses with suitable preprocessing.
These dataset loading packages currently use DataDeps.jl as a back-end.
Research code also might use DataDeps.jl indirectly by making use of packages, such as WordNet.jl\footnote{\url{https://github.com/JuliaText/WordNet.jl}}
 (see \Cref{sec:research-tool-wordnetjl}), which currently use DataDeps.jl to load the data they depend on.
Packages and research code alike depend on data, and DataDeps.jl exists to fill that need.


\subsection{Functionality}
A data dependency is defined using a registration block.
The information in this block is used to solve the issues highlighted in \Cref{sec:issues}.
This code normally consists of:
\begin{description}
	\item[Name] used to refer to the dependency in code, as in the described \datadep{NAME}. 
	This solves the \textbf{Storage Location} issues, as the data is referred to by name, not by path.
	\item[Remote path] to fetch the data from. By fetching the data issues of \textbf{Redistribution} are avoided, as data is not being redistributing data with the code, but fetched using the normal links.
	\item[Message] to be displayed to the user before any download occurs:  allowing the user to be informed of the data's true origin, with other key information such as papers to be cited. This prompt solves the  \textbf{Redistribution} concern of giving proper credit.
	\item[Checksum] for the files being fetched. This solves the \textbf{Replication} issue of ensuring the data that the user receives is exactly as it was when the script was created.
	\item[Post fetch method] to be executed on the fetched files. Most commonly this is used to unpack an archive, but it can also be used to perform preprocessing. This allows complete automation, avoiding the \textbf{Replication} issues related to user mistakes.
\end{description}
\noindent The registration block is effectively executable metadata, instructing on how to obtain the data.

Once the data dependency has been declared using the registration block, it can be referred to by name using a datadep string, written \datadep{Name}.
It can be treated just like it were an absolute path to the data, however it is actually a string macro.
At compile time it is replaced with a block of code which performs the operation shown in \Cref{fig:block}.
The value of this expression is always an absolute path string to the data, even that means the data must be download and placed at that path first.


\begin{figure}
	\resizebox{\textwidth}{!}{
		\begin{tikzpicture}[every text node part/.style={align=center}, auto,node distance=2, ->,
		every edge/.append style={every node/.style={font=\footnotesize}}]
		
		
		\node[blue](start) {\datadep{Name}\\ \textbf{Evaluated}}; 
		
		\node[draw, rectangle, right= 0.5 of start] (search) {0.\\Search\\ \texttt{Load Path}};
		\node[draw, rectangle, above right= of search] (msg) {1.\\Display\\ message};
		\node[draw, rectangle, right= of msg] (fetch) {2.\\Perform\\ fetch method\\ (download)};
		\node[draw, rectangle, right= of fetch] (checksum) {3.\\Validate\\ using\\ checksum};
		\node[draw, rectangle, right= of checksum] (postfetch) {4.\\Perform \\post fetch method\\ e.g. unpack};
		\node[green!60!black, below right=of postfetch](end) {\textbf{Local Path}\\ \textbf{Returned}};
		
		\path (start) edge (search);
		\path (search)  edge node[sloped,below]{datadep} node[sloped,above]{Not Found}  (msg);
		\path (msg)	edge[below] node{remote paths} node[above]{Accept}  (fetch);
		\path (fetch)	edge[below] node{local paths}  (checksum);
		\path (checksum)	edge node[below]{local paths} node[above]{Succeeded\\/Ignored} (postfetch);
		\path (postfetch)	edge (end);
		\path (search) edge node[above]{Found} node[below]{local path} (end);
		
		
		\path (checksum.north) edge[bend right] node[above] {Failed-Retry} (fetch.north);
		
		\node[red, below right = 0.5 of msg, yshift=-0.6cm] (err1) {\textbf{Abort}};
		\path (msg) edge node[above, sloped]{Decline} (err1);
		
		\node[red, below right = 0.5 of checksum, yshift=-0.6cm] (err2) {\textbf{Abort}};
		\path (checksum) edge node[above, sloped]{Failed}  (err2);
		\end{tikzpicture}
	}
	\caption{The process that is executed when a data dependency is accessed by name.		
		 \label{fig:block}
	}
\end{figure}


DataDeps.jl is primarily focused on public, static data.
For researchers who are using private data, or collecting that data while developing the scripts, a manual option is provided; the registration block here would only include a name and a message. This allows users to manage the data themselves by putting a folder somewhere on the load path. They can still refer to it using the \datadep{Name}.
During publication the researcher can upload their data to an archival repository and update the registration.
The use of archival repositories as the remotepath host should combat URL decay \citep{wren2008url}. In general URLs in DataDeps.jl are just as vulnerable to URL decay as those in manual instructions.
However, periodic automated tests can easily be used to confirm if the URLs remain valid.




\subsection{Case Studies}\label{sec:case-studies}
\paragraph{Research Paper: \citet{White2015BOWgen}}
We criticize our own prior work here, so as to avoid casting aspersions on others. 
While this is our own research, already we have forgotten much of how to set it up and get it running.

Two download links are provided:\footnote{Source code and data provided at \url{http://white.ucc.asn.au/publications/White2016BOWgen/}}
one with just the code, and the other with the code and all 3GB of data.
The data consists of two corpora \citep{francis1979brown,moviebook}, and the pretrained embeddings from \citet{pennington2014glove}.
Including the data massively inflates the size of the download, so a user just wanting to read to the source, for understanding, would not wish to download it.
This is solved by DataDep.jl's feature of only downloading data when (and if) it is required.

The license file included with the software goes to pains to explain which files it covers (the source code) and which it does not (the data), and to explain the ownership of the data.
Using DataDeps.jl the predownload message allows the ownership to be made clear.

The scripts themselves use paths as arguments, with relative paths hard-coded in the the top level script.
This is fairly robust, unless the data is moved to a different folder relative to the scripts.
Using DataDeps.jl to refer to the data by name rather than by path would make it robust against data movement.

\paragraph{Research Tool: WordNet.jl}\label{sec:research-tool-wordnetjl}
WordNet.jl is the Julia binding for the WordNet tool \citep{miller1995wordnet}.
As of PR \#8\footnote{\url{https://github.com/JuliaText/WordNet.jl/pull/8}} it now uses DataDeps.jl.
To function, it depends on having the WordNet database.
Previously, after installing the software using the package manager,
the user had to manually download and set this up.
Any packages depending on WordNet.jl also would inherit this manual setup problem.
Now it is handled automatically.

Previously, the WordNet.jl author expressed common concerns about handling the data.
Concerning including it with the repository inflating the download size, and that in including it with the code it would be placed in an unreasonable location on disk.
They were also worried that redistributing a copy would violate some licensing terms.
DataDeps.jl solved both of these issues.

The prior manual instructions for downloading and extracting the data included multiple points of possible confusion.
The gzipped tarball must be correctly extracted.
The user also had to correctly know that the target directory was the \emph{grand-parent} directory of the database files.
With the setup fully automated, no misunderstanding can occur.


\section {Concluding Remarks}
DataDeps.jl aims to help solve reproducibility issues in data driven research by automating the data setup step.
It is hoped that by supporting good practices, with tools like DataDeps.jl, now for the still young Julia programming language
better scientific code can be written in the future .


\section{Availability and Requirements}
DataDeps.jl works on  Windows 7+, Linux, and Mac OS X, with Julia 0.6.
It depends on HTTP.jl, Reexport.jl, and SHA.jl, which are automatically installed.
The source code, documentation, and issue tracker are at \url{https://github.com/oxinabox/DataDeps.jl}.

\newpage
\bibliography{master}
\end{document}
