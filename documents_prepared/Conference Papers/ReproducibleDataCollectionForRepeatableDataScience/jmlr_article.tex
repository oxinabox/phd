\documentclass[twoside,11pt]{article}\usepackage{jmlr2e}


%%%%%%%%%%%
%Graphics
\usepackage[dvinames]{xcolor}
\usepackage{graphicx}
\usepackage{tikz}
\usetikzlibrary{positioning,arrows,shapes}
\tikzset{
	every picture/.style={/utils/exec={\sffamily}},
	every matrix/.style={ampersand replacement=\&, rounded corners=10pt},
	every node/.style = {font=\small, inner sep = 3},
	>=latex
}
%%%%%%%%%%%

\usepackage{enumitem}
\setlist{nosep}

\newcommand{\datadep}[1]{\texttt{datadep"{}#1"{}}}


\usepackage{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% Heading arguments are {volume}{year}{pages}{date submitted}{date published}{paper id}{author-full-names}
%\jmlrheading{1}{2000}{1-48}{4/00}{10/00}{meila00a}{Marina Meil\u{a} and Michael I. Jordan}

% Short headings should be running head and authors last names

\ShortHeadings{DataDeps.jl}{White et. al.}
\firstpageno{1}

\begin{document}

\title{DataDeps.jl: Repeatable Data Setup for Reproducible\\ Data Science}
\author{
%	\name Lyndon White \email lyndon.white@research.uwa.edu.au\\
%	\addr School of Electical, Electronic and Computer Engineering\\
%	The University of Western Australia\\
%	Crawley, WA 6009, Australia
%	%\AND
}
\editor{}


\maketitle

\begin{abstract}
	We present a framework DataDeps.jl for the reproducible handling of static datasets to enhance the repeatability of software scripts used in the data and computational sciences.
	DataDeps.jl is a library for the Julia programming language.
	It is used to automate the data setup part of running software which accompanies a paper to replicate a result.
	This step is commonly done manually, which expends time and allows for confusion.
	This functionality is also useful for other packages which require data to function (e.g. a trained machine learning based model).
	DataDeps.jl simplifies extending research software via traditional means of a software dependency, as the extension does not have to worry about ensuring the data is setup for its dependency.
	DataDeps.jl makes it easier to rerun another authors code, thus enhancing the reproducibility of data science research.
\end{abstract}

\begin{keywords}
Julia; data; data management;  data dependencies; reproducible science; downloading; computational environment setup; continuous integration; software practices.
\end{keywords}

\section{Introduction}

In the movement for reproducible data and computational sciences there have been two key additional requests from authors:
1. Make your research code public, 2. Make your data public \citep{lookafterdata}.
In practice however, this alone is not enough to ensure that even the purely computational results can be replicated.
To get another author's code running on a new machine is often non-trivial.
One is more likely to see errors preventing the code from running, than in the results.
One aspect of this is the data setup, how to acquire the data, and how to connect it to the code.

DataDeps.jl simplifies the automation of the data setup step for Julia \citep{Julia}  packages and research software.
It allows the code to depend on data, and have that data automatically downloaded as required.
DataDeps.jl is a compact tool with a single job, following the unix philosophy of doing one job well.
It increases repeatability of any scientific code that uses data.
It does this by decreasing the effort to get such a program working on a new system,
while also decreasing the effort to write the code in the first place.


\citet{VabdewakkeReproduceableResearch} distinguishes 6 degrees of reproducibility for scientific code.
To achieve either of the 2 highest levels,
requires that ``The results can be easily reproduced by an independent researcher with at most 15 min of user effort''.
It is our experience that one can often expend much of that time just on setting up the data.
This involves reading the instructions, locating the download link, transferring it to the right location, extracting an archive, and identifying how to inform the script as to where the data is located.
These tasks are automatable therefore should be automated; to save user time, and remove the opportunity for mistakes, as per the key practice identified by \citet{10.1371/journal.pbio.1001745} ``let the computer do the work''.

Automating the data setup is part of achieving full automation of the setup in  a new environment.
DataDeps.jl handles the setup of data dependencies in Julia, while BinDeps.jl (and other packages) handle the binary software dependency.
The automation of the full setup is required to make automated testing possible, for example using Continuous Integration testing services, such as TravisCI or AppVeyor. Automated testing is already ubiquitous in use amongst researchers and developers using Julia, but rarely for parts where data is involved.
If the full setup can be automated, such that it can run on a clean CI environment,
it is almost certain that any human trying to reproduce your work 
using your code will be able to do so with little effort.




\section{DataDeps.jl}
\subsection{Ecosystem}

\begin{figure}
	\centering
	\resizebox{!}{0.15\paperheight}{%
		\begin{tikzpicture}[]
		\node[ellipse, thick, draw, inner sep = 3] (datadeps) {\textbf{DataDeps.jl}};
		\node[matrix, xshift=3cm, below right = 1 of datadeps, draw, column sep=15, row sep=7] (datasetpackages) {
			\node{\textbf{Dataset packages}}; \\
			\node[draw,ellipse]{MLDatasets.jl};\\
			\node[draw,ellipse]{CorpusLoaders.jl}; \\
			\node{\phantom{M} \ldots \phantom{M}};\\
		};
		\node[matrix, xshift=-3cm, below left = 1 of datadeps, draw, column sep=15] (packages) {
			\node{\textbf{Packages}}; \\
			\node{\textbf{needing data}}; \\
			\node[draw,ellipse]{WordNet.jl}; \\
			\node{\phantom{M} \ldots \phantom{M}};\\
		};
		\node[ellipse, draw, inner sep = 3, below = 5 of datadeps] (researchcode) {Research Scripts/Software};
		
		\path[->,draw] (datadeps) edge node{raw data} (packages);
		\path[->,draw] (packages) edge node{functionality} (researchcode);
		\path[->,draw] (datadeps) edge node{raw data} (datasetpackages);
		\path[->,draw] (datasetpackages) edge node[xshift=10]{processed/loaded data} (researchcode);
		\path[->,draw] (datadeps) edge node{raw data} (researchcode);	
		\end{tikzpicture}
	}
	\caption{The package ecosystem using DataDeps.jl. DataDeps.jl can be used directly by research code to produce data; or it can be used indirectly by making use of a package which uses DataDeps.jl to manage its data dependencies. \label{fig:eco}}
\end{figure}

As shown in \Cref{fig:eco}, DataDeps.jl exists as a higher level dependency.
Some research code employing commonly used datasets will not directly use DataDeps.jl at all;
rather it will depend on a dataset loading package such as MLDatasets.jl,
or CorpusLoaders.jl, which in turn use DataDeps.jl as their back-end to actually manage their data.
These dataset packages provide a more friendly access to data that has been cleanly loaded into Julia data structures.
For more obscure, or self-created data sets the research code would employ DataDeps.jl directly, and handle the loading of the data itself.
Finally, DataDeps.jl is also used by packages which require data to perform their functionality.
Examples include WordNet.jl which provides functions for non-trivial lookups on the WordNet \citep{miller1995wordnet} database,
or any packages which require a trained machine-learning based model -- the data in this case being the serialised model.
Packages and research code alike depend on data, and DataDeps.jl exists to fill that need.

\subsection{Three common questions about research data}
DataDeps.jl is designed around solving common issues researchers have with their file-based data.
The three questions it is particularly intended to address are:

\begin{description}
	\item[Storage location:] Where do I put it? \label{itm:where}
	\begin{itemize}
		\item Should it be on the local disk (small) or the network file-store (slow)?
		\item If I move it, I'm going to have to reconfigure things
	\end{itemize}
	\item[Redistribution] Is it ok to include it with my work? \label{itm:ownredistribute} I don't own copyright on this data.
	\begin{itemize}
		\item Am I allowed to redistribute this data?
		\item What if people getting the data from me as part of my experiments don't realize the original creator?
	\end{itemize}
	\item[Replication] How can I be sure someone running my code has the same data?
	\begin{itemize}
		\item It is possible for later users to download the wrong data
		\item It is possible for data to be corrupted, or modified (even maliciously).
	\end{itemize}
\end{description}
These three issues are solved by DataDeps.jl.

\subsection{Functionality}
When declaring a data dependency the developer needs only to declare a data registration block.
For a normal data dependency this is a small piece of code consisting of:

\begin{description}
	\item[Name] used to refer to the dependency in code, as in the described \datadep{NAME}. 
	This solves the \textbf{Storage Location} issues, as will be discussed below data is referred to by name, not by path. The data can be moved to any where on the load path, without changing the code. The load path can be configured using an environment variable, allowing it to differ across environments, by default it includes a very wide range of common locations.
	\item[Remote path] a path or a list of paths (normally URLs) to remote copies of the data. By fetching the data from a remote location, the issues of \textbf{Redistribution} are avoided, as you are not distributing data merely using existing links. This also avoids issues with storing data in version control, which causes problems for many version control systems.
	\item[Message] the message to be displayed to the user before any download occurs, it is followed by requiring user acceptance to continue. This allows the user to be informed of the data's true origin, and display other key info like papers about the data to be cited. Together with fetching from a remote path, this solves the \textbf{Redistribution} issue.
	\item[Checksum] a checksum (or list of checksums) for the files being fetch. Via external packages a wide variety of checksums can be supported, including MD5 and all versions of SHA.
	This, together with the automation of the whole process, solves the \textbf{Replication} issue, 
	ensuring the data the user receives is as it was when the software was developed.
	If the checksum is not provided, then one is calculated, together with a warning that this line should be added to the registration block; allowing the researcher to avoid having to use unfamiliar tools to calculate the checksum.
	\item[Post fetch method] a function  (or list of functions) to call on the fetched files. Most commonly used to unpack an archive. This completes the automation of data setup, contribution towards the \textbf{Replication} issue.
\end{description}
\noindent The registration block is effectively metadata, instructing on how to obtain the data.

Once the data dependency has been declared using the registration block, it can be referred to by name using a datadep string, written \datadep{Name}.
It can be treated just like it were an absolute path to the data, however it is actually a a string macro (related to LISP's reader macro).
At compile time it is replaced with a block of code which performs the operation shown in \Cref{fig:block}.
It always resolves to a being a string to an absolute path to the data, even if that means it must download the data first.



\begin{figure}
	\resizebox{\textwidth}{!}{
		\begin{tikzpicture}[every text node part/.style={align=center}, auto,node distance=2, ->,
		every edge/.append style={every node/.style={font=\footnotesize}}]
		
		
		\node[blue](start) {\datadep{Name}\\ \textbf{Evaluated}}; 
		
		\node[draw, rectangle, right= 0.5 of start] (search) {0.\\Search\\ \texttt{Load Path}};
		\node[draw, rectangle, above right= of search] (msg) {1.\\Display\\ message};
		\node[draw, rectangle, right= of msg] (fetch) {2.\\Perform\\ fetch method\\ (download)};
		\node[draw, rectangle, right= of fetch] (checksum) {3.\\Validate\\ using\\ checksum};
		\node[draw, rectangle, right= of checksum] (postfetch) {4.\\Perform \\post fetch method\\ e.g. unpack};
		\node[green!60!black, below right=of postfetch](end) {\textbf{Local Path}\\ \textbf{Returned}};
		
		\path (start) edge (search);
		\path (search)  edge node[sloped,below]{datadep} node[sloped,above]{Not Found}  (msg);
		\path (msg)	edge[below] node{remote paths} node[above]{Accept}  (fetch);
		\path (fetch)	edge[below] node{local paths}  (checksum);
		\path (checksum)	edge node[below]{local paths} node[above]{Success\\/Ignored} (postfetch);
		\path (postfetch)	edge (end);
		\path (search) edge node[above]{Found} node[below]{local path} (end);
		
		
		\path (checksum.north) edge[bend right] node[above] {Failed-Retry} (fetch.north);
		
		\node[red, below right = 0.5 of msg, yshift=-0.6cm] (err1) {\textbf{Abort}};
		\path (msg) edge node[above, sloped]{Decline} (err1);
		
		\node[red, below right = 0.5 of checksum, yshift=-0.6cm] (err2) {\textbf{Abort}};
		\path (checksum) edge node[above, sloped]{Failed}  (err2);
		\end{tikzpicture}
	}
	\caption{The core process for resolving a data dependency. Each step in the top path is linked to one of the properties declared in the registration block.\label{fig:block}
	}
\end{figure}


DataDeps.jl is primarily focused on public, static data.
For researchers who are using private data, or collecting that data while developing the scripts a manual option is provided; the registration block here would only include a name and a message. This allows users to manage the data themselves by putting a folder somewhere on the load path. They can still refer to it using the \datadep{Name}. If it is not found, the message is displayed which should include instructions on fetching it manually.
Before that research is submitted for publications, the user can upload their data to a repository such as DataDryad, FigShare or another archival repository, and update the registration.

The use of archival repositories as the remotepath host should combat URL decay \citep{wren2008url}. Though it remains that URLs in DataDeps.jl are just as vulnerable to URL decay as those in manual instructions.
Unlike manual instructions however, periodic automated tests can easily be use to confirm if the URLs remain valid.

\section {Concluding Remarks}
DataDeps.jl aims to help solve reproducibility issues in data driven research by automating the data setup step.
It is hoped that by setting up for good practices now for the still young Julia programming language, better scientific code can be written in the future.



\section{Availability and Requirements}
DataDeps.jl is verified to work on  Windows 7+, Linux, Mac OS X, with Julia 0.6.
It depends on HTTP.jl, Reexport.jl, and SHA.jl, which are automatically installed when the package is installed through the normal Julia package manager.
The source code, documentation, and issue tracker can be found at \url{https://github.com/oxinabox/DataDeps.jl}.

\vskip 0.2in
\bibliography{master}
\end{document}
