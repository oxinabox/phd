{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ENV[\"LINES\"] = 30\n",
    "ENV[\"COLUMNS\"] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using Pipe\n",
    "function pz(x :: AbstractArray)\n",
    "    println(typeof(x), \": \", size(x))\n",
    "end\n",
    "macro printval(ee)\n",
    "    ee_expr = @sprintf \"%s\" string(ee)\n",
    "    esc(:(println($ee_expr,\" = \", $ee)))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenize (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using PyCall\n",
    "@pyimport nltk\n",
    "function tokenize(sentence::String)\n",
    "    convert(Array{String,1},nltk.word_tokenize(sentence))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_embeddings (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"load_embeddings.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50,268810)\n",
      "Dict{String,Int64}\n",
      "Array{String,1}\n"
     ]
    }
   ],
   "source": [
    "LL,word_indexes, indexed_words =  load_embeddings(\"embeddings-scaled.EMBEDDING_SIZE=50.txt\");\n",
    "size(LL) |> println\n",
    "word_indexes |> typeof |> println\n",
    "indexed_words |> typeof |> println"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unfold_merges (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typealias Embedding Vector{Number}\n",
    "typealias Embeddings Matrix{Number}\n",
    "typealias Words Union(AbstractArray{ASCIIString,1},AbstractArray{String,1})\n",
    "type RAE\n",
    "    L::Matrix{Number}\n",
    "    word_index::Dict{String,Int}\n",
    "    indexed_words::Vector{String}\n",
    "    \n",
    "    W_e::Matrix{Number}\n",
    "    b_e::Vector{Number}\n",
    "    W_d::Matrix{Number}\n",
    "    b_d::Vector{Number}\n",
    "   \n",
    "end\n",
    "\n",
    "\n",
    "function RAE(L::Matrix{Number},word_index::Dict{String,Int}, indexed_words::Vector{String})\n",
    "    emb_width = size(L,1)\n",
    "    \n",
    "    W_e =0.01*randn(emb_width,emb_width*2) \n",
    "    b_e = 0.01*randn(emb_width) \n",
    "    #W_d = 0.01*randn(emb_width*2,emb_width)\n",
    "    W_d = pinv(W_e) #Cheat (Actually why can't I always do this to initialize?);\n",
    "    b_d = 0.01*randn(emb_width*2)\n",
    "    \n",
    "    RAE(L,word_index, indexed_words, W_e, b_e, W_d, b_d)\n",
    "end\n",
    "\n",
    "\n",
    "function get_word_index(rae::RAE, input::String, show_warn=true)\n",
    "    if haskey(rae.word_index, input)\n",
    "        ii = rae.word_index[input]\n",
    "    elseif haskey(rae.word_index, lowercase(input))\n",
    "        ii = rae.word_index[lowercase(input)]\n",
    "    else\n",
    "        ii = rae.word_index[\"*UNKNOWN*\"]\n",
    "        if show_warn\n",
    "            println(\"$input not found. Defaulting.\")\n",
    "        end\n",
    "    end\n",
    "    ii\n",
    "end\n",
    "\n",
    "\n",
    "function eval_word_embedding(rae::RAE, input::String, show_warn=true)\n",
    "    k=get_word_index(rae, input, show_warn)\n",
    "    rae.L[:,k]\n",
    "end\n",
    "\n",
    "function eval_word_embeddings(rae::RAE, inputs::Words, show_warn=false)\n",
    "    ks = @pipe inputs |> map(ii -> get_word_index(rae,ii, show_warn), _)\n",
    "    rae.L[:,ks]\n",
    "end\n",
    "\n",
    "\n",
    "function eval_merges(rae::RAE, c_ijs::Embeddings)\n",
    "    rae.W_e*c_ijs.+rae.b_e\n",
    "end\n",
    "\n",
    "function eval_merges(rae::RAE, c_is::Embeddings, c_js::Embeddings)\n",
    "    @assert size(c_is)==size(c_js)\n",
    "    eval_merges(rae,[c_is;c_js])\n",
    "end\n",
    "\n",
    "function eval_scores(rae::RAE, c_is::Embeddings, c_js::Embeddings,\n",
    "                      pps=eval_merges(rae, c_is, c_js)::Embeddings,\n",
    "                      ĉ_ijs = unfold_merges(rae,pps)::Embeddings)\n",
    "     c_ijs = [c_is;c_js]\n",
    "     \n",
    "     1/2*sum((c_ijs-ĉ_ijs).^2,1)\n",
    "end\n",
    "\n",
    "function reconstruct(rae::RAE, pp::Embedding)\n",
    "    ĉ_ij = rae.W_d*pp+rae.b_d\n",
    "    ĉ_i = ĉ_ij[1:end/2]\n",
    "    ĉ_j = ĉ_ij[end/2+1:end]\n",
    "    ĉ_i, ĉ_j\n",
    "end\n",
    "\n",
    "function unfold_merges(rae::RAE, pps::Embeddings)\n",
    "    ĉ_ijs = rae.W_d*pps .+ rae.b_d\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type ActData\n",
    "    c_ij::Embedding\n",
    "    pp::Embedding\n",
    "    ĉ_ij::Embedding\n",
    "end\n",
    "\n",
    "\n",
    "#data_tree(left::Embedding, data::ActData, right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eval_to_tree (generic function with 2 methods)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "function eval_to_tree(rr::RAE,sentence::String)\n",
    "    eval_to_tree(rr, tokenize(sentence))\n",
    "end\n",
    "\n",
    "function eval_to_tree(rr::RAE, sentence::Words)\n",
    "    tree = tuple(sentence...)\n",
    "    cs = eval_word_embeddings(rr, sentence)\n",
    "    act_tree = tuple_of_cols(cs)\n",
    "    score_total = 0.0\n",
    "    while(size(cs,2)>1)\n",
    "        c_is = cs[:, 1:end-1]\n",
    "        c_js = cs[:, 2:end]\n",
    "        \n",
    "        pps = eval_merges(rr, c_is, c_js)\n",
    "        ĉ_ijs = unfold_merges(rr,pps)\n",
    "        scores = eval_scores(rr, c_is, c_js, pps,ĉ_ijs)\n",
    "        im = indmax(scores)\n",
    "        \n",
    "        score_total+=scores[im]\n",
    "        c_ij=[c_is; c_js][:,im]\n",
    "        pp = pps[:,im]\n",
    "        ĉ_ij = ĉ_ijs[:,im]\n",
    "        act = ActData(c_ij, pp, ĉ_ij)\n",
    "        act_node = (act_tree[im], act, act_tree[im+1])\n",
    "        \n",
    "        cs = [cs[:,1:im-1] pp cs[:,im+2:end]]\n",
    "        tree = tuple(tree[1:im-1]..., (tree[im], tree[im+1]), tree[im+2:end]...)\n",
    "        act_tree = tuple(act_tree[1:im-1]..., act_node, act_tree[im+2:end]...)\n",
    "    end\n",
    "    \n",
    "    #Note The final step in tree creates a tuple containing one element, as first and last parts are empty\n",
    "    tree[1], act_tree[1], cs[:], score_total\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eval_scores_gradient (generic function with 2 methods)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function zero_col(W::Matrix)\n",
    "    zeros(size(W,1),1)\n",
    "end\n",
    "\n",
    "function tuple_of_cols(a::Matrix)\n",
    "    @pipe [a[:,col_ii] for col_ii in 1:size(a,2)] |> tuple(_...)\n",
    "end\n",
    "\n",
    "function BPTS(rae::RAE, nontree::Embedding, δ_above::Matrix)\n",
    "    #Note a tree. but a terminal state\n",
    "    (0,0,0,0)\n",
    "end\n",
    "\n",
    "function BPTS(rae::RAE, tree::(Any,ActData, Any), δ_above=zero_col(rae.W_e))\n",
    "    act=tree[2]\n",
    "    ∇s, δ_input = eval_scores_gradient(rae,act,δ_above)\n",
    "    δ_left  = δ_input[1:end/2,:]\n",
    "    δ_right = δ_input[end/2+1:end,:]\n",
    "\n",
    "    ∇s_left = BPTS(rae, tree[1], δ_left)\n",
    "    ∇s_right = BPTS(rae, tree[3], δ_right)\n",
    "    tuple([l+c+r for (c,l,r) in zip(∇s_left,∇s, ∇s_right)]...)\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "function eval_scores_gradient(rae::RAE, \n",
    "                              act::ActData,\n",
    "                              δ_parent=zero_col(rae.W_e))\n",
    "    #Notice: While this is good to go for multiple concurrent, \n",
    "    #It does't actually do so, as a tree is the \n",
    "    \n",
    "    \n",
    "    c_ijs::Embeddings = act.c_ij''\n",
    "    pps::Embeddings = act.pp''\n",
    "    ĉ_ijs::Embeddings = act.ĉ_ij''\n",
    "    \n",
    "    #http://neuralnetworksanddeeplearning.com/chap2.h)tml\n",
    "    N = size(c_ijs,2)\n",
    "    N⁻¹ = 1 ./ N\n",
    "    da = (ĉ_ijs - c_ijs)\n",
    "    dz_d = 1\n",
    "    δ_d = da.*dz_d #Output Error\n",
    "\n",
    "    ∇W_d = N⁻¹.*δ_d*pps'\n",
    "    ∇b_d = N⁻¹.*sum(δ_d,2)[:]\n",
    "    \n",
    "    \n",
    "    dz_e = 1\n",
    "    δ_e = rae.W_d'*δ_d .*(dz_e .+ δ_parent) #Hidden layer error\n",
    "        \n",
    "\n",
    "    ∇W_e = N⁻¹.*δ_e*c_ijs'\n",
    "    ∇b_e = N⁻¹.*sum(δ_e,2)[:]\n",
    "    \n",
    "    ∇s = (∇W_e, ∇b_e, ∇W_d, ∇b_d)\n",
    "    \n",
    "    #input error, ie parent error for layer below\n",
    "    dz_p = 1\n",
    "    δ_input = (rae.W_e'*δ_e - da).*dz_p\n",
    "    \n",
    "    ∇s, δ_input\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((\"the\",\"boy\"),\"destroyed\"),(\"the\",\"house\"))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using Iterators\n",
    "@pyimport nltk.corpus as nltk_corpus\n",
    "n_training = 10000\n",
    "#training_sents = @pipe nltk_corpus.brown[:sents]() |> take(_,n_training)  |> collect |> convert(Vector{Vector{String}},_);\n",
    "training_sents = @pipe nltk_corpus.brown[:sents]() |> filter(s->1<length(s)<=15, _) |> take(_,n_training)  |> collect |> convert(Vector{Vector{String}},_);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_sents |> size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rae_outer = RAE(LL,word_indexes,indexed_words);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter     Function value   Gradient norm \n",
      "     0     1.920656e+01     6.065785e+01\n",
      "     1     1.726083e+01     1.795733e+01\n",
      "     2     1.654215e+01     1.292458e+01\n",
      "     3     1.619928e+01     1.269423e+01\n",
      "     4     1.607620e+01     7.365931e+00\n",
      "     5     1.595119e+01     4.876974e+00\n",
      "     6     1.586268e+01     4.326252e+00\n",
      "     7     1.579166e+01     4.346318e+00\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "interrupt\nwhile loading In[36], in expression starting on line 64",
     "output_type": "error",
     "traceback": [
      "interrupt\nwhile loading In[36], in expression starting on line 64",
      "",
      " in reduced_dims at reducedim.jl:8",
      " in sum at reducedim.jl:224",
      " in eval_scores_gradient at In[15]:54",
      " in BPTS at In[15]:16",
      " in BPTS at In[15]:20",
      " in BPTS at In[15]:21",
      " in BPTS at In[15]:15",
      " in loss_and_loss_grad! at In[36]:53",
      " in linefunc! at /home/wheel/oxinabox/.julia/v0.3/Optim/src/linesearch/hz_linesearch.jl:609",
      " in hz_linesearch! at /home/wheel/oxinabox/.julia/v0.3/Optim/src/linesearch/hz_linesearch.jl:200",
      " in hz_linesearch! at /home/wheel/oxinabox/.julia/v0.3/Optim/src/linesearch/hz_linesearch.jl:188 (repeats 10 times)",
      " in l_bfgs at /home/wheel/oxinabox/.julia/v0.3/Optim/src/l_bfgs.jl:165",
      " in optimize at /home/wheel/oxinabox/.julia/v0.3/Optim/src/optimize.jl:113"
     ]
    }
   ],
   "source": [
    "using Optim #https://github.com/JuliaOpt/Optim.jl\n",
    "\n",
    "function unpack!(rae::RAE, θ::Vector)\n",
    "    W_e_len = length(rae.W_e)\n",
    "    b_e_len = length(rae.b_e)\n",
    "    W_d_len = length(rae.W_d)\n",
    "    b_d_len = length(rae.b_d)\n",
    "    W_e_shape = size(rae.W_e)\n",
    "    W_d_shape = size(rae.W_d)\n",
    "    \n",
    "    rae.W_e = reshape(θ[1: W_e_len],W_e_shape)\n",
    "    rae.b_e = θ[W_e_len+1: W_e_len+b_e_len]\n",
    "    rae.W_d = reshape(θ[W_e_len+b_e_len+1: W_e_len+b_e_len+W_d_len],W_d_shape)\n",
    "    rae.b_d = θ[W_e_len+b_e_len+W_d_len+1: end]\n",
    "    \n",
    "    rae\n",
    "end\n",
    "\n",
    "function pack(rae::RAE)\n",
    "    [rae.W_e[:],rae.b_e, rae.W_d[:],rae.b_d[:]] \n",
    "end\n",
    "\n",
    "function pack(∇W_e::Matrix{Number}, ∇b_e::Vector{Number}, ∇W_d::Matrix{Number}, ∇b_d::Vector{Number})\n",
    "    [∇W_e[:], ∇b_e, ∇W_d[:], ∇b_d] \n",
    "end\n",
    "\n",
    "#--------------------------------------------------------\n",
    "\n",
    "function loss!(θ::Vector)  \n",
    "    rae = unpack!(rae_outer, θ)\n",
    "    @pipe training_sents |> map( ss-> eval_to_tree(rae, ss)[end], _) |> mean\n",
    "end\n",
    "\n",
    "function loss_grad!(θ::Vector, storage::Vector) \n",
    "    error(\"loss_grad! CALLED\")\n",
    "    storage[:] = 0\n",
    "    storage = zeros(storage)\n",
    "    rae = unpack!(rae_outer, θ)\n",
    "    for ss in training_sents\n",
    "        tree, act_tree, pp, err_total = eval_to_tree(rae, ss)\n",
    "        ∇s=BPTS(rae,act_tree)\n",
    "        storage+=pack(∇s...)\n",
    "    end\n",
    "    storage/=length(training_sents)\n",
    "end\n",
    "\n",
    "function loss_and_loss_grad!(θ::Vector, storage::Vector)   \n",
    "    storage[:] = 0\n",
    "    rae = unpack!(rae_outer, θ)\n",
    "    err = 0.0\n",
    "    for ss in training_sents\n",
    "        tree, act_tree, pp, err_total = eval_to_tree(rae, ss)\n",
    "        ∇s=BPTS(rae,act_tree)\n",
    "        storage[:]+=pack(∇s...)\n",
    "        err+=err_total\n",
    "    end\n",
    "    storage[:]/=length(training_sents)\n",
    "    err/=length(training_sents)\n",
    "    err\n",
    "end\n",
    "\n",
    "f=DifferentiableFunction(loss!,loss_grad!,loss_and_loss_grad!)\n",
    "#Must provide Graident as finite difference requires ~length(θ) calls to f\n",
    "res = optimize(f, pack(rae_outer), method=:l_bfgs, show_trace = true, store_trace = true, iterations = 100)\n",
    "rae_outer = unpack!(rae_outer, res.minimum);\n",
    "print(\"---------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@printval res.method\n",
    "@printval res.f_calls \n",
    "@printval res.g_calls \n",
    "@printval res.x_converged \n",
    "@printval res.iterations\n",
    "@printval res.f_minimum\n",
    "@printval res.gr_converged\n",
    "#@printval res.trace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((\"the\",\"friendship\"),(\"was\",\"lost\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20x8 Array{Any,2}:\n",
       " \"Otevreny\"         0.56231   \"gangland-style\"  0.494649  \"E-mail\"           0.530209  \"Hellmuth\"         0.520546\n",
       " \"Settlment\"        0.558798  \"Conventional\"    0.48383   \"Nachlinger\"       0.492911  \"terse\"            0.519482\n",
       " \"-Russian\"         0.555402  \"Jayamahe\"        0.4831    \"unfed\"            0.491448  \"collateralized\"   0.514727\n",
       " \"Unversity\"        0.547203  \"100-minute\"      0.465743  \"Marais\"           0.488543  \"calmer\"           0.511384\n",
       " \"Permanente\"       0.542418  \"Kalapahar\"       0.465539  \"Stukelj\"          0.469441  \"insuring\"         0.507025\n",
       " \"d'Ivoire\"         0.535266  \"Tonen\"           0.463681  \"Loubser\"          0.467568  \"narrower\"         0.500775\n",
       " \"Seas\"             0.533909  \"Gauck\"           0.463558  \"Juror\"            0.467255  \"Japan-Russia\"     0.490027\n",
       " \"Practicing\"       0.533773  \"railway.\"        0.462134  \"Dostumn\"          0.460294  \"depression-size\"  0.489524\n",
       " \"Banka.\"           0.532672  \"Haarhof\"         0.457813  \"Tunisians\"        0.456056  \"swab\"             0.486529\n",
       " \"Dangerous\"        0.530962  \"anti-India\"      0.456254  \"CURE\"             0.45428   \"unpromising\"      0.485934\n",
       " \"Cities\"           0.529167  \"Darianne\"        0.450235  \"Mycelex-7\"        0.450234  \"fabulous\"         0.48534 \n",
       " \"Fermanagh\"        0.525614  \"COMET\"           0.449413  \"Antonios\"         0.449835  \"night-flying\"     0.484894\n",
       " \"Professionals\"    0.523699  \"Weissenbacher\"   0.449022  \"Tonga\"            0.447682  \"short-sterling\"   0.484431\n",
       " \"Marting\"          0.520664  \"Nouaceur\"        0.447281  \"Burundians\"       0.446023  \"bleaker\"          0.484358\n",
       " \"Democratisation\"  0.51842   \"auto-rickshaws\"  0.443584  \"Raoux\"            0.443972  \"springtime\"       0.479767\n",
       " \"Sahom\"            0.517405  \"Christian-\"      0.443319  \"avuncular\"        0.443769  \"twelve-month\"     0.479583\n",
       " \"Equality\"         0.516591  \"Championship.\"   0.437955  \"UAW-represented\"  0.443062  \"25-basis\"         0.475113\n",
       " \"Buana\"            0.51597   \"Ganden\"          0.437496  \"Arrhenius\"        0.441817  \"privatizing\"      0.475089\n",
       " \"Investing\"        0.514679  \"oraibh\"          0.437452  \"revelling\"        0.439068  \"unoffical\"        0.474659\n",
       " \"Ritblat\"          0.513341  \"photos.\"         0.436803  \"Angelides\"        0.438761  \"strippable\"       0.474049"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"the friendship was lost\"\n",
    "sent_toks = tokenize(sent)\n",
    "\n",
    "tree, act_tree, pp, score_total = eval_to_tree(rae_outer,sent_toks);\n",
    "println(tree)\n",
    "\n",
    "ĉs = unfold(rae_outer,tree,pp)\n",
    "show_bests(rae_outer, ĉs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/JuliaLang/julia/blob/master/doc/manual/profile.rst Actual instructions on profiling\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unfold (generic function with 4 methods)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tree data in tree is not use, other than it's structure.\n",
    "#(((\"the\",\"house\"),(\"destroyed\",(\"the\",\"boy\")))  is equivalent to (((\"\",\"\"),(\"\",(\"\",\"\"))) \n",
    "\n",
    "\n",
    "\n",
    "function unfold(rae::RAE, tree::(String,String), pp::Embedding)\n",
    "    ĉ_is, ĉ_js = reconstruct(rae, pp)\n",
    "    [ĉ_is ĉ_js]\n",
    "end\n",
    "\n",
    "\n",
    "function unfold(rae::RAE, tree::(Any,String), pp::Embedding)\n",
    "    p̂_is, ĉ_js = reconstruct(rae, pp)\n",
    "    ĉ_is = unfold(rae, tree[1], p̂_is)\n",
    "    [ĉ_is ĉ_js]\n",
    "end\n",
    "\n",
    "function unfold(rae::RAE, tree::(String,Any), pp::Embedding)\n",
    "    ĉ_is, p̂_js = reconstruct(rae, pp)\n",
    "    ĉ_js = unfold(rae, tree[2], p̂_js)\n",
    "    [ĉ_is ĉ_js]\n",
    "    \n",
    "end\n",
    "\n",
    "function unfold(rae::RAE, tree::(Any,Any), pp::Embedding)\n",
    "    p̂_is, p̂_js = reconstruct(rae, pp)\n",
    "    ĉ_is = unfold(rae, tree[1], p̂_is)\n",
    "    ĉ_js = unfold(rae, tree[2], p̂_js)\n",
    "    [ĉ_is ĉ_js]\n",
    "end\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "show_bests (generic function with 2 methods)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function cosine_dist(a,b)\n",
    "    (a⋅b)/(norm(a)*norm(b))\n",
    "end\n",
    "\n",
    "function neighbour_dists(cc::Vector{Number}, globe::Matrix{Number})\n",
    "    [cosine_dist(cc, globe[:,ii]) for ii in 1:size(globe,2)]\n",
    "end\n",
    "\n",
    "\n",
    "function show_best(rae::RAE,ĉ::Embedding, nbest=20)\n",
    "    candidates=neighbour_dists(ĉ,rae.L)   \n",
    "    best_cands = [ (findfirst(candidates,score), score)\n",
    "                    for score in select(candidates,1:nbest, rev=true)[1:nbest]]\n",
    "    vcat([[rae.indexed_words[ii] score] for (ii,score) in best_cands]...)\n",
    "end\n",
    "\n",
    "function show_bests(rae::RAE,ĉs::Embeddings, nbest=20)\n",
    "    hcat([show_best(rae,ĉs[:,ii],nbest) for ii in 1:size(ĉs,2)]...)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree, pp, score_total = eval_to_tree(rae_outer,\"easy holdings\")\n",
    "ĉs = unfold(rae_outer,tree,pp)\n",
    "\n",
    "show_bests(rae_outer, ĉs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function depth_inc(ele::(Int,String))\n",
    "    (ele[1]+1,ele[2])\n",
    "end\n",
    "\n",
    "function unfold_struct(tree::(Any,Any))\n",
    "    left_tree = unfold_struct(tree[1]) \n",
    "    left = @pipe left_tree |> map(depth_inc,_)\n",
    "    right_tree = unfold_struct(tree[2]) \n",
    "    right = @pipe right_tree |> map(depth_inc,_)\n",
    "    [left, right, (0,\"\")]\n",
    "end\n",
    "\n",
    "function unfold_struct(tree::(Any,String))\n",
    "    left_tree = unfold_struct(tree[1]) \n",
    "    left = @pipe left_tree |> map(depth_inc,_)\n",
    "    [left, (0,tree[2]), (0,\"\")]\n",
    "end\n",
    "function unfold_struct(tree::(String,Any))\n",
    "    right_tree = unfold_struct(tree[2]) \n",
    "    right = @pipe right_tree |> map(depth_inc,_)\n",
    "    [(0,tree[1]),right, (0,\"\")]\n",
    "end\n",
    "function unfold_struct(tree::(String,String))\n",
    "    [(0,tree[1]), (0, tree[2]), (0,\"\")]\n",
    "end\n",
    "\n",
    "function print_tree(tree::(Any,Any))\n",
    "    \n",
    "    for (depth,word ) in unfold_struct(tree)\n",
    "        println(\"\\t\"^depth, word)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.3.8",
   "language": "julia",
   "name": "julia-0.3"
  },
  "language_info": {
   "name": "julia",
   "version": "0.3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
