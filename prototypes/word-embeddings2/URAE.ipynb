{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "expr: syntax error\n",
      "expr: syntax error\n",
      "expr: syntax error\n",
      "expr: syntax error\n",
      "expr: syntax error\n",
      "expr: syntax error\n",
      "expr: syntax error\n",
      "expr: syntax error\n",
      "expr: syntax error\n",
      "expr: syntax error\n",
      "expr: syntax error\n",
      "expr: syntax error\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18-element Array{Int64,1}:\n",
       "  2\n",
       "  3\n",
       "  4\n",
       "  5\n",
       "  6\n",
       "  7\n",
       "  8\n",
       "  9\n",
       " 10\n",
       " 11\n",
       " 12\n",
       " 13\n",
       " 14\n",
       " 15\n",
       " 16\n",
       " 17\n",
       " 18\n",
       " 19"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for ii in 1:4\n",
    "    addprocs([\"heathred\"])\n",
    "end\n",
    "\n",
    "for ii in 1:3\n",
    "    addprocs([\"amon\"], dir=\"\")\n",
    "    addprocs([\"zeus\"], dir=\"\")\n",
    "    addprocs([\"jove\"], dir=\"\")\n",
    "    addprocs([\"ares\"], dir=\"\")\n",
    "end\n",
    "\n",
    "for ii in 1:10\n",
    "    #addprocs([\"uggp\"], dir=\"\")\n",
    "end\n",
    "\n",
    "addprocs(2)\n",
    "workers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using Iterators\n",
    "using Pipe\n",
    "\n",
    "macro printval(ee)\n",
    "    ee_expr = @sprintf \"%s\" string(ee)\n",
    "    esc(:(println($ee_expr,\" = \", $ee)))\n",
    "end\n",
    "\n",
    "macro pz(ee)\n",
    "    ee_expr = @sprintf \"%s\" string(ee)\n",
    "    esc(:(println($ee_expr,\"\\t\\t\",typeof($ee), \"\\t\", size($ee))))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@everywhere using RecursiveAutoencoders\n",
    "@everywhere  using UnfoldingRAE\n",
    "@everywhere using Zlib\n",
    "\n",
    "using ClusterSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,15000)\n",
      "Dict{String,Int64}\n",
      "Array{String,1}\n"
     ]
    }
   ],
   "source": [
    "using WordEmbeddings\n",
    "LL,word_indexes, indexed_words = load_word2vec_embeddings(\"../../Resources/example_code/word2vec/GoogleNews-vectors-negative300.bin\", 15000)\n",
    "size(LL) |> println\n",
    "word_indexes |> typeof |> println\n",
    "indexed_words |> typeof |> println"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_trees\t\tArray{Any,1}\t(4000,)\n"
     ]
    }
   ],
   "source": [
    "training_trees = open(\"questionbank_sents.jsz\",\"r\") do fs\n",
    "    deserialize(fs)\n",
    "end;\n",
    "@pz training_trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18-element Array{RemoteRef,1}:\n",
       " RemoteRef(2,1,338) \n",
       " RemoteRef(3,1,340) \n",
       " RemoteRef(4,1,342) \n",
       " RemoteRef(5,1,344) \n",
       " RemoteRef(6,1,346) \n",
       " RemoteRef(7,1,348) \n",
       " RemoteRef(8,1,350) \n",
       " RemoteRef(9,1,352) \n",
       " RemoteRef(10,1,354)\n",
       " RemoteRef(11,1,356)\n",
       " RemoteRef(12,1,358)\n",
       " RemoteRef(13,1,360)\n",
       " RemoteRef(14,1,362)\n",
       " RemoteRef(15,1,364)\n",
       " RemoteRef(16,1,366)\n",
       " RemoteRef(17,1,368)\n",
       " RemoteRef(18,1,370)\n",
       " RemoteRef(19,1,372)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_training_trees = r_chunk_data(training_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@everywhere function unpack!(rae::RAE, θ::Vector)\n",
    "    W_e_len = length(rae.W_e)\n",
    "    b_e_len = length(rae.b_e)\n",
    "    W_d_len = length(rae.W_d)\n",
    "    b_d_len = length(rae.b_d)\n",
    "    W_e_shape = size(rae.W_e)\n",
    "    W_d_shape = size(rae.W_d)\n",
    "    \n",
    "    rae.W_e[:] = θ[1: W_e_len]\n",
    "    rae.b_e[:] = θ[W_e_len+1: W_e_len+b_e_len]\n",
    "    rae.W_d[:] = θ[W_e_len+b_e_len+1: W_e_len+b_e_len+W_d_len]\n",
    "    rae.b_d[:] = θ[W_e_len+b_e_len+W_d_len+1: end]\n",
    "    \n",
    "    rae\n",
    "end\n",
    "\n",
    "@everywhere function pack(rae::RAE)\n",
    "    pack(rae.W_e,rae.b_e, rae.W_d,rae.b_d)\n",
    "end\n",
    "\n",
    "@everywhere function pack(∇W_e::NumericMatrix, ∇b_e::NumericVector, ∇W_d::NumericMatrix, ∇b_d::NumericVector)\n",
    "    [∇W_e[:], ∇b_e, ∇W_d[:], ∇b_d] \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 29.370976263 seconds (1098973156 bytes allocated, 5.31% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "loss_and_loss_grad! (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function loss!(θ::Vector)  \n",
    "    #warn(\"loss! not defined\")\n",
    "    grad = similar(θ)\n",
    "    #loss_and_loss_grad!(θ::Vector)\n",
    "    cached_loss_and_loss_grad!(θ, grad)\n",
    "end\n",
    "\n",
    "function loss_grad!(θ::Vector, storage::Vector) \n",
    "    #warn(\"loss_grad not defined\")\n",
    "    cached_loss_and_loss_grad!(θ, grad)\n",
    "end\n",
    "\n",
    "\n",
    "rae_outer = RAE(LL,word_indexes,indexed_words,0.001);\n",
    "@time r_rae_outers = put!(workers(), rae_outer, 2)\n",
    "function loss_and_loss_grad!(θ::Vector, grad::Vector)   \n",
    "    grad[:] = 0\n",
    "    @inbounds for r_rae_outer in r_rae_outers\n",
    "        update_remote(r_rae_outer, rae->unpack!(rae, θ) )\n",
    "    end\n",
    "    \n",
    "    function get_remote_loss_grad_function(r_rae_outer::RemoteRef)\n",
    "        @assert r_rae_outer.where == myid()\n",
    "        rae = fetch(r_rae_outer)        \n",
    "        function loss_and_loss_grad(tree::(Any,Any))\n",
    "            Δs, err = UnfoldingRAE.loss_and_loss_grad(rae, tree)\n",
    "            [pack(Δs...), err]\n",
    "        end\n",
    "    end\n",
    "    loss_and_loss_grads::Array{RemoteRef,1} = map(r_rae_outers) do r_raeouter\n",
    "        remotecall(r_raeouter.where, get_remote_loss_grad_function, r_raeouter)::RemoteRef\n",
    "    end\n",
    "    \n",
    "    \n",
    "    ret = prechunked_mapreduce(r_training_trees, loss_and_loss_grads, (+)) \n",
    "    grad[:] = ret[1:end-1]\n",
    "    err=ret[end]\n",
    "    \n",
    "    grad[:]/=length(training_trees)\n",
    "    err/=length(training_trees)\n",
    "    err\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cached_loss_and_loss_grad! (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_and_loss_grad_cache = Dict{NumericVector,(Number, NumericVector)}()\n",
    "loss_and_loss_grad_cache_hits = 0\n",
    "loss_and_loss_grad_cache_misses = 0\n",
    "function cached_loss_and_loss_grad!(θ::Vector, grad::Vector)\n",
    "    global loss_and_loss_grad_cache\n",
    "    global loss_and_loss_grad_cache_hits\n",
    "    global loss_and_loss_grad_cache_misses\n",
    "    if haskey(loss_and_loss_grad_cache,θ)\n",
    "        loss_and_loss_grad_cache_hits+=1\n",
    "        err, grad[:] = loss_and_loss_grad_cache[θ]\n",
    "        err\n",
    "    else\n",
    "        loss_and_loss_grad_cache_misses+=1\n",
    "        err = loss_and_loss_grad!(θ, grad)\n",
    "        loss_and_loss_grad_cache[θ] = (err, grad)\n",
    "        err\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using NLopt\n",
    "\n",
    "f_call_count = 0\n",
    "function tracking_loss_and_loss_grad!(θ::Vector, grad::Vector)\n",
    "    global f_call_count\n",
    "    f_call_count+=1\n",
    "    f_val = cached_loss_and_loss_grad!(θ, grad)   \n",
    "    println(f_call_count, '\\t',f_val,'\\t',norm(grad))\n",
    "    f_val\n",
    "end\n",
    "#:LD_MMA, :LD_CCSAQ, :LD_LBFGS, :LD_SLSQP, :LD_VAR2, :LD_VAR1, :LD_TNEWTON_RESTART\n",
    "opt = Opt(:LD_LBFGS, length(pack(rae_outer)))\n",
    "\n",
    "#ftol_abs!(opt,1e-9)\n",
    "maxtime!(opt, 60)\n",
    "min_objective!(opt, tracking_loss_and_loss_grad!)\n",
    "\n",
    "#θ = pack(rae_outer)\n",
    "\n",
    "\n",
    "(optf,optx,ret) = optimize!(opt,θ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter     Function value   Gradient norm \n"
     ]
    }
   ],
   "source": [
    "using Optim #https://github.com/JuliaOpt/Optim.jl\n",
    "f=DifferentiableFunction(loss!,loss_grad!,cached_loss_and_loss_grad!)\n",
    "θ = pack(rae_outer)\n",
    "#θ=res.minimum\n",
    "res = optimize(f, θ, method=:cg, show_trace = true, store_trace = true, iterations = 10);\n",
    "@printval res.f_calls \n",
    "@printval res.g_calls \n",
    "@printval res.iterations\n",
    "@printval res.f_minimum\n",
    "@printval res.gr_converged\n",
    "@printval res.x_converged                       \n",
    "@printval res.f_converged \n",
    "@printval res.trace\n",
    "@printval loss_and_loss_grad_cache_hits\n",
    "@printval loss_and_loss_grad_cache_misses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "open(\"rae1062.jsz\",\"w\") do fs\n",
    "    serialize(fs, rae_outer)\n",
    "end;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unpack!(rae_outer, res.minimum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "importall WordEmbeddings \n",
    "function show_best(embedder,ĉ::Embedding, nbest=20, similarity=WordEmbeddings.cosine_sim )\n",
    "    candidates=WordEmbeddings.neighbour_sims(ĉ,embedder.L, similarity)  \n",
    "    candidates[find(map(isnan, candidates))]= -Inf #If the zero vector was an option, it will be NaN similar so it is banned from winning\n",
    "    best_cands = [ (findfirst(candidates,score), score)\n",
    "                    for score in select(candidates,1:nbest, rev=true)[1:nbest]]\n",
    "    vcat([[embedder.indexed_words[ii] round(score,2)] for (ii,score) in best_cands]...)\n",
    "end\n",
    "\n",
    "function show_bests(embedder,ĉs::Embeddings, nbest=20, similarity=WordEmbeddings.cosine_sim)\n",
    "    hcat([show_best(embedder,ĉs[:,ii],nbest, similarity) for ii in 1:size(ĉs,2)]...)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tr=((\"What\", (\"are\", \"birds\")), \"?\")\n",
    "a = fold(rae_outer,tr)\n",
    "b= unfold(rae_outer, a)\n",
    "ĉs = hcat(map(leave-> leave.ĉ, b)...)\n",
    "bests = show_bests(rae_outer, ĉs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "haskey(rae_outer.word_index,\"?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "findfirst(candidates,NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "select(candidates,1:nbest, rev=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.3.9-pre",
   "language": "julia",
   "name": "julia-0.3"
  },
  "language_info": {
   "name": "julia",
   "version": "0.3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
