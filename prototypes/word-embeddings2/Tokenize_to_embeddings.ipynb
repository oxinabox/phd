{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using PyCall\n",
    "@pyimport nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_embeddings (generic function with 1 method)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function load_embeddings(embedding_file)\n",
    "    embeddings = Dict{String,Vector{Float64}}()\n",
    "    #sizehint!(embeddings, 268810)\n",
    "    for line in eachline(open(embedding_file))\n",
    "        fields = line |> split\n",
    "        word = fields[1]\n",
    "        vec = map(parsefloat, fields[2:end])\n",
    "        embeddings[word] = vec\n",
    "    end\n",
    "    embeddings\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vocab_words (generic function with 1 method)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type WordEmbeddingResolver\n",
    "    word2vec::Dict{String,Vector{Float64}}\n",
    "    oov_vec::Vector{Float64} \n",
    "end\n",
    "\n",
    "\n",
    "function WordEmbeddingResolver(embedding_file::String)\n",
    "    word2vec = load_embeddings(embedding_file)\n",
    "    oov_vec = zeros(size(word2vec[\"the\"])) #Default it to zeros\n",
    "    WordEmbeddingResolver(word2vec, oov_vec)\n",
    "end\n",
    "\n",
    "function WordEmbeddingResolver(embedding_file::String, oov_word::String)\n",
    "    word2vec = load_embeddings(embedding_file)\n",
    "    oov_vec = pop!(word2vec, oov_word)\n",
    "    print(oov_vec)\n",
    "    WordEmbeddingResolver(word2vec, oov_vec)\n",
    "end\n",
    "\n",
    "\n",
    "function get_embedding(resolver::WordEmbeddingResolver, word::String)\n",
    "    get(resolver.word2vec, word, resolver.oov_vec) ::Vector{Float64}\n",
    "end\n",
    "\n",
    "function has_word(resolver::WordEmbeddingResolver, word::String)\n",
    "    haskey(resolver.word2vec, word)\n",
    "end\n",
    "\n",
    "function vocab_words(resolver::WordEmbeddingResolver)\n",
    "    Set(keys(resolver.word2vec))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0398781252434,0.048215044877,0.0176077427638,-0.0251486353356,-0.0627525391573,0.025162565373,0.0117941274751,0.06136177709,0.018282828886,0.0289890409378,0.0305114695273,-0.0174257424723,0.0267882660686,-0.0147157088929,-0.00180382572305,-0.0240110330944,0.0348314405236,0.0331470930104,-0.072770576263,-0.0168486166738,-0.0239016486614,-0.0129813224306,-0.0289427776461,-0.0087953471783,-0.00791740590907,0.067884451273,-0.00875883697995,-0.00378532326298,-0.0147556102437,-0.0290714884049,-0.00577404736729,0.00911313898167,-0.0117291610829,-0.0562154301399,-0.0797217562057,-0.00686779437354,0.030256762279,0.00549994945996,-0.00159508308038,-0.0682754357922,-0.0136058665581,-0.0243803014322,-0.0181979406072,0.00254263276224,-0.0295248721186,-0.0390803609727,-0.0137563336122,0.0252651578644,0.0304082419565,0.0337323822856]"
     ]
    }
   ],
   "source": [
    "#embeddings =  WordEmbeddingResolver(\"ACL2012_wordvectors.txt\");\n",
    "embeddings =  WordEmbeddingResolver(\"embeddings-scaled.EMBEDDING_SIZE=50.txt\", \"*UNKNOWN*\");\n",
    "#embeddings =  WordEmbeddingResolver(\"embeddings-scaled.EMBEDDING_SIZE=200.txt\", \"*UNKNOWN*\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split_sentences (generic function with 1 method)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make sentences\n",
    "function split_sentences(ss)\n",
    "    eoss = [0, find((\".\".==ss) | (\"!\".==ss ) | (\"?\" .==ss)), size(ss,1)]\n",
    "    [ss[eoss[ii]+1:eoss[ii+1]] for ii in 1:length(eoss)-1]\n",
    "end\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_sentence_vectors (generic function with 1 method)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_sentence_vectors(document_str::String)\n",
    "    token_sentences = document_str |> nltk.word_tokenize |> split_sentences\n",
    "\n",
    "    [hcat([get_embedding(embeddings, word) for word in sentence]...)\n",
    "        for sentence in token_sentences]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[http://nlp.stanford.edu/pubs/SocherLinNgManning_ICML2011.pdf]\n",
    "\n",
    "http://repository.cmu.edu/cgi/viewcontent.cgi?article=1054&context=robotics\n",
    "\n",
    "http://en.wikipedia.org/wiki/Brown_Corpus#Part-of-speech_tags_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "softmax (generic function with 1 method)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function softmax(z)\n",
    "    e.^z./sum(e.^z,1) \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eval_label (generic function with 1 method)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type RNN\n",
    "    W_score::Matrix{Float64}\n",
    "    W_label::Matrix{Float64}\n",
    "    W::Matrix{Float64}\n",
    "end\n",
    "\n",
    "function RNN(input_width::Int, num_labels::Int)\n",
    "    RNN(0.01*randn(1,input_width+1),\n",
    "        0.01*randn(num_labels,input_width+1),\n",
    "        0.01*randn(input_width,input_width*2+1))\n",
    "end\n",
    "\n",
    "function eval_embedding(rnn::RNN, input_A, input_B)\n",
    "    bias_in = ones(1,size([input_A; input_B], 2))\n",
    "    tanh(rnn.W*[input_A;input_B;bias_in])\n",
    "end\n",
    "\n",
    "function eval_score(rnn::RNN, pp)\n",
    "    bias_in = ones(1,size(pp, 2))\n",
    "    tanh(rnn.W_score*[pp;bias_in])\n",
    "end\n",
    "\n",
    "function eval_label(rnn::RNN, pp)\n",
    "    bias_in = ones(1,size(pp, 2))\n",
    "    softmax(rnn.W_label*[pp;bias_in])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eval_to_tree (generic function with 2 methods)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function word_adjancy_matrix(sentence_len::Int)\n",
    "    [(ii==jj+1) || (ii==jj-1)  for ii in 1:sentence_len, jj in 1:sentence_len]\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "function eval_to_tree(rr::RNN, sentence::AbstractArray{String})\n",
    "    backlookup = sentence\n",
    "    ss = hcat([get_embedding(embeddings, token) for token in backlookup]...)\n",
    "    AA = word_adjancy_matrix(size(ss,2))\n",
    "    \n",
    "    score_total = 0.0\n",
    "    while(any(AA))\n",
    "        iis, jjs = findn(AA)\n",
    "\n",
    "        pps = eval_embedding(rr, ss[:,iis],ss[:,jjs])\n",
    "        scores = eval_score(rr, pps)\n",
    "        best_pair_ind = indmax(scores)\n",
    "        \n",
    "         \n",
    "        ii_best, jj_best = sort([iis[best_pair_ind], jjs[best_pair_ind]])\n",
    "        #The above makes a more readable output, but doesn't do anything useful,\n",
    "        #it is same as below:\n",
    "        #ii_best = iis[best_pair_ind]\n",
    "        #jj_best = jjs[best_pair_ind]\n",
    "        pp_best = pps[:,best_pair_ind]\n",
    "        score_total+=scores[best_pair_ind]\n",
    "        \n",
    "        ss = [ss pp_best]\n",
    "        backlookup = [backlookup, (backlookup[ii_best],backlookup[jj_best])]\n",
    "        \n",
    "        #Adjust Adjacency Matrix\n",
    "\n",
    "        AA[ii_best,jj_best] = false\n",
    "        AA[jj_best,ii_best] = false\n",
    "        AA = [AA; AA[ii_best,:] | AA[jj_best,:]] # Add row\n",
    "        AA = [AA AA[:,ii_best] | AA[:,jj_best]] # Add col\n",
    "        AA[ii_best,:] = AA[jj_best,:] = false\n",
    "        AA[:,ii_best] = AA[:,jj_best] = false #Remove anything that was adjacent to old\n",
    "\n",
    "    end\n",
    "    tree = backlookup[end]\n",
    "    embedding = ss[:,end]\n",
    "    tree, embedding, score_total\n",
    "end\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenize (generic function with 1 method)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function tokenize(sentence::String)\n",
    "    convert(Array{String,1},nltk.word_tokenize(sentence))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((\"The\",(\"house\",(\".\",(\"window\",(\"has\",\"a\"))))),[-0.0168769,-0.0329426,0.0146024,0.0112469,-0.0151907,-0.00793882,0.011336,0.0431983,-0.0707231,0.0647944  â€¦  0.0165571,-0.0100425,0.0304522,0.00663008,0.00529902,-0.0242028,0.0194972,-0.00380375,0.0236347,0.0576142],-0.06525092570204405)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"The house has a window.\"\n",
    "sentence_toks = tokenize(sentence)\n",
    "rr = RNN(50,3)\n",
    "eval_to_tree(rr,sentence_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6-element Array{String,1}:\n",
       " \"The\"   \n",
       " \"house\" \n",
       " \"has\"   \n",
       " \"a\"     \n",
       " \"window\"\n",
       " \".\"     "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function get_all_pos_tags()\n",
    "    lines = split(open(readall,\"brown_tags.txt\"),\"\\n\")\n",
    "    desc_lines = filter(line -> contains(line,\"||\"), lines)\n",
    "    tags = [split(line,\"||\")[1] for line in desc_lines]\n",
    "end\n",
    "pos_tags = get_all_pos_tags();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1(\"The\",\"Fulton\",\"County\",\"Grand\",\"Jury\",\"said\",\"Friday\",\"an\",\"investigation\",\"of\",\"Atlanta's\",\"recent\",\"primary\",\"election\",\"produced\",\"``\",\"no\",\"evidence\",\"''\",\"that\",\"any\",\"irregularities\",\"took\",\"place\",\".\")\n",
      "2(\"The\",\"jury\",\"further\",\"said\",\"in\",\"term-end\",\"presentments\",\"that\",\"the\",\"City\",\"Executive\",\"Committee\",\",\",\"which\",\"had\",\"over-all\",\"charge\",\"of\",\"the\",\"election\",\",\",\"``\",\"deserves\",\"the\",\"praise\",\"and\",\"thanks\",\"of\",\"the\",\"City\",\"of\",\"Atlanta\",\"''\",\"for\",\"the\",\"manner\",\"in\",\"which\",\"the\",\"election\",\"was\",\"conducted\",\".\")\n",
      "3(\"The\",\"September-October\",\"term\",\"jury\",\"had\",\"been\",\"charged\",\"by\",\"Fulton\",\"Superior\",\"Court\",\"Judge\",\"Durwood\",\"Pye\",\"to\",\"investigate\",\"reports\",\"of\",\"possible\",\"``\",\"irregularities\",\"''\",\"in\",\"the\",\"hard-fought\",\"primary\",\"which\",\"was\",\"won\",\"by\",\"Mayor-nominate\",\"Ivan\",\"Allen\",\"Jr.\",\".\")\n",
      "4(\"``\",\"Only\",\"a\",\"relative\",\"handful\",\"of\",\"such\",\"reports\",\"was\",\"received\",\"''\",\",\",\"the\",\"jury\",\"said\",\",\",\"``\",\"considering\",\"the\",\"widespread\",\"interest\",\"in\",\"the\",\"election\",\",\",\"the\",\"number\",\"of\",\"voters\",\"and\",\"the\",\"size\",\"of\",\"this\",\"city\",\"''\",\".\")\n",
      "5(\"The\",\"jury\",\"said\",\"it\",\"did\",\"find\",\"that\",\"many\",\"of\",\"Georgia's\",\"registration\",\"and\",\"election\",\"laws\",\"``\",\"are\",\"outmoded\",\"or\",\"inadequate\",\"and\",\"often\",\"ambiguous\",\"''\",\".\")\n",
      "6(\"It\",\"recommended\",\"that\",\"Fulton\",\"legislators\",\"act\",\"``\",\"to\",\"have\",\"these\",\"laws\",\"studied\",\"and\",\"revised\",\"to\",\"the\",\"end\",\"of\",\"modernizing\",\"and\",\"improving\",\"them\",\"''\",\".\")\n",
      "7(\"The\",\"grand\",\"jury\",\"commented\",\"on\",\"a\",\"number\",\"of\",\"other\",\"topics\",\",\",\"among\",\"them\",\"the\",\"Atlanta\",\"and\",\"Fulton\",\"County\",\"purchasing\",\"departments\",\"which\",\"it\",\"said\",\"``\",\"are\",\"well\",\"operated\",\"and\",\"follow\",\"generally\",\"accepted\",\"practices\",\"which\",\"inure\",\"to\",\"the\",\"best\",\"interest\",\"of\",\"both\",\"governments\",\"''\",\".\")\n",
      "8(\"Merger\",\"proposed\")\n",
      "9(\"However\",\",\",\"the\",\"jury\",\"said\",\"it\",\"believes\",\"``\",\"these\",\"two\",\"offices\",\"should\",\"be\",\"combined\",\"to\",\"achieve\",\"greater\",\"efficiency\",\"and\",\"reduce\",\"the\",\"cost\",\"of\",\"administration\",\"''\",\".\")\n",
      "10(\"The\",\"City\",\"Purchasing\",\"Department\",\",\",\"the\",\"jury\",\"said\",\",\",\"``\",\"is\",\"lacking\",\"in\",\"experienced\",\"clerical\",\"personnel\",\"as\",\"a\",\"result\",\"of\",\"city\",\"personnel\",\"policies\",\"''\",\".\")\n",
      "11(\"It\",\"urged\",\"that\",\"the\",\"city\",\"``\",\"take\",\"steps\",\"to\",\"remedy\",\"''\",\"this\",\"problem\",\".\")\n"
     ]
    }
   ],
   "source": [
    "@pyimport nltk.corpus as nltk_corpus\n",
    "for (ii,tagged_sent) in enumerate(nltk_corpus.brown[:tagged_sents]())\n",
    "    sent, tags = [zip(tagged_sent...)...]\n",
    "    \n",
    "    println(ii, sent)\n",
    "    if ii>10\n",
    "        break\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.3.7-pre debug",
   "language": "julia",
   "name": "julia 0.3 debug"
  },
  "language_info": {
   "name": "julia",
   "version": "0.3.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
