{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ENV[\"LINES\"] = 30\n",
    "ENV[\"COLUMNS\"] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using Pipe\n",
    "function pz(x :: AbstractArray)\n",
    "    println(typeof(x), \": \", size(x))\n",
    "end\n",
    "macro printval(ee)\n",
    "    ee_expr = @sprintf \"%s\" string(ee)\n",
    "    esc(:(println($ee_expr,\" = \", $ee)))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/numpy/core/fromnumeric.py:2499: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  VisibleDeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tokenize (generic function with 1 method)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using PyCall\n",
    "@pyimport nltk\n",
    "function tokenize(sentence::String)\n",
    "    convert(Array{String,1},nltk.word_tokenize(sentence))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_embeddings (generic function with 1 method)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"load_embeddings.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50,268810)\n",
      "Dict{String,Int64}\n",
      "Array{String,1}\n"
     ]
    }
   ],
   "source": [
    "LL,word_indexes, indexed_words =  load_embeddings(\"embeddings-scaled.EMBEDDING_SIZE=50.txt\");\n",
    "size(LL) |> println\n",
    "word_indexes |> typeof |> println\n",
    "indexed_words |> typeof |> println"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unfold_merges (generic function with 1 method)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typealias Embedding Vector{Float64}\n",
    "typealias Embeddings Matrix{Float64}\n",
    "typealias Words Union(AbstractArray{ASCIIString,1},AbstractArray{String,1})\n",
    "type RAE\n",
    "    L::Matrix{Float64}\n",
    "    word_index::Dict{String,Int}\n",
    "    indexed_words::Vector{String}\n",
    "    \n",
    "    W_e::Matrix{Float64}\n",
    "    b_e::Vector{Float64}\n",
    "    W_d::Matrix{Float64}\n",
    "    b_d::Vector{Float64}\n",
    "   \n",
    "end\n",
    "\n",
    "\n",
    "function RAE(L::Matrix{Float64},word_index::Dict{String,Int}, indexed_words::Vector{String})\n",
    "    emb_width = size(L,1)\n",
    "    \n",
    "    W_e =0.01*randn(emb_width,emb_width*2) \n",
    "    b_e = 0.01*randn(emb_width) \n",
    "    #W_d = 0.01*randn(emb_width*2,emb_width)\n",
    "    W_d = pinv(W_e) #Cheat (Actually why can't I always do this to initialize?);\n",
    "    b_d = 0.01*randn(emb_width*2)\n",
    "    \n",
    "    RAE(L,word_index, indexed_words, W_e, b_e, W_d, b_d)\n",
    "end\n",
    "\n",
    "\n",
    "function get_word_index(rae::RAE, input::String, show_warn=true)\n",
    "    if haskey(rae.word_index, input)\n",
    "        ii = rae.word_index[input]\n",
    "    elseif haskey(rae.word_index, lowercase(input))\n",
    "        ii = rae.word_index[lowercase(input)]\n",
    "    else\n",
    "        ii = rae.word_index[\"*UNKNOWN*\"]\n",
    "        if show_warn\n",
    "            println(\"$input not found. Defaulting.\")\n",
    "        end\n",
    "    end\n",
    "    ii\n",
    "end\n",
    "\n",
    "\n",
    "function eval_word_embedding(rae::RAE, input::String, show_warn=true)\n",
    "    k=get_word_index(rae, input, show_warn)\n",
    "    rae.L[:,k]\n",
    "end\n",
    "\n",
    "function eval_word_embeddings(rae::RAE, inputs::Words, show_warn=false)\n",
    "    ks = @pipe inputs |> map(ii -> get_word_index(rae,ii, show_warn), _)\n",
    "    rae.L[:,ks]\n",
    "end\n",
    "\n",
    "\n",
    "function eval_merges(rae::RAE, c_ijs::Embeddings)\n",
    "    tanh(rae.W_e*c_ijs.+rae.b_e)\n",
    "end\n",
    "\n",
    "function eval_merges(rae::RAE, c_is::Embeddings, c_js::Embeddings)\n",
    "    @assert size(c_is)==size(c_js)\n",
    "    eval_merges(rae,[c_is;c_js])\n",
    "end\n",
    "\n",
    "function eval_scores(rae::RAE, c_is::Embeddings, c_js::Embeddings,\n",
    "                      pps=eval_merges(rae, c_is, c_js)::Embeddings,\n",
    "                      ĉ_ijs = unfold_merges(rae,pps)::Embeddings)\n",
    "     c_ijs = [c_is;c_js]\n",
    "     \n",
    "     1/2*sum((c_ijs-ĉ_ijs).^2,1)\n",
    "end\n",
    "\n",
    "function reconstruct(rae::RAE, pp::Embedding)\n",
    "    ĉ_ij = tanh(rae.W_d*pp+rae.b_d)\n",
    "    ĉ_i = ĉ_ij[1:end/2]\n",
    "    ĉ_j = ĉ_ij[end/2+1:end]\n",
    "    ĉ_i, ĉ_j\n",
    "end\n",
    "\n",
    "function unfold_merges(rae::RAE, pps::Embeddings)\n",
    "    ĉ_ijs = tanh(rae.W_d*pps .+ rae.b_d)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type ActData\n",
    "    c_ij::Embedding\n",
    "    pp::Embedding\n",
    "    ĉ_ij::Embedding\n",
    "end\n",
    "\n",
    "\n",
    "#data_tree(left::Embedding, data::ActData, right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eval_to_tree (generic function with 2 methods)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function eval_to_tree(rr::RAE,sentence::String)\n",
    "    eval_to_tree(rr, tokenize(sentence))\n",
    "end\n",
    "\n",
    "function eval_to_tree(rr::RAE, sentence::Words)\n",
    "    tree = tuple(sentence...)\n",
    "    cs = eval_word_embeddings(rr, sentence)\n",
    "    act_tree = tuple_of_cols(cs)\n",
    "    score_total = 0.0\n",
    "    while(size(cs,2)>1)\n",
    "        c_is = cs[:, 1:end-1]\n",
    "        c_js = cs[:, 2:end]\n",
    "        \n",
    "        pps = eval_merges(rr, c_is, c_js)\n",
    "        ĉ_ijs = unfold_merges(rr,pps)\n",
    "        scores = eval_scores(rr, c_is, c_js, pps,ĉ_ijs)\n",
    "        im = indmax(scores)\n",
    "        \n",
    "        score_total+=scores[im]\n",
    "        c_ij=[c_is; c_js][:,im]\n",
    "        pp = pps[:,im]\n",
    "        ĉ_ij = ĉ_ijs[:,im]\n",
    "        act = ActData(c_ij, pp, ĉ_ij)\n",
    "        act_node = (act_tree[im], act, act_tree[im+1])\n",
    "        \n",
    "        cs = [cs[:,1:im-1] pp cs[:,im+2:end]]\n",
    "        tree = tuple(tree[1:im-1]..., (tree[im], tree[im+1]), tree[im+2:end]...)\n",
    "        act_tree = tuple(act_tree[1:im-1]..., act_node, act_tree[im+2:end]...)\n",
    "    end\n",
    "    \n",
    "    #Note The final step in tree creates a tuple containing one element, as first and last parts are empty\n",
    "    tree[1], act_tree[1], cs[:], score_total\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eval_scores_gradient (generic function with 2 methods)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function zero_col(W::Matrix)\n",
    "    zeros(size(W,1),1)\n",
    "end\n",
    "\n",
    "function tuple_of_cols(a::Matrix)\n",
    "    @pipe [a[:,col_ii] for col_ii in 1:size(a,2)] |> tuple(_...)\n",
    "end\n",
    "\n",
    "function BPTS(rae::RAE, nontree::Embedding, δ_above::Matrix)\n",
    "    #Note a tree. but a terminal state\n",
    "    (0,0,0,0)\n",
    "end\n",
    "\n",
    "function BPTS(rae::RAE, tree::(Any,ActData, Any), δ_above=zero_col(rae.W_e))\n",
    "    act=tree[2]\n",
    "    ∇s, δ_input = eval_scores_gradient(rae,act,δ_above)\n",
    "    δ_left  = δ_input[1:end/2,:]\n",
    "    δ_right = δ_input[end/2+1:end,:]\n",
    "\n",
    "    ∇s_left = BPTS(rae, tree[1], δ_left)\n",
    "    ∇s_right = BPTS(rae, tree[3], δ_right)\n",
    "    tuple([l+c+r for (c,l,r) in zip(∇s_left,∇s, ∇s_right)]...)\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "function eval_scores_gradient(rae::RAE, \n",
    "                              act::ActData,\n",
    "                              δ_parent=zero_col(rae.W_e))\n",
    "    #Notice: While this is good to go for multiple concurrent, \n",
    "    #It does't actually do so, as a tree is the \n",
    "    \n",
    "    \n",
    "    c_ijs::Embeddings = act.c_ij''\n",
    "    pps::Embeddings = act.pp''\n",
    "    ĉ_ijs::Embeddings = act.ĉ_ij''\n",
    "    \n",
    "    #http://neuralnetworksanddeeplearning.com/chap2.h)tml\n",
    "    N = size(c_ijs,2)\n",
    "    \n",
    "    da = (ĉ_ijs - c_ijs)\n",
    "    dz_d = (1-ĉ_ijs.^2)\n",
    "    δ_d = da.*dz_d #Output Error\n",
    "\n",
    "    ∇W_d = 1/N*δ_d*pps'\n",
    "    ∇b_d = 1/N*sum(δ_d,2)[:]\n",
    "    \n",
    "    \n",
    "    dz_e = (1-pps.^2)\n",
    "    δ_e = (rae.W_d'*δ_d).*(dz_e .+ δ_parent) #Hidden layer error\n",
    "        \n",
    "\n",
    "    ∇W_e = 1/N*δ_e*c_ijs'\n",
    "    ∇b_e = 1/N*sum(δ_e,2)[:]\n",
    "    \n",
    "    ∇s = (∇W_e, ∇b_e, ∇W_d, ∇b_d)\n",
    "    \n",
    "    #input error, ie parent error for layer below\n",
    "    dz_p = (1-c_ijs.^2)\n",
    "    δ_input = (rae.W_e'*δ_e - da).*dz_p\n",
    "    \n",
    "    ∇s, δ_input\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rr = RAE(LL,word_indexes,indexed_words);\n",
    "\n",
    "sent = \"the boy destroyed the house\"\n",
    "sent_toks = tokenize(sent)\n",
    "\n",
    "tree, act_tree, pp, score_total = eval_to_tree(rr,sent_toks);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((\"the\",\"boy\"),((\"destroyed\",\"the\"),\"house\"))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using Iterators\n",
    "@pyimport nltk.corpus as nltk_corpus\n",
    "n_training = 100000\n",
    "#training_sents = @pipe nltk_corpus.brown[:sents]() |> take(_,n_training)  |> collect |> convert(Vector{Vector{String}},_);\n",
    "training_sents = @pipe nltk_corpus.brown[:sents]() |> filter(s->1<length(s)<=15, _) |> take(_,n_training)  |> collect |> convert(Vector{Vector{String}},_);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23954,)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_sents |> size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using Optim #https://github.com/JuliaOpt/Optim.jl\n",
    "\n",
    "rae_outer = RAE(LL,word_indexes,indexed_words);\n",
    "\n",
    "function unpack!(rae::RAE, θ::Vector)\n",
    "    W_e_len = length(rae.W_e)\n",
    "    b_e_len = length(rae.b_e)\n",
    "    W_d_len = length(rae.W_d)\n",
    "    b_d_len = length(rae.b_d)\n",
    "    W_e_shape = size(rae.W_e)\n",
    "    W_d_shape = size(rae.W_d)\n",
    "    \n",
    "    rae.W_e = reshape(θ[1: W_e_len],W_e_shape)\n",
    "    rae.b_e = θ[W_e_len+1: W_e_len+b_e_len]\n",
    "    rae.W_d = reshape(θ[W_e_len+b_e_len+1: W_e_len+b_e_len+W_d_len],W_d_shape)\n",
    "    rae.b_d = θ[W_e_len+b_e_len+W_d_len+1: end]\n",
    "    \n",
    "    rae\n",
    "end\n",
    "\n",
    "function pack(rae::RAE)\n",
    "    [rae.W_e[:],rae.b_e, rae.W_d[:],rae.b_d[:]] \n",
    "end\n",
    "\n",
    "function pack(∇W_e::Matrix{Float64}, ∇b_e::Vector{Float64}, ∇W_d::Matrix{Float64}, ∇b_d::Vector{Float64})\n",
    "    [∇W_e[:], ∇b_e, ∇W_d[:], ∇b_d] \n",
    "end\n",
    "\n",
    "#--------------------------------------------------------\n",
    "\n",
    "function loss!(θ::Vector)  \n",
    "    rae = unpack!(rae_outer, θ)\n",
    "    @pipe training_sents |> map( ss-> eval_to_tree(rae, ss)[end], _) |> mean\n",
    "end\n",
    "\n",
    "function loss_grad!(θ::Vector, storage::Vector) \n",
    "    error(\"loss_grad! CALLED\")\n",
    "    storage[:] = 0\n",
    "    storage = zeros(storage)\n",
    "    rae = unpack!(rae_outer, θ)\n",
    "    for ss in training_sents\n",
    "        tree, act_tree, pp, err_total = eval_to_tree(rae, ss)\n",
    "        ∇s=BPTS(rae,act_tree)\n",
    "        storage+=pack(∇s...)\n",
    "    end\n",
    "    storage/=length(training_sents)\n",
    "end\n",
    "\n",
    "function loss_and_loss_grad!(θ::Vector, storage::Vector)   \n",
    "    storage[:] = 0\n",
    "    rae = unpack!(rae_outer, θ)\n",
    "    err = 0.0\n",
    "    for ss in training_sents\n",
    "        tree, act_tree, pp, err_total = eval_to_tree(rae, ss)\n",
    "        ∇s=BPTS(rae,act_tree)\n",
    "        storage[:]+=pack(∇s...)\n",
    "        err+=err_total\n",
    "    end\n",
    "    storage[:]/=length(training_sents)\n",
    "    err/=length(training_sents)\n",
    "    err\n",
    "end\n",
    "\n",
    "f=DifferentiableFunction(loss!,loss_grad!,loss_and_loss_grad!)\n",
    "#Must provide Graident as finite difference requires ~length(θ) calls to f\n",
    "res = optimize(f, pack(rae_outer), method=:gradient_descent, show_trace = true,iterations = 2)\n",
    "rae_outer = unpack!(rae_outer, res.minimum);\n",
    "print(\"---------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm(storage) = 7.793957190944008\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.793957190944008"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store = zeros(pack(rae_outer))\n",
    "loss_and_loss_grad!(pack(rae_outer), store)\n",
    "norm(store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1x2 Array{Float64,2}:\n",
       " 0.5  1.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function halve!(a)\n",
    "    a[:]/=2\n",
    "end\n",
    "\n",
    "a=[1.0 2.0]\n",
    "\n",
    "halve!(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "res not defined\nwhile loading In[17], in expression starting on line 18",
     "output_type": "error",
     "traceback": [
      "res not defined\nwhile loading In[17], in expression starting on line 18",
      ""
     ]
    }
   ],
   "source": [
    "#==\n",
    "    method::ASCIIString\n",
    "    initial_x::Array{T,N}\n",
    "    minimum::Array{T,N}\n",
    "    f_minimum::Float64\n",
    "    iterations::Int\n",
    "    iteration_converged::Bool\n",
    "    x_converged::Bool\n",
    "    xtol::Float64\n",
    "    f_converged::Bool\n",
    "    ftol::Float64\n",
    "    gr_converged::Bool\n",
    "    grtol::Float64\n",
    "    trace::OptimizationTrace\n",
    "    f_calls::Int\n",
    "    g_calls::Int\n",
    "=#\n",
    "@printval res.f_calls \n",
    "@printval res.g_calls \n",
    "@printval res.x_converged \n",
    "@printval res.iterations\n",
    "@printval res.f_minimum\n",
    "@printval res.gr_converged\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/JuliaLang/julia/blob/master/doc/manual/profile.rst Actual instructions on profiling\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "type: anonymous: in apply, expected Function, got DifferentiableFunction\nwhile loading In[18], in expression starting on line 2",
     "output_type": "error",
     "traceback": [
      "type: anonymous: in apply, expected Function, got DifferentiableFunction\nwhile loading In[18], in expression starting on line 2",
      "",
      " in anonymous at profile.jl:14"
     ]
    }
   ],
   "source": [
    "Profile.clear()\n",
    "@profile f(pack(rae_outer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "ProfileView not found\nwhile loading In[19], in expression starting on line 1",
     "output_type": "error",
     "traceback": [
      "ProfileView not found\nwhile loading In[19], in expression starting on line 1",
      "",
      " in require at loading.jl:47"
     ]
    }
   ],
   "source": [
    "using ProfileView\n",
    "ProfileView.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unfold (generic function with 4 methods)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tree data in tree is not use, other than it's structure.\n",
    "#(((\"the\",\"house\"),(\"destroyed\",(\"the\",\"boy\")))  is equivalent to (((\"\",\"\"),(\"\",(\"\",\"\"))) \n",
    "\n",
    "\n",
    "\n",
    "function unfold(rae::RAE, tree::(String,String), pp::Embedding)\n",
    "    ĉ_is, ĉ_js = reconstruct(rae, pp)\n",
    "    [ĉ_is ĉ_js]\n",
    "end\n",
    "\n",
    "\n",
    "function unfold(rae::RAE, tree::(Any,String), pp::Embedding)\n",
    "    p̂_is, ĉ_js = reconstruct(rae, pp)\n",
    "    ĉ_is = unfold(rae, tree[1], p̂_is)\n",
    "    [ĉ_is ĉ_js]\n",
    "end\n",
    "\n",
    "function unfold(rae::RAE, tree::(String,Any), pp::Embedding)\n",
    "    ĉ_is, p̂_js = reconstruct(rae, pp)\n",
    "    ĉ_js = unfold(rae, tree[2], p̂_js)\n",
    "    [ĉ_is ĉ_js]\n",
    "    \n",
    "end\n",
    "\n",
    "function unfold(rae::RAE, tree::(Any,Any), pp::Embedding)\n",
    "    p̂_is, p̂_js = reconstruct(rae, pp)\n",
    "    ĉ_is = unfold(rae, tree[1], p̂_is)\n",
    "    ĉ_js = unfold(rae, tree[2], p̂_js)\n",
    "    [ĉ_is ĉ_js]\n",
    "end\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "show_bests (generic function with 2 methods)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function cosine_dist(a,b)\n",
    "    (a⋅b)/(norm(a)*norm(b))\n",
    "end\n",
    "\n",
    "function neighbour_dists(cc::Vector{Float64}, globe::Matrix{Float64})\n",
    "    [cosine_dist(cc, globe[:,ii]) for ii in 1:size(globe,2)]\n",
    "end\n",
    "\n",
    "\n",
    "function show_best(rae::RAE,ĉ::Embedding, nbest=20)\n",
    "    candidates=neighbour_dists(ĉ,rae.L)   \n",
    "    best_cands = [ (findfirst(candidates,score), score)\n",
    "                    for score in select(candidates,1:nbest, rev=true)[1:nbest]]\n",
    "    vcat([[rae.indexed_words[ii] score] for (ii,score) in best_cands]...)\n",
    "end\n",
    "\n",
    "function show_bests(rae::RAE,ĉs::Embeddings, nbest=20)\n",
    "    hcat([show_best(rae,ĉs[:,ii],nbest) for ii in 1:size(ĉs,2)]...)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "tokenize not defined\nwhile loading In[22], in expression starting on line 1",
     "output_type": "error",
     "traceback": [
      "tokenize not defined\nwhile loading In[22], in expression starting on line 1",
      "",
      " in eval_to_tree at In[11]:2"
     ]
    }
   ],
   "source": [
    "tree, pp, score_total = eval_to_tree(rae_outer,\"easy holdings\")\n",
    "ĉs = unfold(rae_outer,tree,pp)\n",
    "\n",
    "show_bests(rae_outer, ĉs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: New definition \n",
      "    unfold_struct((String,Any),) at In[23]:19\n",
      "is ambiguous with: \n",
      "    unfold_struct((Any,String),) at In[23]:14.\n",
      "To fix, define \n",
      "    unfold_struct((String,String),)\n",
      "before the new definition.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "print_tree (generic function with 1 method)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function depth_inc(ele::(Int,String))\n",
    "    (ele[1]+1,ele[2])\n",
    "end\n",
    "\n",
    "function unfold_struct(tree::(Any,Any))\n",
    "    left_tree = unfold_struct(tree[1]) \n",
    "    left = @pipe left_tree |> map(depth_inc,_)\n",
    "    right_tree = unfold_struct(tree[2]) \n",
    "    right = @pipe right_tree |> map(depth_inc,_)\n",
    "    [left, right, (0,\"\")]\n",
    "end\n",
    "\n",
    "function unfold_struct(tree::(Any,String))\n",
    "    left_tree = unfold_struct(tree[1]) \n",
    "    left = @pipe left_tree |> map(depth_inc,_)\n",
    "    [left, (0,tree[2]), (0,\"\")]\n",
    "end\n",
    "function unfold_struct(tree::(String,Any))\n",
    "    right_tree = unfold_struct(tree[2]) \n",
    "    right = @pipe right_tree |> map(depth_inc,_)\n",
    "    [(0,tree[1]),right, (0,\"\")]\n",
    "end\n",
    "function unfold_struct(tree::(String,String))\n",
    "    [(0,tree[1]), (0, tree[2]), (0,\"\")]\n",
    "end\n",
    "\n",
    "function print_tree(tree::(Any,Any))\n",
    "    \n",
    "    for (depth,word ) in unfold_struct(tree)\n",
    "        println(\"\\t\"^depth, word)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.3.8",
   "language": "julia",
   "name": "julia-0.3"
  },
  "language_info": {
   "name": "julia",
   "version": "0.3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
