{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for ii in 1:6\n",
    "    #addprocs([\"heathred\"])\n",
    "end\n",
    "\n",
    "for ii in 1:4\n",
    "    #addprocs([\"amon\"], dir=\"\")\n",
    "    #addprocs([\"zeus\"], dir=\"\")\n",
    "    #addprocs([\"jove\"], dir=\"\")\n",
    "end\n",
    "\n",
    "for ii in 1:10\n",
    "    #addprocs([\"uggp\"], dir=\"\")\n",
    "end\n",
    "\n",
    "addprocs(6)\n",
    "workers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "include(\"ClusterSoup.jl\")\n",
    "@everywhere using RecursiveAutoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using Pipe\n",
    "function pz(x :: AbstractArray)\n",
    "    println(typeof(x), \": \", size(x))\n",
    "end\n",
    "macro printval(ee)\n",
    "    ee_expr = @sprintf \"%s\" string(ee)\n",
    "    esc(:(println($ee_expr,\" = \", $ee)))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using PyCall\n",
    "@pyimport nltk\n",
    "function tokenize(sentence::String)\n",
    "    convert(Array{String,1},nltk.word_tokenize(sentence))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "include(\"load_embeddings.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LL,word_indexes, indexed_words =  load_embeddings(\"embeddings-scaled.EMBEDDING_SIZE=200.txt\");\n",
    "size(LL) |> println\n",
    "word_indexes |> typeof |> println\n",
    "indexed_words |> typeof |> println"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using Iterators\n",
    "@pyimport nltk.corpus as nltk_corpus\n",
    "n_training = 4261\n",
    "training_sents = @pipe nltk_corpus.brown[:sents]() |> filter(s->1<length(s)<=5, _) |> take(_,n_training)  |> collect |> convert(Vector{Vector{String}},_);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_sents |> size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chunk_data(:training_sents, training_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@everywhere function unpack!(rae::RAE, θ::Vector)\n",
    "    W_e_len = length(rae.W_e)\n",
    "    b_e_len = length(rae.b_e)\n",
    "    W_d_len = length(rae.W_d)\n",
    "    b_d_len = length(rae.b_d)\n",
    "    W_e_shape = size(rae.W_e)\n",
    "    W_d_shape = size(rae.W_d)\n",
    "    \n",
    "    rae.W_e = reshape(θ[1: W_e_len],W_e_shape)\n",
    "    rae.b_e = θ[W_e_len+1: W_e_len+b_e_len]\n",
    "    rae.W_d = reshape(θ[W_e_len+b_e_len+1: W_e_len+b_e_len+W_d_len],W_d_shape)\n",
    "    rae.b_d = θ[W_e_len+b_e_len+W_d_len+1: end]\n",
    "    \n",
    "    rae\n",
    "end\n",
    "\n",
    "@everywhere function pack(rae::RAE)\n",
    "    [rae.W_e[:],rae.b_e, rae.W_d[:],rae.b_d[:]] \n",
    "end\n",
    "\n",
    "@everywhere function pack(∇W_e::Matrix{Float64}, ∇b_e::Vector{Float64}, ∇W_d::Matrix{Float64}, ∇b_d::Vector{Float64})\n",
    "    [∇W_e[:], ∇b_e, ∇W_d[:], ∇b_d] \n",
    "end\n",
    "\n",
    "#--------------------------------------------------------\n",
    "\n",
    "function loss!(θ::Vector)  \n",
    "    error(\"loss not defined\")\n",
    "end\n",
    "\n",
    "function loss_grad!(θ::Vector, storage::Vector) \n",
    "    error(\"loss_grad not defined\")\n",
    "end\n",
    "\n",
    "rae_outer = RAE(LL,word_indexes,indexed_words);\n",
    "set_global(:rae_outer,rae_outer)\n",
    "function loss_and_loss_grad!(θ::Vector, grad::Vector)   \n",
    "    grad[:] = 0\n",
    "    for pid in workers()\n",
    "        remotecall(pid, θv->unpack!(rae_outer, θv),θ) \n",
    "    end\n",
    "    function loss_and_loss_grad(ss::Words)\n",
    "        tree, act_tree, pp, err = eval_to_tree(rae_outer, ss)\n",
    "        ∇s=BPTS(rae_outer,act_tree)\n",
    "        [pack(∇s...), err]\n",
    "    end\n",
    "    \n",
    "    ret = prechunked_mapreduce(:training_sents, loss_and_loss_grad, (+)) \n",
    "    grad[:] = ret[1:end-1]\n",
    "    err=ret[end]\n",
    "    \n",
    "    grad[:]/=length(training_sents)\n",
    "    err/=length(training_sents)\n",
    "    err\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using NLopt\n",
    "\n",
    "f_call_count = 0\n",
    "function tracking_loss_and_loss_grad!(θ::Vector, grad::Vector)\n",
    "    global f_call_count\n",
    "    f_call_count+=1\n",
    "    f_val = loss_and_loss_grad!(θ, grad)   \n",
    "    println(f_call_count, '\\t',f_val,'\\t',norm(grad))\n",
    "    f_val\n",
    "end\n",
    "#:LD_LBFGS, :LD_MMA\n",
    "opt = Opt(:LD_MMA, length(pack(rae_outer)))\n",
    "ftol_abs!(opt,1e-9)\n",
    "maxtime!(opt, 6000)\n",
    "min_objective!(opt, tracking_loss_and_loss_grad!)\n",
    "(optf,optx,ret) = optimize!(opt,pack(rae_outer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#rae_outer = remotecall_fetch(4, dummy->rae_outer,nothing);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using Optim #https://github.com/JuliaOpt/Optim.jl\n",
    "f=DifferentiableFunction(loss!,loss_grad!,loss_and_loss_grad!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Profile.clear()\n",
    "#Profile.init(delay=0.1)\n",
    "tic()\n",
    "res = optimize(f, pack(rae_outer), method=:l_bfgs, show_trace = true, store_trace = true, iterations = 10);\n",
    "time_take = toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#==\n",
    "    method::ASCIIString\n",
    "    initial_x::Array{T,N}\n",
    "    minimum::Array{T,N}\n",
    "    f_minimum::Float64\n",
    "    iterations::Int\n",
    "    iteration_converged::Bool\n",
    "    x_converged::Bool\n",
    "    xtol::Float64\n",
    "    f_converged::Bool\n",
    "    ftol::Float64\n",
    "    gr_converged::Bool\n",
    "    grtol::Float64\n",
    "    trace::OptimizationTrace\n",
    "    f_calls::Int\n",
    "    g_calls::Int\n",
    "=#\n",
    "@printval time_take\n",
    "@printval res.f_calls \n",
    "@printval res.g_calls \n",
    "@printval res.x_converged \n",
    "@printval res.iterations\n",
    "@printval res.f_minimum\n",
    "@printval res.gr_converged\n",
    "@printval res.trace\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/JuliaLang/julia/blob/master/doc/manual/profile.rst Actual instructions on profiling\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using ProfileView\n",
    "ProfileView.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##3000: 1<len(sentence)<=5\n",
    " - **base:** elapsed time: 138.752550969 seconds (34239757952 bytes allocated, 83.92% gc time)\n",
    " - **base 2 (after restart)** elapsed time: 232.798843691 seconds (58940288804 bytes allocated, 83.25% gc time)\n",
    " \n",
    " \n",
    " - **2 sys after fix:**\n",
    "  - **1st** elapsed time: 209.497508123 seconds (51858148 bytes allocated, 0.16% gc time)\n",
    "  - **2nd** elapsed time: 207.234529931 seconds (20805144 bytes allocated, 0.08% gc time) \n",
    "  \n",
    " - **12 (on 3 Amon, 4 Heathred, 5 Motsugo**\n",
    "  - **1st** elapsed time: 29.078831144 seconds (68477788 bytes allocated, 0.58% gc time)\n",
    "  - **2nd** elapsed time: 27.259917889 seconds (63650168 bytes allocated, 3.03% gc time)\n",
    "  \n",
    " - **16**\n",
    "  - **1st**  elapsed time: 31.49018094 seconds (213737316 bytes allocated, 3.27% gc time)\n",
    "  - **2nd** elapsed time: 23.265633784 seconds (104136464 bytes allocated, 2.41% gc time)\n",
    "  \n",
    "  ##23954: 1<len(sentence)<15\n",
    "  - **16** elapsed time: 3034.431581365 seconds (113266660 bytes allocated, 0.04% gc time)\n",
    "  - **24, for 15 iterations** elapsed time: 2478.921464409 seconds (701113364 bytes allocated, 0.18% gc time)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function cosine_dist(a,b)\n",
    "    (a⋅b)/(norm(a)*norm(b))\n",
    "end\n",
    "\n",
    "function neighbour_dists(cc::Vector{Float64}, globe::Matrix{Float64})\n",
    "    [cosine_dist(cc, globe[:,ii]) for ii in 1:size(globe,2)]\n",
    "end\n",
    "\n",
    "\n",
    "function show_best(rae::RAE,ĉ::Embedding, nbest=20)\n",
    "    candidates=neighbour_dists(ĉ,rae.L)   \n",
    "    best_cands = [ (findfirst(candidates,score), score)\n",
    "                    for score in select(candidates,1:nbest, rev=true)[1:nbest]]\n",
    "    vcat([[rae.indexed_words[ii] round(score,2)] for (ii,score) in best_cands]...)\n",
    "end\n",
    "\n",
    "function show_bests(rae::RAE,ĉs::Embeddings, nbest=20)\n",
    "    hcat([show_best(rae,ĉs[:,ii],nbest) for ii in 1:size(ĉs,2)]...)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sent = \"dangerous trends predict failure\"\n",
    "sent_toks = tokenize(sent)\n",
    "\n",
    "tree, act_tree, pp, score_total = eval_to_tree(rae_outer,sent_toks);\n",
    "println(tree)\n",
    "\n",
    "ĉs = unfold(rae_outer,tree,pp)\n",
    "bests= show_bests(rae_outer, ĉs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bests[1:4,1:2:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.3.8",
   "language": "julia",
   "name": "julia-0.3"
  },
  "language_info": {
   "name": "julia",
   "version": "0.3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
