{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ENV[\"LINES\"] = 30\n",
    "ENV[\"COLUMNS\"] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using Pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function pz(x :: AbstractArray)\n",
    "    println(typeof(x), \": \", size(x))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using PyCall\n",
    "@pyimport nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function tokenize(sentence::String)\n",
    "    convert(Array{String,1},nltk.word_tokenize(sentence))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "include(\"load_embeddings.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LL,word_index,indexed_words =  load_embeddings(\"embeddings-scaled.EMBEDDING_SIZE=50.txt\");\n",
    "size(LL) |> println\n",
    "word_index|> typeof |> println\n",
    "indexed_words|> typeof |> println"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "typealias Embedding Vector{Float64}\n",
    "typealias Embeddings Matrix{Float64}\n",
    "typealias Words Union(AbstractArray{ASCIIString,1},AbstractArray{String,1})\n",
    "type RAE\n",
    "    L::Matrix{Float64}\n",
    "    word_index::Dict{String,BitVector}\n",
    "    indexed_words::Vector{String}\n",
    "    \n",
    "    W_e::Matrix{Float64}\n",
    "    W_d::Matrix{Float64}\n",
    "   \n",
    "end\n",
    "\n",
    "\n",
    "function RAE(L::Matrix{Float64}, word_index::Dict{String,BitVector}, indexed_words::Vector{String})\n",
    "    emb_width = size(L,1)\n",
    "    \n",
    "    W_e =0.01*randn(emb_width,emb_width*2+1) \n",
    "    #W_d = 0.01*randn(emb_width*2,emb_width+1)\n",
    "    W_d = [pinv(W_e)[1:end-1,:] zeros(size(pinv(W_e),1)-1) ] #Cheat (Actually why can't I always do this to initialize?);\n",
    "    RAE(L,word_index, indexed_words, W_e, W_d)\n",
    "end\n",
    "\n",
    "function eval_embedding(rae::RAE, input::String, show_warn=true)\n",
    "    if haskey(rae.word_index, input)\n",
    "        k = rae.word_index[input]\n",
    "    elseif haskey(word_index, lowercase(input))\n",
    "        k = rae.word_index[lowercase(input)]\n",
    "    else\n",
    "        k = rae.word_index[\"*UNKNOWN*\"]\n",
    "        if show_warn\n",
    "            println(\"$input not found. Defaulting.\")\n",
    "        end\n",
    "    end\n",
    "    rae.L*k\n",
    "end\n",
    "\n",
    "function eval_embeddings(rae::RAE, inputs::Words, show_warn=false)\n",
    "    @pipe inputs |> map(ii -> eval_embedding(rae,ii, show_warn), _) |> hcat(_...)\n",
    "end\n",
    "\n",
    "function eval_embeddings(rae::RAE, c_is::Embeddings, c_js::Embeddings)\n",
    "    @assert size(c_is)==size(c_js)\n",
    "    bias_in = ones(1,size([c_is], 2))\n",
    "    tanh(rae.W_e*[c_is;c_js;bias_in])\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function eval_scores(rae::RAE, c_is::Embeddings, c_js::Embeddings)\n",
    "    pps=eval_embeddings(rae, c_is, c_js)\n",
    "    c_ijs = [c_is;c_js]\n",
    "    bias_in = ones(1,size(pps, 2))\n",
    "    ĉ_ijs = tanh(rae.W_d*[pps;bias_in])\n",
    "    \n",
    "    sum((c_ijs-ĉ_ijs).^2,1)\n",
    "end\n",
    "\n",
    "#A better scoring function is given in SorcherRAE (eaquation 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function eval_to_tree(rr::RAE,sentence::String)\n",
    "    eval_to_tree(rr, tokenize(sentence))\n",
    "end\n",
    "\n",
    "function eval_to_tree(rr::RAE, sentence::Words)\n",
    "    tree = tuple(sentence...)\n",
    "    cs = eval_embeddings(rr, sentence)\n",
    "    score_total = 0.0\n",
    "    while(size(cs,2)>1)\n",
    "        c_is = cs[:, 1:end-1]\n",
    "        c_js = cs[:, 2:end]\n",
    "        \n",
    "        pps = eval_embeddings(rr, c_is, c_js)\n",
    "        scores = eval_scores(rr, c_is, c_js)\n",
    "        im = indmax(scores)\n",
    "        \n",
    "        score_total+=scores[im]\n",
    "         \n",
    "        cs = [cs[:,1:im-1] pps[:,im] cs[:,im+2:end]]\n",
    "        tree = tuple(tree[1:im-1]..., (tree[im], tree[im+1]), tree[im+2:end]...)\n",
    "    end\n",
    "    tree = tree[1] #The final step creates a tuple containing one element, as first and last parts are empty\n",
    "    embedding = cs[:]\n",
    "    tree, embedding, score_total\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rr = RAE(LL,word_index,indexed_words);\n",
    "\n",
    "sent = \"the boy destroyed the house\"\n",
    "sent_toks = tokenize(sent)\n",
    "\n",
    "tree, pp, score_total = eval_to_tree(rr,sent_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using Iterators\n",
    "@pyimport nltk.corpus as nltk_corpus\n",
    "n_training = 40000\n",
    "training_sents = @pipe nltk_corpus.brown[:sents]() |> take(_,n_training)  |> collect |> convert(Vector{Vector{String}},_);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "using Optim\n",
    "\n",
    "rae_outer = RAE(LL,word_index,indexed_words);\n",
    "\n",
    "function unpack!(rae::RAE, θ::Vector)\n",
    "    W_e_len = length(rae.W_e)\n",
    "    W_d_len = length(rae.W_d)\n",
    "    W_e_shape = size(rae.W_e)\n",
    "    W_d_shape = size(rae.W_d)\n",
    "    \n",
    "    rae.W_e = reshape(θ[1:W_e_len],W_e_shape)\n",
    "    rae.W_d = reshape(θ[W_e_len+1:end],W_d_shape)\n",
    "    \n",
    "    rae\n",
    "end\n",
    "\n",
    "function pack(rae::RAE)\n",
    "    [rae.W_e[:], rae.W_d[:]] \n",
    "end\n",
    "\n",
    "function f(θ::Vector)\n",
    "    rae = unpack!(rae_outer, θ)\n",
    "    @pipe training_sents |> map( ss-> eval_to_tree(rae, ss)[3], _) |> mean\n",
    "end\n",
    "\n",
    "\n",
    "res = optimize(f, pack(rae_outer), method=:l_bfgs, show_trace = true, store_trace=true, iterations = 10)\n",
    "println(res)\n",
    "rae_outer = unpack!(rae_outer, res.minimum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tree data in tree is not use, other than it's structure.\n",
    "#(((\"the\",\"house\"),(\"destroyed\",(\"the\",\"boy\")))  is equivalent to (((\"\",\"\"),(\"\",(\"\",\"\"))) \n",
    "\n",
    "function reconstruct(rae::RAE, pp::Embedding)\n",
    "    bias_in = 1\n",
    "    ĉ_ijs = tanh(rae.W_d*[pp;bias_in])\n",
    "    ĉ_is = ĉ_ijs[1:end/2]\n",
    "    ĉ_js = ĉ_ijs[end/2+1:end]\n",
    "    ĉ_is, ĉ_js\n",
    "end\n",
    "\n",
    "function unfold(rae::RAE, tree::(String,String), pp::Embedding)\n",
    "    ĉ_is, ĉ_js = reconstruct(rae, pp)\n",
    "    [ĉ_is ĉ_js]\n",
    "end\n",
    "\n",
    "\n",
    "function unfold(rae::RAE, tree::(Any,String), pp::Embedding)\n",
    "    p̂_is, ĉ_js = reconstruct(rae, pp)\n",
    "    ĉ_is = unfold(rae, tree[1], p̂_is)\n",
    "    [ĉ_is ĉ_js]\n",
    "end\n",
    "\n",
    "function unfold(rae::RAE, tree::(String,Any), pp::Embedding)\n",
    "    ĉ_is, p̂_js = reconstruct(rae, pp)\n",
    "    ĉ_js = unfold(rae, tree[2], p̂_js)\n",
    "    [ĉ_is ĉ_js]\n",
    "    \n",
    "end\n",
    "\n",
    "function unfold(rae::RAE, tree::(Any,Any), pp::Embedding)\n",
    "    p̂_is, p̂_js = reconstruct(rae, pp)\n",
    "    ĉ_is = unfold(rae, tree[1], p̂_is)\n",
    "    ĉ_js = unfold(rae, tree[2], p̂_js)\n",
    "    [ĉ_is ĉ_js]\n",
    "end\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree, pp, score_total = eval_to_tree(rr,\"killer cows\")\n",
    "ĉs = unfold(rr,tree,pp)\n",
    "\n",
    "show_bests(rr, ĉs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function cosine_dist(a,b)\n",
    "    (a⋅b)/(norm(a)*norm(b))\n",
    "end\n",
    "\n",
    "function neighbour_dists(cc::Vector{Float64}, globe::Matrix{Float64})\n",
    "    [cosine_dist(cc, globe[:,ii]) for ii in 1:size(globe,2)]\n",
    "end\n",
    "\n",
    "\n",
    "function show_best(rae::RAE,ĉ::Embedding, nbest=20)\n",
    "    candidates=neighbour_dists(ĉ,rae.L)   \n",
    "    best_cands = [ (findfirst(candidates,score), score)\n",
    "                    for score in select(candidates,1:nbest, rev=true)[1:nbest]]\n",
    "    vcat([[rae.indexed_words[ii] score] for (ii,score) in best_cands]...)\n",
    "end\n",
    "\n",
    "function show_bests(rae::RAE,ĉs::Embeddings, nbest=20)\n",
    "    hcat([show_best(rae,ĉs[:,ii],nbest) for ii in 1:size(ĉs,2)]...)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function depth_inc(ele::(Int,String))\n",
    "    (ele[1]+1,ele[2])\n",
    "end\n",
    "\n",
    "function unfold_struct(tree::(Any,Any))\n",
    "    left_tree = unfold_struct(tree[1]) \n",
    "    left = @pipe left_tree |> map(depth_inc,_)\n",
    "    right_tree = unfold_struct(tree[2]) \n",
    "    right = @pipe right_tree |> map(depth_inc,_)\n",
    "    [left, right, (0,\"\")]\n",
    "end\n",
    "\n",
    "function unfold_struct(tree::(Any,String))\n",
    "    left_tree = unfold_struct(tree[1]) \n",
    "    left = @pipe left_tree |> map(depth_inc,_)\n",
    "    [left, (0,tree[2]), (0,\"\")]\n",
    "end\n",
    "function unfold_struct(tree::(String,Any))\n",
    "    right_tree = unfold_struct(tree[2]) \n",
    "    right = @pipe right_tree |> map(depth_inc,_)\n",
    "    [(0,tree[1]),right, (0,\"\")]\n",
    "end\n",
    "function unfold_struct(tree::(String,String))\n",
    "    [(0,tree[1]), (0, tree[2]), (0,\"\")]\n",
    "end\n",
    "\n",
    "function print_tree(tree::(Any,Any))\n",
    "    \n",
    "    for (depth,word ) in unfold_struct(tree)\n",
    "        println(\"\\t\"^depth, word)\n",
    "    end\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.3.7-pre debug",
   "language": "julia",
   "name": "julia 0.3 debug"
  },
  "language_info": {
   "name": "julia",
   "version": "0.3.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
