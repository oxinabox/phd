{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/numpy/core/fromnumeric.py:2499: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  VisibleDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "using PyCall\n",
    "@pyimport nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenize (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function tokenize(sentence::String)\n",
    "    convert(Array{String,1},nltk.word_tokenize(sentence))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_embeddings (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"load_embeddings.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,268810)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LL,word_index,indexed_words =  load_embeddings(\"embeddings-scaled.EMBEDDING_SIZE=50.txt\");\n",
    "size(LL) |> println\n",
    "word_index|> typeof |> println\n",
    "indexed_words|> typeof |> println"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eval_score (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typealias Embedding Vector{Float64}\n",
    "typealias Embeddings Matrix{Float64}\n",
    "\n",
    "type RAE\n",
    "    L::Matrix{Float64}\n",
    "    word_index::Dict{String,BitVector}\n",
    "    indexed_words::Vector{String}\n",
    "    \n",
    "    W_e::Matrix{Float64}\n",
    "    W_d::Matrix{Float64}\n",
    "   \n",
    "end\n",
    "\n",
    "\n",
    "function RAE(L::Matrix{Float64}, word_index::Dict{String,BitVector}, indexed_words::Vector{String})\n",
    "    emb_width = size(L,1)\n",
    "    \n",
    "    RAE(L,word_index, indexed_words,\n",
    "        0.01*randn(emb_width,emb_width*2+1),\n",
    "        0.01*randn(emb_width*2,emb_width) )\n",
    "end\n",
    "\n",
    "function eval_embedding(rae::RAE, input::String)\n",
    "    k=word_index[input]\n",
    "    rae.L*eval_embedding\n",
    "end\n",
    "\n",
    "function eval_embeddings(rae::RAE, c_is::Embeddings, c_js::Embeddings)\n",
    "    @assert size(c_is)==size(c_js)\n",
    "    bias_in = ones(1,size([c_is], 2))\n",
    "    tanh(rae.W_e*[c_is;c_js;bias_in])\n",
    "end\n",
    "\n",
    "function eval_scores(rae::RAE, input_A::Embeddings, input_B::Embeddings)\n",
    "    pp=eval_embedding(rae, input_A, input_B)\n",
    "    \n",
    "    bias_in = ones(1,size(pp, 2))\n",
    "    ĉ_ijs = tanh(rae.W_d*[pp;bias_in])\n",
    "    \n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eval_to_tree (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function word_adjancy_matrix(sentence_len::Int)\n",
    "    #TODO: Replace this whole adjancy matrix with a linked list\n",
    "    [(ii==jj+1) || (ii==jj-1)  for ii in 1:sentence_len, jj in 1:sentence_len]\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "function eval_to_tree(rr::RNN, sentence::AbstractArray{String})\n",
    "    backlookup = sentence\n",
    "    ss = hcat([get_embedding(embeddings, token) for token in backlookup]...)\n",
    "    AA = word_adjancy_matrix(size(ss,2))\n",
    "    \n",
    "    score_total = 0.0\n",
    "    while(any(AA))\n",
    "        iis, jjs = findn(AA)\n",
    "\n",
    "        pps = eval_embedding(rr, ss[:,iis],ss[:,jjs])\n",
    "        scores = eval_score(rr, pps)\n",
    "        best_pair_ind = indmax(scores)\n",
    "        \n",
    "         \n",
    "        ii_best, jj_best = sort([iis[best_pair_ind], jjs[best_pair_ind]])\n",
    "        #The above makes a more readable output, but doesn't do anything useful,\n",
    "        #it is same as below:\n",
    "        #ii_best = iis[best_pair_ind]\n",
    "        #jj_best = jjs[best_pair_ind]\n",
    "        pp_best = pps[:,best_pair_ind]\n",
    "        score_total+=scores[best_pair_ind]\n",
    "        \n",
    "        ss = [ss pp_best]\n",
    "        backlookup = [backlookup, (backlookup[ii_best],backlookup[jj_best])]\n",
    "        \n",
    "        #Adjust Adjacency Matrix\n",
    "\n",
    "        AA[ii_best,jj_best] = false\n",
    "        AA[jj_best,ii_best] = false\n",
    "        AA = [AA; AA[ii_best,:] | AA[jj_best,:]] # Add row\n",
    "        AA = [AA AA[:,ii_best] | AA[:,jj_best]] # Add col\n",
    "        AA[ii_best,:] = AA[jj_best,:] = false\n",
    "        AA[:,ii_best] = AA[:,jj_best] = false #Remove anything that was adjacent to old\n",
    "\n",
    "    end\n",
    "    tree = backlookup[end]\n",
    "    embedding = ss[:,end]\n",
    "    tree, embedding, score_total\n",
    "end\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenize (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "input_width not defined\nwhile loading In[11], in expression starting on line 3",
     "output_type": "error",
     "traceback": [
      "input_width not defined\nwhile loading In[11], in expression starting on line 3",
      "",
      " in RNN at In[6]:11"
     ]
    }
   ],
   "source": [
    "sentence = \"The house has a window.\"\n",
    "sentence_toks = tokenize(sentence)\n",
    "rr = RNN(LL,3)\n",
    "eval_to_tree(rr,sentence_toks)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function bpts(rr::RNN, p)\n",
    "    δp = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function get_all_pos_tags()\n",
    "    lines = split(open(readall,\"brown_tags.txt\"),\"\\n\")\n",
    "    desc_lines = filter(line -> contains(line,\"||\"), lines)\n",
    "    tags = [split(line,\"||\")[1] for line in desc_lines]\n",
    "end\n",
    "pos_tags = get_all_pos_tags();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length(pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ACL2012_wordvectors.txt\\nbrown_tags.txt\\nembeddings-scaled.EMBEDDING_SIZE=200.txt\\nembeddings-scaled.EMBEDDING_SIZE=50.txt\\nFactoristation.ipynb\\ngit.ipynb\\nhypernym_distance.ipynb\\nLets build a NN for practice.ipynb\\nload_embeddings.jl\\nMacro experiments.ipynb\\nParseToEmbeedings.ipynb\\nSentence splitting and POS.ipynb\\nTokenize_to_embeddings.ipynb\\nwordVectors.txt\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readall(`ls`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.4.0-dev",
   "language": "julia",
   "name": "julia 0.4"
  },
  "language_info": {
   "name": "julia",
   "version": "0.3.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
