{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6-element Array{Int64,1}:\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5\n",
       " 6\n",
       " 7"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for ii in 1:6\n",
    "    #addprocs([\"heathred\"])\n",
    "end\n",
    "\n",
    "for ii in 1:4\n",
    "    #addprocs([\"amon\"], dir=\"\")\n",
    "    #addprocs([\"zeus\"], dir=\"\")\n",
    "    #addprocs([\"jove\"], dir=\"\")\n",
    "end\n",
    "\n",
    "for ii in 1:10\n",
    "    #addprocs([\"uggp\"], dir=\"\")\n",
    "end\n",
    "\n",
    "addprocs(6)\n",
    "workers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "include(\"ClusterSoup.jl\")\n",
    "@everywhere using RecursiveAutoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using Pipe\n",
    "function pz(x :: AbstractArray)\n",
    "    println(typeof(x), \": \", size(x))\n",
    "end\n",
    "macro printval(ee)\n",
    "    ee_expr = @sprintf \"%s\" string(ee)\n",
    "    esc(:(println($ee_expr,\" = \", $ee)))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/nltk/app/__init__.py:45: UserWarning: nltk.app.wordfreq not loaded (requires the pylab library).\n",
      "  warnings.warn(\"nltk.app.wordfreq not loaded \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tokenize (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using PyCall\n",
    "@pyimport nltk\n",
    "function tokenize(sentence::String)\n",
    "    convert(Array{String,1},nltk.word_tokenize(sentence))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50,268810)\n",
      "Dict{String,Int64}\n",
      "Array{String,1}\n"
     ]
    }
   ],
   "source": [
    "using WordEmbeddings\n",
    "LL,word_indexes, indexed_words =  load_embeddings(\"embeddings-scaled.EMBEDDING_SIZE=50.txt\");\n",
    "size(LL) |> println\n",
    "word_indexes |> typeof |> println\n",
    "indexed_words |> typeof |> println"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using Iterators\n",
    "@pyimport nltk.corpus as nltk_corpus\n",
    "n_training = 400 #4261\n",
    "training_sents = @pipe nltk_corpus.brown[:sents]() |> filter(s->1<length(s)<=5, _) |> take(_,n_training)  |> collect |> convert(Vector{Vector{String}},_);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_sents |> size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2: Array{Array{String,1},1}: 67\n",
      "3: Array{Array{String,1},1}: 67\n",
      "4: Array{Array{String,1},1}: 67\n",
      "5: Array{Array{String,1},1}: 67\n",
      "6: Array{Array{String,1},1}: 66\n",
      "7: Array{Array{String,1},1}: 66\n"
     ]
    }
   ],
   "source": [
    "chunk_data(:training_sents, training_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss_and_loss_grad! (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@everywhere function unpack!(rae::RAE, θ::Vector)\n",
    "    W_e_len = length(rae.W_e)\n",
    "    b_e_len = length(rae.b_e)\n",
    "    W_d_len = length(rae.W_d)\n",
    "    b_d_len = length(rae.b_d)\n",
    "    W_e_shape = size(rae.W_e)\n",
    "    W_d_shape = size(rae.W_d)\n",
    "    \n",
    "    rae.W_e = reshape(θ[1: W_e_len],W_e_shape)\n",
    "    rae.b_e = θ[W_e_len+1: W_e_len+b_e_len]\n",
    "    rae.W_d = reshape(θ[W_e_len+b_e_len+1: W_e_len+b_e_len+W_d_len],W_d_shape)\n",
    "    rae.b_d = θ[W_e_len+b_e_len+W_d_len+1: end]\n",
    "    \n",
    "    rae\n",
    "end\n",
    "\n",
    "@everywhere function pack(rae::RAE)\n",
    "    [rae.W_e[:],rae.b_e, rae.W_d[:],rae.b_d[:]] \n",
    "end\n",
    "\n",
    "@everywhere function pack(∇W_e::Matrix{Number}, ∇b_e::Vector{Number}, ∇W_d::Matrix{Number}, ∇b_d::Vector{Number})\n",
    "    [∇W_e[:], ∇b_e, ∇W_d[:], ∇b_d] \n",
    "end\n",
    "\n",
    "#--------------------------------------------------------\n",
    "\n",
    "function loss!(θ::Vector)  \n",
    "    error(\"loss not defined\")\n",
    "end\n",
    "\n",
    "function loss_grad!(θ::Vector, storage::Vector) \n",
    "    error(\"loss_grad not defined\")\n",
    "end\n",
    "\n",
    "rae_outer = RAE(LL,word_indexes,indexed_words);\n",
    "set_global(:rae_outer,rae_outer)\n",
    "function loss_and_loss_grad!(θ::Vector, grad::Vector)   \n",
    "    grad[:] = 0\n",
    "    for pid in workers()\n",
    "        remotecall(pid, θv->unpack!(rae_outer, θv),θ) \n",
    "    end\n",
    "    function loss_and_loss_grad(ss::Words)\n",
    "        tree, act_tree, pp, err = eval_to_tree(rae_outer, ss)\n",
    "        ∇s=BPTS(rae_outer,act_tree)\n",
    "        [pack(∇s...), err]\n",
    "    end\n",
    "    \n",
    "    ret = prechunked_mapreduce(:training_sents, loss_and_loss_grad, (+)) \n",
    "    grad[:] = ret[1:end-1]\n",
    "    err=ret[end]\n",
    "    \n",
    "    grad[:]/=length(training_sents)\n",
    "    err/=length(training_sents)\n",
    "    err\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "exception on 5: ERROR: arrays could not be broadcast to a common size\n",
      " in broadcast_shape at broadcast.jl:40\n",
      " in eval_scores_gradient at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/RecursiveAutoencoders.jl:185\n",
      " in BPTS at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/RecursiveAutoencoders.jl:150\n",
      " in BPTS at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/RecursiveAutoencoders.jl:149\n",
      " in anonymous at In[13]:44\n",
      " in map at abstractarray.jl:1328\n",
      " in anonymous at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/ClusterSoup.jl:29\n",
      " in anonymous at multi.jl:848\n",
      " in run_work_thunk at multi.jl:621\n",
      " in run_work_thunk at multi.jl:630\n",
      " in anonymous at task.jl:6\n",
      "exception on 3: exception on 2: exception on 6: ERROR: arrays could not be broadcast to a common size\n",
      " in broadcast_shape at broadcast.jl:40\n",
      " in eval_scores_gradient at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/RecursiveAutoencoders.jl:185\n",
      " in BPTS at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/RecursiveAutoencoders.jl:150\n",
      " in BPTS at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/RecursiveAutoencoders.jl:149\n",
      " in anonymous at In[13]:44\n",
      " in map at abstractarray.jl:1328\n",
      " in anonymous at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/ClusterSoup.jl:29\n",
      " in anonymous at multi.jl:848\n",
      " in run_work_thunk at multi.jl:621\n",
      " in run_work_thunk at multi.jl:630\n",
      " in anonymous at task.jl:6\n",
      "exception on 7: ERROR: arrays could not be broadcast to a common size\n",
      " in broadcast_shape at broadcast.jl:40\n",
      " in eval_scores_gradient at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/RecursiveAutoencoders.jl:185\n",
      " in BPTS at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/RecursiveAutoencoders.jl:150\n",
      " in BPTS at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/RecursiveAutoencoders.jl:149\n",
      " in anonymous at In[13]:44\n",
      " in map at abstractarray.jl:1328\n",
      " in anonymous at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/ClusterSoup.jl:29\n",
      " in anonymous at multi.jl:848\n",
      " in run_work_thunk at multi.jl:621\n",
      " in run_work_thunk at multi.jl:630\n",
      " in anonymous at task.jl:6\n",
      "ERROR: arrays could not be broadcast to a common size\n",
      " in broadcast_shape at broadcast.jl:40\n",
      " in eval_scores_gradient at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/RecursiveAutoencoders.jl:185\n",
      " in BPTS at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/RecursiveAutoencoders.jl:150\n",
      " in BPTS at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/RecursiveAutoencoders.jl:149\n",
      " in anonymous at In[13]:44\n",
      " in map at abstractarray.jl:1328\n",
      " in anonymous at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/ClusterSoup.jl:29\n",
      " in anonymous at multi.jl:848\n",
      " in run_work_thunk at multi.jl:621\n",
      " in run_work_thunk at multi.jl:630\n",
      " in anonymous at task.jl:6\n",
      "exception on 4: ERROR: arrays could not be broadcast to a common size\n",
      " in broadcast_shape at broadcast.jl:40\n",
      " in eval_scores_gradient at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/RecursiveAutoencoders.jl:185\n",
      " in BPTS at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/RecursiveAutoencoders.jl:150\n",
      " in BPTS at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/RecursiveAutoencoders.jl:149\n",
      " in anonymous at In[13]:44\n",
      " in map at abstractarray.jl:1328\n",
      " in anonymous at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/ClusterSoup.jl:29\n",
      " in anonymous at multi.jl:848\n",
      " in run_work_thunk at multi.jl:621\n",
      " in run_work_thunk at multi.jl:630\n",
      " in anonymous at task.jl:6\n",
      "ERROR: arrays could not be broadcast to a common size\n",
      " in broadcast_shape at broadcast.jl:40\n",
      " in eval_scores_gradient at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/RecursiveAutoencoders.jl:185\n",
      " in BPTS at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/RecursiveAutoencoders.jl:150\n",
      " in BPTS at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/RecursiveAutoencoders.jl:149\n",
      " in anonymous at In[13]:44\n",
      " in map at abstractarray.jl:1328\n",
      " in anonymous at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/ClusterSoup.jl:29\n",
      " in anonymous at multi.jl:848\n",
      " in run_work_thunk at multi.jl:621\n",
      " in run_work_thunk at multi.jl:630\n",
      " in anonymous at task.jl:6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in callback catch\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "`+` has no method matching +(::ErrorException, ::ErrorException)\nwhile loading In[14], in expression starting on line 16",
     "output_type": "error",
     "traceback": [
      "`+` has no method matching +(::ErrorException, ::ErrorException)\nwhile loading In[14], in expression starting on line 16",
      "",
      " in _mapreduce at reduce.jl:166",
      " in mapreduce at reduce.jl:182",
      " in reduce at reduce.jl:190",
      " in prechunked_mapreduce at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/ClusterSoup.jl:34",
      " in loss_and_loss_grad! at In[13]:48",
      " in tracking_loss_and_loss_grad! at In[14]:7",
      " in nlopt_callback_wrapper at /home/wheel/oxinabox/.julia/v0.3/NLopt/src/NLopt.jl:414"
     ]
    }
   ],
   "source": [
    "using NLopt\n",
    "\n",
    "f_call_count = 0\n",
    "function tracking_loss_and_loss_grad!(θ::Vector, grad::Vector)\n",
    "    global f_call_count\n",
    "    f_call_count+=1\n",
    "    f_val = loss_and_loss_grad!(θ, grad)   \n",
    "    println(f_call_count, '\\t',f_val,'\\t',norm(grad))\n",
    "    f_val\n",
    "end\n",
    "#:LD_LBFGS, :LD_MMA\n",
    "opt = Opt(:LD_MMA, length(pack(rae_outer)))\n",
    "ftol_abs!(opt,1e-9)\n",
    "maxtime!(opt, 6000)\n",
    "min_objective!(opt, tracking_loss_and_loss_grad!)\n",
    "(optf,optx,ret) = optimize!(opt,pack(rae_outer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#rae_outer = remotecall_fetch(4, dummy->rae_outer,nothing);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DifferentiableFunction(loss!,loss_grad!,loss_and_loss_grad!)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Optim #https://github.com/JuliaOpt/Optim.jl\n",
    "f=DifferentiableFunction(loss!,loss_grad!,loss_and_loss_grad!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter     Function value   Gradient norm \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "exception on 2: ERROR: arrays could not be broadcast to a common size\n",
      " in broadcast_shape at broadcast.jl:40\n",
      " in eval_scores_gradient at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/RecursiveAutoencoders.jl:185\n",
      " in BPTS at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/RecursiveAutoencoders.jl:150\n",
      " in BPTS at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/RecursiveAutoencoders.jl:149\n",
      " in anonymous at In[13]:44\n",
      " in map at abstractarray.jl:1328\n",
      " in anonymous at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/ClusterSoup.jl:29\n",
      " in anonymous at multi.jl:848\n",
      " in run_work_thunk at multi.jl:621\n",
      " in run_work_thunk at multi.jl:630\n",
      " in anonymous at task.jl:6\n",
      "exception on 4: exception on 3: ERROR: arrays could not be broadcast to a common size\n",
      " in broadcast_shape at broadcast.jl:40\n",
      " in eval_scores_gradient at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/RecursiveAutoencoders.jl:185\n",
      " in BPTS at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/RecursiveAutoencoders.jl:150\n",
      " in BPTS at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/RecursiveAutoencoders.jl:149\n",
      " in anonymous at In[13]:44\n",
      " in map at abstractarray.jl:1328\n",
      " in anonymous at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/ClusterSoup.jl:29\n",
      " in anonymous at multi.jl:848\n",
      " in run_work_thunk at multi.jl:621\n",
      " in run_work_thunk at multi.jl:630\n",
      " in anonymous at task.jl:6\n",
      "exception on 5: exception on 6: ERROR: arrays could not be broadcast to a common size\n",
      " in broadcast_shape at broadcast.jl:40\n",
      " in eval_scores_gradient at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/RecursiveAutoencoders.jl:185\n",
      " in BPTS at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/RecursiveAutoencoders.jl:150\n",
      " in BPTS at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/RecursiveAutoencoders.jl:149\n",
      " in anonymous at In[13]:44\n",
      " in map at abstractarray.jl:1328\n",
      " in anonymous at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/ClusterSoup.jl:29\n",
      " in anonymous at multi.jl:848\n",
      " in run_work_thunk at multi.jl:621\n",
      " in run_work_thunk at multi.jl:630\n",
      " in anonymous at task.jl:6\n",
      "ERROR: arrays could not be broadcast to a common size\n",
      " in broadcast_shape at broadcast.jl:40\n",
      " in eval_scores_gradient at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/RecursiveAutoencoders.jl:185\n",
      " in BPTS at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/RecursiveAutoencoders.jl:150\n",
      " in BPTS at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/RecursiveAutoencoders.jl:149\n",
      " in anonymous at In[13]:44\n",
      " in map at abstractarray.jl:1328\n",
      " in anonymous at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/ClusterSoup.jl:29\n",
      " in anonymous at multi.jl:848\n",
      " in run_work_thunk at multi.jl:621\n",
      " in run_work_thunk at multi.jl:630\n",
      " in anonymous at task.jl:6\n",
      "ERROR: arrays could not be broadcast to a common size\n",
      " in broadcast_shape at broadcast.jl:40\n",
      " in eval_scores_gradient at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/RecursiveAutoencoders.jl:185\n",
      " in BPTS at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/RecursiveAutoencoders.jl:150\n",
      " in BPTS at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/RecursiveAutoencoders.jl:149\n",
      " in anonymous at In[13]:44\n",
      " in map at abstractarray.jl:1328\n",
      " in anonymous at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/ClusterSoup.jl:29\n",
      " in anonymous at multi.jl:848\n",
      " in run_work_thunk at multi.jl:621\n",
      " in run_work_thunk at multi.jl:630\n",
      " in anonymous at task.jl:6\n",
      "exception on 7: ERROR: arrays could not be broadcast to a common size\n",
      " in broadcast_shape at broadcast.jl:40\n",
      " in eval_scores_gradient at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/RecursiveAutoencoders.jl:185\n",
      " in BPTS at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/RecursiveAutoencoders.jl:150\n",
      " in BPTS at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/RecursiveAutoencoders.jl:149\n",
      " in anonymous at In[13]:44\n",
      " in map at abstractarray.jl:1328\n",
      " in anonymous at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/ClusterSoup.jl:29\n",
      " in anonymous at multi.jl:848\n",
      " in run_work_thunk at multi.jl:621\n",
      " in run_work_thunk at multi.jl:630\n",
      " in anonymous at task.jl:6\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "`+` has no method matching +(::ErrorException, ::ErrorException)\nwhile loading In[16], in expression starting on line 4",
     "output_type": "error",
     "traceback": [
      "`+` has no method matching +(::ErrorException, ::ErrorException)\nwhile loading In[16], in expression starting on line 4",
      "",
      " in _mapreduce at reduce.jl:166",
      " in mapreduce at reduce.jl:182",
      " in reduce at reduce.jl:190",
      " in prechunked_mapreduce at /home/wheel/oxinabox/phd/prototypes/word-embeddings2/ClusterSoup.jl:34",
      " in loss_and_loss_grad! at In[13]:48",
      " in l_bfgs at /home/wheel/oxinabox/.julia/v0.3/Optim/src/l_bfgs.jl:122",
      " in optimize at /home/wheel/oxinabox/.julia/v0.3/Optim/src/optimize.jl:113"
     ]
    }
   ],
   "source": [
    "#Profile.clear()\n",
    "#Profile.init(delay=0.1)\n",
    "tic()\n",
    "res = optimize(f, pack(rae_outer), method=:l_bfgs, show_trace = true, store_trace = true, iterations = 10);\n",
    "time_take = toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#==\n",
    "    method::ASCIIString\n",
    "    initial_x::Array{T,N}\n",
    "    minimum::Array{T,N}\n",
    "    f_minimum::Number\n",
    "    iterations::Int\n",
    "    iteration_converged::Bool\n",
    "    x_converged::Bool\n",
    "    xtol::Number\n",
    "    f_converged::Bool\n",
    "    ftol::Number\n",
    "    gr_converged::Bool\n",
    "    grtol::Number\n",
    "    trace::OptimizationTrace\n",
    "    f_calls::Int\n",
    "    g_calls::Int\n",
    "=#\n",
    "@printval time_take\n",
    "@printval res.f_calls \n",
    "@printval res.g_calls \n",
    "@printval res.x_converged \n",
    "@printval res.iterations\n",
    "@printval res.f_minimum\n",
    "@printval res.gr_converged\n",
    "@printval res.trace\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/JuliaLang/julia/blob/master/doc/manual/profile.rst Actual instructions on profiling\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using ProfileView\n",
    "ProfileView.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##3000: 1<len(sentence)<=5\n",
    " - **base:** elapsed time: 138.752550969 seconds (34239757952 bytes allocated, 83.92% gc time)\n",
    " - **base 2 (after restart)** elapsed time: 232.798843691 seconds (58940288804 bytes allocated, 83.25% gc time)\n",
    " \n",
    " \n",
    " - **2 sys after fix:**\n",
    "  - **1st** elapsed time: 209.497508123 seconds (51858148 bytes allocated, 0.16% gc time)\n",
    "  - **2nd** elapsed time: 207.234529931 seconds (20805144 bytes allocated, 0.08% gc time) \n",
    "  \n",
    " - **12 (on 3 Amon, 4 Heathred, 5 Motsugo**\n",
    "  - **1st** elapsed time: 29.078831144 seconds (68477788 bytes allocated, 0.58% gc time)\n",
    "  - **2nd** elapsed time: 27.259917889 seconds (63650168 bytes allocated, 3.03% gc time)\n",
    "  \n",
    " - **16**\n",
    "  - **1st**  elapsed time: 31.49018094 seconds (213737316 bytes allocated, 3.27% gc time)\n",
    "  - **2nd** elapsed time: 23.265633784 seconds (104136464 bytes allocated, 2.41% gc time)\n",
    "  \n",
    "  ##23954: 1<len(sentence)<15\n",
    "  - **16** elapsed time: 3034.431581365 seconds (113266660 bytes allocated, 0.04% gc time)\n",
    "  - **24, for 15 iterations** elapsed time: 2478.921464409 seconds (701113364 bytes allocated, 0.18% gc time)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function cosine_dist(a,b)\n",
    "    (a⋅b)/(norm(a)*norm(b))\n",
    "end\n",
    "\n",
    "function neighbour_dists(cc::Vector{Number}, globe::Matrix{Number})\n",
    "    [cosine_dist(cc, globe[:,ii]) for ii in 1:size(globe,2)]\n",
    "end\n",
    "\n",
    "\n",
    "function show_best(rae::RAE,ĉ::Embedding, nbest=20)\n",
    "    candidates=neighbour_dists(ĉ,rae.L)   \n",
    "    best_cands = [ (findfirst(candidates,score), score)\n",
    "                    for score in select(candidates,1:nbest, rev=true)[1:nbest]]\n",
    "    vcat([[rae.indexed_words[ii] round(score,2)] for (ii,score) in best_cands]...)\n",
    "end\n",
    "\n",
    "function show_bests(rae::RAE,ĉs::Embeddings, nbest=20)\n",
    "    hcat([show_best(rae,ĉs[:,ii],nbest) for ii in 1:size(ĉs,2)]...)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sent = \"dangerous trends predict failure\"\n",
    "sent_toks = tokenize(sent)\n",
    "\n",
    "tree, act_tree, pp, score_total = eval_to_tree(rae_outer,sent_toks);\n",
    "println(tree)\n",
    "\n",
    "ĉs = unfold(rae_outer,tree,pp)\n",
    "bests= show_bests(rae_outer, ĉs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bests[1:4,1:2:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.3.8",
   "language": "julia",
   "name": "julia-0.3"
  },
  "language_info": {
   "name": "julia",
   "version": "0.3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
