{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using WordNet\n",
    "using WordEmbeddings, SoftmaxClassifier\n",
    "using Utils\n",
    "using Query\n",
    "using Distances\n",
    "using Iterators\n",
    "using JLD\n",
    "using Trees\n",
    "using AbstractTrees\n",
    "using BlossomV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@everywhere  using AdaGram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ee = load(\"../eval/models/plain/tokenised_lowercase_WestburyLab.wikicorp.201004_50__i1.jld\",\"ee\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "semtree = JLD.load(\"semtree.jld\", \"semtree\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition semhuff_initialize_AdaGram(Trees.BranchNode, Integer, Integer) in module Main at In[10]:2 overwritten at In[20]:2.\n",
      "WARNING: Method definition #semhuff_initialize_AdaGram(Array{Any, 1}, Main.#semhuff_initialize_AdaGram, Trees.BranchNode, Integer, Integer) in module Main overwritten.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "semhuff_initialize_AdaGram (generic function with 1 method)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function semhuff_initialize_AdaGram(semtree::Trees.BranchNode, dim::Integer, num_meanings::Integer; alpha::Float64=0.01, d::Float64=0.0)\n",
    "    paths = Dict(node.data => path for (node, path) in Trees.get_paths(semtree))\n",
    "        \n",
    "    codes = Dict(w=> convert(Vector{Int8}, oc - 1) for (w, oc) in leaves_of(semtree))\n",
    "    dict = AdaGram.Dictionary(convert(Vector{AbstractString},collect(keys(paths))))\n",
    "    freqs = Vector{Int64}(length(codes))\n",
    "    huffman_outputs = Vector{AdaGram.HierarchicalOutput}(length(codes))\n",
    "    for word in dict.id2word\n",
    "        id = dict.word2id[word]\n",
    "        freqs[id] = round(Int64,ee.distribution[word] * ee.corpus_size) #Todo: The math on this is not quiet right, because subsampling could have messed with the Corpus Size\n",
    "\n",
    "        huffman_outputs[id] = AdaGram.HierarchicalOutput(codes[word], paths[word])\n",
    "    end;\n",
    "        \n",
    "    vm = AdaGram.VectorModel(freqs, dim, num_meanings, alpha,d, huffman_outputs)\n",
    "    vm, dict\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11-element Array{Int64,1}:\n",
       "  2\n",
       "  3\n",
       "  4\n",
       "  5\n",
       "  6\n",
       "  7\n",
       "  8\n",
       "  9\n",
       " 10\n",
       " 11\n",
       " 12"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addprocs(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_name = \"semhuff_v1\"\n",
    "param_save_fn =  \"../eval/models/adagram/$(base_name).params.jld\"\n",
    "output_fn = \"../eval/models/adagram/$(base_name).adagram_model\"#\"file to save the model (in Julia format)\"\n",
    "@assert !isfile(output_fn)\n",
    "@param_save param_save_fn begin\n",
    "\tnprocessors = nprocs()\n",
    "\ttrain_fn  =  \"../eval/data/corpora/WikiCorp/tokenised_lowercase_WestburyLab.wikicorp.201004.txt\" #\"training text data\"\n",
    "\toutput_fn = output_fn #file to save the model (in Julia format)\"\n",
    "    semsimsource_fn = \"../eval/models/plain/tokenised_lowercase_WestburyLab.wikicorp.201004_50__i1.jld\"\n",
    "\n",
    "\twindow = 10 #\"(max) window size\" C in the paper\n",
    "\tmin_freq  = 20 #\"min. frequency of the word\"\n",
    "\tremove_top_k = 0 #\"remove top K most frequent words\"\n",
    "\tdim  = 300 #\"dimensionality of representations\"\n",
    "\tprototypes = 5 #\"number of word prototypes\" T in the paper\n",
    "\talpha = 0.15 #\"prior probability of allocating a new prototype\"\n",
    "\td  = 0.0 #\"parameter of Pitman-Yor process\" D in paper\n",
    "\tsubsample = 1e-5 #\"subsampling treshold. useful value is 1e-5\"\n",
    "\tcontext_cut  = true #\"randomly reduce size of the context\"\n",
    "\tepochs = 1 #\"number of epochs to train\"\n",
    "\tinitcount = 1. #\"initial weight (count) on first sense for each word\"\n",
    "\tstopwords = Set{AbstractString}() #\"list of stop words\"\n",
    "\tsense_treshold = 1e-10 #\"minimal probability of a meaning to contribute into gradients\"\n",
    "\tsave_treshold = 0.0 #\"minimal probability of a meaning to save after training\"\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vm, dict = semhuff_initialize_AdaGram(semtree, 300, 5; alpha=0.15, d=0.0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFrom worker 2:\t64000 words read, 1443333/541936072\n",
      "\tFrom worker 3:\t64000 words read, 543495711/1083872144\n",
      "\tFrom worker 4:\t64000 words read, 1085336468/1625808216\n",
      "\tFrom worker 5:\t64000 words read, 1627306849/2167744288\n",
      "\tFrom worker 6:\t64000 words read, 2169224390/2709680360\n",
      "\tFrom worker 7:\t64000 words read, 2711151461/3251616432\n",
      "\tFrom worker 8:\t64000 words read, 3253113250/3793552504\n",
      "\tFrom worker 9:\t64000 words read, 3795047471/4335488576\n",
      "\tFrom worker 10:\t64000 words read, 4337017677/4877424648\n",
      "\tFrom worker 11:\t64000 words read, 4878935567/5419360720\n",
      "\tFrom worker 12:\t64000 words read, 5420892477/5961296792\n",
      "\tFrom worker 2:\t0.22% -10.5548 0.0249 0.0249 2.06/4.00 0.55 kwords/sec\n",
      "\tFrom worker 5:\t0.22% -10.5549 0.0249 0.0249 2.13/4.00 0.56 kwords/sec\n",
      "\tFrom worker 4:\t0.23% -10.5568 0.0249 0.0249 2.08/4.00 0.55 kwords/sec\n",
      "\tFrom worker 3:\t0.23% -10.5564 0.0249 0.0249 2.07/4.00 0.53 kwords/sec\n",
      "\tFrom worker 6:\t0.23% -10.5578 0.0249 0.0249 2.03/4.00 0.55 kwords/sec\n",
      "\tFrom worker 7:\t0.23% -10.5581 0.0249 0.0249 2.03/4.00 0.55 kwords/sec\n",
      "\tFrom worker 9:\t0.23% -10.5581 0.0249 0.0249 2.02/4.00 0.56 kwords/sec\n",
      "\tFrom worker 8:\t0.23% -10.5578 0.0249 0.0249 2.01/4.00 0.55 kwords/sec\n",
      "\tFrom worker 11:\t0.23% -10.5577 0.0249 0.0249 1.92/4.00 0.55 kwords/sec\n",
      "\tFrom worker 10:\t0.23% -10.5575 0.0249 0.0249 1.94/4.00 0.54 kwords/sec\n",
      "\tFrom worker 12:\t0.23% -10.5564 0.0249 0.0249 1.90/4.00 0.53 kwords/sec\n",
      "\tFrom worker 5:\t0.24% -10.5529 0.0249 0.0249 1.92/4.00 0.58 kwords/sec\n",
      "\tFrom worker 4:\t0.24% -10.5522 0.0249 0.0249 1.88/4.00 0.57 kwords/sec\n",
      "\tFrom worker 3:\t0.24% -10.5521 0.0249 0.0249 1.89/4.00 0.58 kwords/sec\n",
      "\tFrom worker 2:\t0.24% -10.5518 0.0249 0.0249 1.86/4.00 0.55 kwords/sec\n",
      "\tFrom worker 6:\t0.24% -10.5501 0.0249 0.0249 1.88/4.00 0.56 kwords/sec\n",
      "\tFrom worker 7:\t0.24% -10.5500 0.0249 0.0249 1.86/4.00 0.57 kwords/sec\n",
      "\tFrom worker 8:\t0.24% -10.5499 0.0249 0.0249 1.86/4.00 0.58 kwords/sec\n",
      "\tFrom worker 9:\t0.24% -10.5507 0.0249 0.0249 1.86/4.00 0.57 kwords/sec\n",
      "\tFrom worker 11:\t0.24% -10.5498 0.0249 0.0249 1.81/4.00 0.57 kwords/sec\n",
      "\tFrom worker 10:\t0.24% -10.5476 0.0249 0.0249 1.77/4.00 0.56 kwords/sec\n",
      "\tFrom worker 12:\t0.24% -10.5459 0.0249 0.0249 1.81/4.00 0.54 kwords/sec\n",
      "\tFrom worker 5:\t0.25% -10.5414 0.0249 0.0249 1.84/4.00 0.60 kwords/sec\n",
      "\tFrom worker 3:\t0.25% -10.5406 0.0249 0.0249 1.82/4.00 0.57 kwords/sec\n"
     ]
    }
   ],
   "source": [
    "inplace_train_vectors!(vm, dict, train_fn, window;\n",
    "                       threshold=subsample, context_cut=context_cut,\n",
    "\t\t\t\t\t   epochs=epochs, init_count=initcount, sense_treshold=sense_treshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import WordEmbeddings: NetworkType\n",
    "\n",
    "type SemHuff <: NetworkType\n",
    "    source::GenWordEmbedding\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using Training\n",
    "using PooledElements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function initialize_network!(embed::GenWordEmbedding, network_type::SemHuff)\n",
    "    source_tree = network_type.source.classification_tree\n",
    "    source_embeddings = network_type.source.embedding\n",
    "    \n",
    "    debug(\"Began SemHuff sorting\")\n",
    "    semtree = semhuff(source_tree, source_embeddings, 30);\n",
    "    debug(\"Completed SemHuff sorting\")\n",
    "    debug(\"Began classification tree creation\")\n",
    "    embed.classification_tree = transform_tree(semtree, \n",
    "                            leaf_transform = word->word,\n",
    "    internal_transform = dummy -> LinearClassifier(2,embed.dim))\n",
    "    \n",
    "    embed.codebook = Dict(leaves_of(classification_tree))\n",
    "    debug(\"Completed SemHuff Bootstrapping\")\n",
    "    embed\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sem_ee = deepcopy(ee)\n",
    "sem_ee.network_type = SemHuff(ee)\n",
    "sem_ee.embedding = Dict(pstring(word)=>wv for (word, wv) in ee.embedding)\n",
    "initialize_embedding(sem_ee,sem_ee.init_type)\n",
    "initialize_network!(sem_ee,sem_ee.network_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.0-rc0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
