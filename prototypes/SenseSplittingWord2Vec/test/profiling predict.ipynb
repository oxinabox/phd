{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition anynull(AbstractArray) in module NullableArrays at /home/ubuntu/.julia/v0.5/NullableArrays/src/primitives.jl:175 overwritten in module PooledElements at /home/ubuntu/.julia/v0.5/PooledElements/src/pooledstringarray.jl:243.\n",
      "WARNING: Method definition warn(Exception) in module Base at util.jl:373 overwritten in module Lumberjack at /home/ubuntu/.julia/v0.5/Lumberjack/src/lumbermill.jl:99.\n",
      "WARNING: Method definition #warn(Array, Base.#warn, Exception) in module Base overwritten in module Lumberjack.\n",
      "WARNING: Method definition error(AbstractString) in module Base at error.jl:21 overwritten in module Lumberjack at /home/ubuntu/.julia/v0.5/Lumberjack/src/lumbermill.jl:138.\n",
      "WARNING: Method definition error(Any...) in module Base at error.jl:22 overwritten in module Lumberjack at /home/ubuntu/.julia/v0.5/Lumberjack/src/lumbermill.jl:114.\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "LoadError: LoadError: LoadError: syntax: extra token \"prob\" after end of expression\nwhile loading /mnt_volume/phd/prototypes/SenseSplittingWord2Vec/src/Query.jl, in expression starting on line 1\nwhile loading /mnt_volume/phd/prototypes/SenseSplittingWord2Vec/src/Training.jl, in expression starting on line 10\nwhile loading In[13], in expression starting on line 2",
     "output_type": "error",
     "traceback": [
      "LoadError: LoadError: LoadError: syntax: extra token \"prob\" after end of expression\nwhile loading /mnt_volume/phd/prototypes/SenseSplittingWord2Vec/src/Query.jl, in expression starting on line 1\nwhile loading /mnt_volume/phd/prototypes/SenseSplittingWord2Vec/src/Training.jl, in expression starting on line 10\nwhile loading In[13], in expression starting on line 2",
      ""
     ]
    }
   ],
   "source": [
    "using WordEmbeddings\n",
    "using Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"models/text8_miniscule.model\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_dir = joinpath(\"data\") #For local run from testing directory\n",
    "\n",
    "test_filename = \"text8_miniscule\"\n",
    "test_file = joinpath(data_dir, test_filename)\n",
    "\n",
    "\n",
    "model_file = \"models/text8_miniscule.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_sense_embedding (generic function with 1 method)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function test_sense_embedding(inputfile)\n",
    "\n",
    "\tembed = WordSenseEmbedding(30, random_inited, huffman_tree, subsampling = 0, iter=2, strength=0.4, force_minibatch_size=100)\n",
    "\t@time train(embed, inputfile)\n",
    "\n",
    "    save(embed, model_file)\n",
    "\tembed\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Profile.clear()  # in case we have any previous profiling data\n",
    "@profile test_sense_embedding(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using ProfileView\n",
    "\n",
    "ProfileView.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using SoftmaxClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition test(Any) in module Main at In[17]:2 overwritten at In[58]:2.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "test (generic function with 2 methods)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function test(fn)\n",
    "    embed = restore(model_file)\n",
    "    words = split(open(readstring,test_file,\"r\"))\n",
    "    time_total = 0.0\n",
    "    for ii in 10:length(words)-1000\n",
    "        word = words[ii]\n",
    "        !haskey(embed.codebook,word) && continue \n",
    "        context = [words[ii-5:ii-1]; words[ii+1:ii+5]]\n",
    "        context = filter(w->haskey(embed.codebook,w),context)\n",
    "        tic()\n",
    "        fn(embed,word, context)\n",
    "        time_total+=toq()\n",
    "    end\n",
    "    time_total\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition WSD2(WordEmbeddings.WordSenseEmbedding, AbstractString, AbstractArray{#S<:AbstractString, 1}) in module Main at In[18]:2 overwritten at In[59]:2.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WSD2 (generic function with 1 method)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function WSD2{S<:AbstractString}(embed::WordEmbeddings.WordSenseEmbedding, word::AbstractString, context::AbstractVector{S})\n",
    "    function prob_of_context{S<:AbstractString}(embed::GenWordEmbedding, context::AbstractVector{S}, input::Vector{Float32})\n",
    "        total_logprob=0.0 #Work in logprob to avoid underflow, and get more stability\n",
    "        for target_word in context\n",
    "            # discard words not presenting in the classification tree\n",
    "            haskey(embed.codebook, target_word) || continue\n",
    "            node = embed.classification_tree      \n",
    "\n",
    "            word_logprob = 0.0\n",
    "            for code in embed.codebook[target_word]  \n",
    "                word_logprob+=log(predict(node.data, input)[code])\n",
    "                node = node.children[code]\n",
    "            end\n",
    "            total_logprob+=word_logprob\n",
    "        end\n",
    "        exp(total_logprob) #Going back out of the log domain is not required for external logic, but it is nice for clarity\n",
    "    end\n",
    "    \n",
    "    \n",
    "    sense_embeddings = embed.embedding[word]\n",
    "    prob, most_likely_sense_id = findmax([prob_of_context(embed, context, input) for input in sense_embeddings])\n",
    "    return most_likely_sense_id\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3.448796 seconds (14.17 M allocations: 758.525 MB, 5.53% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.0366613659999997"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc()\n",
    "@time test(WSD2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition WSD3(WordEmbeddings.WordSenseEmbedding, AbstractString, AbstractArray{#S<:AbstractString, 1}) in module Main at In[19]:2 overwritten at In[61]:2.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WSD3 (generic function with 1 method)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@fastmath function WSD3{S<:AbstractString}(embed::WordEmbeddings.WordSenseEmbedding, word::AbstractString, context::AbstractVector{S})\n",
    "    function prob_of_context{S<:AbstractString}(embed::GenWordEmbedding, context::AbstractVector{S}, input::Vector{Float32})\n",
    "        total_prob=0.0 #Work in logprob to avoid underflow, and get more stability\n",
    "        @inbounds for target_word in context\n",
    "            # discard words not presenting in the classification tree\n",
    "            haskey(embed.codebook, target_word) || continue\n",
    "            node = embed.classification_tree      \n",
    "\n",
    "            word_prob = 0.0\n",
    "            @inbounds for code in embed.codebook[target_word]  \n",
    "                word_prob*=predict(node.data, input)[code]\n",
    "                node = node.children[code]\n",
    "            end\n",
    "            total_prob*=word_prob\n",
    "        end\n",
    "        exp(total_prob) #Going back out of the log domain is not required for external logic, but it is nice for clarity\n",
    "    end\n",
    "    \n",
    "    \n",
    "    sense_embeddings = embed.embedding[word]\n",
    "    prob, most_likely_sense_id = findmax([prob_of_context(embed, context, input) for input in sense_embeddings])\n",
    "    return most_likely_sense_id\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3.237457 seconds (14.16 M allocations: 758.139 MB, 6.06% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.8264243710000008"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc()\n",
    "@time test(WSD3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using StatsFuns\n",
    "import SoftmaxClassifier.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition softmax5!(AbstractArray{#R<:AbstractFloat, N<:Any}) in module Main at In[22]:2 overwritten at In[64]:2.\n",
      "WARNING: Method definition predict5(SoftmaxClassifier.LinearClassifier, AbstractArray{#F<:AbstractFloat, 1}) in module Main at In[22]:11 overwritten at In[64]:11.\n",
      "WARNING: Method definition WSD5(WordEmbeddings.WordSenseEmbedding, AbstractString, AbstractArray{#S<:AbstractString, 1}) in module Main at In[22]:23 overwritten at In[64]:23.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WSD5 (generic function with 1 method)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@inbounds @inline function softmax5!{R<:AbstractFloat}(t::AbstractArray{R})\n",
    "    u = max(t[1],t[2])\n",
    "    @inbounds t[1] = exp(t[1] - u)\n",
    "    @inbounds t[2] = exp(t[2] - u)\n",
    "    @inbounds u = t[1]+t[2]\n",
    "    @inbounds t[1]/=u\n",
    "    @inbounds t[2]/=u\n",
    "    t\n",
    "end\n",
    "@fastmath function predict5{F<:AbstractFloat}(c::LinearClassifier, x::AbstractVector{F})\n",
    "    t= F[0., 0.]\n",
    "    @inbounds for ii in 1: size(c.weights,1)\n",
    "        @inbounds t[1]+=c.weights[ii,1]*x[ii]\n",
    "        @inbounds t[2]+=c.weights[ii,2]*x[ii]\n",
    "    end\n",
    "    t\n",
    "    return softmax5!(t)\n",
    "end\n",
    "\n",
    "@fastmath function WSD5{S<:AbstractString}(embed::WordEmbeddings.WordSenseEmbedding, word::AbstractString, context::AbstractVector{S})\n",
    "\n",
    "    \n",
    "    function prob_of_context{S<:AbstractString}(embed::GenWordEmbedding, context::AbstractVector{S}, input::Vector{Float32})\n",
    "        total_prob=0.0 #Work in logprob to avoid underflow, and get more stability\n",
    "        @inbounds for target_word in context\n",
    "            # discard words not presenting in the classification tree\n",
    "            haskey(embed.codebook, target_word) || continue\n",
    "            node = embed.classification_tree      \n",
    "\n",
    "            word_prob = 0.0\n",
    "            @inbounds for code in embed.codebook[target_word]  \n",
    "                word_prob*=predict5(node.data, input)[code]\n",
    "                node = node.children[code]\n",
    "            end\n",
    "            total_prob*=word_prob\n",
    "        end\n",
    "        total_prob #Going back out of the log domain is not required for external logic, but it is nice for clarity\n",
    "    end\n",
    "        \n",
    "    sense_embeddings = embed.embedding[word]\n",
    "    prob, most_likely_sense_id = findmax([prob_of_context(embed, context, input) for input in sense_embeddings])\n",
    "    return most_likely_sense_id\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8.032951 seconds (3.72 M allocations: 333.225 MB, 0.92% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.645712660000006"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc()\n",
    "@time test(WSD5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition softmax6!(#R<:AbstractFloat, #R<:AbstractFloat) in module Main at In[93]:2 overwritten at In[96]:2.\n",
      "WARNING: Method definition predict6(SoftmaxClassifier.LinearClassifier, AbstractArray{#F<:AbstractFloat, 1}) in module Main at In[93]:11 overwritten at In[96]:11.\n",
      "WARNING: Method definition WSD6(WordEmbeddings.WordSenseEmbedding, AbstractString, AbstractArray{#S<:AbstractString, 1}) in module Main at In[93]:24 overwritten at In[96]:24.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WSD6 (generic function with 1 method)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@fastmath @inline function softmax2{R<:AbstractFloat}(t1::R,t2::R)\n",
    "    u = max(t1,t2)\n",
    "    t1 = exp(t1 - u)\n",
    "    t2 = exp(t2 - u)\n",
    "    s = t1+t2\n",
    "    t1/=s\n",
    "    t2/=s\n",
    "    t1,t2\n",
    "end\n",
    "@fastmath function predict{F<:AbstractFloat}(c::LinearClassifier{2}, x::AbstractVector{F})\n",
    "    t1=zero(F)\n",
    "    t2=zero(F)\n",
    "    @inbounds for ii in 1: size(c.weights,1)\n",
    "        @inbounds t1+=c.weights[ii,1]*x[ii]\n",
    "        @inbounds t2+=c.weights[ii,2]*x[ii]\n",
    "    end\n",
    "    #return softmax!([t1,t2])\n",
    "    return softmax2(t1,t2)\n",
    "end\n",
    "\n",
    "@fastmath function WSD6{S<:AbstractString}(embed::WordEmbeddings.WordSenseEmbedding, word::AbstractString, context::AbstractVector{S})\n",
    "\n",
    "    \n",
    "    function prob_of_context{S<:AbstractString}(embed::GenWordEmbedding, context::AbstractVector{S}, input::Vector{Float32})\n",
    "        total_prob=0.0 #Work in logprob to avoid underflow, and get more stability\n",
    "        @inbounds for target_word in context\n",
    "            # discard words not presenting in the classification tree\n",
    "            haskey(embed.codebook, target_word) || continue\n",
    "            node = embed.classification_tree      \n",
    "\n",
    "            word_prob = 0.0\n",
    "            @inbounds for code in embed.codebook[target_word]  \n",
    "                word_prob*=predict6(node.data, input)[code]\n",
    "                node = node.children[code]\n",
    "            end\n",
    "            total_prob*=word_prob\n",
    "        end\n",
    "        total_prob #Going back out of the log domain is not required for external logic, but it is nice for clarity\n",
    "    end\n",
    "        \n",
    "    sense_embeddings = embed.embedding[word]\n",
    "    prob, most_likely_sense_id = findmax([prob_of_context(embed, context, input) for input in sense_embeddings])\n",
    "    return most_likely_sense_id\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.726085 seconds (3.62 M allocations: 62.971 MB, 1.19% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.440744877999999"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc()\n",
    "@time test(WSD6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition softmax7!(NTuple{#K<:Any, #R<:AbstractFloat}) in module Main at In[68]:2 overwritten at In[90]:2.\n",
      "WARNING: Method definition predict7(SoftmaxClassifier.LinearClassifier{#K<:Any}, AbstractArray{#F<:AbstractFloat, 1}) in module Main at In[68]:12 overwritten at In[90]:12.\n",
      "WARNING: Method definition prob_of_context(WordEmbeddings.GenWordEmbedding, AbstractArray{#S<:AbstractString, 1}, Array{Float32, 1}) in module Main at In[68]:23 overwritten at In[90]:23.\n",
      "WARNING: Method definition WSD7(WordEmbeddings.WordSenseEmbedding, AbstractString, AbstractArray{#S<:AbstractString, 1}) in module Main at In[68]:39 overwritten at In[90]:39.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WSD7 (generic function with 1 method)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@generated function softmax7!{K,R<:AbstractFloat}(ts::NTuple{K,R})\n",
    "    quote\n",
    "        u = maximum(ts)\n",
    "        @nexprs $K j->t_j = exp(ts[j]-u)\n",
    "        s=0.0\n",
    "        @nexprs $K j->s+=t_j\n",
    "        @nexprs $K j->t_j/=s\n",
    "        @ntuple $K t\n",
    "    end\n",
    "end\n",
    "@generated function predict7{K,F<:AbstractFloat}(c::LinearClassifier{K}, x::AbstractVector{F})\n",
    "    quote\n",
    "        @inbounds begin \n",
    "            @nexprs $K j->t_j = 0.0f0\n",
    "            @simd for ii in 1: size(c.weights,1)\n",
    "                @nexprs $K j->t_j = c.weights[ii,j]*x[j]\n",
    "            end\n",
    "            return softmax!(@ntuple $K t)\n",
    "        end\n",
    "    end\n",
    "end\n",
    "@inbounds function prob_of_context{S<:AbstractString}(embed::GenWordEmbedding, context::AbstractVector{S}, input::Vector{Float32})\n",
    "    total_prob=0.0 #Work in logprob to avoid underflow, and get more stability\n",
    "    for target_word in context\n",
    "        # discard words not presenting in the classification tree\n",
    "        haskey(embed.codebook, target_word) || continue\n",
    "        node = embed.classification_tree      \n",
    "        \n",
    "        \n",
    "        for code in embed.codebook[target_word]  \n",
    "            total_prob*=predict7(node.data, input)[code]\n",
    "            node = node.children[code]\n",
    "        end\n",
    "    end\n",
    "    total_prob #Going back out of the log domain is not required for external logic, but it is nice for clarity\n",
    "end\n",
    "\n",
    "@fastmath function WSD7{S<:AbstractString}(embed::WordEmbeddings.WordSenseEmbedding, word::AbstractString, context::AbstractVector{S})       \n",
    "    sense_embeddings = embed.embedding[word]\n",
    "    prob, most_likely_sense_id = findmax([prob_of_context(embed, context, input) for input in sense_embeddings])\n",
    "    return most_likely_sense_id\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.272414 seconds (10.59 M allocations: 169.394 MB, 1.49% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.9885797159999994"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc()\n",
    "@time test(WSD7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WSD8 (generic function with 1 method)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@generated function softmax8!{K,R<:AbstractFloat}(ts::AbstractVector{R}, ::Type{Val{K}})\n",
    "    quote\n",
    "        u = maximum(ts)\n",
    "        @nexprs $K j->t_j = exp(ts[j]-u)\n",
    "        s=0.0\n",
    "        @nexprs $K j->s+=t_j\n",
    "        @nexprs $K j->+t_j\n",
    "        @nexprs $K j->t_j/=s\n",
    "        @ntuple $K t\n",
    "    end\n",
    "end\n",
    "\n",
    "@fastmath function predict8{F<:AbstractFloat}(c::LinearClassifier, x::AbstractVector{F})\n",
    "    t1=zero(F)\n",
    "    t2=zero(F)\n",
    "    x_len = length(x)\n",
    "    @simd for ii in 1:x_len\n",
    "        @inbounds t1+=c.weights[ii,1]*x[ii]\n",
    "        @inbounds t2+=c.weights[ii,2]*x[ii]\n",
    "    end\n",
    "    return softmax8!(t1,t2)\n",
    "end\n",
    "@inbounds function prob_of_context8{S<:AbstractString}(embed::GenWordEmbedding, context::AbstractVector{S}, input::Vector{Float32})\n",
    "    total_prob=0.0 #Work in logprob to avoid underflow, and get more stability\n",
    "    for target_word in context\n",
    "        # discard words not presenting in the classification tree\n",
    "        haskey(embed.codebook, target_word) || continue\n",
    "        node = embed.classification_tree      \n",
    "        \n",
    "        \n",
    "        for code in embed.codebook[target_word]  \n",
    "            total_prob*=predict8(node.data, input)[code]\n",
    "            node = node.children[code]\n",
    "        end\n",
    "    end\n",
    "    total_prob #Going back out of the log domain is not required for external logic, but it is nice for clarity\n",
    "end\n",
    "\n",
    "@fastmath function WSD8{S<:AbstractString}(embed::WordEmbeddings.WordSenseEmbedding, word::AbstractString, context::AbstractVector{S})       \n",
    "    sense_embeddings = embed.embedding[word]\n",
    "    prob, most_likely_sense_id = findmax([prob_of_context8(embed, context, input) for input in sense_embeddings])\n",
    "    return most_likely_sense_id\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: MethodError: no method matching softmax8!(::Float32, ::Float32)\nwhile loading In[29], in expression starting on line 155",
     "output_type": "error",
     "traceback": [
      "LoadError: MethodError: no method matching softmax8!(::Float32, ::Float32)\nwhile loading In[29], in expression starting on line 155",
      ""
     ]
    }
   ],
   "source": [
    "gc()\n",
    "@time test(WSD8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "2 methods for generic function <b>softmax!</b>:<ul><li> softmax!<i>{R<:AbstractFloat,T<:Real}</i>(r::<b>AbstractArray{R,N<:Any}</b>, x::<b>AbstractArray{T,N<:Any}</b>) at <a href=\"https://github.com/JuliaStats/StatsFuns.jl/tree/723edaa163c95fc78c8d0b520150a91139acf434/src/basicfuns.jl#L147\" target=\"_blank\">/home/ubuntu/.julia/v0.5/StatsFuns/src/basicfuns.jl:147</a></li> <li> softmax!<i>{T<:AbstractFloat}</i>(x::<b>AbstractArray{T,N<:Any}</b>) at <a href=\"https://github.com/JuliaStats/StatsFuns.jl/tree/723edaa163c95fc78c8d0b520150a91139acf434/src/basicfuns.jl#L161\" target=\"_blank\">/home/ubuntu/.julia/v0.5/StatsFuns/src/basicfuns.jl:161</a></li> </ul>"
      ],
      "text/plain": [
       "# 2 methods for generic function \"softmax!\":\n",
       "softmax!{R<:AbstractFloat,T<:Real}(r::AbstractArray{R,N<:Any}, x::AbstractArray{T,N<:Any}) at /home/ubuntu/.julia/v0.5/StatsFuns/src/basicfuns.jl:147\n",
       "softmax!{T<:AbstractFloat}(x::AbstractArray{T,N<:Any}) at /home/ubuntu/.julia/v0.5/StatsFuns/src/basicfuns.jl:161"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methods(StatsFuns.softmax!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using ProfileView\n",
    "Profile.clear()\n",
    "@profile test(WSD7)\n",
    "ProfileView.view()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using ProfileView\n",
    "Profile.clear()\n",
    "@profile test(WSD6)\n",
    "ProfileView.view()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using ProfileView\n",
    "Profile.clear()\n",
    "@profile test(WSD5)\n",
    "ProfileView.view()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using ProfileView\n",
    "Profile.clear()\n",
    "@profile test(WSD3)\n",
    "ProfileView.view()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "?max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using Base.Cartesian\n",
    "using StatsFuns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5f0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv(2.f0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "softmax2! (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@fastmath function softmax2!{R<:AbstractFloat}(t1::R,t2::R)\n",
    "    u = max(t1,t2)\n",
    "    t1 = exp(t1 - u)\n",
    "    t2 = exp(t2 - u)\n",
    "    s = t1+t2\n",
    "    t1/=s\n",
    "    t2/=s\n",
    "    t1,t2\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition softmaxK!(NTuple{#K<:Any, #R<:AbstractFloat}) in module Main at In[3]:2 overwritten at In[36]:2.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "softmaxK! (generic function with 1 method)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@generated function softmaxK!{K,R<:AbstractFloat}(ts::NTuple{K,R})\n",
    "    quote\n",
    "        u = maximum(ts)\n",
    "        @nexprs $K j->t_j = exp(ts[j]-u)\n",
    "        s=0.0\n",
    "        @nexprs $K j->s+=t_j\n",
    "        @nexprs $K j->t_j/=s\n",
    "        @ntuple $K t\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: syntax: missing comma or ) in argument list\nwhile loading In[44], in expression starting on line 1",
     "output_type": "error",
     "traceback": [
      "LoadError: syntax: missing comma or ) in argument list\nwhile loading In[44], in expression starting on line 1",
      ""
     ]
    }
   ],
   "source": [
    "@generated function softmaxKf!{K,R<:AbstractFloat}(ts::NTuple{K,R})\n",
    "    quote\n",
    "        u = maximum(ts)\n",
    "        @nexprs( $K j-> t_j = @fastmath(exp(ts[j]-u))\n",
    "        s=0.0\n",
    "        @nexprs( $K j->( s+=t_j)\n",
    "        @nexprs( $K j->( t_j/=s)\n",
    "        @ntuple $K t\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "softmaxKAB! (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@generated function softmaxKAB!{K,R<:AbstractFloat}(ts::AbstractVector{R}, ::Type{Val{K}})\n",
    "    quote\n",
    "        u = maximum(ts)\n",
    "        @nexprs $K j->t_j = exp(ts[j]-u)\n",
    "        s=0.0f0\n",
    "        @nexprs $K j->s+=t_j\n",
    "        @nexprs $K j->t_j/=s\n",
    "        @ntuple $K t\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for ii in 1:1000\n",
    "    v=rand(2)\n",
    "    s1 =  softmax(v)\n",
    "    s2 = softmax2a!(v[1],v[2])\n",
    "    @assert(s1[1]≈s2[1], \"$(s1[1]) !=  $(s2[1])\")\n",
    "    @assert(s1[2]≈s2[2], \"$(s1[2]) !=  $(s2[2])\")\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t.text\n",
      "Filename: In[256]\n",
      "Source line: 0\n",
      "\tpushq\t%rbp\n",
      "\tmovq\t%rsp, %rbp\n",
      "\tpushq\t%rbx\n",
      "\tpushq\t%rax\n",
      "\tmovq\t%rdi, %rbx\n",
      "\tmovabsq\t$exp, %rax\n",
      "Source line: 3\n",
      "\tvucomisd\t%xmm1, %xmm0\n",
      "\tjbe\tL59\n",
      "Source line: 4\n",
      "\tvsubsd\t%xmm0, %xmm1, %xmm0\n",
      "Source line: 5\n",
      "\tcallq\t*%rax\n",
      "\tmovabsq\t$140639058038784, %rax  # imm = 0x7FE915189000\n",
      "\tvmovsd\t(%rax), %xmm1           # xmm1 = mem[0],zero\n",
      "Source line: 6\n",
      "\tvaddsd\t%xmm1, %xmm0, %xmm2\n",
      "Source line: 231\n",
      "\tvdivsd\t%xmm2, %xmm1, %xmm1\n",
      "Source line: 7\n",
      "\tvmulsd\t%xmm0, %xmm1, %xmm2\n",
      "Source line: 8\n",
      "\tjmp\tL91\n",
      "Source line: 10\n",
      "L59:\n",
      "\tvsubsd\t%xmm1, %xmm0, %xmm0\n",
      "Source line: 11\n",
      "\tcallq\t*%rax\n",
      "\tmovabsq\t$140639058038784, %rax  # imm = 0x7FE915189000\n",
      "\tvmovsd\t(%rax), %xmm1           # xmm1 = mem[0],zero\n",
      "Source line: 12\n",
      "\tvaddsd\t%xmm1, %xmm0, %xmm2\n",
      "Source line: 231\n",
      "\tvdivsd\t%xmm2, %xmm1, %xmm2\n",
      "Source line: 13\n",
      "\tvmulsd\t%xmm0, %xmm2, %xmm1\n",
      "Source line: 15\n",
      "L91:\n",
      "\tvmovsd\t%xmm2, 8(%rbx)\n",
      "\tvmovsd\t%xmm1, (%rbx)\n",
      "\tmovq\t%rbx, %rax\n",
      "\taddq\t$8, %rsp\n",
      "\tpopq\t%rbx\n",
      "\tpopq\t%rbp\n",
      "\tretq\n",
      "\tnop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition softmax2a!(#R<:AbstractFloat, #R<:AbstractFloat) in module Main at In[234]:2 overwritten at In[256]:3.\n"
     ]
    }
   ],
   "source": [
    "@fastmath function softmax2a!{R<:AbstractFloat}(t1::R,t2::R)\n",
    "    \n",
    "    if t1>t2\n",
    "        z=t2-t1\n",
    "        m  = exp(z)\n",
    "        r1 = inv(one(R)+m)\n",
    "        r2 = m*r1\n",
    "        (r1,r2)\n",
    "    else #t2>t1\n",
    "        z=t1-t2\n",
    "        m  = exp(z)\n",
    "        r2 = inv(one(R)+m)\n",
    "        r1 = m*r2\n",
    "    end\n",
    "    (r1,r2)\n",
    "\n",
    "end\n",
    "@code_native softmax2a!(0.25,0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t.text\n",
      "Filename: In[251]\n",
      "Source line: 0\n",
      "\tpushq\t%rbp\n",
      "\tmovq\t%rsp, %rbp\n",
      "\tpushq\t%rbx\n",
      "\tpushq\t%rax\n",
      "\tmovq\t%rdi, %rbx\n",
      "Source line: 3\n",
      "\tvsubsd\t%xmm0, %xmm1, %xmm0\n",
      "Source line: 272\n",
      "\tmovabsq\t$exp, %rax\n",
      "\tcallq\t*%rax\n",
      "\tmovabsq\t$140639058132992, %rax  # imm = 0x7FE9151A0000\n",
      "Source line: 4\n",
      "\tvmovsd\t(%rax), %xmm1           # xmm1 = mem[0],zero\n",
      "\tvaddsd\t%xmm1, %xmm0, %xmm2\n",
      "Source line: 231\n",
      "\tvdivsd\t%xmm2, %xmm1, %xmm1\n",
      "Source line: 5\n",
      "\tvmulsd\t%xmm0, %xmm1, %xmm0\n",
      "Source line: 6\n",
      "\tvmovsd\t%xmm1, (%rbx)\n",
      "\tvmovsd\t%xmm0, 8(%rbx)\n",
      "\tmovq\t%rbx, %rax\n",
      "\taddq\t$8, %rsp\n",
      "\tpopq\t%rbx\n",
      "\tpopq\t%rbp\n",
      "\tretq\n",
      "\tnopw\t%cs:(%rax,%rax)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition softmax2c(#R<:AbstractFloat, #R<:AbstractFloat) in module Main at In[250]:3 overwritten at In[251]:3.\n"
     ]
    }
   ],
   "source": [
    "@fastmath @inline function softmax2c{R<:AbstractFloat}(t1::R,t2::R)              \n",
    "    #This is the softmax function, but particularly optimised.                  \n",
    "    z = exp(t2-t1)                                                              \n",
    "    r1 = inv(one(R)+z)                                                          \n",
    "    r2 = z*r1                                                                  \n",
    "    (r1,r2)                                                                     \n",
    "end       \n",
    "@code_native softmax2c(0.25,0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t.text\n",
      "Filename: basicfuns.jl\n",
      "Source line: 0\n",
      "\tpushq\t%rbp\n",
      "\tmovq\t%rsp, %rbp\n",
      "\tpushq\t%r15\n",
      "\tpushq\t%r14\n",
      "\tpushq\t%r13\n",
      "\tpushq\t%r12\n",
      "\tpushq\t%rbx\n",
      "\tsubq\t$72, %rsp\n",
      "\tmovq\t%rsi, %rbx\n",
      "\tmovq\t%rdi, %r14\n",
      "\tmovabsq\t$140639742601600, %r13  # imm = 0x7FE93DE62980\n",
      "\tmovq\t$0, -56(%rbp)\n",
      "\tmovq\t$0, -48(%rbp)\n",
      "\tmovq\t$4, -72(%rbp)\n",
      "\tmovabsq\t$jl_tls_states, %r15\n",
      "\tmovq\t(%r15), %rax\n",
      "\tmovq\t%rax, -64(%rbp)\n",
      "\tleaq\t-72(%rbp), %rax\n",
      "\tmovq\t%rax, (%r15)\n",
      "Source line: 147\n",
      "\tmovq\t8(%rbx), %r12\n",
      "Source line: 229\n",
      "\tcmpq\t%r12, 8(%r14)\n",
      "\tjne\tL498\n",
      "Source line: 159\n",
      "\tmovabsq\t$_mapreduce, %rax\n",
      "\tmovq\t%rbx, %rdi\n",
      "\tcallq\t*%rax\n",
      "\tvmovapd\t%xmm0, %xmm1\n",
      "\tvmovsd\t%xmm1, -88(%rbp)\n",
      "\txorl\t%eax, %eax\n",
      "Source line: 70\n",
      "\tcmpq\t$0, %r12\n",
      "\tcmovgq\t%r12, %rax\n",
      "\tcmpq\t$0, %rax\n",
      "\tje\tL470\n",
      "\tmovq\t%rax, -104(%rbp)\n",
      "\tmovq\t%r12, %rax\n",
      "\tmovq\t%rax, -96(%rbp)\n",
      "\txorl\t%r12d, %r12d\n",
      "\tvxorpd\t%xmm2, %xmm2, %xmm2\n",
      "\tcmpq\t$0, %rax\n",
      "\tmovl\t$0, %r15d\n",
      "\tcmovgq\t%rax, %r15\n",
      "\tnopl\t(%rax,%rax)\n",
      "Source line: 152\n",
      "L176:\n",
      "\tvmovsd\t%xmm2, -80(%rbp)\n",
      "\tmovq\t(%rbx), %rax\n",
      "\tvmovsd\t(%rax,%r12,8), %xmm0    # xmm0 = mem[0],zero\n",
      "Source line: 209\n",
      "\tvsubsd\t%xmm1, %xmm0, %xmm0\n",
      "\tleaq\t-673892112(%r13), %rax\n",
      "\tcallq\t*%rax\n",
      "\tvmovsd\t-80(%rbp), %xmm2        # xmm2 = mem[0],zero\n",
      "\tvmovsd\t-88(%rbp), %xmm1        # xmm1 = mem[0],zero\n",
      "\tmovq\t(%r14), %rax\n",
      "\tvmovsd\t%xmm0, (%rax,%r12,8)\n",
      "\tvaddsd\t%xmm0, %xmm2, %xmm2\n",
      "Source line: 70\n",
      "\taddq\t$1, %r12\n",
      "\tcmpq\t%r12, %r15\n",
      "\tjne\tL176\n",
      "\tcmpq\t$0, -104(%rbp)\n",
      "\tmovabsq\t$jl_tls_states, %r15\n",
      "\tmovq\t-96(%rbp), %rbx\n",
      "Source line: 70\n",
      "\tje\tL470\n",
      "\tmovl\t$1, %edx\n",
      "\tmovabsq\t$140648397283328, %rax  # imm = 0x7FEB41C22000\n",
      "\tvmovsd\t(%rax), %xmm0           # xmm0 = mem[0],zero\n",
      "Source line: 154\n",
      "\tvdivsd\t%xmm2, %xmm0, %xmm0\n",
      "Source line: 156\n",
      "\tmovq\t(%r14), %rax\n",
      "\tcmpq\t$1, %rbx\n",
      "Source line: 70\n",
      "\tjl\tL411\n",
      "\tmovl\t$1, %edx\n",
      "\tleaq\t1(%rbx), %rcx\n",
      "\tmovq\t%rbx, %rsi\n",
      "\tandq\t$-16, %rsi\n",
      "\torq\t$1, %rsi\n",
      "\tcmpq\t$1, %rsi\n",
      "\tje\tL406\n",
      "\tvmovddup\t%xmm0, %xmm1    # xmm1 = xmm0[0,0]\n",
      "\tvinsertf128\t$1, %xmm1, %ymm1, %ymm1\n",
      "\tleaq\t96(%rax), %rdx\n",
      "\tmovq\t%rbx, %rdi\n",
      "\tshrq\t$4, %rdi\n",
      "\tshlq\t$4, %rdi\n",
      "\tnopw\t(%rax,%rax)\n",
      "Source line: 211\n",
      "L352:\n",
      "\tvmulpd\t-96(%rdx), %ymm1, %ymm2\n",
      "\tvmulpd\t-64(%rdx), %ymm1, %ymm3\n",
      "\tvmulpd\t-32(%rdx), %ymm1, %ymm4\n",
      "\tvmulpd\t(%rdx), %ymm1, %ymm5\n",
      "\tvmovupd\t%ymm2, -96(%rdx)\n",
      "\tvmovupd\t%ymm3, -64(%rdx)\n",
      "\tvmovupd\t%ymm4, -32(%rdx)\n",
      "\tvmovupd\t%ymm5, (%rdx)\n",
      "Source line: 70\n",
      "\taddq\t$128, %rdx\n",
      "\taddq\t$-16, %rdi\n",
      "\tjne\tL352\n",
      "\tmovq\t%rsi, %rdx\n",
      "L406:\n",
      "\tcmpq\t%rdx, %rcx\n",
      "\tje\tL470\n",
      "L411:\n",
      "\txorl\t%ecx, %ecx\n",
      "\tcmpq\t$0, %rbx\n",
      "\tcmovgq\t%rbx, %rcx\n",
      "\taddq\t$1, %rcx\n",
      "\tsubq\t%rdx, %rcx\n",
      "\taddq\t$-1, %rdx\n",
      "\tshlq\t$3, %rdx\n",
      "\taddq\t%rdx, %rax\n",
      "\tnopw\t(%rax,%rax)\n",
      "Source line: 211\n",
      "L448:\n",
      "\tvmulsd\t(%rax), %xmm0, %xmm1\n",
      "\tvmovsd\t%xmm1, (%rax)\n",
      "Source line: 70\n",
      "\taddq\t$-1, %rcx\n",
      "\taddq\t$8, %rax\n",
      "\tcmpq\t$0, %rcx\n",
      "\tjne\tL448\n",
      "Source line: 158\n",
      "L470:\n",
      "\tmovq\t-64(%rbp), %rax\n",
      "\tmovq\t%rax, (%r15)\n",
      "\tmovq\t%r14, %rax\n",
      "\taddq\t$72, %rsp\n",
      "\tpopq\t%rbx\n",
      "\tpopq\t%r12\n",
      "\tpopq\t%r13\n",
      "\tpopq\t%r14\n",
      "\tpopq\t%r15\n",
      "\tpopq\t%rbp\n",
      "\tvzeroupper\n",
      "\tretq\n",
      "Source line: 229\n",
      "L498:\n",
      "\tmovabsq\t$jl_gc_alloc_1w, %rax\n",
      "\tcallq\t*%rax\n",
      "\tmovq\t%rax, -56(%rbp)\n",
      "\tleaq\t-47968848(%r13), %rcx\n",
      "\tmovq\t%rcx, -8(%rax)\n",
      "\tmovq\t%r13, -48(%rbp)\n",
      "\tmovq\t%r13, (%rax)\n",
      "\tmovabsq\t$jl_throw, %rcx\n",
      "\tmovq\t%rax, %rdi\n",
      "\tcallq\t*%rcx\n",
      "\tnopw\t%cs:(%rax,%rax)\n"
     ]
    }
   ],
   "source": [
    "@code_native softmax!([0.25,0.25],[0.25,0.25] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables:\n",
      "  #self#::#softmax2!\n",
      "  t1::Float64\n",
      "  t2::Float64\n",
      "  u::Float64\n",
      "  s::Float64\n",
      "\n",
      "Body:\n",
      "  begin  # In[2], line 2:\n",
      "      u::Float64 = (Base.select_value)((Base.lt_float)(t1::Float64,t2::Float64)::Bool,t2::Float64,t1::Float64)::Float64 # In[2], line 3:\n",
      "      GenSym(0) = (Base.FastMath.box)(Float64,((top(getfield))(Base.FastMath.Base,:sub_float_fast)::I)(t1::Float64,u::Float64))::Float64 # fastmath.jl, line 272:\n",
      "      t1::Float64 = (top(ccall))((top(tuple))(\"exp\",Base.FastMath.libm)::Tuple{ASCIIString,ASCIIString},Base.FastMath.Float64,(top(svec))(Base.FastMath.Float64)::SimpleVector,GenSym(0),0)::Float64 # In[2], line 4:\n",
      "      GenSym(2) = (Base.FastMath.box)(Float64,((top(getfield))(Base.FastMath.Base,:sub_float_fast)::I)(t2::Float64,u::Float64))::Float64 # fastmath.jl, line 272:\n",
      "      t2::Float64 = (top(ccall))((top(tuple))(\"exp\",Base.FastMath.libm)::Tuple{ASCIIString,ASCIIString},Base.FastMath.Float64,(top(svec))(Base.FastMath.Float64)::SimpleVector,GenSym(2),0)::Float64 # In[2], line 5:\n",
      "      s::Float64 = (Base.FastMath.box)(Float64,((top(getfield))(Base.FastMath.Base,:add_float_fast)::I)(t1::Float64,t2::Float64))::Float64 # In[2], line 6:\n",
      "      t1::Float64 = (Base.FastMath.box)(Float64,((top(getfield))(Base.FastMath.Base,:div_float_fast)::I)(t1::Float64,s::Float64))::Float64 # In[2], line 7:\n",
      "      t2::Float64 = (Base.FastMath.box)(Float64,((top(getfield))(Base.FastMath.Base,:div_float_fast)::I)(t2::Float64,s::Float64))::Float64 # In[2], line 8:\n",
      "      return (top(tuple))(t1::Float64,t2::Float64)::Tuple{Float64,Float64}\n",
      "  end::Tuple{Float64,Float64}\n"
     ]
    }
   ],
   "source": [
    "@code_warntype softmax2!(0.25,0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.008026 seconds (2.89 k allocations: 180.209 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition test() in module Main at In[217]:2 overwritten at In[219]:2.\n"
     ]
    }
   ],
   "source": [
    "function test()\n",
    "    for ii in 1:1000\n",
    "        StatsFuns.softmax!([0.25,0.5])\n",
    "    end\n",
    "end\n",
    "gc()\n",
    "@time test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.010031 seconds (1.98 k allocations: 88.513 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition testa() in module Main at In[239]:2 overwritten at In[240]:2.\n"
     ]
    }
   ],
   "source": [
    "function testa()\n",
    "    for ii in 1:100000\n",
    "        softmax2b!(0.25/ii,1./ii)\n",
    "    end\n",
    "end\n",
    "gc()\n",
    "@time testa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.009845 seconds (1.98 k allocations: 88.513 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition testa() in module Main at In[241]:2 overwritten at In[242]:2.\n"
     ]
    }
   ],
   "source": [
    "function testa()\n",
    "    for ii in 1:100000\n",
    "        softmax2a!(0.25/ii,1./ii)\n",
    "    end\n",
    "end\n",
    "gc()\n",
    "@time testa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.011857 seconds (2.02 k allocations: 90.215 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition testb() in module Main at In[229]:2 overwritten at In[231]:2.\n"
     ]
    }
   ],
   "source": [
    "function testb()\n",
    "    for ii in 1:100000\n",
    "        softmax2!(0.25/ii,1./ii)\n",
    "    end\n",
    "end\n",
    "gc()\n",
    "@time testb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.006289 seconds (1.75 k allocations: 80.685 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition test() in module Main at In[37]:2 overwritten at In[38]:2.\n"
     ]
    }
   ],
   "source": [
    "function test()\n",
    "    for ii in 1:1000\n",
    "        softmaxK!((0.25,0.5))\n",
    "    end\n",
    "end\n",
    "gc()\n",
    "@time test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.008434 seconds (4.99 k allocations: 217.851 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition test() in module Main at In[11]:2 overwritten at In[12]:2.\n"
     ]
    }
   ],
   "source": [
    "function test()\n",
    "    for ii in 1:1000\n",
    "        softmaxKAB!([0.25,0.5],Val{2})\n",
    "    end\n",
    "end\n",
    "gc()\n",
    "@time test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Float32(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a[:]=(4,5,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median([1,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.0-dev",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
