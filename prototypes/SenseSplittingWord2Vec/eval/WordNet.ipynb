{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(\"Utils\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using ProgressMeter\n",
    "using SwiftObjectStores\n",
    "using CorpusLoaders\n",
    "using WordNet\n",
    "using AdaGram\n",
    "using AdaGramCompat\n",
    "using WordEmbeddings, SoftmaxClassifier\n",
    "using Utils\n",
    "using Query\n",
    "using Distances\n",
    "using JLD\n",
    "\n",
    "using SenseAlignment\n",
    "\n",
    "importfrom(CorpusLoaders, :sensekey)\n",
    "importfrom(WordNet, :sensekey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordNet.DB"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const WN_PATH=\"data/corpora/WordNet-2.1/\"\n",
    "#WN_PATH3 = \"/usr/share/nltk_data/corpora/wordnet/\"\n",
    "db = DB(WN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#am = AdaGramCompat.AdaGramModel(load_model(\"models/adagram/v1_d100.adagram_model\")...)\n",
    "#am = AdaGramModel(load_model(\"models/adagram/more_senses.adagram_model\")...)\n",
    "#am = open(deserialize,\"models/adagram/more_senses.adagram_model.jsz\", \"r\");\n",
    "am = load(\"models/adagram/more_senses.adagram_model.jld\", \"am\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s_am = get_jld(SwiftService(), \"sensemodels\", \"adagram/semhuff_more_senses.adagram_model.jld\", \"am\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ee = restore(\"models/ss/tokenised_lowercase_WestburyLab.wikicorp.201004_100_i1.jld\");\n",
    "ee = load(\"models/ss/tokenised_lowercase_WestburyLab.wikicorp.201004_100_i1.jld\", \"ee\")\n",
    "\n",
    "#ee = restore(\"models/ss/keep/tokenised_lowercase_WestburyLab.wikicorp.201004_50__m170000000.model\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "challenges = load_challenges_semeval2007t7(\"data/corpora/wsd/semeval2007_t7/test/eng-coarse-all-words.xml\");\n",
    "solutions = load_solutions_semeval2007t7(\"data/corpora/wsd/semeval2007_t7/key/dataset21.test.key\");\n",
    "semcor = index_semcor(lazyload_semcor(\"data/corpora/semcor2.1/brown1/tagfiles/\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element SubArray{String,1,Array{String,1},Tuple{Array{Int64,1}},false}:\n",
       " \"fire\"  \n",
       " \"can\"   \n",
       " \"be\"    \n",
       " \"built;\"\n",
       " \"\\\"the\" \n",
       " \"was\"   \n",
       " \"so\"    \n",
       " \"large\" \n",
       " \"you\"   \n",
       " \"could\" "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function window(context, index::Int, window_size::Int=10)\n",
    "    window_lower_bound = max(index - window_size÷2, 1)\n",
    "    window_upper_bound = min(index + window_size÷2, length(context))\n",
    "    view(context, [window_lower_bound:index-1 ; index+1:window_upper_bound])\n",
    "end\n",
    "\n",
    "function window(tagged_sense::TaggedSentence, index::Int, window_size::Int=10)\n",
    "    context = lowercase.(strip_tags(tagged_sense))\n",
    "    window(context, index, window_size)\n",
    "end\n",
    "   \n",
    "function window(context, word::AbstractString, window_size::Int=10)\n",
    "    context = lowercase.(context)\n",
    "    occurances = find(context.==word)\n",
    "    index =  length(occurances) > 0 ? occurances[ceil(Int, end/2)] : 0\n",
    "    window(context, index, window_size)\n",
    "\n",
    "end\n",
    "\n",
    "\n",
    "window((drop(semcor,400) |> first |> last |> first)...)\n",
    "\n",
    "window((synsets(db, db[\"fireplace\", 'n']) |> first).gloss |> split, \"fireplace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_all_usages (generic function with 1 method)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"Collect up the usages from a indexed tagged source\"\n",
    "function get_usages(usage_index::SemcorIndex, key)\n",
    "    if haskey(usage_index, key)\n",
    "        [window(lowercase.(strip_tags(sent)), index) for (sent, index) in usage_index[key]]\n",
    "    else\n",
    "        Vector{String}[]\n",
    "    end\n",
    "end\n",
    "\n",
    "function get_usages(synset::Synset, lemma_word::AbstractString)\n",
    "    gloss::Vector{SubString{String}} = lowercase.(punctuation_space_tokenize(synset.gloss))\n",
    "    [window(gloss, lemma_word)]\n",
    "end\n",
    "\n",
    "function get_all_usages(wn::DB, semcor::SemcorIndex, lemma_word, pos)   \n",
    "    lemma = db[pos, lemma_word]\n",
    "    target_synsets::Vector{Synset} = synsets(db, lemma)\n",
    "    \n",
    "    Dict{Synset,AbstractVector{AbstractVector}}((synset => get_usages(synset, lemma_word)\n",
    "        #[get_usages(semcor, sensekey(db, synset, lemma)); get_usages(synset, lemma_word)]\n",
    "                    for synset in target_synsets))  \n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lexically_informed_embeddings (generic function with 2 methods)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_identical(col) = length(col)==1 || !any(x->x!=col[1],col[2:end])\n",
    "\n",
    "function _lexically_informed_embeddings(wn::DB,ee, word,lemma_word, pos)\n",
    "    indexed_corpus = semcor #TODO: Pass this as a parameter, not as a gloel\n",
    "    target_synset_examples = get_all_usages(wn, indexed_corpus, lemma_word, pos)\n",
    "    target_synsets = collect(keys(target_synset_examples))\n",
    "    lem = db[lemma_word, pos]\n",
    "        \n",
    "    embeddings = Vector{Vector{Float32}}(length(target_synsets))\n",
    "    for (ii,(synset, examples)) in enumerate(target_synset_examples)\n",
    "        context::Vector{SubString{String}} = vcat(examples...)\n",
    "        embeddings[ii] =synthesize_embedding(ee,context, word, lemma_word)\n",
    "    end\n",
    "        \n",
    "    \n",
    "    if all_identical(embeddings)\n",
    "        #Use MCWS\n",
    "        score, index = findmax(sensecount(db, ss, lem ) for ss in target_synsets)\n",
    "        target_synsets=[target_synsets[index]] # Throw out others\n",
    "        embeddings=[embeddings[1]]\n",
    "    end\n",
    "        \n",
    "    embeddings,target_synsets,lem\n",
    "end\n",
    "\n",
    "lexically_informed_embeddings(wn::DB, ee, lemma_word, pos) = lexically_informed_embeddings(db,ee, lemma_word, lemma_word, pos)\n",
    "        \n",
    "_li_embeddings = Dict{Tuple{DB, Any, String, String, Char}, Tuple{Vector{Vector{Float32}}, Vector{Synset}, Lemma}}()\n",
    "function lexically_informed_embeddings(wn::DB, ee, word,lemma_word, pos)\n",
    "    get!(_li_embeddings, (wn, ee, word, lemma_word, pos)) do\n",
    "        _lexically_informed_embeddings(wn, ee, word, lemma_word, pos)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "most_frequent_sense (generic function with 1 method)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function supervised_wsd(challenge, ee, wn::DB)\n",
    "    try\n",
    "        embeddings,target_synsets,lem = lexically_informed_embeddings(wn,ee,\n",
    "                                                            challenge.word, \n",
    "                                                            challenge.lemma, challenge.pos)\n",
    "        \n",
    "        priors = [float(sensecount(db, ss, lem)) for ss in target_synsets] #TODO use thing\n",
    "        priors .+= 100\n",
    "        #priors .+= sqrt(sum(priors))/length(priors)\n",
    "        priors ./= sum(priors)\n",
    "        probs_of_sense = general_wsd(ee, challenge.context, embeddings, priors)\n",
    "               \n",
    "     \n",
    "        sense_index= indmax(probs_of_sense)        \n",
    "        synset = target_synsets[sense_index]\n",
    "        sk = sensekey(wn, synset, lem)\n",
    "        Nullable(sk)\n",
    "    catch ex\n",
    "        isa(ex, KeyError) || rethrow(ex)\n",
    "        @show ex\n",
    "        Nullable{String}()\n",
    "    end\n",
    "end\n",
    "\n",
    "function most_frequent_sense(challenge, wn::DB)\n",
    "    try\n",
    "        lem = wn[challenge.pos, challenge.lemma]\n",
    "        target_synsets::Vector{Synset} = synsets(db, lem)\n",
    "        \n",
    "        sense_freqs =  Float32[sensecount(db, ss, lem) for ss in target_synsets]\n",
    "        sense_index= indmax(sense_freqs)\n",
    "        synset = target_synsets[sense_index]\n",
    "        \n",
    "        sk = sensekey(wn, synset,  lem)\n",
    "        Nullable(sk)\n",
    "    catch ex\n",
    "        isa(ex, KeyError) || rethrow(ex)\n",
    "        Nullable{String}()\n",
    "    end\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evalute_on_wsd_challenge_MFS (generic function with 1 method)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function evalute_on_wsd_challenge(challenges, solutions, method)\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    notattempted = 0\n",
    "    @showprogress for (challenge, ground_solution) in zip(challenges, solutions)\n",
    "        assert(challenge.id == ground_solution.id)\n",
    "        output_sense = method(challenge)\n",
    "        if isnull(output_sense)\n",
    "            notattempted+=1\n",
    "        else\n",
    "            if get(output_sense) ∈ ground_solution.solutions\n",
    "                correct+=1\n",
    "            else\n",
    "                incorrect+=1\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    @show notattempted\n",
    "    precision = correct/(correct+incorrect)\n",
    "    recall = correct/(correct+incorrect+notattempted)\n",
    "    f1 = (2*precision*recall) / (precision+recall)\n",
    "    return precision, recall, f1\n",
    "end\n",
    "    \n",
    "    \n",
    "function evalute_on_wsd_challenge(challenges, solutions, ee, wn::DB)\n",
    "    method = challenge -> supervised_wsd(challenge, ee, wn)\n",
    "    evalute_on_wsd_challenge(challenges, solutions, method)\n",
    "end\n",
    "\n",
    "function evalute_on_wsd_challenge_MFS(challenges, solutions, wn::DB)\n",
    "    method = challenge -> most_frequent_sense(challenge, wn)\n",
    "    evalute_on_wsd_challenge(challenges, solutions, method)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:  19%|████████                                 |  ETA: 0:00:08ex = KeyError(\" SubString{String}[\\\"noncompetitively\\\"], nor SubString{String}[\\\"noncompetitively\\\"] have embeddings\")\n",
      "Progress:  23%|██████████                               |  ETA: 0:00:08ex = KeyError(\" SubString{String}[\\\"semiliterate\\\"], nor SubString{String}[\\\"semiliterate\\\"] have embeddings\")\n",
      "Progress: 100%|█████████████████████████████████████████| Time: 0:00:09\n",
      "notattempted = 2\n",
      "overall: \t\t(0.7953242170269078,0.7946231820185103,0.794973544973545)\n"
     ]
    }
   ],
   "source": [
    "println(\"overall: \\t\\t\", evalute_on_wsd_challenge(challenges, solutions, am, db))\n",
    "\n",
    "#println(\"only nouns  : \\t\\t\", \n",
    "#@show nn = evalute_on_wsd_challenge(only_of_pos(challenges,'n'), only_of_pos(solutions,'n'), am, db)\n",
    "#println(\"only verbs  : \\t\\t\", \n",
    "#@show vv = evalute_on_wsd_challenge(only_of_pos(challenges,'v'), only_of_pos(solutions,'v'), am, db)\n",
    "#println(\"only adjecti: \\t\\t\", \n",
    "#@show aa = evalute_on_wsd_challenge(only_of_pos(challenges,'a'), only_of_pos(solutions,'a'), am, db)\n",
    "#println(\"only adverbs: \\t\\t\", \n",
    "#@show rr = evalute_on_wsd_challenge(only_of_pos(challenges,'r'), only_of_pos(solutions,'r'), am, db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "println(\"overall: \\t\\t\", evalute_on_wsd_challenge(challenges, solutions, s_am, db))\n",
    "\n",
    "#println(\"only nouns  : \\t\\t\", \n",
    "#@show nn = evalute_on_wsd_challenge(only_of_pos(challenges,'n'), only_of_pos(solutions,'n'), s_am, db)\n",
    "#println(\"only verbs  : \\t\\t\", \n",
    "#@show vv = evalute_on_wsd_challenge(only_of_pos(challenges,'v'), only_of_pos(solutions,'v'), s_am, db)\n",
    "#println(\"only adjecti: \\t\\t\", \n",
    "#@show aa = evalute_on_wsd_challenge(only_of_pos(challenges,'a'), only_of_pos(solutions,'a'), s_am, db)\n",
    "#println(\"only adverbs: \\t\\t\", \n",
    "#@show rr = evalute_on_wsd_challenge(only_of_pos(challenges,'r'), only_of_pos(solutions,'r'), s_am, db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"models/adagram/more_senses.adagram_model.jld\n",
    "### with Adagram Disambig weighting (prior used)\n",
    "### with SemCor data \n",
    "overall: \t\t(0.655408489274304,0.6328779197884531,0.6439461883408072)\n",
    "- nn = evalute_on_wsd_challenge(only_of_pos(challenges,'n'),only_of_pos(solutions,'n'),am,db) = (0.7161410018552876,0.6967509025270758,0.706312900274474)\n",
    "- vv = evalute_on_wsd_challenge(only_of_pos(challenges,'v'),only_of_pos(solutions,'v'),am,db) = (0.5106382978723404,0.4873096446700508,0.4987012987012987)\n",
    "- aa = evalute_on_wsd_challenge(only_of_pos(challenges,'a'),only_of_pos(solutions,'a'),am,db) = (0.6619718309859155,0.649171270718232,0.6555090655509065)\n",
    "- rr = evalute_on_wsd_challenge(only_of_pos(challenges,'r'),only_of_pos(solutions,'r'),am,db) = (0.7268041237113402,0.6778846153846154,0.7014925373134329)\n",
    "\n",
    "### with Adagram Disambig weighting (prior used)\n",
    "### with just glosses \n",
    "\n",
    "overall: \t\t(0.6704701049748973,0.6474217717055972,0.658744394618834)\n",
    "- nn = evalute_on_wsd_challenge(only_of_pos(challenges,'n'),only_of_pos(solutions,'n'),am,db) = (0.7133580705009277,0.694043321299639,0.7035681610247027)\n",
    "- vv = evalute_on_wsd_challenge(only_of_pos(challenges,'v'),only_of_pos(solutions,'v'),am,db) = (0.5780141843971631,0.5516074450084603,0.5645021645021645)\n",
    "- aa = evalute_on_wsd_challenge(only_of_pos(challenges,'a'),only_of_pos(solutions,'a'),am,db) = (0.6535211267605634,0.6408839779005525,0.6471408647140865)\n",
    "- rr = evalute_on_wsd_challenge(only_of_pos(challenges,'r'),only_of_pos(solutions,'r'),am,db) = (0.7319587628865979,0.6826923076923077,0.7064676616915424)\n",
    "\n",
    "\n",
    "\n",
    "# \"semhuff_more_senses.adagram_model.jld\n",
    "\n",
    "### with Adagram Disambig weighting (prior used)\n",
    "### with just glosses \n",
    " - overall: \t\t(0.6704701049748973,0.6474217717055972,0.658744394618834)\n",
    " - nn = evalute_on_wsd_challenge(only_of_pos(challenges,'n'),only_of_pos(solutions,'n'),am,db) = (0.7133580705009277,0.694043321299639,0.7035681610247027)\n",
    " - vv = evalute_on_wsd_challenge(only_of_pos(challenges,'v'),only_of_pos(solutions,'v'),am,db) = (0.5780141843971631,0.5516074450084603,0.5645021645021645)\n",
    " - aa = evalute_on_wsd_challenge(only_of_pos(challenges,'a'),only_of_pos(solutions,'a'),am,db) = (0.6535211267605634,0.6408839779005525,0.6471408647140865)\n",
    " - rr = evalute_on_wsd_challenge(only_of_pos(challenges,'r'),only_of_pos(solutions,'r'),am,db) = (0.7319587628865979,0.6826923076923077,0.7064676616915424)\n",
    " \n",
    " ### with Adagram Disambig weighting (prior used)\n",
    " ### With semcore\n",
    " - overall: \t\t(0.6134185303514377,0.5923314235345968,0.6026905829596412)\n",
    " - nn = evalute_on_wsd_challenge(only_of_pos(challenges,'n'),only_of_pos(solutions,'n'),s_am,db) = (0.6252319109461967,0.6083032490974729,0.6166514181152789)\n",
    " - vv = evalute_on_wsd_challenge(only_of_pos(challenges,'v'),only_of_pos(solutions,'v'),s_am,db) = (0.5638297872340425,0.5380710659898477,0.5506493506493505)\n",
    " - aa = evalute_on_wsd_challenge(only_of_pos(challenges,'a'),only_of_pos(solutions,'a'),s_am,db) = (0.6169014084507042,0.6049723756906077,0.610878661087866)\n",
    " - rr = evalute_on_wsd_challenge(only_of_pos(challenges,'r'),only_of_pos(solutions,'r'),s_am,db) = (0.6855670103092784,0.6394230769230769,0.6616915422885572)\n",
    " \n",
    " \n",
    " # Most Frequent Sense\n",
    " \n",
    "  -  overall: \t\t(0.7783164389598942,0.7783164389598942,0.7783164389598942)\n",
    "  - only nouns  : \t\t(0.7653429602888087,0.7653429602888087,0.7653429602888087)\n",
    "  - only verbs  : \t\t(0.7529610829103215,0.7529610829103215,0.7529610829103215)\n",
    "  - only adjecti: \t\t(0.8038674033149171,0.8038674033149171,0.8038674033149171)\n",
    "  - only adverbs: \t\t(0.875,0.875,0.875)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "println(\"overall: \\t\\t\", evalute_on_wsd_challenge(challenges, solutions, ee, db))\n",
    "\n",
    "#println(\"only nouns  : \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'n'), only_of_pos(solutions,'n'), ee, db))\n",
    "#println(\"only verbs  : \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'v'), only_of_pos(solutions,'v'), ee, db))\n",
    "#println(\"only adjecti: \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'a'), only_of_pos(solutions,'a'), ee, db))\n",
    "#println(\"only adverbs: \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'r'), only_of_pos(solutions,'r'), ee, db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "println(\"overall: \\t\\t\", evalute_on_wsd_challenge_MFS(challenges, solutions, db))\n",
    "\n",
    "#println(\"only nouns  : \\t\\t\", evalute_on_wsd_challenge_MFS(only_of_pos(challenges,'n'), only_of_pos(solutions,'n'), db))\n",
    "#println(\"only verbs  : \\t\\t\", evalute_on_wsd_challenge_MFS(only_of_pos(challenges,'v'), only_of_pos(solutions,'v'), db))\n",
    "#println(\"only adjecti: \\t\\t\", evalute_on_wsd_challenge_MFS(only_of_pos(challenges,'a'), only_of_pos(solutions,'a'), db))\n",
    "#println(\"only adverbs: \\t\\t\", evalute_on_wsd_challenge_MFS(only_of_pos(challenges,'r'), only_of_pos(solutions,'r'), db))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Zero shot WSI for 1 shot WSD\n",
    "using Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rr = FixedWordSenseEmbedding(ee.dimension, random_inited, huffman_tree; initial_nsenses=50)\n",
    "rr.corpus_size = ee.corpus_size\n",
    "rr.distribution = ee.distribution\n",
    "rr.codebook = ee.codebook\n",
    "rr.classification_tree = ee.classification_tree\n",
    "Training.initialize_embedding(rr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rr.embedding[\"us\"] |> length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "println(\"overall: \\t\\t\", evalute_on_wsd_challenge(challenges, solutions, rr, db))\n",
    "\n",
    "println(\"only nouns  : \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'n'), only_of_pos(solutions,'n'), rr, db))\n",
    "println(\"only verbs  : \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'v'), only_of_pos(solutions,'v'), rr, db))\n",
    "println(\"only adjecti: \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'a'), only_of_pos(solutions,'a'), rr, db))\n",
    "println(\"only adverbs: \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'r'), only_of_pos(solutions,'r'), rr, db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hh = deepcopy(rr)\n",
    "for word in keys(rr.embedding)\n",
    "    append!(hh.embedding[word], ee.embedding[word])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "println(\"overall: \\t\\t\", evalute_on_wsd_challenge(challenges, solutions, hh, db))\n",
    "\n",
    "println(\"only nouns  : \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'n'), only_of_pos(solutions,'n'), hh, db))\n",
    "println(\"only verbs  : \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'v'), only_of_pos(solutions,'v'), hh, db))\n",
    "println(\"only adjecti: \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'a'), only_of_pos(solutions,'a'), hh, db))\n",
    "println(\"only adverbs: \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'r'), only_of_pos(solutions,'r'), hh, db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mapping_corpus = load_semcor(\"data/corpora/semcor2.1/brown1/tagfiles/\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agirresAlignment (generic function with 2 methods)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function agirresAlignment(ee, wn::DB, mapping_corpus, hard=true)\n",
    "    maps = Dict{Tuple{String, Char}, Matrix{Float32}}()\n",
    "    freqs = Dict{Tuple{String, Char}, Vector{Int}}()\n",
    "    \n",
    "    function proc_word(word::TaggedWord, sentence::TaggedSentence)\n",
    "    end\n",
    "    \n",
    "    function proc_word(taggedword::SenseAnnotatedWord, sentence::TaggedSentence)\n",
    "        local wn_sensekeys\n",
    "        pos = pennPOStoWordNetPOS(taggedword.pos)\n",
    "       \n",
    "        try \n",
    "            wn_sensekeys = sensekeys(wn, wn[pos, taggedword.lemma])\n",
    "        catch exception\n",
    "            exception |> typeof <: KeyError || rethrow()\n",
    "            warn(\"Could not find wordnet lemma for $taggedword\")\n",
    "            return\n",
    "        end\n",
    "        \n",
    "        target_wnsn = findfirst(wn_sensekeys .== sensekey(taggedword))\n",
    "        if target_wnsn==0\n",
    "            warn(\"$(sensekey(taggedword)) not in  $(wn_sensekeys).\\n\\nIssue is with $taggedword\")\n",
    "            return\n",
    "        end\n",
    "\n",
    "        wvs = all_word_sense_vectors(ee,taggedword.word)\n",
    "        if length(wvs) == 0\n",
    "            warn(\"No embedding for $(taggedword.word); skipping\")\n",
    "            return\n",
    "        end\n",
    "        \n",
    "        ########\n",
    "        \n",
    "\n",
    "        map = get!(maps, (taggedword.lemma, pos)) do\n",
    "            zeros(length(wvs), length(wn_sensekeys))\n",
    "        end\n",
    "        \n",
    "        freq = get!(freqs, (taggedword.lemma, pos)) do \n",
    "            zeros(Int, length(wn_sensekeys))\n",
    "        end\n",
    "        \n",
    "        \n",
    "        context = lowercase.(strip_tags(sentence))\n",
    "        wv_probs = general_wsd(ee,context, wvs)\n",
    "        @assert sum(wv_probs) ≈ 1f0\n",
    "        @assert !any(isnan.(wv_probs))\n",
    "        freq[target_wnsn] += 1\n",
    "        if hard\n",
    "            map[indmax(wv_probs),target_wnsn] += 1\n",
    "        else\n",
    "            map[:,target_wnsn] += wv_probs\n",
    "        end\n",
    "        \n",
    "    end\n",
    "    \n",
    "    for sentence in mapping_corpus\n",
    "        for word in sentence\n",
    "            proc_word(word, sentence)\n",
    "        end\n",
    "    end\n",
    " \n",
    "    \n",
    "    for ((word,pos), freq) in freqs\n",
    "        mm = maps[(word,pos)]\n",
    "        mm ./= freq'\n",
    "        mm[isnan.(mm)] = 0f0 #NaNs are just frequency 0 items\n",
    "        @assert(all(isapprox.(sum(mm, 1), 1f0; atol=1f-5) | isapprox.(sum(mm, 1), 0f0; atol=1f-5)), \"($word , $pos) not sum to one, $(sum(mm,1))\")\n",
    "    end\n",
    "    \n",
    "    maps, freqs\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "maps_soft, freqs  = agirresAlignment(am, db, mapping_corpus, false);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maps2 = deepcopy(maps);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head>\n",
       "     <script src=\"/home/ubuntu/.julia/v0.5/PlotlyJS/deps/plotly-latest.min.js\"></script>\n",
       "</head>\n",
       "<body>\n",
       "     <div id=\"fc688aa8-0557-418e-bee3-dca62611c49c\" class=\"plotly-graph-div\"></div>\n",
       "\n",
       "<script>\n",
       "    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "    window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "    Plotly.newPlot('fc688aa8-0557-418e-bee3-dca62611c49c', [{\"yaxis\":\"y\",\"y\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30],\"colorscale\":[[0.0,\"rgb(0, 0, 4)\"],[0.034482758620689655,\"rgb(4, 3, 20)\"],[0.06896551724137931,\"rgb(13, 8, 41)\"],[0.10344827586206896,\"rgb(24, 12, 60)\"],[0.13793103448275862,\"rgb(38, 12, 81)\"],[0.1724137931034483,\"rgb(54, 9, 97)\"],[0.20689655172413793,\"rgb(69, 10, 105)\"],[0.2413793103448276,\"rgb(84, 15, 109)\"],[0.27586206896551724,\"rgb(97, 19, 110)\"],[0.3103448275862069,\"rgb(111, 25, 110)\"],[0.3448275862068966,\"rgb(125, 30, 109)\"],[0.3793103448275862,\"rgb(140, 35, 105)\"],[0.41379310344827586,\"rgb(154, 40, 101)\"],[0.4482758620689655,\"rgb(166, 45, 96)\"],[0.4827586206896552,\"rgb(180, 51, 89)\"],[0.5172413793103449,\"rgb(193, 58, 80)\"],[0.5517241379310345,\"rgb(206, 67, 71)\"],[0.5862068965517241,\"rgb(216, 76, 62)\"],[0.6206896551724138,\"rgb(226, 87, 52)\"],[0.6551724137931034,\"rgb(235, 100, 41)\"],[0.6896551724137931,\"rgb(241, 115, 29)\"],[0.7241379310344828,\"rgb(247, 130, 18)\"],[0.7586206896551724,\"rgb(250, 144, 8)\"],[0.7931034482758621,\"rgb(252, 161, 8)\"],[0.8275862068965517,\"rgb(252, 178, 22)\"],[0.8620689655172413,\"rgb(250, 196, 42)\"],[0.896551724137931,\"rgb(246, 213, 67)\"],[0.9310344827586207,\"rgb(243, 229, 93)\"],[0.9655172413793104,\"rgb(242, 244, 130)\"],[1.0,\"rgb(252, 255, 164)\"]],\"showlegend\":false,\"name\":\"y1\",\"type\":\"heatmap\",\"xaxis\":\"x\",\"z\":[[0.012715286,0.024590794,0.009409795,0.010432618,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.02432633,0.02038731,0.023904515,0.021420373,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.01824799,0.027015442,0.014702983,0.02555364,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.021420406,0.019982202,0.0215483,0.032841016,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.020577937,0.036833744,0.022883045,0.019001901,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.014940511,0.027108327,0.011875202,0.013305413,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.019592064,0.020284425,0.019607615,0.02024832,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.033045918,0.025966018,0.034881797,0.05113273,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.012888222,0.011083763,0.015047348,0.01208657,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.021778941,0.021188749,0.022560671,0.030229382,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.025032382,0.0259249,0.029064203,0.053243253,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.022088056,0.014006068,0.019168412,0.022117596,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.018312281,0.025994793,0.013927304,0.012777448,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0209712,0.04221215,0.017617526,0.0333385,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.017089993,0.015860781,0.018177494,0.016232802,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.02222349,0.021488544,0.019195864,0.016756617,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.018315494,0.017483126,0.018508809,0.012276121,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.05049189,0.046515778,0.05132251,0.045929138,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.050538804,0.046393983,0.051510558,0.04590941,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.050501157,0.046429507,0.05140579,0.045789078,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.050672542,0.046597075,0.051535144,0.04614847,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.050535962,0.046347983,0.051340867,0.045896802,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.05044718,0.046226945,0.051238846,0.0456489,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.050465893,0.046154507,0.05134015,0.04587746,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.050493035,0.04628071,0.05132766,0.045955777,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.050392937,0.046146296,0.051168386,0.045781173,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.050442908,0.046364628,0.05141474,0.045909125,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.050406873,0.046198953,0.05125229,0.045868624,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.050531805,0.046442844,0.051572803,0.046151068,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.050512504,0.046489652,0.051489364,0.046140682,0.0,0.0,0.0,0.0,0.0,0.0,0.0]],\"x\":[1,2,3,4,5,6,7,8,9,10,11]}],\n",
       "               {\"yaxis\":{\"type\":\"-\",\"titlefont\":{\"size\":15,\"color\":\"rgba(0, 0, 0, 1.000)\",\"family\":\"Helvetica\"},\"title\":\"\",\"tickfont\":{\"size\":11,\"color\":\"rgba(0, 0, 0, 1.000)\",\"family\":\"Helvetica\"},\"tickmode\":\"array\",\"showgrid\":true,\"tickvals\":[10.0,20.0,30.0],\"domain\":[0.057305336832895896,0.9901574803149605],\"ticktext\":[\"10\",\"20\",\"30\"],\"zeroline\":false,\"linecolor\":\"rgba(0, 0, 0, 1.000)\",\"tickcolor\":\"rgba(0, 0, 0, 1.000)\",\"anchor\":\"x\"},\"annotations\":[],\"width\":600,\"plot_bgcolor\":\"rgba(255, 255, 255, 1.000)\",\"showlegend\":true,\"legend\":{\"bgcolor\":\"rgba(255, 255, 255, 1.000)\",\"font\":{\"size\":11,\"color\":\"rgba(0, 0, 0, 1.000)\",\"family\":\"Helvetica\"},\"bordercolor\":\"rgba(0, 0, 0, 1.000)\"},\"xaxis\":{\"type\":\"-\",\"titlefont\":{\"size\":15,\"color\":\"rgba(0, 0, 0, 1.000)\",\"family\":\"Helvetica\"},\"title\":\"\",\"tickfont\":{\"size\":11,\"color\":\"rgba(0, 0, 0, 1.000)\",\"family\":\"Helvetica\"},\"tickmode\":\"array\",\"showgrid\":true,\"tickvals\":[2.0,4.0,6.0,8.0,10.0],\"domain\":[0.05905511811023622,0.9934383202099738],\"ticktext\":[\"2\",\"4\",\"6\",\"8\",\"10\"],\"zeroline\":false,\"linecolor\":\"rgba(0, 0, 0, 1.000)\",\"tickcolor\":\"rgba(0, 0, 0, 1.000)\",\"anchor\":\"y\"},\"paper_bgcolor\":\"rgba(255, 255, 255, 1.000)\",\"margin\":{\"r\":0,\"l\":0,\"b\":0,\"t\":20},\"height\":400}, {showLink: false});\n",
       "\n",
       " </script>\n",
       "\n",
       "</body>\n",
       "</html>\n"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maps_soft[(\"dark\", 'a')] |> heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head>\n",
       "     <script src=\"/home/ubuntu/.julia/v0.5/PlotlyJS/deps/plotly-latest.min.js\"></script>\n",
       "</head>\n",
       "<body>\n",
       "     <div id=\"e611d395-df43-4fa5-98f4-7c2a4df45d2c\" class=\"plotly-graph-div\"></div>\n",
       "\n",
       "<script>\n",
       "    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "    window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "    Plotly.newPlot('e611d395-df43-4fa5-98f4-7c2a4df45d2c', [{\"yaxis\":\"y\",\"y\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30],\"colorscale\":[[0.0,\"rgb(0, 0, 4)\"],[0.034482758620689655,\"rgb(4, 3, 20)\"],[0.06896551724137931,\"rgb(13, 8, 41)\"],[0.10344827586206896,\"rgb(24, 12, 60)\"],[0.13793103448275862,\"rgb(38, 12, 81)\"],[0.1724137931034483,\"rgb(54, 9, 97)\"],[0.20689655172413793,\"rgb(69, 10, 105)\"],[0.2413793103448276,\"rgb(84, 15, 109)\"],[0.27586206896551724,\"rgb(97, 19, 110)\"],[0.3103448275862069,\"rgb(111, 25, 110)\"],[0.3448275862068966,\"rgb(125, 30, 109)\"],[0.3793103448275862,\"rgb(140, 35, 105)\"],[0.41379310344827586,\"rgb(154, 40, 101)\"],[0.4482758620689655,\"rgb(166, 45, 96)\"],[0.4827586206896552,\"rgb(180, 51, 89)\"],[0.5172413793103449,\"rgb(193, 58, 80)\"],[0.5517241379310345,\"rgb(206, 67, 71)\"],[0.5862068965517241,\"rgb(216, 76, 62)\"],[0.6206896551724138,\"rgb(226, 87, 52)\"],[0.6551724137931034,\"rgb(235, 100, 41)\"],[0.6896551724137931,\"rgb(241, 115, 29)\"],[0.7241379310344828,\"rgb(247, 130, 18)\"],[0.7586206896551724,\"rgb(250, 144, 8)\"],[0.7931034482758621,\"rgb(252, 161, 8)\"],[0.8275862068965517,\"rgb(252, 178, 22)\"],[0.8620689655172413,\"rgb(250, 196, 42)\"],[0.896551724137931,\"rgb(246, 213, 67)\"],[0.9310344827586207,\"rgb(243, 229, 93)\"],[0.9655172413793104,\"rgb(242, 244, 130)\"],[1.0,\"rgb(252, 255, 164)\"]],\"showlegend\":false,\"name\":\"y1\",\"type\":\"heatmap\",\"xaxis\":\"x\",\"z\":[[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.045454547,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.13636364,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.045454547,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.045454547,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.045454547,0.0,0.33333334,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.22727273,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.13636364,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.09090909,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.13636364,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.09090909,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.16666667,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]],\"x\":[1,2,3,4,5,6,7,8,9,10,11]}],\n",
       "               {\"yaxis\":{\"type\":\"-\",\"titlefont\":{\"size\":15,\"color\":\"rgba(0, 0, 0, 1.000)\",\"family\":\"Helvetica\"},\"title\":\"\",\"tickfont\":{\"size\":11,\"color\":\"rgba(0, 0, 0, 1.000)\",\"family\":\"Helvetica\"},\"tickmode\":\"array\",\"showgrid\":true,\"tickvals\":[10.0,20.0,30.0],\"domain\":[0.057305336832895896,0.9901574803149605],\"ticktext\":[\"10\",\"20\",\"30\"],\"zeroline\":false,\"linecolor\":\"rgba(0, 0, 0, 1.000)\",\"tickcolor\":\"rgba(0, 0, 0, 1.000)\",\"anchor\":\"x\"},\"annotations\":[],\"width\":600,\"plot_bgcolor\":\"rgba(255, 255, 255, 1.000)\",\"showlegend\":true,\"legend\":{\"bgcolor\":\"rgba(255, 255, 255, 1.000)\",\"font\":{\"size\":11,\"color\":\"rgba(0, 0, 0, 1.000)\",\"family\":\"Helvetica\"},\"bordercolor\":\"rgba(0, 0, 0, 1.000)\"},\"xaxis\":{\"type\":\"-\",\"titlefont\":{\"size\":15,\"color\":\"rgba(0, 0, 0, 1.000)\",\"family\":\"Helvetica\"},\"title\":\"\",\"tickfont\":{\"size\":11,\"color\":\"rgba(0, 0, 0, 1.000)\",\"family\":\"Helvetica\"},\"tickmode\":\"array\",\"showgrid\":true,\"tickvals\":[2.0,4.0,6.0,8.0,10.0],\"domain\":[0.05905511811023622,0.9934383202099738],\"ticktext\":[\"2\",\"4\",\"6\",\"8\",\"10\"],\"zeroline\":false,\"linecolor\":\"rgba(0, 0, 0, 1.000)\",\"tickcolor\":\"rgba(0, 0, 0, 1.000)\",\"anchor\":\"y\"},\"paper_bgcolor\":\"rgba(255, 255, 255, 1.000)\",\"margin\":{\"r\":0,\"l\":0,\"b\":0,\"t\":20},\"height\":400}, {showLink: false});\n",
       "\n",
       " </script>\n",
       "\n",
       "</body>\n",
       "</html>\n"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maps[(\"dark\", 'a')] |> heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30×3 Array{Float32,2}:\n",
       " 0.0   0.0  0.0\n",
       " 0.0   0.0  0.0\n",
       " 0.0   0.0  0.0\n",
       " 0.0   0.0  0.0\n",
       " 0.0   0.0  0.0\n",
       " 0.0   0.0  0.0\n",
       " 0.0   0.0  0.0\n",
       " 0.0   0.0  0.0\n",
       " 0.0   0.0  0.0\n",
       " 0.0   0.0  0.0\n",
       " 0.0   0.0  0.0\n",
       " 0.5   0.0  0.0\n",
       " 0.0   0.0  0.0\n",
       " 0.0   0.0  0.0\n",
       " 0.0   0.0  0.0\n",
       " 0.0   0.0  0.0\n",
       " 0.0   0.0  0.0\n",
       " 0.0   0.0  0.0\n",
       " 0.0   0.0  0.0\n",
       " 0.0   0.0  0.0\n",
       " 0.0   0.0  0.0\n",
       " 0.25  0.0  0.0\n",
       " 0.0   0.0  0.0\n",
       " 0.0   0.0  0.0\n",
       " 0.0   0.0  0.0\n",
       " 0.0   0.0  0.0\n",
       " 0.0   0.0  0.0\n",
       " 0.0   0.0  0.0\n",
       " 0.0   0.0  0.0\n",
       " 0.25  0.0  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freq = [4,0,0]\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "LoadError: AssertionError: (distinctly , r) not sum to one, Float32[0.25 0.0 0.0]\nwhile loading In[261], in expression starting on line 1",
     "output_type": "error",
     "traceback": [
      "LoadError: AssertionError: (distinctly , r) not sum to one, Float32[0.25 0.0 0.0]\nwhile loading In[261], in expression starting on line 1",
      "",
      " in macro expansion; at ./In[261]:10 [inlined]",
      " in anonymous at ./<missing>:?",
      " in include_string(::String, ::String) at ./loading.jl:380",
      " in execute_request_0x535c5df2(::ZMQ.Socket, ::IJulia.Msg) at /home/ubuntu/.julia/v0.5/IJulia/src/execute_request.jl:183",
      " in eventloop(::ZMQ.Socket) at /home/ubuntu/.julia/v0.5/IJulia/src/IJulia.jl:143",
      " in (::IJulia.##26#32)() at ./task.jl:309"
     ]
    }
   ],
   "source": [
    "for ((word,pos), freq) in freqs\n",
    "\n",
    "    mm = maps[(word,pos)]\n",
    "    if word==\"distinctly\"\n",
    "        display(mm)\n",
    "        @show freq\n",
    "    end\n",
    "    mm ./= freq'\n",
    "    mm[isnan.(mm)] = 0f0 #NaNs are just frequency 0 items\n",
    "    @assert(all(isapprox.(sum(mm, 1), 1f0; atol=1f-5) | isapprox.(sum(mm, 1), 0f0; atol=1f-5)), \"($word , $pos) not sum to one, $(sum(mm,1))\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×3 Array{Float64,2}:\n",
       " 0.00390626  0.0  0.0"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm=[0.0          0.0  0.0\n",
    " 0.0          0.0  0.0\n",
    " 0.0          0.0  0.0\n",
    " 0.0          0.0  0.0\n",
    " 0.0          0.0  0.0\n",
    " 0.0          0.0  0.0\n",
    " 0.0          0.0  0.0\n",
    " 0.0          0.0  0.0\n",
    " 0.0          0.0  0.0\n",
    " 0.0          0.0  0.0\n",
    " 0.0          0.0  0.0\n",
    " 0.00195313   0.0  0.0\n",
    " 0.0          0.0  0.0\n",
    " 0.0          0.0  0.0\n",
    " 0.0          0.0  0.0\n",
    " 0.0          0.0  0.0\n",
    " 0.0          0.0  0.0\n",
    " 0.0          0.0  0.0\n",
    " 0.0          0.0  0.0\n",
    " 0.0          0.0  0.0\n",
    " 0.0          0.0  0.0\n",
    " 0.000976563  0.0  0.0\n",
    " 0.0          0.0  0.0\n",
    " 0.0          0.0  0.0\n",
    " 0.0          0.0  0.0\n",
    " 0.0          0.0  0.0\n",
    " 0.0          0.0  0.0\n",
    " 0.0          0.0  0.0\n",
    " 0.0          0.0  0.0\n",
    "0.000976563  0.0  0.0]\n",
    "\n",
    "f=[4, 0, 0]\n",
    "#mm ./=f'\n",
    "#mm[isnan(mm)] = 0f0\n",
    "\n",
    "sum(mm,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{WordNet.Synset,1}:\n",
       " (n) fancy woman, kept woman, mistress (an adulterous woman; a woman who has an ongoing extramarital sexual relationship with a man)\n",
       " (n) schoolmarm, schoolmistress, mistress, schoolma'am (a woman schoolteacher (especially one regarded as strict))                  \n",
       " (n) mistress (a woman master who directs the work of others)                                                                       "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdynsets(db, db[\"mistress\",'n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f=freqs[(\"mistress\",'n')]\n",
    "m=maps[(\"mistress\",'n')];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×3 Array{Float32,2}:\n",
       " 0.333333  NaN  NaN"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((m.*f')./f', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Int64,1}:\n",
       " 3\n",
       " 0\n",
       " 0"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30×3 Array{Float32,2}:\n",
       " 0.00652636  0.0  0.0\n",
       " 0.0113097   0.0  0.0\n",
       " 0.00587937  0.0  0.0\n",
       " 0.00850576  0.0  0.0\n",
       " 0.00693034  0.0  0.0\n",
       " 0.00718986  0.0  0.0\n",
       " 0.00740473  0.0  0.0\n",
       " 0.00760459  0.0  0.0\n",
       " 0.00806295  0.0  0.0\n",
       " 0.0125396   0.0  0.0\n",
       " 0.0125999   0.0  0.0\n",
       " 0.0125813   0.0  0.0\n",
       " 0.0125818   0.0  0.0\n",
       " 0.0125811   0.0  0.0\n",
       " 0.0125876   0.0  0.0\n",
       " 0.0126029   0.0  0.0\n",
       " 0.0125542   0.0  0.0\n",
       " 0.0125799   0.0  0.0\n",
       " 0.0126165   0.0  0.0\n",
       " 0.0125908   0.0  0.0\n",
       " 0.0125243   0.0  0.0\n",
       " 0.0125602   0.0  0.0\n",
       " 0.012558    0.0  0.0\n",
       " 0.0125552   0.0  0.0\n",
       " 0.0125249   0.0  0.0\n",
       " 0.0125527   0.0  0.0\n",
       " 0.01256     0.0  0.0\n",
       " 0.0125958   0.0  0.0\n",
       " 0.0125347   0.0  0.0\n",
       " 0.0125383   0.0  0.0"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30×3 Array{Float32,2}:\n",
       " 0.00652636  0.0  0.0\n",
       " 0.0113097   0.0  0.0\n",
       " 0.00587937  0.0  0.0\n",
       " 0.00850576  0.0  0.0\n",
       " 0.00693034  0.0  0.0\n",
       " 0.00718986  0.0  0.0\n",
       " 0.00740473  0.0  0.0\n",
       " 0.00760459  0.0  0.0\n",
       " 0.00806295  0.0  0.0\n",
       " 0.0125396   0.0  0.0\n",
       " 0.0125999   0.0  0.0\n",
       " 0.0125813   0.0  0.0\n",
       " 0.0125818   0.0  0.0\n",
       " 0.0125811   0.0  0.0\n",
       " 0.0125876   0.0  0.0\n",
       " 0.0126029   0.0  0.0\n",
       " 0.0125542   0.0  0.0\n",
       " 0.0125799   0.0  0.0\n",
       " 0.0126165   0.0  0.0\n",
       " 0.0125908   0.0  0.0\n",
       " 0.0125243   0.0  0.0\n",
       " 0.0125602   0.0  0.0\n",
       " 0.012558    0.0  0.0\n",
       " 0.0125552   0.0  0.0\n",
       " 0.0125249   0.0  0.0\n",
       " 0.0125527   0.0  0.0\n",
       " 0.01256     0.0  0.0\n",
       " 0.0125958   0.0  0.0\n",
       " 0.0125347   0.0  0.0\n",
       " 0.0125383   0.0  0.0"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: AssertionError: (mistress , n) not sum to one, Float32[0.333333 0.0 0.0]\nwhile loading In[158], in expression starting on line 1",
     "output_type": "error",
     "traceback": [
      "LoadError: AssertionError: (mistress , n) not sum to one, Float32[0.333333 0.0 0.0]\nwhile loading In[158], in expression starting on line 1",
      "",
      " in macro expansion; at ./In[158]:6 [inlined]",
      " in anonymous at ./<missing>:?",
      " in include_string(::String, ::String) at ./loading.jl:380",
      " in execute_request_0x535c5df2(::ZMQ.Socket, ::IJulia.Msg) at /home/ubuntu/.julia/v0.5/IJulia/src/execute_request.jl:183",
      " in eventloop(::ZMQ.Socket) at /home/ubuntu/.julia/v0.5/IJulia/src/IJulia.jl:143",
      " in (::IJulia.##26#32)() at ./task.jl:309"
     ]
    }
   ],
   "source": [
    "for ((word,pos), freq) in freqs\n",
    "    mm = maps[(word,pos)]\n",
    "    mm ./= freq'\n",
    "    mm[isnan.(mm)] = 0f0 #NaNs are just frequency 0 items\n",
    "\n",
    "    @assert(all(isapprox.(sum(mm, 1), 1f0; atol=1f-5) | isapprox.(sum(mm, 1), 0f0; atol=1f-5)), \"($word , $pos) not sum to one, $(sum(mm,1))\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m = Float32[0.0150112 0.0147748 0.0171722; 0.0159644 0.014621 0.0122244; 0.00841263 0.00262739 0.00442265; 0.0185166 0.0221436 0.0104815; 0.0155252 0.0116558 0.0130272; 0.0200327 0.0206719 0.0270401; 0.0183518 0.0147128 0.0137959; 0.0212607 0.0206148 0.0108512; 0.0198786 0.0334265 0.0163113; 0.0196717 0.0180344 0.0197542; 0.0175429 0.0200894 0.0147291; 0.00896113 0.00171742 0.00859674; 0.0205545 0.0221308 0.021097; 0.0198728 0.0162866 0.0175935; 0.0181413 0.0173828 0.0139159; 0.0149031 0.0108267 0.0123045; 0.019012 0.0140359 0.0107693; 0.0540428 0.0554914 0.0573607; 0.0544689 0.0556893 0.0582956; 0.0545567 0.0557555 0.058339; 0.054545 0.0556979 0.0581404; 0.0545304 0.0556947 0.0584079; 0.0545265 0.0557521 0.0580926; 0.0546027 0.0557701 0.0580193; 0.0545625 0.055723 0.0581764; 0.0544826 0.0557654 0.0581798; 0.0544326 0.055626 0.058163; 0.0545346 0.0557326 0.0581324; 0.0545564 0.0558114 0.0581876; 0.0545451 0.055738 0.0584186]\n",
      "f = [57,12,1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3-element Array{Int64,1}:\n",
       " 57\n",
       " 12\n",
       "  1"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = maps[\"city\",'n']\n",
    "f = freqs[\"city\",'n']\n",
    "@show m\n",
    "@show f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×3 Array{BigFloat,2}:\n",
       " 9.999999674037098884582519531250000000000000000000000000000000000000000000000000e-01  9.999999908031895756721496582031250000000000000000000000000000000000000000000000e-01  9.999999967403709888458251953125000000000000000000000000000000000000000000000000e-01"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(BigFloat.(m),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = [1.0 2 3 0 ; 11 22 33 0 ; 111 222 333 0; 1111 2222 3333 0; 11111 22222 33333 5]\n",
    "b = [5, -5, 1, 0]\n",
    "\n",
    "@show a./b'\n",
    "\n",
    "a./=b'\n",
    "a[isnan(a)]=0.0\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = copy(m)\n",
    "@show n\n",
    "@show f\n",
    "n./=f'\n",
    "n[isnan.(n)]=0.0\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "isnan.([NaN 1; Inf 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ww = CorpusLoaders.Semcor.SenseAnnotatedWord{SubString{String}}(\"NN\",\"funds\",1,\"1:21:00::\",\"funds\")\n",
    "sensekey(ww)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@show ww.pos \n",
    "ww.lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "methods(sensekey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.0-rc0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
