{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Base.writemime is deprecated.\n",
      "  likely near /home/ubuntu/.julia/v0.5/IJulia/src/kernel.jl:31\n",
      "WARNING: Base.writemime is deprecated.\n",
      "  likely near /home/ubuntu/.julia/v0.5/IJulia/src/kernel.jl:31\n",
      "WARNING: Base.writemime is deprecated.\n",
      "  likely near /home/ubuntu/.julia/v0.5/IJulia/src/kernel.jl:31\n",
      "WARNING: Base.writemime is deprecated.\n",
      "  likely near /home/ubuntu/.julia/v0.5/IJulia/src/kernel.jl:31\n",
      "INFO: Recompiling stale cache file /home/ubuntu/.julia/lib/v0.5/DataStructures.ji for module DataStructures.\n",
      "WARNING: could not import Base.complement into DataStructures\n",
      "WARNING: could not import Base.complement! into DataStructures\n",
      "INFO: Recompiling stale cache file /home/ubuntu/.julia/lib/v0.5/StatsFuns.ji for module StatsFuns.\n",
      "INFO: Recompiling stale cache file /home/ubuntu/.julia/lib/v0.5/Distances.ji for module Distances.\n",
      "INFO: Recompiling stale cache file /home/ubuntu/.julia/lib/v0.5/NearestNeighbors.ji for module NearestNeighbors.\n",
      "INFO: Recompiling stale cache file /home/ubuntu/.julia/lib/v0.5/Devectorize.ji for module Devectorize.\n",
      "WARNING: Base.ASCIIString is deprecated, use String instead.\n",
      "  likely near /home/ubuntu/.julia/v0.5/Devectorize/src/texpr.jl:293\n",
      "WARNING: Base.ASCIIString is deprecated, use String instead.\n",
      "  likely near /home/ubuntu/.julia/v0.5/Devectorize/src/texpr.jl:293\n",
      "WARNING: Base.ASCIIString is deprecated, use String instead.\n",
      "  likely near /home/ubuntu/.julia/v0.5/NearestNeighbors/src/knn.jl:1\n",
      "WARNING: Base.ASCIIString is deprecated, use String instead.\n",
      "  likely near /home/ubuntu/.julia/v0.5/NearestNeighbors/src/knn.jl:1\n",
      "WARNING: Base.ASCIIString is deprecated, use String instead.\n",
      "  likely near /home/ubuntu/.julia/v0.5/NearestNeighbors/src/knn.jl:1\n",
      "INFO: Recompiling stale cache file /home/ubuntu/.julia/lib/v0.5/Iterators.ji for module Iterators.\n"
     ]
    }
   ],
   "source": [
    "using WordNet\n",
    "using WordEmbeddings, SoftmaxClassifier\n",
    "using Utils\n",
    "using Query\n",
    "using Distances\n",
    "using Iterators\n",
    "using LightXML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: redefining constant WN_PATH\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WordNet.DB"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Base.writemime is deprecated.\n",
      "  likely near /home/ubuntu/.julia/v0.5/IJulia/src/kernel.jl:31\n",
      "WARNING: Base.writemime is deprecated.\n",
      "  likely near /home/ubuntu/.julia/v0.5/IJulia/src/kernel.jl:31\n",
      "WARNING: Base.writemime is deprecated.\n",
      "  likely near /home/ubuntu/.julia/v0.5/IJulia/src/kernel.jl:31\n",
      "WARNING: Base.writemime is deprecated.\n",
      "  likely near /home/ubuntu/.julia/v0.5/IJulia/src/kernel.jl:31\n",
      "WARNING: Base.writemime is deprecated.\n",
      "  likely near /home/ubuntu/.julia/v0.5/IJulia/src/kernel.jl:31\n",
      "in display_dict at /home/ubuntu/.julia/v0.5/IJulia/src/execute_request.jl\n"
     ]
    }
   ],
   "source": [
    "const WN_PATH=\"data/corpora/WordNet-2.1/\"\n",
    "db = DB(WN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: utf8(s::AbstractString) is deprecated, use String(s) instead.\n",
      " in depwarn(::String, ::Symbol) at ./deprecated.jl:64\n",
      " in utf8(::SubString{String}) at ./deprecated.jl:50\n",
      " in _collect(::Array{SubString{String},1}, ::Base.Generator{Array{SubString{String},1},Base.#utf8}, ::Base.EltypeUnknown, ::Base.HasShape) at ./array.jl:283\n",
      " in #error_content#12(::Symbol, ::String, ::Function, ::LoadError, ::Array{Ptr{Void},1}) at /home/ubuntu/.julia/v0.5/IJulia/src/execute_request.jl:75\n",
      " in execute_request_0x535c5df2(::ZMQ.Socket, ::IJulia.Msg) at /home/ubuntu/.julia/v0.5/IJulia/src/execute_request.jl:238\n",
      " in eventloop(::ZMQ.Socket) at /home/ubuntu/.julia/v0.5/IJulia/src/IJulia.jl:143\n",
      " in (::IJulia.##24#30)() at ./task.jl:309\n",
      "while loading /home/ubuntu/.julia/v0.5/IJulia/src/kernel.jl, in expression starting on line 31\n",
      "WARNING: utf8(s::AbstractString) is deprecated, use String(s) instead.\n",
      " in depwarn(::String, ::Symbol) at ./deprecated.jl:64\n",
      " in utf8(::SubString{String}) at ./deprecated.jl:50\n",
      " in collect_to!(::Array{String,1}, ::Base.Generator{Array{SubString{String},1},Base.#utf8}, ::Int64, ::Int64) at ./array.jl:302\n",
      " in _collect(::Array{SubString{String},1}, ::Base.Generator{Array{SubString{String},1},Base.#utf8}, ::Base.EltypeUnknown, ::Base.HasShape) at ./array.jl:284\n",
      " in #error_content#12(::Symbol, ::String, ::Function, ::LoadError, ::Array{Ptr{Void},1}) at /home/ubuntu/.julia/v0.5/IJulia/src/execute_request.jl:75\n",
      " in execute_request_0x535c5df2(::ZMQ.Socket, ::IJulia.Msg) at /home/ubuntu/.julia/v0.5/IJulia/src/execute_request.jl:238\n",
      " in eventloop(::ZMQ.Socket) at /home/ubuntu/.julia/v0.5/IJulia/src/IJulia.jl:143\n",
      " in (::IJulia.##24#30)() at ./task.jl:309\n",
      "while loading /home/ubuntu/.julia/v0.5/IJulia/src/kernel.jl, in expression starting on line 31\n"
     ]
    }
   ],
   "source": [
    "#ee = restore(\"models/ss/tokenised_lowercase_WestburyLab.wikicorp.201004_100_i1.model\");\n",
    "ee = restore(\"models/ss/keep/tokenised_lowercase_WestburyLab.wikicorp.201004_50__m170000000.model\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition normal_probs(Array{T<:Any, 1}) in module Main at In[164]:2 overwritten at In[168]:2.\n",
      "WARNING: Method definition weighted_average(Any, Any) in module Main at In[164]:11 overwritten at In[168]:11.\n",
      "WARNING: Method definition synthesize_embedding(Any, Any, Any) in module Main at In[164]:20 overwritten at In[168]:20.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "synthesize_embedding (generic function with 1 method)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "punctuation_space_tokenize (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function poormans_tokenize(source)\n",
    "    cleaned = filter(s->!ispunct(s), lowercase(source))\n",
    "    map(string,  split(cleaned))::Vector{SubString{String}}\n",
    "end\n",
    "\n",
    "function punctuation_space_tokenize(source)\n",
    "    preprocced = lowercase(source)\n",
    "    pass1=replace(preprocced,r\"[[:punct:]]*[[:space:]][[:punct:]]*\",\" \")\n",
    "    pass2=replace(pass1,r\"[[:punct:]]*$|^[[:punct:]]*\",\"\")\n",
    "    split(pass2)\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sense_keys (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function load_sense_key_map(wn_basedir)\n",
    "    path=joinpath(wn_basedir, \"dict\",\"index.sense\")\n",
    "    sense_key_map = Dict{Tuple{Int64,String},String}()\n",
    "    for line in eachline(path)\n",
    "        full_sense_key, offset_str, sense_num_str, tagcount_str = split(line) \n",
    "        lemma_name = first(split(full_sense_key,'%'))\n",
    "        sense_offset = parse(Int64, offset_str)\n",
    "        index = (sense_offset,lemma_name)\n",
    "        @assert(!haskey(sense_key_map, index))\n",
    "        sense_key_map[index] = full_sense_key\n",
    "    end\n",
    "    sense_key_map\n",
    "end\n",
    "\n",
    "\n",
    "function sense_key(lem::Lemma, ss::Synset,sense_key_map)\n",
    "    sense_key_map[(ss.offset,lem.word)]\n",
    "end\n",
    "function sense_keys(lem::Lemma,sense_key_map)\n",
    "    [sense_key_map[(ss_offset,lem.word)] for ss_offset in lem.synset_offsets ]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sense_key_map = load_sense_key_map(WN_PATH);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{String,1}:\n",
       " \"six%5:00:00:cardinal:00\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sense_keys(db['a',\"six\"],sense_key_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"discover%2:39:03::\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Base.writemime is deprecated.\n",
      "  likely near /home/ubuntu/.julia/v0.5/IJulia/src/kernel.jl:31\n",
      "WARNING: Base.writemime is deprecated.\n",
      "  likely near /home/ubuntu/.julia/v0.5/IJulia/src/kernel.jl:31\n",
      "WARNING: Base.writemime is deprecated.\n",
      "  likely near /home/ubuntu/.julia/v0.5/IJulia/src/kernel.jl:31\n",
      "WARNING: Base.writemime is deprecated.\n",
      "  likely near /home/ubuntu/.julia/v0.5/IJulia/src/kernel.jl:31\n",
      "WARNING: Base.writemime is deprecated.\n",
      "  likely near /home/ubuntu/.julia/v0.5/IJulia/src/kernel.jl:31\n",
      "in display_dict at /home/ubuntu/.julia/v0.5/IJulia/src/execute_request.jl\n"
     ]
    }
   ],
   "source": [
    "sense_key_map[2134693,\"discover\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "immutable WsdChallenge\n",
    "    id::String\n",
    "    word::String\n",
    "    lemma::String\n",
    "    pos::Char\n",
    "    context::Vector{String}\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition (::Type{Main.WsdChallenge})(String, String, String, Char, Array{String, 1}) in module Main at In[14]:2 overwritten at In[17]:2.\n",
      "WARNING: Method definition (::Type{Main.WsdChallenge})(Any, Any, Any, Any, Any) in module Main at In[14]:2 overwritten at In[17]:2.\n",
      "WARNING: Method definition load_challenges() in module Main at In[14]:10 overwritten at In[17]:10.\n",
      "WARNING: Method definition load_challenges(Any) in module Main at In[14]:10 overwritten at In[17]:10.\n",
      "WARNING: bytestring(p::Union{Ptr{Int8},Ptr{UInt8}}) is deprecated, use unsafe_string(p) instead.\n",
      " in depwarn(::String, ::Symbol) at ./deprecated.jl:64\n",
      " in bytestring(::Ptr{UInt8}) at ./deprecated.jl:50\n",
      " in _xcopystr at /home/ubuntu/.julia/v0.5/LightXML/src/LightXML.jl:39 [inlined]\n",
      " in content(::LightXML.XMLNode) at /home/ubuntu/.julia/v0.5/LightXML/src/nodes.jl:171\n",
      " in (::##15#17{LightXML.XMLElement})() at ./In[17]:18\n",
      "while loading In[17], in expression starting on line 32\n",
      "WARNING: bytestring(p::Union{Ptr{Int8},Ptr{UInt8}}) is deprecated, use unsafe_string(p) instead.\n",
      " in depwarn(::String, ::Symbol) at ./deprecated.jl:64\n",
      " in bytestring(::Ptr{UInt8}) at ./deprecated.jl:50\n",
      " in _xcopystr at /home/ubuntu/.julia/v0.5/LightXML/src/LightXML.jl:39 [inlined]\n",
      " in #attribute#1(::Bool, ::Function, ::LightXML.XMLElement, ::String) at /home/ubuntu/.julia/v0.5/LightXML/src/nodes.jl:226\n",
      " in (::##15#17{LightXML.XMLElement})() at ./In[17]:22\n",
      "while loading In[17], in expression starting on line 32\n"
     ]
    }
   ],
   "source": [
    "function load_challenges_semeval2007(xml_file=\"data/corpora/wsd/semeval2007_t7/test/eng-coarse-all-words.xml\")\n",
    "    xdoc = parse_file(xml_file)\n",
    "    xroot = root(xdoc)\n",
    "    Task() do\n",
    "        for text_node in child_elements(xroot)\n",
    "            #@show text_node\n",
    "            #text = child_nodes(text_node) |> collect\n",
    "            #println(text)\n",
    "            for sentence_node in child_elements(text_node)\n",
    "                sentence = punctuation_space_tokenize(content(sentence_node))\n",
    "\n",
    "                for lemma_node in child_elements(sentence_node)\n",
    "                    word = content(lemma_node) |> lowercase\n",
    "                    lemma = attribute(lemma_node,\"lemma\")|> lowercase\n",
    "                    pos = first(attribute(lemma_node,\"pos\"))\n",
    "                    id = attribute(lemma_node,\"id\")\n",
    "                    context = filter(w->w!=word, sentence)\n",
    "                    produce(WsdChallenge(id, word, lemma, pos, context))\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end\n",
    "challenges = load_challenges_semeval2007() |> collect;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition (::Type{Main.WsdSolution})(Any, Any, Any, Any) in module Main at In[18]:2 overwritten at In[132]:2.\n",
      "WARNING: Method definition only_of_pos(Any, Any) in module Main at In[18]:7 overwritten at In[132]:7.\n",
      "WARNING: Method definition load_solutions() in module Main at In[18]:10 overwritten at In[132]:10.\n",
      "WARNING: Method definition load_solutions(Any) in module Main at In[18]:10 overwritten at In[132]:10.\n"
     ]
    }
   ],
   "source": [
    "immutable WsdSolution\n",
    "    id\n",
    "    lemma\n",
    "    pos\n",
    "    solutions\n",
    "end\n",
    "only_of_pos(data, pos) = filter(d->d.pos==pos, data)\n",
    "\n",
    "function load_solutions(key_file=\"data/corpora/wsd/semeval2007_t7/key/dataset21.test.key\")\n",
    "    map(eachline(key_file)) do line\n",
    "        line_data, comment = split(line,\"!!\")\n",
    "        fields = split(line_data)\n",
    "        doc_id = fields[1]\n",
    "        instance_id = fields[2]\n",
    "        solutions = fields[3:end]\n",
    "        \n",
    "        lemma,pos = match(r\"lemma=(.*)#(.)\", comment).captures\n",
    "        WsdSolution(instance_id, lemma, pos[1], solutions)\n",
    "    end\n",
    "end\n",
    "\n",
    "solutions = load_solutions();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: KeyError: key \"in addition\" not found\nwhile loading In[143], in expression starting on line 3",
     "output_type": "error",
     "traceback": [
      "LoadError: KeyError: key \"in addition\" not found\nwhile loading In[143], in expression starting on line 3",
      "",
      " in getindex at ./dict.jl:701 [inlined]",
      " in lexically_informed_embeddings(::WordNet.DB, ::WordEmbeddings.FixedWordSenseEmbedding, ::String, ::String, ::Char) at ./In[138]:4",
      " in include_string(::String, ::String) at ./loading.jl:380",
      " in eventloop(::ZMQ.Socket) at /home/ubuntu/.julia/v0.5/IJulia/src/IJulia.jl:143",
      " in (::IJulia.##24#30)() at ./task.jl:309"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sense_frequency (generic function with 1 method)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function sense_frequency(ss::Synset, lem::Lemma)\n",
    "    lem_count = lem.tagsense_count\n",
    "    lem_count+0.1(sum(values(ss.word_counts))-lem_count)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition normal_probs(Array{T<:Any, 1}) in module Main at In[178]:2 overwritten at In[179]:2.\n",
      "WARNING: Method definition weighted_average(Any, Any) in module Main at In[178]:11 overwritten at In[179]:11.\n",
      "WARNING: Method definition synthesize_embedding(Any, Any, Any) in module Main at In[178]:20 overwritten at In[179]:20.\n",
      "WARNING: Method definition all_identical(Any) in module Main at In[178]:30 overwritten at In[179]:30.\n",
      "WARNING: Method definition lexically_informed_embeddings(Any, Any, Any, Any) in module Main at In[178]:32 overwritten at In[179]:32.\n",
      "WARNING: Method definition lexically_informed_embeddings(Any, Any, Any, Any, Any) in module Main at In[178]:35 overwritten at In[179]:35.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "lexically_informed_embeddings (generic function with 2 methods)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function normal_probs(logprobs::Vector)\n",
    "    ret = copy(logprobs)\n",
    "    max_lp = maximum(logprobs)\n",
    "    ret.-=max_lp #Bring closer to zero\n",
    "    map!(exp,ret)\n",
    "    denom = sum(ret)\n",
    "    ret./=denom\n",
    "    ret\n",
    "end\n",
    "function weighted_average(logprobs, embeddings)\n",
    "    ret = zeros(first(embeddings))\n",
    "    for (weight, embedding) in zip(normal_probs(logprobs), embeddings)\n",
    "        ret.+= weight.*embedding\n",
    "    end\n",
    "    ret\n",
    "end\n",
    "\n",
    "\n",
    "function synthesize_embedding(ee,context, phrase)\n",
    "    words = split(phrase,\" \")\n",
    "    wvs = vcat((get(ee.embedding,w,Vector{Float32}[]) for w in words)...)\n",
    "    if length(wvs) == 0\n",
    "            throw(KeyError(\"None of $words have embeddings\"))\n",
    "    end\n",
    "    logprobs = [Query.logprob_of_context(ee, context,wv; skip_oov=true, normalise_over_length=true) for wv in wvs]\n",
    "    weighted_average(logprobs, wvs)\n",
    "end\n",
    "\n",
    "\n",
    "all_identical(col) = length(col)==1 || !any(x->x!=col[1],col[2:end])\n",
    "\n",
    "lexically_informed_embeddings(db,ee, lemma_word, pos) = lexically_informed_embeddings(db,ee, lemma_word, lemma_word, pos)\n",
    "function lexically_informed_embeddings(db,ee, word,lemma_word, pos)\n",
    "    \n",
    "    lemma = db[pos, lemma_word]\n",
    "    target_synsets::Vector{Synset} = synsets(db, lemma)\n",
    "         \n",
    "    embeddings = Vector{Vector{Float32}}(length(target_synsets))\n",
    "    for (ii,synset) in enumerate(target_synsets)\n",
    "        context::Vector{SubString{String}} = collect(filter!(w->w!=word, punctuation_space_tokenize(synset.gloss)))\n",
    "        embeddings[ii] = synthesize_embedding(ee,context, word)\n",
    "    end\n",
    "        \n",
    "    \n",
    "    if all_identical(embeddings)\n",
    "        #Use MCWS\n",
    "        score, index = findmax(sense_frequency(ss,lemma) for ss in target_synsets)\n",
    "        target_synsets=[target_synsets[index]] # Throw out others\n",
    "        embeddings=[embeddings[1]]\n",
    "    end\n",
    "        \n",
    "    embeddings,target_synsets,lemma\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array{Float32,1}[Float32[-0.0835615,0.0436134,0.0357565,-0.195218,-0.0150616,0.0623249,0.000887029,0.0132962,-0.0190318,-0.0587051,-0.191609,0.0257554,0.0670426,-0.00430257,-0.0481629,0.0370439,0.0283803,-0.0854695,-0.0418194,0.0370742,0.105485,-0.0919684,0.0572593,0.0477335,0.0413913,-0.018515,0.0389618,0.318222,-0.0848608,-0.0312266,0.0250157,0.037267,0.0501295,0.0405783,0.0541011,-0.160077,0.082792,0.154932,-0.151211,0.0877451,-0.13094,-0.0204533,-0.0477487,0.00436434,0.040013,0.0844666,0.00706025,0.0455183,0.122014,-0.102058]],WordNet.Synset[(r) in addition, additionally, to boot (by way of addition; furthermore; \"he serves additionally as the CEO\")],in_addition.r)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mw_challenges = [c for c in challenges if contains(c.lemma,\"_\")]\n",
    "challenge = mw_challenges[1]\n",
    "lexically_informed_embeddings(db,ee, challenge.word, challenge.lemma, challenge.pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition supervised_wsd(Main.WsdChallenge, WordEmbeddings.WordSenseEmbedding, WordNet.DB, Any) in module Main at In[175]:2 overwritten at In[181]:2.\n",
      "WARNING: Method definition most_frequent_sense(Any, WordNet.DB, Any) in module Main at In[175]:23 overwritten at In[181]:23.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "most_frequent_sense (generic function with 3 methods)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function supervised_wsd(challenge::WsdChallenge, ee::WordSenseEmbedding, wn::DB, sense_key_map)\n",
    "    try\n",
    "        embeddings,target_synsets,lemma = lexically_informed_embeddings(wn,ee,\n",
    "                                                            challenge.word, \n",
    "                                                            challenge.lemma, challenge.pos)\n",
    "        #sense_index = Query.WSD(ee, embeddings, challenge.context; skip_oov=true)\n",
    "        logprobs_of_context = [logprob_of_context(ee,challenge.context, wv; skip_oov=true, normalise_over_length=true) \n",
    "                                    for wv in embeddings] \n",
    "      \n",
    "        sense_index= indmax(logprobs_of_context)\n",
    "\n",
    "        \n",
    "        synset = target_synsets[sense_index]\n",
    "        sk = sense_key(lemma, synset, sense_key_map)\n",
    "        Nullable(sk)\n",
    "    catch ex\n",
    "        isa(ex, KeyError) || rethrow(ex)\n",
    "        Nullable{String}()\n",
    "    end\n",
    "end\n",
    "\n",
    "function most_frequent_sense(challenge, wn::DB, sense_key_map)\n",
    "    try\n",
    "        lemma = wn[challenge.pos, challenge.lemma]\n",
    "        target_synsets::Vector{Synset} = synsets(db, lemma)\n",
    "        \n",
    "        sense_freqs =  Float32[sense_frequency(ss,lemma) for ss in target_synsets]      \n",
    "        sense_index= indmax(sense_freqs)\n",
    "        synset = target_synsets[sense_index]\n",
    "        \n",
    "        sk = sense_key(lemma, synset, sense_key_map)\n",
    "        Nullable(sk)\n",
    "    catch ex\n",
    "        isa(ex, KeyError) || rethrow(ex)\n",
    "        Nullable{String}()\n",
    "    end\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition evalute_on_wsd_challenge(Any, Any, Any) in module Main at In[176]:2 overwritten at In[182]:2.\n",
      "WARNING: Method definition evalute_on_wsd_challenge(Any, Any, WordEmbeddings.WordSenseEmbedding, WordNet.DB, Any) in module Main at In[176]:26 overwritten at In[182]:26.\n",
      "WARNING: Method definition evalute_on_wsd_challenge_MFS(Any, Any, WordNet.DB, Any) in module Main at In[176]:32 overwritten at In[182]:32.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "evalute_on_wsd_challenge_MFS (generic function with 1 method)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function evalute_on_wsd_challenge(challenges, solutions, method)\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    notattempted = 0\n",
    "    for (challenge, ground_solution) in zip(challenges, solutions)\n",
    "        assert(challenge.id == ground_solution.id)\n",
    "        output_sense = method(challenge)\n",
    "        if isnull(output_sense)\n",
    "            notattempted+=1\n",
    "        else\n",
    "            if get(output_sense) âˆˆ ground_solution.solutions\n",
    "                correct+=1\n",
    "            else\n",
    "                incorrect+=1\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    precision = correct/(correct+incorrect)\n",
    "    recall = correct/(correct+incorrect+notattempted)\n",
    "    f1 = (2*precision*recall) / (precision+recall)\n",
    "    return precision, recall, f1\n",
    "end\n",
    "    \n",
    "    \n",
    "function evalute_on_wsd_challenge(challenges, solutions, ee::WordSenseEmbedding, wn::DB, sense_key_map)\n",
    "    method = challenge -> supervised_wsd(challenge, ee, wn, sense_key_map)\n",
    "    evalute_on_wsd_challenge(challenges, solutions, method)\n",
    "end\n",
    "\n",
    "\n",
    "function evalute_on_wsd_challenge_MFS(challenges, solutions, wn::DB, sense_key_map)\n",
    "    method = challenge -> most_frequent_sense(challenge, wn, sense_key_map)\n",
    "    evalute_on_wsd_challenge(challenges, solutions, method)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall: \t\t(0.6370501999111506,0.6319964742177171,0.6345132743362832)\n",
      "only nouns  : \t\t(0.6554545454545454,0.6507220216606499,0.6530797101449276)\n",
      "only verbs  : \t\t(0.5502555366269165,0.5465313028764806,0.5483870967741935)\n",
      "only adjecti: \t\t(0.7011173184357542,0.6933701657458563,0.6972222222222222)\n",
      "only adverbs: \t\t(0.6747572815533981,0.6682692307692307,0.6714975845410628)\n"
     ]
    }
   ],
   "source": [
    "println(\"overall: \\t\\t\", evalute_on_wsd_challenge(challenges, solutions, ee, db, sense_key_map))\n",
    "\n",
    "println(\"only nouns  : \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'n'), only_of_pos(solutions,'n'), ee, db, sense_key_map))\n",
    "println(\"only verbs  : \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'v'), only_of_pos(solutions,'v'), ee, db, sense_key_map))\n",
    "println(\"only adjecti: \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'a'), only_of_pos(solutions,'a'), ee, db, sense_key_map))\n",
    "println(\"only adverbs: \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'r'), only_of_pos(solutions,'r'), ee, db, sense_key_map))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall: \t\t(0.5932128691053328,0.5932128691053328,0.5932128691053328)\n",
      "only nouns  : \t\t(0.592057761732852,0.592057761732852,0.592057761732852)\n",
      "only verbs  : \t\t(0.48392554991539766,0.48392554991539766,0.48392554991539766)\n",
      "only adjecti: \t\t(0.6823204419889503,0.6823204419889503,0.6823204419889503)\n",
      "only adverbs: \t\t(0.7548076923076923,0.7548076923076923,0.7548076923076922)\n"
     ]
    }
   ],
   "source": [
    "println(\"overall: \\t\\t\", evalute_on_wsd_challenge_MFS(challenges, solutions, db, sense_key_map))\n",
    "\n",
    "println(\"only nouns  : \\t\\t\", evalute_on_wsd_challenge_MFS(only_of_pos(challenges,'n'), only_of_pos(solutions,'n'), db, sense_key_map))\n",
    "println(\"only verbs  : \\t\\t\", evalute_on_wsd_challenge_MFS(only_of_pos(challenges,'v'), only_of_pos(solutions,'v'), db, sense_key_map))\n",
    "println(\"only adjecti: \\t\\t\", evalute_on_wsd_challenge_MFS(only_of_pos(challenges,'a'), only_of_pos(solutions,'a'), db, sense_key_map))\n",
    "println(\"only adverbs: \\t\\t\", evalute_on_wsd_challenge_MFS(only_of_pos(challenges,'r'), only_of_pos(solutions,'r'), db, sense_key_map))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: replacing module Training\n",
      "\n",
      "WARNING: deprecated syntax \"[a=>b for (a,b) in c]\".\n",
      "Use \"Dict(a=>b for (a,b) in c)\" instead.\n"
     ]
    }
   ],
   "source": [
    "#Zero shot WSI for 1 shot WSD\n",
    "using Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rr = FixedWordSenseEmbedding(ee.dimension, random_inited, huffman_tree; initial_nsenses=1)\n",
    "rr.distribution = ee.distribution\n",
    "rr.codebook = ee.codebook\n",
    "rr.classification_tree = ee.classification_tree\n",
    "Training.initialize_embedding(rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rr.initial_nsenses=100\n",
    "Training.initialize_embedding(rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall: \t\t(0.5886272767658818,0.5839576906126047,0.5862831858407079)\n",
      "only nouns  : \t\t(0.5881818181818181,0.5839350180505415,0.586050724637681)\n",
      "only verbs  : \t\t(0.4787052810902896,0.4754653130287648,0.4770797962648557)\n",
      "only adjecti: \t\t(0.6787709497206704,0.6712707182320442,0.675)\n",
      "only adverbs: \t\t(0.7475728155339806,0.7403846153846154,0.7439613526570048)\n"
     ]
    }
   ],
   "source": [
    "println(\"overall: \\t\\t\", evalute_on_wsd_challenge(challenges, solutions, rr, db, sense_key_map))\n",
    "\n",
    "println(\"only nouns  : \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'n'), only_of_pos(solutions,'n'), rr, db, sense_key_map))\n",
    "println(\"only verbs  : \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'v'), only_of_pos(solutions,'v'), rr, db, sense_key_map))\n",
    "println(\"only adjecti: \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'a'), only_of_pos(solutions,'a'), rr, db, sense_key_map))\n",
    "println(\"only adverbs: \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'r'), only_of_pos(solutions,'r'), rr, db, sense_key_map))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hh = deepcopy(rr)\n",
    "for word in keys(rr.embedding)\n",
    "    append!(hh.embedding[word], ee.embedding[word])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall: \t\t(0.6126166148378498,0.6077567210224769,0.6101769911504425)\n",
      "only nouns  : \t\t(0.6263636363636363,0.621841155234657,0.6240942028985507)\n",
      "only verbs  : \t\t(0.5434412265758092,0.5397631133671743,0.5415959252971138)\n",
      "only adjecti: \t\t(0.6731843575418994,0.6657458563535912,0.6694444444444444)\n",
      "only adverbs: \t\t(0.6310679611650486,0.625,0.6280193236714976)\n"
     ]
    }
   ],
   "source": [
    "println(\"overall: \\t\\t\", evalute_on_wsd_challenge(challenges, solutions, hh, db, sense_key_map))\n",
    "\n",
    "println(\"only nouns  : \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'n'), only_of_pos(solutions,'n'), hh, db, sense_key_map))\n",
    "println(\"only verbs  : \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'v'), only_of_pos(solutions,'v'), hh, db, sense_key_map))\n",
    "println(\"only adjecti: \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'a'), only_of_pos(solutions,'a'), hh, db, sense_key_map))\n",
    "println(\"only adverbs: \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'r'), only_of_pos(solutions,'r'), hh, db, sense_key_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.0-dev",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
