{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using WordNet\n",
    "using AdaGram\n",
    "using AdaGramCompat\n",
    "\n",
    "using CorpusLoaders\n",
    "using CorpusLoaders.Semcor\n",
    "using WordEmbeddings, SoftmaxClassifier\n",
    "using Utils\n",
    "using Query\n",
    "using Distances\n",
    "using Iterators\n",
    "using LightXML\n",
    "using JLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordNet.DB"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const WN_PATH=\"data/corpora/WordNet-2.1/\"\n",
    "#WN_PATH3 = \"/usr/share/nltk_data/corpora/wordnet/\"\n",
    "db = DB(WN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#am = AdaGramCompat.AdaGramModel(load_model(\"models/adagram/v1_d100.adagram_model\")...)\n",
    "#am = AdaGramModel(load_model(\"models/adagram/more_senses.adagram_model\")...)\n",
    "#am = open(deserialize,\"models/adagram/more_senses.adagram_model.jsz\", \"r\");\n",
    "am = load(\"models/adagram/more_senses.adagram_model.jld\", \"am\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ee = restore(\"models/ss/tokenised_lowercase_WestburyLab.wikicorp.201004_100_i1.jld\");\n",
    "ee = load(\"models/ss/tokenised_lowercase_WestburyLab.wikicorp.201004_100_i1.jld\", \"ee\")\n",
    "\n",
    "#ee = restore(\"models/ss/keep/tokenised_lowercase_WestburyLab.wikicorp.201004_50__m170000000.model\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(\"CorpusLoaders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "using CorpusLoaders.Semeval2007t7\n",
    "\n",
    "challenges = load_challenges_semeval2007t7(\"data/corpora/wsd/semeval2007_t7/test/eng-coarse-all-words.xml\");\n",
    "solutions = load_solutions_semeval2007t7(\"data/corpora/wsd/semeval2007_t7/key/dataset21.test.key\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "semcor = index_semcor(lazyload_semcor(\"data/corpora/semcor2.1/brown1/tagfiles/\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "only_of_pos (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_of_pos(data, pos) = filter(d->d.pos==pos, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sense_frequency (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function sense_frequency(ss::Synset, lem::Lemma)\n",
    "    lem_count = lem.tagsense_count\n",
    "    #lem_count+0.1(sum(values(ss.word_counts))-lem_count) #Do not use Synset's other counts. It owrks out worse\n",
    "    lem_count\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#typealias Usages{S<:AbstractString, V<:AbstractVector{S}} Dict{Synset, Abs }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_all_usages (generic function with 1 method)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Collect up the usages from a indexed tagged source\"\n",
    "function get_usages(usage_index::Dict{String, Vector{Semcor.TaggedSentence}}, key)\n",
    "    if haskey(usage_index, key)\n",
    "        [map(lowercase, strip_tags(sent)) for sent in usage_index[key]]\n",
    "    else\n",
    "        Vector{String}[]\n",
    "    end\n",
    "end\n",
    "\n",
    "function get_usages(synset::Synset)\n",
    "    gloss::Vector{SubString{String}} = map(lowercase, punctuation_space_tokenize(synset.gloss))\n",
    "    [gloss]\n",
    "end\n",
    "\n",
    "function get_all_usages(wn::DB, semcor::Dict{String, Vector{Semcor.TaggedSentence}}, lemma_word, pos)   \n",
    "    lemma = db[pos, lemma_word]\n",
    "    target_synsets::Vector{Synset} = synsets(db, lemma)\n",
    "    \n",
    "    Dict{Synset,AbstractVector{AbstractVector}}((synset => get_usages(synset)\n",
    "        #get_usages(semcor, sensekey(db, synset, lemma)); get_usages(synset)]\n",
    "                    for synset in target_synsets))  \n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "all_word_sense_vectors (generic function with 2 methods)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function all_word_sense_vectors(ee::WordSenseEmbedding, word)\n",
    "    get(ee.embedding, word, Vector{Float32}[])\n",
    "end\n",
    "\n",
    "function all_word_sense_vectors(am::AdaGramCompat.AdaGramModel, word)\n",
    "    if haskey(am.dict.word2id, word)\n",
    "        wsv_mat = word_sense_vectors(am, word)\n",
    "        [view(wsv_mat,:,ii) for ii in 1:size(wsv_mat,2)]\n",
    "    else\n",
    "        Vector{Float32}[]\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "synthesize_embedding (generic function with 2 methods)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function normal_probs(logprobs::Vector)\n",
    "    ret = copy(logprobs)\n",
    "    @show mean(logprobs)\n",
    "    @show max_lp = maximum(logprobs)\n",
    "    ret.-=max_lp #Bring closer to zero\n",
    "    map!(exp,ret)\n",
    "    denom = sum(ret)\n",
    "    ret./=denom\n",
    "    @show ret\n",
    "    ret\n",
    "end\n",
    "function weighted_average(logprobs, embeddings)\n",
    "    ret = zeros(first(embeddings))\n",
    "    for (weight, embedding) in zip(normal_probs(logprobs), embeddings)\n",
    "        ret.+= weight.*embedding\n",
    "    end\n",
    "    ret\n",
    "end\n",
    "\n",
    "\n",
    "function synthesize_embedding1(ee,context::AbstractVector, word_or_phrase::AbstractString)\n",
    "    words = split(word_or_phrase, \" \")\n",
    "    wvs = vcat((all_word_sense_vectors(ee,w) for w in words)...)\n",
    "    if length(wvs) == 0\n",
    "            throw(KeyError(\"None of $words have embeddings\"))\n",
    "    end\n",
    "        logprobs = [Query.logprob_of_context(ee, context, wv; skip_oov=true, normalise_over_length=false) for wv in wvs]\n",
    "    weighted_average(logprobs, wvs)\n",
    "end\n",
    "\n",
    "    \n",
    "\n",
    "function synthesize_embedding(am::AdaGramModel,context::AbstractVector, word::AbstractString)\n",
    "    known_context = filter(c->haskey(am.dict.word2id, c), context)\n",
    "    sum(all_word_sense_vectors(am, word).*disambiguate(am.vm, am.dict, word, known_context))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Note the disambig prob fumctions :\n",
    " - Query.logprob_of_context(am, context, wv; , normalise_over_length=false)\n",
    "- Adagram.disambiguate(am.vm, am.dict, word, known_context, false))\n",
    "Are identical. That is with normalise_over_length false for Logprob-of-context, \n",
    "and use_prior false for Adagram.disambiguate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l_use = SubString{String}[\"sloping\",\"land\",\"especially\",\"the\",\"slope\",\"beside\",\"a\",\"body\",\"of\",\"water\",\"they\",\"pulled\",\"the\",\"canoe\",\"up\",\"on\",\"the\",\"bank\",\"he\",\"sat\",\"on\",\"the\",\"bank\",\"of\",\"the\",\"river\",\"and\",\"watched\",\"the\",\"currents\"]\n",
      "mean(logprobs) = -223.88046f0\n",
      "max_lp = maximum(logprobs) = -209.24814f0\n",
      "ret = Float32[2.74554f-16,1.33641f-19,1.94756f-11,9.23107f-19,1.13482f-13,2.64748f-22,1.55055f-11,2.565f-21,8.18769f-21,2.6063f-16,1.66657f-14,9.36849f-12,3.15721f-16,0.0441032,0.0618453,0.0592532,0.0649737,0.059418,0.0608503,0.0634502,0.0580682,0.0578868,0.0635035,0.0656825,0.0569155,0.0518538,0.0572447,0.0552748,0.0535602,0.0661159]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10-element Array{Tuple{AbstractString,Int64,Float32},1}:\n",
       " (\"doms\",2,0.00349899)      \n",
       " (\"identifed\",2,0.00337902) \n",
       " (\"da1\",1,0.00337019)       \n",
       " (\"dey\",5,0.00333783)       \n",
       " (\"p√©rouse\",2,0.00333376)   \n",
       " (\"dilutes\",3,0.00332366)   \n",
       " (\"mennonites\",3,0.00331573)\n",
       " (\"eendracht\",2,0.00330707) \n",
       " (\"bront√´\",3,0.0033024)     \n",
       " (\"kudu\",3,0.00329984)      "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = \"bank\"\n",
    "uses = get_all_usages(db, semcor, w, 'n')\n",
    "l_uses= uses[collect(keys(uses))[3]]\n",
    "l_use = l_uses[1]\n",
    "#l_use = split(\"i swam in the water near the i saw a fish\")\n",
    "@show l_use\n",
    "wv = synthesize_embedding1(am,l_use, w)\n",
    "nearest_neighbors(am.vm, am.dict, wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{Tuple{AbstractString,Int64,Float32},1}:\n",
       " (\"doms\",2,0.00349898)      \n",
       " (\"identifed\",2,0.00337904) \n",
       " (\"da1\",1,0.00337019)       \n",
       " (\"dey\",5,0.00333786)       \n",
       " (\"p√©rouse\",2,0.00333378)   \n",
       " (\"dilutes\",3,0.00332369)   \n",
       " (\"mennonites\",3,0.00331575)\n",
       " (\"eendracht\",2,0.0033071)  \n",
       " (\"bront√´\",3,0.0033024)     \n",
       " (\"kudu\",3,0.00329986)      "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv_a =  sum(all_word_sense_vectors(am, \"bank\").*disambiguate(am.vm, am.dict, w, l_use, false))\n",
    "nearest_neighbors(am.vm, am.dict, wv_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100√ó3 Array{Float32,2}:\n",
       " -0.000549951  -0.000549953   1.97906f-9 \n",
       "  8.82424f-5    8.82341f-5    8.29459f-9 \n",
       " -0.000169456  -0.00016947    1.39116f-8 \n",
       "  5.33938f-6    5.33941f-6   -2.91038f-11\n",
       "  0.00181305    0.00181306   -1.22236f-8 \n",
       " -0.000852755  -0.000852769   1.45519f-8 \n",
       "  0.000529032   0.000529015   1.70548f-8 \n",
       "  0.000679199   0.000679156   4.26662f-8 \n",
       "  0.000364573   0.000364558   1.57743f-8 \n",
       " -3.76887f-5   -3.76736f-5   -1.50612f-8 \n",
       " -0.000271979  -0.000271983   4.13274f-9 \n",
       " -0.000335945  -0.000335975   2.93076f-8 \n",
       "  0.000768151   0.000768134   1.74041f-8 \n",
       " -0.000324189  -0.000324187  -1.97906f-9 \n",
       " -0.00020649   -0.000206471  -1.84955f-8 \n",
       " -0.000205744  -0.000205765   2.09693f-8 \n",
       " -0.000113083  -0.000113092   9.45874f-9 \n",
       "  0.000643895   0.000643911  -1.60071f-8 \n",
       "  8.59268f-5    8.59088f-5    1.80589f-8 \n",
       "  6.41633f-5    6.41821f-5   -1.87574f-8 \n",
       "  0.00128759    0.0012876    -1.00117f-8 \n",
       "  0.00079151    0.000791473   3.6438f-8  \n",
       "  0.000198559   0.00019857   -1.12341f-8 \n",
       " -0.000288214  -0.000288207  -6.60657f-9 \n",
       "  0.00118168    0.0011817    -1.42027f-8 \n",
       "  0.000569982   0.000569967   1.47265f-8 \n",
       " -0.000378205  -0.000378189  -1.64728f-8 \n",
       "  3.39218f-5    3.39087f-5    1.30822f-8 \n",
       "  0.00119477    0.00119478   -1.62981f-9 \n",
       "  0.00102227    0.00102227   -6.17001f-9 \n",
       "  0.00060372    0.000603733  -1.32713f-8 \n",
       " -0.000244194  -0.000244191  -3.84171f-9 \n",
       " -0.00118618   -0.00118618   -5.82077f-9 \n",
       " -0.000226595  -0.000226604   9.00764f-9 \n",
       "  0.0001655     0.000165516  -1.62836f-8 \n",
       " -0.000254602  -0.000254595  -7.53789f-9 \n",
       " -0.00109279   -0.0010928     3.14321f-9 \n",
       "  0.00104131    0.00104132   -1.18744f-8 \n",
       "  0.000360849   0.000360847   2.00816f-9 \n",
       "  6.86202f-5    6.86158f-5    4.31464f-9 \n",
       " -0.000553977  -0.000553998   2.1304f-8  \n",
       "  0.000727964   0.00072795    1.40863f-8 \n",
       "  4.01134f-5    4.01121f-5    1.32059f-9 \n",
       "  0.000239659   0.000239667  -8.07631f-9 \n",
       "  0.000352378   0.000352349   2.95695f-8 \n",
       " -0.000101463  -0.000101467   3.85626f-9 \n",
       "  0.00061507    0.000615067   2.61934f-9 \n",
       " -4.1831f-5    -4.18286f-5   -2.38651f-9 \n",
       "  6.21822f-5    6.21553f-5    2.69501f-8 \n",
       " -0.00024785   -0.000247847  -2.56114f-9 \n",
       " -0.000801157  -0.000801144  -1.22818f-8 \n",
       "  9.45472f-5    9.45224f-5    2.47674f-8 \n",
       " -0.00135514   -0.00135513   -1.47847f-8 \n",
       " -0.00123352   -0.00123352    0.0        \n",
       "  0.001309      0.00130899    5.58794f-9 \n",
       "  8.17797f-5    8.17827f-5   -3.01952f-9 \n",
       "  0.000322671   0.000322667   4.10364f-9 \n",
       " -0.00105605   -0.00105609    4.09782f-8 \n",
       " -0.00083222   -0.000832217  -2.91038f-9 \n",
       "  0.000110413   0.000110423  -9.96806f-9 \n",
       "  0.000277123   0.000277099   2.40107f-8 \n",
       " -0.00186015   -0.00186015    3.60887f-9 \n",
       " -9.19693f-5   -9.19662f-5   -3.0268f-9  \n",
       " -0.00070054   -0.000700549   9.19681f-9 \n",
       " -0.000248741  -0.000248743   2.56114f-9 \n",
       " -0.000205405  -0.00020543    2.54367f-8 \n",
       " -3.76245f-6   -3.75142f-6   -1.10276f-8 \n",
       " -0.000211996  -0.00021197   -2.66009f-8 \n",
       " -2.87901f-5   -2.8781f-5    -9.11677f-9 \n",
       " -0.000900938  -0.000900932  -5.99539f-9 \n",
       "  0.000482016   0.000482013   3.37604f-9 \n",
       " -0.00104295   -0.00104297    2.51457f-8 \n",
       "  0.00065549    0.000655482   8.67294f-9 \n",
       "  0.000145826   0.000145817   9.72068f-9 \n",
       "  0.000305504   0.000305509  -5.00586f-9 \n",
       " -0.000389078  -0.000389084   5.99539f-9 \n",
       "  0.000455388   0.000455385   3.23053f-9 \n",
       "  0.000108082   0.000108064   1.81026f-8 \n",
       "  0.000393589   0.000393562   2.67755f-8 \n",
       "  0.000118987   0.000118989  -1.57161f-9 \n",
       "  0.000644821   0.000644813   7.74162f-9 \n",
       " -0.000918392  -0.000918399   6.22822f-9 \n",
       " -0.00164563   -0.00164563   -3.60887f-9 \n",
       " -0.000276919  -0.00027689   -2.90165f-8 \n",
       " -0.000918781  -0.000918795   1.41445f-8 \n",
       " -0.000210676  -0.000210668  -7.37782f-9 \n",
       "  0.00039693    0.000396952  -2.19443f-8 \n",
       "  1.47181f-5    1.47165f-5    1.58616f-9 \n",
       " -0.00022248   -0.000222475  -5.10772f-9 \n",
       " -8.15975f-5   -8.15754f-5   -2.20898f-8 \n",
       "  0.000911787   0.00091179   -3.25963f-9 \n",
       "  5.38643f-5    5.38471f-5    1.71858f-8 \n",
       "  0.00136598    0.00136598    4.65661f-10\n",
       " -0.000680295  -0.000680322   2.7474f-8  \n",
       "  0.000544274   0.000544262   1.19908f-8 \n",
       "  0.000108547   0.000108553  -6.25732f-9 \n",
       " -0.000996805  -0.000996806   1.04774f-9 \n",
       "  0.000124445   0.000124469  -2.39525f-8 \n",
       "  0.000714547   0.000714537   9.60426f-9 \n",
       "  8.42969f-5    8.43044f-5   -7.54517f-9 "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[wv wv_a wv-wv_a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l_ee, l_ss, lem = lexically_informed_embeddings(db, am, \"bank\", \"bank\", 'n');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ss = (n) bank building, bank (a building in which the business of banking transacted; \"the bank is on the corner of Nassau and Witherspoon\")\n",
      "nearest_neighbors(am.vm,am.dict,tle) = Tuple{AbstractString,Int64,Float32}[(\"bank\",5,1.95574),(\"banker\",8,1.70124),(\"trust\",12,1.67848),(\"savings\",9,1.65595),(\"investments\",5,1.6485),(\"stock\",5,1.64087),(\"investor\",3,1.63579),(\"real\",13,1.63575),(\"j.p\",3,1.63418),(\"investment\",8,1.63387)]\n",
      "--------------------------------\n",
      "\n",
      "\n",
      "ss = (n) bank (a supply or stock held in reserve for future use (especially in emergencies))\n",
      "nearest_neighbors(am.vm,am.dict,tle) = Tuple{AbstractString,Int64,Float32}[(\"bank\",8,2.99978),(\"banks\",1,2.85707),(\"deposits\",2,2.84313),(\"bank's\",1,2.83829),(\"exchange\",2,2.8291),(\"balance\",3,2.81137),(\"depositors\",1,2.8109),(\"treasury\",2,2.80644),(\"reserve\",8,2.79827),(\"money\",2,2.79216)]\n",
      "--------------------------------\n",
      "\n",
      "\n",
      "ss = (n) bank (sloping land (especially the slope beside a body of water); \"they pulled the canoe up on the bank\"; \"he sat on the bank of the river and watched the currents\")\n",
      "nearest_neighbors(am.vm,am.dict,tle) = Tuple{AbstractString,Int64,Float32}[(\"swinging\",4,1.48086),(\"bank\",3,1.45601),(\"forded\",1,1.44938),(\"river's\",2,1.42043),(\"dwindles\",2,1.42017),(\"flowed\",5,1.41193),(\"northeasterly\",3,1.41063),(\"above\",1,1.39862),(\"bend\",11,1.39696),(\"blackton\",2,1.39629)]\n",
      "--------------------------------\n",
      "\n",
      "\n",
      "ss = (n) bank (an arrangement of similar objects in a row or in tiers; \"he operated a bank of switches\")\n",
      "nearest_neighbors(am.vm,am.dict,tle) = Tuple{AbstractString,Int64,Float32}[(\"bank\",11,2.10228),(\"moved\",14,1.70219),(\"opens\",7,1.67622),(\"advance\",3,1.63352),(\"up/down\",1,1.62547),(\"at\",4,1.6168),(\"pushbuttons\",1,1.61243),(\"beside\",8,1.61192),(\"loses\",11,1.61162),(\"noticed\",9,1.61125)]\n",
      "--------------------------------\n",
      "\n",
      "\n",
      "ss = (n) savings bank, coin bank, money box, bank (a container (usually with a slot in the top) for keeping money at home; \"the coin bank was empty\")\n",
      "nearest_neighbors(am.vm,am.dict,tle) = Tuple{AbstractString,Int64,Float32}[(\"bank\",11,1.90975),(\"moved\",14,1.54738),(\"opens\",7,1.54156),(\"noticed\",9,1.48758),(\"advance\",3,1.48712),(\"beside\",8,1.48263),(\"twice\",12,1.4781),(\"successive\",6,1.47602),(\"up/down\",1,1.47458),(\"trip\",2,1.47239)]\n",
      "--------------------------------\n",
      "\n",
      "\n",
      "ss = (n) bank (the funds held by a gambling house or the dealer in some gambling games; \"he tried to break the bank at Monte Carlo\")\n",
      "nearest_neighbors(am.vm,am.dict,tle) = Tuple{AbstractString,Int64,Float32}[(\"bank\",13,1.73733),(\"robber\",1,1.58367),(\"jewelry\",4,1.49273),(\"cash\",7,1.48159),(\"heist\",1,1.47108),(\"criminals\",4,1.46849),(\"robbers\",1,1.45977),(\"accomplices\",4,1.45807),(\"eliot\",4,1.44849),(\"robbery\",2,1.44727)]\n",
      "--------------------------------\n",
      "\n",
      "\n",
      "ss = (n) bank (a flight maneuver; aircraft tips laterally about its longitudinal axis (especially in turning); \"the plane went into a steep bank\")\n",
      "nearest_neighbors(am.vm,am.dict,tle) = Tuple{AbstractString,Int64,Float32}[(\"bank\",11,2.12419),(\"moved\",14,1.71917),(\"opens\",7,1.69393),(\"advance\",3,1.6525),(\"up/down\",1,1.64304),(\"at\",4,1.63342),(\"pushbuttons\",1,1.63076),(\"loses\",11,1.63018),(\"beside\",8,1.62919),(\"noticed\",9,1.6259)]\n",
      "--------------------------------\n",
      "\n",
      "\n",
      "ss = (n) depository financial institution, banking concern, bank, banking company (a financial institution that accepts deposits and channels the money into lending activities; \"he cashed a check at the bank\"; \"that bank holds the mortgage on my home\")\n",
      "nearest_neighbors(am.vm,am.dict,tle) = Tuple{AbstractString,Int64,Float32}[(\"bank\",8,3.01565),(\"banks\",1,2.87158),(\"deposits\",2,2.85778),(\"bank's\",1,2.85294),(\"exchange\",2,2.84424),(\"balance\",3,2.82611),(\"depositors\",1,2.82601),(\"treasury\",2,2.82153),(\"reserve\",8,2.81289),(\"money\",2,2.80692)]\n",
      "--------------------------------\n",
      "\n",
      "\n",
      "ss = (n) cant, camber, bank (a slope in the turn of a road or track; the outside is higher than the inside in order to reduce the effects of centrifugal force)\n",
      "nearest_neighbors(am.vm,am.dict,tle) = Tuple{AbstractString,Int64,Float32}[(\"bank\",11,2.12429),(\"moved\",14,1.71924),(\"opens\",7,1.69399),(\"advance\",3,1.65257),(\"up/down\",1,1.64311),(\"at\",4,1.63348),(\"pushbuttons\",1,1.63084),(\"loses\",11,1.63024),(\"beside\",8,1.62924),(\"noticed\",9,1.62598)]\n",
      "--------------------------------\n",
      "\n",
      "\n",
      "ss = (n) bank (a long ridge or pile; \"a huge bank of earth\")\n",
      "nearest_neighbors(am.vm,am.dict,tle) = Tuple{AbstractString,Int64,Float32}[(\"bank\",12,1.27519),(\"enclosing\",1,1.097),(\"110m\",3,1.0944),(\"serre-pon√ßon\",1,1.09271),(\"190m\",1,1.08879),(\"6.7¬†km\",2,1.07481),(\"320m\",2,1.06596),(\"shore-line\",1,1.06574),(\"downstream\",6,1.06272),(\"kilometer\",3,1.06242)]\n",
      "--------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for (tle, ss) in zip(l_ee,l_ss)\n",
    "    @show ss\n",
    "    @show nearest_neighbors(am.vm, am.dict, tle)\n",
    "    println(\"-\"^32)\n",
    "    println(\"\\n\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "No documentation found.\n",
       "\\texttt{AdaGram.var_update_z!} is a \\texttt{Function}.\n",
       "\\begin{verbatim}\n",
       "# 2 methods for generic function \"var_update_z!\":\n",
       "var_update_z!{Tw<:Integer}(vm::AdaGram.VectorModel, x::Tw, y::Tw, z::DenseArray{Float64,N<:Any}) at /home/ubuntu/.julia/v0.5/AdaGram/src/gradient.jl:93\n",
       "var_update_z!{Tw<:Integer}(vm::AdaGram.VectorModel, x::Tw, y::Tw, z::DenseArray{Float64,N<:Any}, num_meanings::Int64) at /home/ubuntu/.julia/v0.5/AdaGram/src/gradient.jl:93\n",
       "\\end{verbatim}\n"
      ],
      "text/markdown": [
       "No documentation found.\n",
       "\n",
       "`AdaGram.var_update_z!` is a `Function`.\n",
       "\n",
       "```\n",
       "# 2 methods for generic function \"var_update_z!\":\n",
       "var_update_z!{Tw<:Integer}(vm::AdaGram.VectorModel, x::Tw, y::Tw, z::DenseArray{Float64,N<:Any}) at /home/ubuntu/.julia/v0.5/AdaGram/src/gradient.jl:93\n",
       "var_update_z!{Tw<:Integer}(vm::AdaGram.VectorModel, x::Tw, y::Tw, z::DenseArray{Float64,N<:Any}, num_meanings::Int64) at /home/ubuntu/.julia/v0.5/AdaGram/src/gradient.jl:93\n",
       "```\n"
      ],
      "text/plain": [
       "No documentation found.\n",
       "\n",
       "`AdaGram.var_update_z!` is a `Function`.\n",
       "\n",
       "```\n",
       "# 2 methods for generic function \"var_update_z!\":\n",
       "var_update_z!{Tw<:Integer}(vm::AdaGram.VectorModel, x::Tw, y::Tw, z::DenseArray{Float64,N<:Any}) at /home/ubuntu/.julia/v0.5/AdaGram/src/gradient.jl:93\n",
       "var_update_z!{Tw<:Integer}(vm::AdaGram.VectorModel, x::Tw, y::Tw, z::DenseArray{Float64,N<:Any}, num_meanings::Int64) at /home/ubuntu/.julia/v0.5/AdaGram/src/gradient.jl:93\n",
       "```\n"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?AdaGram.var_update_z!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lexically_informed_embeddings (generic function with 2 methods)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_identical(col) = length(col)==1 || !any(x->x!=col[1],col[2:end])\n",
    "    \n",
    "\n",
    "function _lexically_informed_embeddings(wn::DB,ee, word,lemma_word, pos)\n",
    "    indexed_corpus = semcor #TODO: Pass this as a parameter, not as a gloel\n",
    "    target_synset_examples = get_all_usages(wn, indexed_corpus, lemma_word, pos)\n",
    "    target_synsets = collect(keys(target_synset_examples))\n",
    "    lemma = db[lemma_word, pos]\n",
    "        \n",
    "    embeddings = Vector{Vector{Float32}}(length(target_synsets))\n",
    "    for (ii,(synset, examples)) in enumerate(target_synset_examples)\n",
    "        embeddings[ii] = mean(examples) do eg#::AbstractVector\n",
    "        context::Vector{SubString{String}} = filter(w::AbstractString->w!=word, eg)\n",
    "        synthesize_embedding(ee,context, word)\n",
    "        end\n",
    "    end\n",
    "        \n",
    "    \n",
    "    if all_identical(embeddings)\n",
    "        #Use MCWS\n",
    "        score, index = findmax(sense_frequency(ss,lemma) for ss in target_synsets)\n",
    "        target_synsets=[target_synsets[index]] # Throw out others\n",
    "        embeddings=[embeddings[1]]\n",
    "    end\n",
    "        \n",
    "    embeddings,target_synsets,lemma\n",
    "end\n",
    "\n",
    "lexically_informed_embeddings(wn::DB, ee, lemma_word, pos) = lexically_informed_embeddings(db,ee, lemma_word, lemma_word, pos)\n",
    "        \n",
    "_li_embeddings = Dict{Tuple{DB, Any, String, String, Char}, Tuple{Vector{Vector{Float32}}, Vector{Synset}, Lemma}}()\n",
    "function lexically_informed_embeddings(wn::DB, ee, word,lemma_word, pos)\n",
    "    get!(_li_embeddings, (wn, ee, word, lemma_word, pos)) do\n",
    "        _lexically_informed_embeddings(wn, ee, word, lemma_word, pos)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "most_frequent_sense (generic function with 1 method)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function supervised_wsd(challenge, ee, wn::DB)\n",
    "    try\n",
    "        embeddings,target_synsets,lemma = lexically_informed_embeddings(wn,ee,\n",
    "                                                            challenge.word, \n",
    "                                                            challenge.lemma, challenge.pos)\n",
    "        #sense_index = Query.WSD(ee, embeddings, challenge.context; skip_oov=true)\n",
    "        logprobs_of_context = [logprob_of_context(ee,challenge.context, wv; skip_oov=true, normalise_over_length=true) \n",
    "                                    for wv in embeddings] \n",
    "      \n",
    "        sense_index= indmax(logprobs_of_context)\n",
    "\n",
    "        \n",
    "        synset = target_synsets[sense_index]\n",
    "        sk = sensekey(wn, synset, lemma)\n",
    "        Nullable(sk)\n",
    "    catch ex\n",
    "        isa(ex, KeyError) || rethrow(ex)\n",
    "        Nullable{String}()\n",
    "    end\n",
    "end\n",
    "\n",
    "function most_frequent_sense(challenge, wn::DB)\n",
    "    try\n",
    "        lemma = wn[challenge.pos, challenge.lemma]\n",
    "        target_synsets::Vector{Synset} = synsets(db, lemma)\n",
    "        \n",
    "        sense_freqs =  Float32[sense_frequency(ss,lemma) for ss in target_synsets]      \n",
    "        sense_index= indmax(sense_freqs)\n",
    "        synset = target_synsets[sense_index]\n",
    "        \n",
    "        sk = sensekey(wn, synset,  lemma)\n",
    "        Nullable(sk)\n",
    "    catch ex\n",
    "        isa(ex, KeyError) || rethrow(ex)\n",
    "        Nullable{String}()\n",
    "    end\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using ProgressMeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evalute_on_wsd_challenge_MFS (generic function with 1 method)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function evalute_on_wsd_challenge(challenges, solutions, method)\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    notattempted = 0\n",
    "    @showprogress for (challenge, ground_solution) in zip(challenges, solutions)\n",
    "        assert(challenge.id == ground_solution.id)\n",
    "        output_sense = method(challenge)\n",
    "        if isnull(output_sense)\n",
    "            notattempted+=1\n",
    "        else\n",
    "            if get(output_sense) ‚àà ground_solution.solutions\n",
    "                correct+=1\n",
    "            else\n",
    "                incorrect+=1\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    precision = correct/(correct+incorrect)\n",
    "    recall = correct/(correct+incorrect+notattempted)\n",
    "    f1 = (2*precision*recall) / (precision+recall)\n",
    "    return precision, recall, f1\n",
    "end\n",
    "    \n",
    "    \n",
    "function evalute_on_wsd_challenge(challenges, solutions, ee, wn::DB)\n",
    "    method = challenge -> supervised_wsd(challenge, ee, wn)\n",
    "    evalute_on_wsd_challenge(challenges, solutions, method)\n",
    "end\n",
    "\n",
    "\n",
    "function evalute_on_wsd_challenge_MFS(challenges, solutions, wn::DB)\n",
    "    method = challenge -> most_frequent_sense(challenge, wn)\n",
    "    evalute_on_wsd_challenge(challenges, solutions, method)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Time: 0:00:29\n",
      "overall: \t\t(0.6704701049748973,0.6474217717055972,0.658744394618834)\n",
      "Progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Time: 0:00:04\n",
      "nn = evalute_on_wsd_challenge(only_of_pos(challenges,'n'),only_of_pos(solutions,'n'),am,db) = (0.7133580705009277,0.694043321299639,0.7035681610247027)\n",
      "Progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Time: 0:00:05\n",
      "vv = evalute_on_wsd_challenge(only_of_pos(challenges,'v'),only_of_pos(solutions,'v'),am,db) = (0.5780141843971631,0.5516074450084603,0.5645021645021645)\n",
      "Progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Time: 0:00:01\n",
      "aa = evalute_on_wsd_challenge(only_of_pos(challenges,'a'),only_of_pos(solutions,'a'),am,db) = (0.6535211267605634,0.6408839779005525,0.6471408647140865)\n",
      "Progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Time: 0:00:01\n",
      "rr = evalute_on_wsd_challenge(only_of_pos(challenges,'r'),only_of_pos(solutions,'r'),am,db) = (0.7319587628865979,0.6826923076923077,0.7064676616915424)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7319587628865979,0.6826923076923077,0.7064676616915424)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "println(\"overall: \\t\\t\", evalute_on_wsd_challenge(challenges, solutions, am, db))\n",
    "\n",
    "#println(\"only nouns  : \\t\\t\", \n",
    "@show nn = evalute_on_wsd_challenge(only_of_pos(challenges,'n'), only_of_pos(solutions,'n'), am, db)\n",
    "#println(\"only verbs  : \\t\\t\", \n",
    "@show vv = evalute_on_wsd_challenge(only_of_pos(challenges,'v'), only_of_pos(solutions,'v'), am, db)\n",
    "#println(\"only adjecti: \\t\\t\", \n",
    "@show aa = evalute_on_wsd_challenge(only_of_pos(challenges,'a'), only_of_pos(solutions,'a'), am, db)\n",
    "#println(\"only adverbs: \\t\\t\", \n",
    "@show rr = evalute_on_wsd_challenge(only_of_pos(challenges,'r'), only_of_pos(solutions,'r'), am, db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "No documentation found.\n",
       "\\texttt{AdaGram.exp_normalize!} is a \\texttt{Function}.\n",
       "\\begin{verbatim}\n",
       "# 1 method for generic function \"exp_normalize!\":\n",
       "exp_normalize!(x) at /home/ubuntu/.julia/v0.5/AdaGram/src/AdaGram.jl:120\n",
       "\\end{verbatim}\n"
      ],
      "text/markdown": [
       "No documentation found.\n",
       "\n",
       "`AdaGram.exp_normalize!` is a `Function`.\n",
       "\n",
       "```\n",
       "# 1 method for generic function \"exp_normalize!\":\n",
       "exp_normalize!(x) at /home/ubuntu/.julia/v0.5/AdaGram/src/AdaGram.jl:120\n",
       "```\n"
      ],
      "text/plain": [
       "No documentation found.\n",
       "\n",
       "`AdaGram.exp_normalize!` is a `Function`.\n",
       "\n",
       "```\n",
       "# 1 method for generic function \"exp_normalize!\":\n",
       "exp_normalize!(x) at /home/ubuntu/.julia/v0.5/AdaGram/src/AdaGram.jl:120\n",
       "```\n"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?AdaGram.exp_normalize!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"models/adagram/more_senses.adagram_model.jld\n",
    "### with Adagram Disambig weighting (prior used)\n",
    "### with SemCor data \n",
    "overall: \t\t(0.655408489274304,0.6328779197884531,0.6439461883408072)\n",
    "nn = evalute_on_wsd_challenge(only_of_pos(challenges,'n'),only_of_pos(solutions,'n'),am,db) = (0.7161410018552876,0.6967509025270758,0.706312900274474)\n",
    "vv = evalute_on_wsd_challenge(only_of_pos(challenges,'v'),only_of_pos(solutions,'v'),am,db) = (0.5106382978723404,0.4873096446700508,0.4987012987012987)\n",
    "aa = evalute_on_wsd_challenge(only_of_pos(challenges,'a'),only_of_pos(solutions,'a'),am,db) = (0.6619718309859155,0.649171270718232,0.6555090655509065)\n",
    "rr = evalute_on_wsd_challenge(only_of_pos(challenges,'r'),only_of_pos(solutions,'r'),am,db) = (0.7268041237113402,0.6778846153846154,0.7014925373134329)\n",
    "\n",
    "### with Adagram Disambig weighting (prior used)\n",
    "### with just glosses \n",
    "\n",
    "overall: \t\t(0.6704701049748973,0.6474217717055972,0.658744394618834)\n",
    "nn = evalute_on_wsd_challenge(only_of_pos(challenges,'n'),only_of_pos(solutions,'n'),am,db) = (0.7133580705009277,0.694043321299639,0.7035681610247027)\n",
    "vv = evalute_on_wsd_challenge(only_of_pos(challenges,'v'),only_of_pos(solutions,'v'),am,db) = (0.5780141843971631,0.5516074450084603,0.5645021645021645)\n",
    "aa = evalute_on_wsd_challenge(only_of_pos(challenges,'a'),only_of_pos(solutions,'a'),am,db) = (0.6535211267605634,0.6408839779005525,0.6471408647140865)\n",
    "rr = evalute_on_wsd_challenge(only_of_pos(challenges,'r'),only_of_pos(solutions,'r'),am,db) = (0.7319587628865979,0.6826923076923077,0.7064676616915424)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Time: 0:04:42\n",
      "overall: \t\t(0.6067567567567568,0.5936535918907008,0.6001336600579195)\n",
      "Progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Time: 0:00:01\n",
      "only nouns  : \t\t(0.6344383057090239,0.621841155234657,0.6280765724703737)\n",
      "Progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Time: 0:00:01\n",
      "only verbs  : \t\t(0.5129533678756477,0.5025380710659898,0.5076923076923077)\n",
      "Progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Time: 0:00:00\n",
      "only adjecti: \t\t(0.6275071633237822,0.6049723756906077,0.6160337552742615)\n",
      "only adverbs: \t\t(0.6893203883495146,0.6826923076923077,0.6859903381642513)\n"
     ]
    }
   ],
   "source": [
    "println(\"overall: \\t\\t\", evalute_on_wsd_challenge(challenges, solutions, ee, db))\n",
    "\n",
    "println(\"only nouns  : \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'n'), only_of_pos(solutions,'n'), ee, db))\n",
    "println(\"only verbs  : \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'v'), only_of_pos(solutions,'v'), ee, db))\n",
    "println(\"only adjecti: \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'a'), only_of_pos(solutions,'a'), ee, db))\n",
    "println(\"only adverbs: \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'r'), only_of_pos(solutions,'r'), ee, db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall: \t\t(0.7783164389598942,0.7783164389598942,0.7783164389598942)\n",
      "only nouns  : \t\t(0.7653429602888087,0.7653429602888087,0.7653429602888087)\n",
      "only verbs  : \t\t(0.7529610829103215,0.7529610829103215,0.7529610829103215)\n",
      "only adjecti: \t\t(0.8038674033149171,0.8038674033149171,0.8038674033149171)\n",
      "only adverbs: \t\t(0.875,0.875,0.875)\n"
     ]
    }
   ],
   "source": [
    "println(\"overall: \\t\\t\", evalute_on_wsd_challenge_MFS(challenges, solutions, db))\n",
    "\n",
    "println(\"only nouns  : \\t\\t\", evalute_on_wsd_challenge_MFS(only_of_pos(challenges,'n'), only_of_pos(solutions,'n'), db))\n",
    "println(\"only verbs  : \\t\\t\", evalute_on_wsd_challenge_MFS(only_of_pos(challenges,'v'), only_of_pos(solutions,'v'), db))\n",
    "println(\"only adjecti: \\t\\t\", evalute_on_wsd_challenge_MFS(only_of_pos(challenges,'a'), only_of_pos(solutions,'a'), db))\n",
    "println(\"only adverbs: \\t\\t\", evalute_on_wsd_challenge_MFS(only_of_pos(challenges,'r'), only_of_pos(solutions,'r'), db))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Zero shot WSI for 1 shot WSD\n",
    "using Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rr = FixedWordSenseEmbedding(ee.dimension, random_inited, huffman_tree; initial_nsenses=50)\n",
    "rr.corpus_size = ee.corpus_size\n",
    "rr.distribution = ee.distribution\n",
    "rr.codebook = ee.codebook\n",
    "rr.classification_tree = ee.classification_tree\n",
    "Training.initialize_embedding(rr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr.embedding[\"us\"] |> length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall: \t\t(0.6522522522522523,0.6381665932128691,0.6451325462241033)\n",
      "only nouns  : \t\t(0.6869244935543278,0.6732851985559567,0.6800364630811304)\n",
      "only verbs  : \t\t(0.5630397236614854,0.5516074450084603,0.5572649572649573)\n",
      "only adjecti: \t\t(0.667621776504298,0.643646408839779,0.6554149085794655)\n",
      "only adverbs: \t\t(0.6941747572815534,0.6875,0.6908212560386474)\n"
     ]
    }
   ],
   "source": [
    "println(\"overall: \\t\\t\", evalute_on_wsd_challenge(challenges, solutions, rr, db))\n",
    "\n",
    "println(\"only nouns  : \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'n'), only_of_pos(solutions,'n'), rr, db))\n",
    "println(\"only verbs  : \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'v'), only_of_pos(solutions,'v'), rr, db))\n",
    "println(\"only adjecti: \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'a'), only_of_pos(solutions,'a'), rr, db))\n",
    "println(\"only adverbs: \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'r'), only_of_pos(solutions,'r'), rr, db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hh = deepcopy(rr)\n",
    "for word in keys(rr.embedding)\n",
    "    append!(hh.embedding[word], ee.embedding[word])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall: \t\t(0.654054054054054,0.6399294843543412,0.6469146803296949)\n",
      "only nouns  : \t\t(0.6804788213627992,0.6669675090252708,0.6736554238833182)\n",
      "only verbs  : \t\t(0.5544041450777202,0.5431472081218274,0.5487179487179487)\n",
      "only adjecti: \t\t(0.6962750716332379,0.6712707182320442,0.6835443037974684)\n",
      "only adverbs: \t\t(0.7233009708737864,0.7163461538461539,0.7198067632850241)\n"
     ]
    }
   ],
   "source": [
    "println(\"overall: \\t\\t\", evalute_on_wsd_challenge(challenges, solutions, hh, db))\n",
    "\n",
    "println(\"only nouns  : \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'n'), only_of_pos(solutions,'n'), hh, db))\n",
    "println(\"only verbs  : \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'v'), only_of_pos(solutions,'v'), hh, db))\n",
    "println(\"only adjecti: \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'a'), only_of_pos(solutions,'a'), hh, db))\n",
    "println(\"only adverbs: \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'r'), only_of_pos(solutions,'r'), hh, db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using JLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.0-rc0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
