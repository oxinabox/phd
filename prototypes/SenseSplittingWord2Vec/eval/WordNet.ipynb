{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using ProgressMeter\n",
    "using SwiftObjectStores\n",
    "using CorpusLoaders\n",
    "using WordNet\n",
    "using AdaGram\n",
    "using AdaGramCompat\n",
    "using WordEmbeddings, SoftmaxClassifier\n",
    "using Utils\n",
    "using Query\n",
    "using Distances\n",
    "using JLD\n",
    "\n",
    "using SenseAlignment\n",
    "\n",
    "importfrom(CorpusLoaders, :sensekey)\n",
    "importfrom(WordNet, :sensekey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordNet.DB"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const WN_PATH=\"data/corpora/WordNet-2.1/\"\n",
    "#WN_PATH3 = \"/usr/share/nltk_data/corpora/wordnet/\"\n",
    "db = DB(WN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#am = AdaGramCompat.AdaGramModel(load_model(\"models/adagram/v1_d100.adagram_model\")...)\n",
    "#am = AdaGramModel(load_model(\"models/adagram/more_senses.adagram_model\")...)\n",
    "#am = open(deserialize,\"models/adagram/more_senses.adagram_model.jsz\", \"r\");\n",
    "am = load(\"models/adagram/more_senses.adagram_model.jld\", \"am\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(length.(collect(values(ee.embedding))).>1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s_am = get_jld(SwiftService(), \"sensemodels\", \"adagram/semhuff_more_senses.adagram_model.jld\", \"am\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ee = restore(\"models/ss/tokenised_lowercase_WestburyLab.wikicorp.201004_100_i1.jld\");\n",
    "ee = load(\"models/ss/tokenised_lowercase_WestburyLab.wikicorp.201004_100_i1.jld\", \"ee\")\n",
    "\n",
    "#ee = restore(\"models/ss/keep/tokenised_lowercase_WestburyLab.wikicorp.201004_50__m170000000.model\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "challenges = lazyload_challenges_semeval2007t7(\"data/corpora/wsd/semeval2007_t7/test/eng-coarse-all-words.xml\",\n",
    "                                            10, x->!isalnum(x)) |> collect;\n",
    "solutions = load_solutions_semeval2007t7(\"data/corpora/wsd/semeval2007_t7/key/dataset21.test.key\");\n",
    "\n",
    "#semcor = index_semcor(lazyload_semcor(\"data/corpora/semcor2.1/brown1/tagfiles/\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "semcor = index_semcor([load_semcor(\"data/corpora/semcor2.1/brown1/tagfiles/\")\n",
    "    load_semcor(\"data/corpora/semcor2.1/brown2/tagfiles/\");\n",
    "    load_semcor(\"data/corpora/semcor2.1/brownv/\")\n",
    "    ]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cs = db.counts |> length\n",
    "ws = db.sensekeys|> length\n",
    "@show cs\n",
    "@show ws\n",
    "@show ws - cs\n",
    "@show (ws - cs)/ws \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "challenges[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "window (generic function with 6 methods)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function window(context, index::Int, window_size::Int=10)\n",
    "    window_lower_bound = max(index - window_size÷2, 1)\n",
    "    window_upper_bound = min(index + window_size÷2, length(context))\n",
    "    view(context, [window_lower_bound:index-1 ; index+1:window_upper_bound])\n",
    "end\n",
    "\n",
    "function window(tagged_sense::TaggedSentence, index::Int, window_size::Int=10)\n",
    "    context = lowercase.(strip_tags(tagged_sense))\n",
    "    window(context, index, window_size)\n",
    "end\n",
    "   \n",
    "function window(context, word::AbstractString, window_size::Int=10)\n",
    "    context = lowercase.(context)\n",
    "    occurances = find(context.==word)\n",
    "    if length(occurances) > 0\n",
    "        index =  occurances[ceil(Int, end/2)]\n",
    "        window(context, index, window_size)\n",
    "    else\n",
    "        context  #don't window\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_all_usages (generic function with 1 method)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"Collect up the usages from a indexed tagged source\"\n",
    "function get_usages(usage_index::SemcorIndex, key)\n",
    "    if haskey(usage_index, key)\n",
    "        [window(lowercase.(strip_tags(sent)), index) for (sent, index) in usage_index[key]]\n",
    "    else\n",
    "        Vector{String}[]\n",
    "    end\n",
    "end\n",
    "\n",
    "function get_usages(synset::Synset, lemma_word::AbstractString)\n",
    "    gloss::Vector{SubString{String}} = lowercase.(punctuation_space_tokenize(synset.gloss))\n",
    "    #[window(gloss, lemma_word)]\n",
    "    [gloss]\n",
    "end\n",
    "\n",
    "function get_all_usages(wn::DB, lemma_word, pos)   \n",
    "    lemma = db[pos, lemma_word]\n",
    "    target_synsets::Vector{Synset} = synsets(db, lemma)\n",
    "    \n",
    "    Dict{Synset,AbstractVector{AbstractVector}}((synset => get_usages(synset, lemma_word)\n",
    "        #[get_usages(semcor, sensekey(db, synset, lemma)); get_usages(synset, lemma_word)]\n",
    "                    for synset in target_synsets))  \n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lexically_informed_embeddings (generic function with 1 method)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_identical(col) = length(col)==1 || !any(x->x!=col[1],col[2:end])\n",
    "\n",
    "function _lexically_informed_embeddings(wn::DB,ee, word,lemma_word, pos;kw_args... )\n",
    "    target_synset_examples = get_all_usages(wn, lemma_word, pos)\n",
    "    target_synsets = collect(keys(target_synset_examples))\n",
    "    lem = db[lemma_word, pos]\n",
    "        \n",
    "    embeddings = Vector{Vector{Float32}}(length(target_synsets))\n",
    "    for (ii,(synset, examples)) in enumerate(target_synset_examples)\n",
    "        context::Vector{SubString{String}} = vcat(examples...)\n",
    "        @assert context |> length > 0 \n",
    "        embeddings[ii] =synthesize_embedding(ee,context, word, lemma_word;kw_args...)\n",
    "    end\n",
    "        \n",
    "    \n",
    "    if length(target_synsets)!=1 && all_identical(embeddings)\n",
    "        throw(KeyError(\"Only 1 embedding for $word\"))\n",
    "    end\n",
    "        \n",
    "    embeddings,target_synsets,lem\n",
    "end\n",
    "\n",
    "    \n",
    "_li_embeddings = Dict{Any, Tuple{Vector{Vector{Float32}}, Vector{Synset}, Lemma}}()\n",
    "function lexically_informed_embeddings(args...;kwargs... )\n",
    "get!(_li_embeddings, (args,kwargs)) do\n",
    "        _lexically_informed_embeddings(args...;kwargs...)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "most_frequent_sense (generic function with 1 method)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function supervised_wsd(challenge, ee, wn::DB; \n",
    "     normalise_over_context_length::Bool=true,\n",
    "     normalize_over_prior::Bool=false,\n",
    "     use_prior_for_alignment::Bool= false,\n",
    "     MFS_backoff::Bool = false\n",
    "    )\n",
    "    try\n",
    "        embeddings,target_synsets,lem = lexically_informed_embeddings(wn,ee,\n",
    "                                                            challenge.word, \n",
    "                                                            challenge.lemma, challenge.pos; \n",
    "                                                            use_prior = use_prior_for_alignment,\n",
    "                                                            normalise_over_context_length = normalise_over_context_length,\n",
    "                                                            normalize_over_prior = normalize_over_prior,\n",
    "                                                            \n",
    "        )\n",
    "        \n",
    "        priors = [float(sensecount(db, ss, lem)) for ss in target_synsets] #TODO use thing\n",
    "        priors += 1#length(priors)\n",
    "        #priors .+= sqrt(sum(priors))/length(priors)\n",
    "        priors ./= sum(priors)\n",
    "        @assert(challenge.context |> length >0, challenge)\n",
    "        context = lowercase.(challenge.context)\n",
    "        probs_of_sense = general_wsd(ee, context, embeddings, priors; \n",
    "                                    normalise_over_context_length = normalise_over_context_length,\n",
    "                                    normalize_over_prior = normalize_over_prior\n",
    "        )\n",
    "               \n",
    "     \n",
    "        sense_index= indmax(probs_of_sense)        \n",
    "        synset = target_synsets[sense_index]\n",
    "        sk = sensekey(wn, synset, lem)\n",
    "        Nullable(sk)\n",
    "    catch ex\n",
    "        if MFS_backoff\n",
    "            most_frequent_sense(challenge, wn)\n",
    "        else\n",
    "            isa(ex, KeyError) || rethrow(ex)\n",
    "            #@show ex\n",
    "            Nullable{String}()\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "function most_frequent_sense(challenge, wn::DB)\n",
    "    try\n",
    "        lem = wn[challenge.pos, challenge.lemma]\n",
    "        target_synsets::Vector{Synset} = synsets(db, lem)\n",
    "        \n",
    "        sense_freqs =  Float32[sensecount(db, ss, lem) for ss in target_synsets]\n",
    "        sense_index= indmax(sense_freqs)\n",
    "        synset = target_synsets[sense_index]\n",
    "        \n",
    "        sk = sensekey(wn, synset,  lem)\n",
    "        Nullable(sk)\n",
    "    catch ex\n",
    "        isa(ex, KeyError) || rethrow(ex)\n",
    "        Nullable{String}()\n",
    "    end\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evalute_on_wsd_challenge_MFS (generic function with 1 method)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function evalute_on_wsd_challenge(challenges, solutions, method)\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    notattempted = 0\n",
    "    @showprogress for (challenge, ground_solution) in zip(challenges, solutions)\n",
    "        assert(challenge.id == ground_solution.id)\n",
    "        output_sense = method(challenge)\n",
    "        if isnull(output_sense)\n",
    "            notattempted+=1\n",
    "        else\n",
    "            if get(output_sense) ∈ ground_solution.solutions\n",
    "                correct+=1\n",
    "            else\n",
    "                incorrect+=1\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    @show notattempted\n",
    "    precision = correct/(correct+incorrect)\n",
    "    recall = correct/(correct+incorrect+notattempted)\n",
    "    f1 = (2*precision*recall) / (precision+recall)\n",
    "    return precision, recall, f1\n",
    "end\n",
    "    \n",
    "    \n",
    "function evalute_on_wsd_challenge(challenges, solutions, ee, wn::DB; kwargs...)\n",
    "    method = challenge -> supervised_wsd(challenge, ee, wn; kwargs...)\n",
    "    evalute_on_wsd_challenge(challenges, solutions, method)\n",
    "end\n",
    "\n",
    "function evalute_on_wsd_challenge_MFS(challenges, solutions, wn::DB)\n",
    "    method = challenge -> most_frequent_sense(challenge, wn)\n",
    "    evalute_on_wsd_challenge(challenges, solutions, method)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:   1%|                                         |  ETA: 0:04:46"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "LoadError: InterruptException:\nwhile loading In[87], in expression starting on line 1",
     "output_type": "error",
     "traceback": [
      "LoadError: InterruptException:\nwhile loading In[87], in expression starting on line 1",
      "",
      " in unsafe_view at ./subarray.jl:80 [inlined]",
      " in view at ./subarray.jl:65 [inlined]",
      " in #logprob_of_context#3(::Bool, ::Function, ::AdaGramCompat.AdaGramModel, ::Array{SubString{String},1}, ::SubArray{Float32,1,SharedArray{Float32,3},Tuple{Colon,Int64,Int64},true}) at /mnt_volume/phd/prototypes/SenseSplittingWord2Vec/src/AdaGramCompat.jl:59",
      " in (::Query.#kw##logprob_of_context)(::Array{Any,1}, ::Query.#logprob_of_context, ::AdaGramCompat.AdaGramModel, ::Array{SubString{String},1}, ::SubArray{Float32,1,SharedArray{Float32,3},Tuple{Colon,Int64,Int64},true}) at ./<missing>:0",
      " in #general_wsd#1(::Bool, ::Bool, ::Function, ::AdaGramCompat.AdaGramModel, ::Array{SubString{String},1}, ::Array{SubArray{Float32,1,SharedArray{Float32,3},Tuple{Colon,Int64,Int64},true},1}, ::Array{Float64,1}) at /mnt_volume/phd/prototypes/SenseSplittingWord2Vec/src/SenseAlignment.jl:43",
      " in (::SenseAlignment.#kw##general_wsd)(::Array{Any,1}, ::SenseAlignment.#general_wsd, ::AdaGramCompat.AdaGramModel, ::Array{SubString{String},1}, ::Array{SubArray{Float32,1,SharedArray{Float32,3},Tuple{Colon,Int64,Int64},true},1}, ::Array{Float64,1}) at ./<missing>:0",
      " in #synthesize_embedding#12(::Bool, ::Bool, ::Bool, ::Function, ::AdaGramCompat.AdaGramModel, ::Array{SubString{String},1}, ::String, ::String) at /mnt_volume/phd/prototypes/SenseSplittingWord2Vec/src/SenseAlignment.jl:108",
      " in (::SenseAlignment.#kw##synthesize_embedding)(::Array{Any,1}, ::SenseAlignment.#synthesize_embedding, ::AdaGramCompat.AdaGramModel, ::Array{SubString{String},1}, ::String, ::String) at ./<missing>:0",
      " in #_lexically_informed_embeddings#132(::Array{Any,1}, ::Function, ::WordNet.DB, ::AdaGramCompat.AdaGramModel, ::String, ::String, ::Char) at ./In[69]:12",
      " in (::#kw##_lexically_informed_embeddings)(::Array{Any,1}, ::#_lexically_informed_embeddings, ::WordNet.DB, ::AdaGramCompat.AdaGramModel, ::String, ::String, ::Char) at ./<missing>:0",
      " in (::##134#135{Array{Any,1},Tuple{WordNet.DB,AdaGramCompat.AdaGramModel,String,String,Char}})() at ./In[69]:27",
      " in get!(::##134#135{Array{Any,1},Tuple{WordNet.DB,AdaGramCompat.AdaGramModel,String,String,Char}}, ::Dict{Any,Tuple{Array{Array{Float32,1},1},Array{WordNet.Synset,1},WordNet.Lemma}}, ::Tuple{Tuple{WordNet.DB,AdaGramCompat.AdaGramModel,String,String,Char},Array{Any,1}}) at ./dict.jl:664",
      " in #lexically_informed_embeddings#133(::Array{Any,1}, ::Function, ::WordNet.DB, ::Vararg{Any,N}) at ./In[69]:26",
      " in (::#kw##lexically_informed_embeddings)(::Array{Any,1}, ::#lexically_informed_embeddings, ::WordNet.DB, ::Vararg{Any,N}) at ./<missing>:0",
      " in #supervised_wsd#160(::Bool, ::Bool, ::Bool, ::Bool, ::Function, ::CorpusLoaders.WsdChallenge{SubArray{String,1,Array{String,1},Tuple{Array{Int64,1}},false}}, ::AdaGramCompat.AdaGramModel, ::WordNet.DB) at ./In[85]:8",
      " in (::#kw##supervised_wsd)(::Array{Any,1}, ::#supervised_wsd, ::CorpusLoaders.WsdChallenge{SubArray{String,1,Array{String,1},Tuple{Array{Int64,1}},false}}, ::AdaGramCompat.AdaGramModel, ::WordNet.DB) at ./<missing>:0",
      " in (::##166#167{Array{Any,1},AdaGramCompat.AdaGramModel,WordNet.DB})(::CorpusLoaders.WsdChallenge{SubArray{String,1,Array{String,1},Tuple{Array{Int64,1}},false}}) at ./In[86]:27",
      " in macro expansion at ./In[86]:7 [inlined]",
      " in macro expansion at /home/ubuntu/.julia/v0.5/ProgressMeter/src/ProgressMeter.jl:473 [inlined]",
      " in evalute_on_wsd_challenge(::Array{CorpusLoaders.WsdChallenge{SubArray{String,1,Array{String,1},Tuple{Array{Int64,1}},false}},1}, ::Array{CorpusLoaders.WsdSolution,1}, ::##166#167{Array{Any,1},AdaGramCompat.AdaGramModel,WordNet.DB}) at ./In[86]:5",
      " in (::#kw##evalute_on_wsd_challenge)(::Array{Any,1}, ::#evalute_on_wsd_challenge, ::Array{CorpusLoaders.WsdChallenge{SubArray{String,1,Array{String,1},Tuple{Array{Int64,1}},false}},1}, ::Array{CorpusLoaders.WsdSolution,1}, ::AdaGramCompat.AdaGramModel, ::WordNet.DB) at ./<missing>:0",
      " in include_string(::String, ::String) at ./loading.jl:380",
      " in execute_request_0x535c5df2(::ZMQ.Socket, ::IJulia.Msg) at /home/ubuntu/.julia/v0.5/IJulia/src/execute_request.jl:183",
      " in eventloop(::ZMQ.Socket) at /home/ubuntu/.julia/v0.5/IJulia/src/IJulia.jl:143",
      " in (::IJulia.##26#32)() at ./task.jl:309"
     ]
    }
   ],
   "source": [
    "evalute_on_wsd_challenge(challenges, solutions, am, db;   \n",
    "    normalise_over_context_length = true,\n",
    "    normalize_over_prior = false,\n",
    "    use_prior_for_alignment = false)\n",
    "#(0.7825319805910895,0.7818422212428383,0.7821869488536156) #using first 5 words of gloss if word not found\n",
    "#(0.7847375385972651,0.7840458351696783,0.7843915343915344) #using whole gloss if word not found\n",
    "#(0.7834142037935597\t0.7827236668135743\t0.7830687830687831) #using whole gloss always"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "synthesize_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30-element Array{Float64,1}:\n",
       " 0.0508993  \n",
       " 0.0746286  \n",
       " 0.0819043  \n",
       " 0.0334354  \n",
       " 0.0699029  \n",
       " 0.133938   \n",
       " 0.0746971  \n",
       " 0.0361085  \n",
       " 0.032563   \n",
       " 0.0735142  \n",
       " 0.102609   \n",
       " 0.0471056  \n",
       " 0.0558083  \n",
       " 0.0865038  \n",
       " 0.046381   \n",
       " 8.65113e-7 \n",
       " 1.7389e-7  \n",
       " 3.52441e-8 \n",
       " 7.14442e-9 \n",
       " 1.44827e-9 \n",
       " 2.93583e-10\n",
       " 5.95131e-11\n",
       " 1.20641e-11\n",
       " 2.44555e-12\n",
       " 4.95744e-13\n",
       " 1.00494e-13\n",
       " 2.03714e-14\n",
       " 4.12955e-15\n",
       " 8.37114e-16\n",
       " 2.12839e-16"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_word_sense_priors(am,\"six\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{WordNet.Synset,1}:\n",
       " (n) VI, hexad, 6, six, sextuplet, Captain Hicks, half a dozen, sixer, sise, sextet, sestet (the cardinal number that is the sum of five and one)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synsets(db,db[\"six\",'n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "am.vm.In[:, :, am.dict.word2id[\"six\"]];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 100%|█████████████████████████████████████████| Time: 0:00:23\n",
      "notattempted = 455\n",
      "0.7254685777287762\t0.5799911855442926\t0.6446240509429342\n"
     ]
    }
   ],
   "source": [
    "evalute_on_wsd_challenge(challenges, solutions, ee, db;  \n",
    "MFS_backoff = false,\n",
    "normalise_over_context_length = false,\n",
    "normalize_over_prior = false,\n",
    "use_prior_for_alignment = true\n",
    ") |> x->join(x,\"\\t\") |> println\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7994711326575584"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(length(challenges) - 455)/length(challenges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evalute_on_wsd_challenge(challenges, solutions, am, db;\n",
    "    normalise_over_context_length = true,\n",
    "    normalize_over_prior = true,\n",
    "    use_prior_for_alignment = false)\n",
    "#(0.7860608734009704,0.7853680035257823,0.7857142857142858) #using first 5 words of gloss if word not found\n",
    "#(0.7913542126157918,0.7906566769501984,0.791005291005291) #using whole gloss if word not found\n",
    "#(0.7992942214380239,0.7985896870868224,0.798941798941799)  #using whole gloss always"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evalute_on_wsd_challenge(challenges, solutions, am, db;\n",
    "normalise_over_context_length = false,\n",
    "normalize_over_prior = false,\n",
    "    use_prior_for_alignment = true)\n",
    "#(0.7741508601676224,0.7734684883208461,0.7738095238095237) #using whole gloss always"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evalute_on_wsd_challenge(challenges, solutions, am, db;\n",
    "normalise_over_context_length = false,\n",
    "normalize_over_prior = false,\n",
    "use_prior_for_alignment = false)\n",
    "#(0.7741508601676224,0.7734684883208461,0.7738095238095237) #using whole gloss always"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evalute_on_wsd_challenge(challenges, solutions, am, db;\n",
    "    normalise_over_context_length = true,\n",
    "    normalize_over_prior = true,\n",
    "    use_prior_for_alignment = true)\n",
    "#(0.7860608734009704,0.7853680035257823,0.7857142857142858)  #using first 5 words of gloss if word not found\n",
    "#(0.7913542126157918,0.7906566769501984,0.791005291005291) #using whole gloss if word not found\n",
    "#(0.7992942214380239,0.7985896870868224,0.798941798941799)  #using whole gloss always"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pos(c::eltype(challenges)) = c.pos\n",
    "\n",
    "f1_n = evalute_on_wsd_challenge(challenges[pos.(challenges).=='n'], solutions[pos.(challenges).=='n'], ee, db;\n",
    "    normalise_over_context_length = true,\n",
    "    normalize_over_prior = true,\n",
    "    use_prior_for_alignment = false,\n",
    "    MFS_backoff = true) |>  last\n",
    "print(\"\\t\")\n",
    "\n",
    "f1_v = evalute_on_wsd_challenge(challenges[pos.(challenges).=='v'], solutions[pos.(challenges).=='v'], ee, db;\n",
    "    normalise_over_context_length = true,\n",
    "    normalize_over_prior = true,\n",
    "    use_prior_for_alignment = false,\n",
    "    MFS_backoff = true) |>  last \n",
    "print(\"\\t\")\n",
    "\n",
    "f1_a = evalute_on_wsd_challenge(challenges[pos.(challenges).=='a'], solutions[pos.(challenges).=='a'], ee, db;\n",
    "    normalise_over_context_length = true,\n",
    "    normalize_over_prior = true,\n",
    "    use_prior_for_alignment = false,\n",
    "    MFS_backoff = true) |>  last \n",
    "print(\"\\t\")\n",
    "\n",
    "f1_r = evalute_on_wsd_challenge(challenges[pos.(challenges).=='r'], solutions[pos.(challenges).=='r'], ee, db;\n",
    "    normalise_over_context_length = true,\n",
    "    normalize_over_prior = true,\n",
    "    use_prior_for_alignment = false,\n",
    "    MFS_backoff = true) |>  last \n",
    "print(\"\\n\\n\\n\\n\")\n",
    "print(f1_n,\"\\t\")\n",
    "print(f1_v,\"\\t\")\n",
    "print(f1_a,\"\\t\")\n",
    "print(f1_r,\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "0.7818181818181819\t0.7540425531914893\t0.779184247538678\t0.8888888888888888\n",
    "\t\t\n",
    "\n",
    "println(\"overall: \\t\\t\", evalute_on_wsd_challenge(challenges, solutions, am, db))\n",
    "\n",
    "#println(\"only nouns  : \\t\\t\", \n",
    "#@show nn = evalute_on_wsd_challenge(only_of_pos(challenges,'n'), only_of_pos(solutions,'n'), am, db)\n",
    "#println(\"only verbs  : \\t\\t\", \n",
    "#@show vv = evalute_on_wsd_challenge(only_of_pos(challenges,'v'), only_of_pos(solutions,'v'), am, db)\n",
    "#println(\"only adjecti: \\t\\t\", \n",
    "#@show aa = evalute_on_wsd_challenge(only_of_pos(challenges,'a'), only_of_pos(solutions,'a'), am, db)\n",
    "#println(\"only adverbs: \\t\\t\", \n",
    "#@show rr = evalute_on_wsd_challenge(only_of_pos(challenges,'r'), only_of_pos(solutions,'r'), am, db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "println(\"overall: \\t\\t\", evalute_on_wsd_challenge(challenges, solutions, ee, db))\n",
    "\n",
    "#println(\"only nouns  : \\t\\t\", \n",
    "#@show nn = evalute_on_wsd_challenge(only_of_pos(challenges,'n'), only_of_pos(solutions,'n'), am, db)\n",
    "#println(\"only verbs  : \\t\\t\", \n",
    "#@show vv = evalute_on_wsd_challenge(only_of_pos(challenges,'v'), only_of_pos(solutions,'v'), am, db)\n",
    "#println(\"only adjecti: \\t\\t\", \n",
    "#@show aa = evalute_on_wsd_challenge(only_of_pos(challenges,'a'), only_of_pos(solutions,'a'), am, db)\n",
    "#println(\"only adverbs: \\t\\t\", \n",
    "#@show rr = evalute_on_wsd_challenge(only_of_pos(challenges,'r'), only_of_pos(solutions,'r'), am, db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "println(\"overall: \\t\\t\", evalute_on_wsd_challenge(challenges, solutions, s_am, db))\n",
    "\n",
    "#println(\"only nouns  : \\t\\t\", \n",
    "#@show nn = evalute_on_wsd_challenge(only_of_pos(challenges,'n'), only_of_pos(solutions,'n'), s_am, db)\n",
    "#println(\"only verbs  : \\t\\t\", \n",
    "#@show vv = evalute_on_wsd_challenge(only_of_pos(challenges,'v'), only_of_pos(solutions,'v'), s_am, db)\n",
    "#println(\"only adjecti: \\t\\t\", \n",
    "#@show aa = evalute_on_wsd_challenge(only_of_pos(challenges,'a'), only_of_pos(solutions,'a'), s_am, db)\n",
    "#println(\"only adverbs: \\t\\t\", \n",
    "#@show rr = evalute_on_wsd_challenge(only_of_pos(challenges,'r'), only_of_pos(solutions,'r'), s_am, db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"models/adagram/more_senses.adagram_model.jld\n",
    "### with Adagram Disambig weighting (prior used)\n",
    "### with SemCor data \n",
    "overall: \t\t(0.655408489274304,0.6328779197884531,0.6439461883408072)\n",
    "- nn = evalute_on_wsd_challenge(only_of_pos(challenges,'n'),only_of_pos(solutions,'n'),am,db) = (0.7161410018552876,0.6967509025270758,0.706312900274474)\n",
    "- vv = evalute_on_wsd_challenge(only_of_pos(challenges,'v'),only_of_pos(solutions,'v'),am,db) = (0.5106382978723404,0.4873096446700508,0.4987012987012987)\n",
    "- aa = evalute_on_wsd_challenge(only_of_pos(challenges,'a'),only_of_pos(solutions,'a'),am,db) = (0.6619718309859155,0.649171270718232,0.6555090655509065)\n",
    "- rr = evalute_on_wsd_challenge(only_of_pos(challenges,'r'),only_of_pos(solutions,'r'),am,db) = (0.7268041237113402,0.6778846153846154,0.7014925373134329)\n",
    "\n",
    "### with Adagram Disambig weighting (prior used)\n",
    "### with just glosses \n",
    "\n",
    "overall: \t\t(0.6704701049748973,0.6474217717055972,0.658744394618834)\n",
    "- nn = evalute_on_wsd_challenge(only_of_pos(challenges,'n'),only_of_pos(solutions,'n'),am,db) = (0.7133580705009277,0.694043321299639,0.7035681610247027)\n",
    "- vv = evalute_on_wsd_challenge(only_of_pos(challenges,'v'),only_of_pos(solutions,'v'),am,db) = (0.5780141843971631,0.5516074450084603,0.5645021645021645)\n",
    "- aa = evalute_on_wsd_challenge(only_of_pos(challenges,'a'),only_of_pos(solutions,'a'),am,db) = (0.6535211267605634,0.6408839779005525,0.6471408647140865)\n",
    "- rr = evalute_on_wsd_challenge(only_of_pos(challenges,'r'),only_of_pos(solutions,'r'),am,db) = (0.7319587628865979,0.6826923076923077,0.7064676616915424)\n",
    "\n",
    "\n",
    "\n",
    "# \"semhuff_more_senses.adagram_model.jld\n",
    "\n",
    "### with Adagram Disambig weighting (prior used)\n",
    "### with just glosses \n",
    " - overall: \t\t(0.6704701049748973,0.6474217717055972,0.658744394618834)\n",
    " - nn = evalute_on_wsd_challenge(only_of_pos(challenges,'n'),only_of_pos(solutions,'n'),am,db) = (0.7133580705009277,0.694043321299639,0.7035681610247027)\n",
    " - vv = evalute_on_wsd_challenge(only_of_pos(challenges,'v'),only_of_pos(solutions,'v'),am,db) = (0.5780141843971631,0.5516074450084603,0.5645021645021645)\n",
    " - aa = evalute_on_wsd_challenge(only_of_pos(challenges,'a'),only_of_pos(solutions,'a'),am,db) = (0.6535211267605634,0.6408839779005525,0.6471408647140865)\n",
    " - rr = evalute_on_wsd_challenge(only_of_pos(challenges,'r'),only_of_pos(solutions,'r'),am,db) = (0.7319587628865979,0.6826923076923077,0.7064676616915424)\n",
    " \n",
    " ### with Adagram Disambig weighting (prior used)\n",
    " ### With semcore\n",
    " - overall: \t\t(0.6134185303514377,0.5923314235345968,0.6026905829596412)\n",
    " - nn = evalute_on_wsd_challenge(only_of_pos(challenges,'n'),only_of_pos(solutions,'n'),s_am,db) = (0.6252319109461967,0.6083032490974729,0.6166514181152789)\n",
    " - vv = evalute_on_wsd_challenge(only_of_pos(challenges,'v'),only_of_pos(solutions,'v'),s_am,db) = (0.5638297872340425,0.5380710659898477,0.5506493506493505)\n",
    " - aa = evalute_on_wsd_challenge(only_of_pos(challenges,'a'),only_of_pos(solutions,'a'),s_am,db) = (0.6169014084507042,0.6049723756906077,0.610878661087866)\n",
    " - rr = evalute_on_wsd_challenge(only_of_pos(challenges,'r'),only_of_pos(solutions,'r'),s_am,db) = (0.6855670103092784,0.6394230769230769,0.6616915422885572)\n",
    " \n",
    " \n",
    " # Most Frequent Sense\n",
    " \n",
    "  -  overall: \t\t(0.7783164389598942,0.7783164389598942,0.7783164389598942)\n",
    "  - only nouns  : \t\t(0.7653429602888087,0.7653429602888087,0.7653429602888087)\n",
    "  - only verbs  : \t\t(0.7529610829103215,0.7529610829103215,0.7529610829103215)\n",
    "  - only adjecti: \t\t(0.8038674033149171,0.8038674033149171,0.8038674033149171)\n",
    "  - only adverbs: \t\t(0.875,0.875,0.875)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "println(\"overall: \\t\\t\", evalute_on_wsd_challenge(challenges, solutions, ee, db))\n",
    "\n",
    "#println(\"only nouns  : \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'n'), only_of_pos(solutions,'n'), ee, db))\n",
    "#println(\"only verbs  : \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'v'), only_of_pos(solutions,'v'), ee, db))\n",
    "#println(\"only adjecti: \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'a'), only_of_pos(solutions,'a'), ee, db))\n",
    "#println(\"only adverbs: \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'r'), only_of_pos(solutions,'r'), ee, db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "println(\"overall: \\t\\t\", evalute_on_wsd_challenge_MFS(challenges, solutions, db))\n",
    "\n",
    "#println(\"only nouns  : \\t\\t\", evalute_on_wsd_challenge_MFS(only_of_pos(challenges,'n'), only_of_pos(solutions,'n'), db))\n",
    "#println(\"only verbs  : \\t\\t\", evalute_on_wsd_challenge_MFS(only_of_pos(challenges,'v'), only_of_pos(solutions,'v'), db))\n",
    "#println(\"only adjecti: \\t\\t\", evalute_on_wsd_challenge_MFS(only_of_pos(challenges,'a'), only_of_pos(solutions,'a'), db))\n",
    "#println(\"only adverbs: \\t\\t\", evalute_on_wsd_challenge_MFS(only_of_pos(challenges,'r'), only_of_pos(solutions,'r'), db))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Zero shot WSI for 1 shot WSD\n",
    "using Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rr = FixedWordSenseEmbedding(ee.dimension, random_inited, huffman_tree; initial_nsenses=50)\n",
    "rr.corpus_size = ee.corpus_size\n",
    "rr.distribution = ee.distribution\n",
    "rr.codebook = ee.codebook\n",
    "rr.classification_tree = ee.classification_tree\n",
    "Training.initialize_embedding(rr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rr.embedding[\"us\"] |> length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "println(\"overall: \\t\\t\", evalute_on_wsd_challenge(challenges, solutions, rr, db))\n",
    "\n",
    "println(\"only nouns  : \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'n'), only_of_pos(solutions,'n'), rr, db))\n",
    "println(\"only verbs  : \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'v'), only_of_pos(solutions,'v'), rr, db))\n",
    "println(\"only adjecti: \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'a'), only_of_pos(solutions,'a'), rr, db))\n",
    "println(\"only adverbs: \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'r'), only_of_pos(solutions,'r'), rr, db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hh = deepcopy(rr)\n",
    "for word in keys(rr.embedding)\n",
    "    append!(hh.embedding[word], ee.embedding[word])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "println(\"overall: \\t\\t\", evalute_on_wsd_challenge(challenges, solutions, hh, db))\n",
    "\n",
    "println(\"only nouns  : \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'n'), only_of_pos(solutions,'n'), hh, db))\n",
    "println(\"only verbs  : \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'v'), only_of_pos(solutions,'v'), hh, db))\n",
    "println(\"only adjecti: \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'a'), only_of_pos(solutions,'a'), hh, db))\n",
    "println(\"only adverbs: \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'r'), only_of_pos(solutions,'r'), hh, db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(\"CorpusLoaders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mapping_corpus = CorpusLoaders.lazyload_semcor(\"data/corpora/semcor2.1/brown1/tagfiles/\", 10) |> collect;\n",
    "append!(mapping_corpus, CorpusLoaders.lazyload_semcor(\"data/corpora/semcor2.1/brown2/tagfiles/\", 10)|> collect);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "identify (generic function with 2 methods)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function identify(::PosTaggedWord, wn::DB,ee)\n",
    "    throw(KeyError(\"No sense in a PosTaggedWord\"))\n",
    "end\n",
    "\n",
    "function identify(taggedword::SenseAnnotatedWord, wn::DB,ee)\n",
    "    pos = pennPOStoWordNetPOS(taggedword.pos)\n",
    "    wn_sensekeys = sensekeys(wn, wn[pos, taggedword.lemma])\n",
    "    nsenses = length(wn_sensekeys)\n",
    "    \n",
    "    target_wnsn = findfirst(wn_sensekeys .== sensekey(taggedword))\n",
    "    target_wnsn==0 && throw(KeyError(\"$(sensekey(taggedword)) not in  $(wn_sensekeys).\\n\\nIssue is with $taggedword\"))\n",
    "\n",
    "    wvs = all_word_sense_vectors(ee,taggedword.word, taggedword.lemma)\n",
    "    priors = all_word_sense_priors(ee,taggedword.word, taggedword.lemma)\n",
    "    length(wvs) == 0 && throw(KeyError(\"No embedding for $(taggedword.word); skipping\"))\n",
    "    \n",
    "    target_wnsn, nsenses, pos, wvs, priors\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agirresAlignment (generic function with 2 methods)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function agirresAlignment(ee, wn::DB, mapping_corpus, hard=true)\n",
    "    maps = Dict{Tuple{String, String, Char}, Matrix{Float32}}()\n",
    "    freqs = Dict{Tuple{String, String, Char}, Vector{Int}}()\n",
    "    \n",
    "    function proc_word(word::PosTaggedWord, sentence)\n",
    "    end\n",
    "    \n",
    "    function proc_word(taggedword::SenseAnnotatedWord, sentence)\n",
    "        local target_wnsn, nsenses, pos, wvs, priors\n",
    "        try\n",
    "            target_wnsn, nsenses, pos, wvs, priors = identify(taggedword, wn::DB,ee)\n",
    "        catch err\n",
    "            typeof(err)<:KeyError ||rethrow(ee)\n",
    "            return\n",
    "        end\n",
    "        ########\n",
    "        \n",
    "        map = get!(maps, (taggedword.word, taggedword.lemma, pos)) do\n",
    "            zeros(length(wvs), nsenses)\n",
    "        end\n",
    "        \n",
    "        freq = get!(freqs, (taggedword.word, taggedword.lemma, pos)) do \n",
    "            zeros(Int, nsenses)\n",
    "        end\n",
    "        \n",
    "        context = lowercase.(strip_tags(sentence))\n",
    "        wv_probs = general_wsd(ee,context, wvs, priors)\n",
    "        @assert(length(wv_probs) == length(wvs))\n",
    "        @assert sum(wv_probs) ≈ 1f0\n",
    "        @assert !any(isnan.(wv_probs))\n",
    "        freq[target_wnsn] += 1\n",
    "        if hard\n",
    "            map[indmax(wv_probs),target_wnsn] += 1\n",
    "        else\n",
    "            @assert(length(map[:,target_wnsn]) == length(wv_probs),\n",
    "            \"$(length(map[:,target_wnsn])) != $(length(wv_probs)) for \\\"$(taggedword.lemma)\\\"\"           \n",
    "            )\n",
    "            map[:,target_wnsn] += wv_probs\n",
    "        end\n",
    "        \n",
    "    end\n",
    "    \n",
    "    @showprogress for (word, sentence) in mapping_corpus\n",
    "        proc_word(word, sentence)\n",
    "    end\n",
    " \n",
    "    \n",
    "    @showprogress for ((word, lem, pos), freq) in freqs\n",
    "        mm = maps[(word, lem, pos)]\n",
    "        mm ./= freq'\n",
    "        mm[isnan.(mm)] = 0f0 #NaNs are just frequency 0 items\n",
    "        @assert(all(isapprox.(sum(mm, 1), 1f0; atol=1f-5) \n",
    "                    | isapprox.(sum(mm, 1), 0f0; atol=1f-5)), \n",
    "                    \"($word , $pos) not sum to one, $(sum(mm,1))\")\n",
    "    end\n",
    "\n",
    "    maps, freqs\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evalute_on_wsd_challenge (generic function with 3 methods)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nobackoff(challenge, ee, wn) = Nullable{String}()\n",
    "MSF_backoff(challenge, ee, wn) = most_frequent_sense(challenge, wn)\n",
    "refitting_backoff(challenge, ee, wn) = supervised_wsd(challenge, ee, wn::DB; \n",
    "    normalise_over_context_length =true,\n",
    "    normalize_over_prior =true,\n",
    "    use_prior_for_alignment = true,\n",
    "    MFS_backoff = false\n",
    ")\n",
    "\n",
    "function mapped_wsd(challenge, ee, wn::DB, maps::Associative{Tuple{String, String, Char}, Matrix{Float32}};\n",
    "                    backoff = nobackoff)\n",
    "    l_smoothing = 1\n",
    "    l_c_smoothing = 1\n",
    "    try\n",
    "        lem = wn[challenge.lemma, challenge.pos]\n",
    "        target_synsets = synsets(wn, lem)\n",
    "        \n",
    "        wvs = all_word_sense_vectors(ee, challenge.word)\n",
    "        length(wvs) > 0 || throw(KeyError(\"No embeddings for \"*challenge.word))\n",
    "        \n",
    "        p_l = Float32[sensecount(db, l_i, lem) for l_i in target_synsets]\n",
    "        p_l .+= l_smoothing\n",
    "        p_l./=sum(p_l)\n",
    "\n",
    "        p_u_c = general_wsd(ee,challenge.context, wvs)\n",
    "\n",
    "        pseudo_p_l_uc = maps[challenge.word, challenge.lemma, challenge.pos]\n",
    "        p_l_c = vec(p_u_c'*pseudo_p_l_uc)\n",
    "        p_l_c.+= -1*min(minimum(p_l_c),0.0) + l_c_smoothing\n",
    "        p_l_c./=sum(p_l_c)\n",
    "        @assert(all(p_l_c.>=0), p_l_c)\n",
    "        \n",
    "        probs_of_sense = sqrt(p_l_c.*p_l)\n",
    "        \n",
    "        sense_index= indmax(probs_of_sense)        \n",
    "        synset = target_synsets[sense_index]\n",
    "        sk = sensekey(wn, synset, lem)\n",
    "        Nullable(sk)\n",
    "    catch ex\n",
    "        isa(ex, KeyError) || rethrow(ex)\n",
    "        backoff(challenge,ee,wn)\n",
    "    end   \n",
    "end\n",
    "\n",
    "function evalute_on_wsd_challenge(challenges, solutions, ee, wn::DB, maps; backoff=nobackoff)\n",
    "    method = challenge -> mapped_wsd(challenge, ee, wn, maps; backoff=backoff)\n",
    "    evalute_on_wsd_challenge(challenges, solutions, method)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:   0%|                                         |  ETA: 0:34:27"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "LoadError: InterruptException:\nwhile loading In[48], in expression starting on line 1",
     "output_type": "error",
     "traceback": [
      "LoadError: InterruptException:\nwhile loading In[48], in expression starting on line 1",
      "",
      " in #logprob_of_context#3(::Bool, ::Function, ::AdaGramCompat.AdaGramModel, ::Array{String,1}, ::SubArray{Float32,1,SharedArray{Float32,3},Tuple{Colon,Int64,Int64},true}) at /mnt_volume/phd/prototypes/SenseSplittingWord2Vec/src/AdaGramCompat.jl:59",
      " in (::Query.#kw##logprob_of_context)(::Array{Any,1}, ::Query.#logprob_of_context, ::AdaGramCompat.AdaGramModel, ::Array{String,1}, ::SubArray{Float32,1,SharedArray{Float32,3},Tuple{Colon,Int64,Int64},true}) at ./<missing>:0",
      " in #general_wsd#1(::Bool, ::Bool, ::Function, ::AdaGramCompat.AdaGramModel, ::Array{String,1}, ::Array{SubArray{Float32,1,SharedArray{Float32,3},Tuple{Colon,Int64,Int64},true},1}, ::Array{Float64,1}) at /mnt_volume/phd/prototypes/SenseSplittingWord2Vec/src/SenseAlignment.jl:43",
      " in (::#proc_word#26{AdaGramCompat.AdaGramModel,WordNet.DB,Bool,Dict{Tuple{String,String,Char},Array{Float32,2}},Dict{Tuple{String,String,Char},Array{Int64,1}}})(::CorpusLoaders.SenseAnnotatedWord{SubString{String}}, ::SubArray{CorpusLoaders.TaggedWord,1,Array{CorpusLoaders.TaggedWord,1},Tuple{Array{Int64,1}},false}) at ./In[15]:27",
      " in macro expansion at ./In[15]:44 [inlined]",
      " in macro expansion at /home/ubuntu/.julia/v0.5/ProgressMeter/src/ProgressMeter.jl:473 [inlined]",
      " in agirresAlignment(::AdaGramCompat.AdaGramModel, ::WordNet.DB, ::Array{Tuple{CorpusLoaders.SenseAnnotatedWord{SubString{String}},SubArray{CorpusLoaders.TaggedWord,1,Array{CorpusLoaders.TaggedWord,1},Tuple{Array{Int64,1}},false}},1}, ::Bool) at ./In[15]:43",
      " in include_string(::String, ::String) at ./loading.jl:380",
      " in execute_request_0x535c5df2(::ZMQ.Socket, ::IJulia.Msg) at /home/ubuntu/.julia/v0.5/IJulia/src/execute_request.jl:183",
      " in eventloop(::ZMQ.Socket) at /home/ubuntu/.julia/v0.5/IJulia/src/IJulia.jl:143",
      " in (::IJulia.##26#32)() at ./task.jl:309"
     ]
    }
   ],
   "source": [
    "maps_hard_am, freqs  = agirresAlignment(am, db, mapping_corpus, true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:  20%|████████                                 |  ETA: 0:00:26ex = KeyError(\" SubString{String}[\\\"noncompetitively\\\"], nor SubString{String}[\\\"noncompetitively\\\"] have embeddings\")\n",
      "Progress:  25%|██████████                               |  ETA: 0:00:24ex = KeyError(\" SubString{String}[\\\"semiliterate\\\"], nor SubString{String}[\\\"semiliterate\\\"] have embeddings\")\n",
      "Progress: 100%|█████████████████████████████████████████| Time: 0:00:34\n",
      "notattempted = 2\n",
      "overall: \t\t(0.78429642699603,0.7836051123843103,0.7839506172839507)\n"
     ]
    }
   ],
   "source": [
    "println(\"overall: \\t\\t\", evalute_on_wsd_challenge(\n",
    "challenges, solutions, am, db, maps_hard_am;\n",
    "backoff = refitting_backoff\n",
    "))\n",
    "\n",
    "#maps_soft(am) overall: \t\t(0.6897311591009255,0.6897311591009255,0.6897311591009255\n",
    "#maps_hard(am) overall: \t\t(0.7814014984574702,0.7814014984574702,0.7814014984574703)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Int(95//100 * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8431026884089907"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(length(challenges) - 356)/length(challenges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function matrix_from_rows{T}(Xs::Vector{Vector{T}})\n",
    "    ret = Matrix{T}(length(Xs), length(first(Xs)))\n",
    "    for (ii,row) in enumerate(Xs)\n",
    "        @inbounds ret[ii,:] = row\n",
    "    end\n",
    "    ret\n",
    "end\n",
    "\n",
    "function bestfact!(x)\n",
    "    if size(x,1)<size(x,2)\n",
    "        svdfact!(x)\n",
    "    elseif size(x,1)>=size(x,2)\n",
    "        qrfact!(x, Val{true})\n",
    "    #else\n",
    "    #    @assert(size(x,1)==size(x,2))\n",
    "    #    lufact!(x)\n",
    "    end\n",
    "end\n",
    "\n",
    "function leastSquaresAlignment(ee, wn::DB, mapping_corpus, hard=true)\n",
    "    vars = Dict{Tuple{String, String, Char}, Tuple{Vector{Vector{Float32}}, Vector{Vector{Float32}}}}()\n",
    "    \n",
    "    function proc_word(word::TaggedWord, sentence::TaggedSentence)\n",
    "    end\n",
    "    \n",
    "    function proc_word(taggedword::SenseAnnotatedWord, sentence::TaggedSentence)\n",
    "        local target_wnsn, nsenses, pos, wvs\n",
    "        try\n",
    "            target_wnsn, nsenses, pos, wvs = identify(taggedword, wn::DB,ee)\n",
    "        catch err\n",
    "            typeof(err)<:KeyError ||rethrow(ee)\n",
    "            return\n",
    "        end\n",
    "        ########\n",
    "        \n",
    "        Xs, Ys = get!(vars, (taggedword.word, taggedword.lemma, pos)) do\n",
    "            Vector{Vector{Float32}}(), Vector{Vector{Float32}}()\n",
    "        end    \n",
    "        \n",
    "        context = lowercase.(strip_tags(sentence))\n",
    "        wv_probs = general_wsd(ee,context, wvs)\n",
    "        @assert(length(wv_probs) == length(wvs))\n",
    "        @assert sum(wv_probs) ≈ 1f0\n",
    "        @assert !any(isnan.(wv_probs))\n",
    "        push!(Xs, wv_probs)\n",
    "        y = zeros(nsenses)\n",
    "        y[target_wnsn] = 1f0\n",
    "        push!(Ys, y)\n",
    "    end\n",
    "    \n",
    "    @showprogress for sentence in mapping_corpus\n",
    "        for word in sentence\n",
    "            proc_word(word, sentence)\n",
    "        end\n",
    "    end\n",
    " \n",
    "    maps = Dict{Tuple{String, String, Char}, Matrix{Float32}}()\n",
    "    \n",
    "    @showprogress for (key, (Xs,Ys)) in vars\n",
    "        X = matrix_from_rows(Xs)\n",
    "        Y = matrix_from_rows(Ys)\n",
    "        try \n",
    "            maps[key] = bestfact!(X)\\Y\n",
    "        catch err\n",
    "            @show X\n",
    "            println(\"-\"^30)\n",
    "            @show Y\n",
    "            rethrow(err)\n",
    "        end    \n",
    "    end\n",
    "\n",
    "    maps\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maps_ls_am = leastSquaresAlignment(am, db, mapping_corpus);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "println(\"overall: \\t\\t\", evalute_on_wsd_challenge(challenges, solutions, am, db, maps_ls_am))\n",
    "#am, db, maps_ls_am overall: \t\t(0.753195240193918,0.753195240193918,0.7531952401939179)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "split(\"it was a brutal war by all accounts\")\n",
    "word = civil "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#maps = deepcopy(maps_ls_am);\n",
    "\n",
    "\n",
    "p_u_c = general_wsd(am, split(\"our regular lunchtime was bread and cheese\"), all_word_sense_vectors(am,key[1]))\n",
    "v = mm'*p_u_c\n",
    "v./=sum(v)\n",
    "v.*= p_l\n",
    "@show v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "key, mm = drop(maps,500) |> first |> deepcopy \n",
    "mm+=1\n",
    "@show key\n",
    "@show size(mm)\n",
    "ss = synsets(db, db[key[2:end]...])\n",
    "display(ss)\n",
    "\n",
    "p_l = Float32[sensecount(db, ss_i, db[key[2:end]...]) for ss_i in ss]\n",
    "p_l +=1\n",
    "p_l./=sum(p_l)\n",
    "display(p_l)\n",
    "\n",
    "p_u_c = general_wsd(am, split(\"it was a very expensive for the taxi\"), all_word_sense_vectors(am,key[1]))\n",
    "v = p_u_c'*mm\n",
    "v./=sum(v)\n",
    "vec(v).*p_l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function hybrid_wsd(challenge, ee, wn::DB, maps::Associative{Tuple{String, String, Char}, Matrix{Float32}})\n",
    "\n",
    "end\n",
    "\n",
    "function evalute_on_wsd_challenge_hybrid(challenges, solutions, ee, wn::DB, maps)\n",
    "    method = challenge -> hybrid_wsd(challenge, ee, wn, maps)\n",
    "    evalute_on_wsd_challenge(challenges, solutions, method)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "println(\"overall: \\t\\t\", evalute_on_wsd_challenge_hybrid(challenges, solutions, am, db, maps_ls_am))\n",
    "#am, db, maps_ls_am overall: \t\t(0.753195240193918,0.753195240193918,0.7531952401939179)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.0-rc0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
