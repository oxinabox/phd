{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(\"Utils\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using ProgressMeter\n",
    "using SwiftObjectStores\n",
    "using CorpusLoaders\n",
    "using WordNet\n",
    "using AdaGram\n",
    "using AdaGramCompat\n",
    "using WordEmbeddings, SoftmaxClassifier\n",
    "using Utils\n",
    "using Query\n",
    "using Distances\n",
    "using JLD\n",
    "\n",
    "using SenseAlignment\n",
    "\n",
    "importfrom(CorpusLoaders, :sensekey)\n",
    "importfrom(WordNet, :sensekey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordNet.DB"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const WN_PATH=\"data/corpora/WordNet-2.1/\"\n",
    "#WN_PATH3 = \"/usr/share/nltk_data/corpora/wordnet/\"\n",
    "db = DB(WN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#am = AdaGramCompat.AdaGramModel(load_model(\"models/adagram/v1_d100.adagram_model\")...)\n",
    "#am = AdaGramModel(load_model(\"models/adagram/more_senses.adagram_model\")...)\n",
    "#am = open(deserialize,\"models/adagram/more_senses.adagram_model.jsz\", \"r\");\n",
    "am = load(\"models/adagram/more_senses.adagram_model.jld\", \"am\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s_am = get_jld(SwiftService(), \"sensemodels\", \"adagram/semhuff_more_senses.adagram_model.jld\", \"am\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ee = restore(\"models/ss/tokenised_lowercase_WestburyLab.wikicorp.201004_100_i1.jld\");\n",
    "ee = load(\"models/ss/tokenised_lowercase_WestburyLab.wikicorp.201004_100_i1.jld\", \"ee\")\n",
    "\n",
    "#ee = restore(\"models/ss/keep/tokenised_lowercase_WestburyLab.wikicorp.201004_50__m170000000.model\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "challenges = load_challenges_semeval2007t7(\"data/corpora/wsd/semeval2007_t7/test/eng-coarse-all-words.xml\");\n",
    "solutions = load_solutions_semeval2007t7(\"data/corpora/wsd/semeval2007_t7/key/dataset21.test.key\");\n",
    "semcor = index_semcor(lazyload_semcor(\"data/corpora/semcor2.1/brown1/tagfiles/\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element SubArray{String,1,Array{String,1},Tuple{Array{Int64,1}},false}:\n",
       " \"fire\"  \n",
       " \"can\"   \n",
       " \"be\"    \n",
       " \"built;\"\n",
       " \"\\\"the\" \n",
       " \"was\"   \n",
       " \"so\"    \n",
       " \"large\" \n",
       " \"you\"   \n",
       " \"could\" "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function window(context, index::Int, window_size::Int=10)\n",
    "    window_lower_bound = max(index - window_size÷2, 1)\n",
    "    window_upper_bound = min(index + window_size÷2, length(context))\n",
    "    view(context, [window_lower_bound:index-1 ; index+1:window_upper_bound])\n",
    "end\n",
    "\n",
    "function window(tagged_sense::TaggedSentence, index::Int, window_size::Int=10)\n",
    "    context = lowercase.(strip_tags(tagged_sense))\n",
    "    window(context, index, window_size)\n",
    "end\n",
    "   \n",
    "function window(context, word::AbstractString, window_size::Int=10)\n",
    "    context = lowercase.(context)\n",
    "    occurances = find(context.==word)\n",
    "    index =  length(occurances) > 0 ? occurances[ceil(Int, end/2)] : 0\n",
    "    window(context, index, window_size)\n",
    "\n",
    "end\n",
    "\n",
    "\n",
    "window((drop(semcor,400) |> first |> last |> first)...)\n",
    "\n",
    "window((synsets(db, db[\"fireplace\", 'n']) |> first).gloss |> split, \"fireplace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_all_usages (generic function with 1 method)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"Collect up the usages from a indexed tagged source\"\n",
    "function get_usages(usage_index::SemcorIndex, key)\n",
    "    if haskey(usage_index, key)\n",
    "        [window(lowercase.(strip_tags(sent)), index) for (sent, index) in usage_index[key]]\n",
    "    else\n",
    "        Vector{String}[]\n",
    "    end\n",
    "end\n",
    "\n",
    "function get_usages(synset::Synset, lemma_word::AbstractString)\n",
    "    gloss::Vector{SubString{String}} = lowercase.(punctuation_space_tokenize(synset.gloss))\n",
    "    [window(gloss, lemma_word)]\n",
    "end\n",
    "\n",
    "function get_all_usages(wn::DB, semcor::SemcorIndex, lemma_word, pos)   \n",
    "    lemma = db[pos, lemma_word]\n",
    "    target_synsets::Vector{Synset} = synsets(db, lemma)\n",
    "    \n",
    "    Dict{Synset,AbstractVector{AbstractVector}}((synset => get_usages(synset, lemma_word)\n",
    "        #[get_usages(semcor, sensekey(db, synset, lemma)); get_usages(synset, lemma_word)]\n",
    "                    for synset in target_synsets))  \n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lexically_informed_embeddings (generic function with 2 methods)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_identical(col) = length(col)==1 || !any(x->x!=col[1],col[2:end])\n",
    "\n",
    "function _lexically_informed_embeddings(wn::DB,ee, word,lemma_word, pos)\n",
    "    indexed_corpus = semcor #TODO: Pass this as a parameter, not as a gloel\n",
    "    target_synset_examples = get_all_usages(wn, indexed_corpus, lemma_word, pos)\n",
    "    target_synsets = collect(keys(target_synset_examples))\n",
    "    lem = db[lemma_word, pos]\n",
    "        \n",
    "    embeddings = Vector{Vector{Float32}}(length(target_synsets))\n",
    "    for (ii,(synset, examples)) in enumerate(target_synset_examples)\n",
    "        context::Vector{SubString{String}} = vcat(examples...)\n",
    "        embeddings[ii] =synthesize_embedding(ee,context, word, lemma_word)\n",
    "    end\n",
    "        \n",
    "    \n",
    "    if all_identical(embeddings)\n",
    "        #Use MCWS\n",
    "        score, index = findmax(sensecount(db, ss, lem ) for ss in target_synsets)\n",
    "        target_synsets=[target_synsets[index]] # Throw out others\n",
    "        embeddings=[embeddings[1]]\n",
    "    end\n",
    "        \n",
    "    embeddings,target_synsets,lem\n",
    "end\n",
    "\n",
    "lexically_informed_embeddings(wn::DB, ee, lemma_word, pos) = lexically_informed_embeddings(db,ee, lemma_word, lemma_word, pos)\n",
    "        \n",
    "_li_embeddings = Dict{Tuple{DB, Any, String, String, Char}, Tuple{Vector{Vector{Float32}}, Vector{Synset}, Lemma}}()\n",
    "function lexically_informed_embeddings(wn::DB, ee, word,lemma_word, pos)\n",
    "    get!(_li_embeddings, (wn, ee, word, lemma_word, pos)) do\n",
    "        _lexically_informed_embeddings(wn, ee, word, lemma_word, pos)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "most_frequent_sense (generic function with 1 method)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function supervised_wsd(challenge, ee, wn::DB)\n",
    "    try\n",
    "        embeddings,target_synsets,lem = lexically_informed_embeddings(wn,ee,\n",
    "                                                            challenge.word, \n",
    "                                                            challenge.lemma, challenge.pos)\n",
    "        \n",
    "        priors = [float(sensecount(db, ss, lem)) for ss in target_synsets] #TODO use thing\n",
    "        priors .+= 100\n",
    "        #priors .+= sqrt(sum(priors))/length(priors)\n",
    "        priors ./= sum(priors)\n",
    "        probs_of_sense = general_wsd(ee, challenge.context, embeddings, priors)\n",
    "               \n",
    "     \n",
    "        sense_index= indmax(probs_of_sense)        \n",
    "        synset = target_synsets[sense_index]\n",
    "        sk = sensekey(wn, synset, lem)\n",
    "        Nullable(sk)\n",
    "    catch ex\n",
    "        isa(ex, KeyError) || rethrow(ex)\n",
    "        @show ex\n",
    "        Nullable{String}()\n",
    "    end\n",
    "end\n",
    "\n",
    "function most_frequent_sense(challenge, wn::DB)\n",
    "    try\n",
    "        lem = wn[challenge.pos, challenge.lemma]\n",
    "        target_synsets::Vector{Synset} = synsets(db, lem)\n",
    "        \n",
    "        sense_freqs =  Float32[sensecount(db, ss, lem) for ss in target_synsets]\n",
    "        sense_index= indmax(sense_freqs)\n",
    "        synset = target_synsets[sense_index]\n",
    "        \n",
    "        sk = sensekey(wn, synset,  lem)\n",
    "        Nullable(sk)\n",
    "    catch ex\n",
    "        isa(ex, KeyError) || rethrow(ex)\n",
    "        Nullable{String}()\n",
    "    end\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evalute_on_wsd_challenge_MFS (generic function with 1 method)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function evalute_on_wsd_challenge(challenges, solutions, method)\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    notattempted = 0\n",
    "    @showprogress for (challenge, ground_solution) in zip(challenges, solutions)\n",
    "        assert(challenge.id == ground_solution.id)\n",
    "        output_sense = method(challenge)\n",
    "        if isnull(output_sense)\n",
    "            notattempted+=1\n",
    "        else\n",
    "            if get(output_sense) ∈ ground_solution.solutions\n",
    "                correct+=1\n",
    "            else\n",
    "                incorrect+=1\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    @show notattempted\n",
    "    precision = correct/(correct+incorrect)\n",
    "    recall = correct/(correct+incorrect+notattempted)\n",
    "    f1 = (2*precision*recall) / (precision+recall)\n",
    "    return precision, recall, f1\n",
    "end\n",
    "    \n",
    "    \n",
    "function evalute_on_wsd_challenge(challenges, solutions, ee, wn::DB)\n",
    "    method = challenge -> supervised_wsd(challenge, ee, wn)\n",
    "    evalute_on_wsd_challenge(challenges, solutions, method)\n",
    "end\n",
    "\n",
    "function evalute_on_wsd_challenge_MFS(challenges, solutions, wn::DB)\n",
    "    method = challenge -> most_frequent_sense(challenge, wn)\n",
    "    evalute_on_wsd_challenge(challenges, solutions, method)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:  19%|████████                                 |  ETA: 0:00:08ex = KeyError(\" SubString{String}[\\\"noncompetitively\\\"], nor SubString{String}[\\\"noncompetitively\\\"] have embeddings\")\n",
      "Progress:  23%|██████████                               |  ETA: 0:00:08ex = KeyError(\" SubString{String}[\\\"semiliterate\\\"], nor SubString{String}[\\\"semiliterate\\\"] have embeddings\")\n",
      "Progress: 100%|█████████████████████████████████████████| Time: 0:00:09\n",
      "notattempted = 2\n",
      "overall: \t\t(0.7953242170269078,0.7946231820185103,0.794973544973545)\n"
     ]
    }
   ],
   "source": [
    "println(\"overall: \\t\\t\", evalute_on_wsd_challenge(challenges, solutions, am, db))\n",
    "\n",
    "#println(\"only nouns  : \\t\\t\", \n",
    "#@show nn = evalute_on_wsd_challenge(only_of_pos(challenges,'n'), only_of_pos(solutions,'n'), am, db)\n",
    "#println(\"only verbs  : \\t\\t\", \n",
    "#@show vv = evalute_on_wsd_challenge(only_of_pos(challenges,'v'), only_of_pos(solutions,'v'), am, db)\n",
    "#println(\"only adjecti: \\t\\t\", \n",
    "#@show aa = evalute_on_wsd_challenge(only_of_pos(challenges,'a'), only_of_pos(solutions,'a'), am, db)\n",
    "#println(\"only adverbs: \\t\\t\", \n",
    "#@show rr = evalute_on_wsd_challenge(only_of_pos(challenges,'r'), only_of_pos(solutions,'r'), am, db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "println(\"overall: \\t\\t\", evalute_on_wsd_challenge(challenges, solutions, s_am, db))\n",
    "\n",
    "#println(\"only nouns  : \\t\\t\", \n",
    "#@show nn = evalute_on_wsd_challenge(only_of_pos(challenges,'n'), only_of_pos(solutions,'n'), s_am, db)\n",
    "#println(\"only verbs  : \\t\\t\", \n",
    "#@show vv = evalute_on_wsd_challenge(only_of_pos(challenges,'v'), only_of_pos(solutions,'v'), s_am, db)\n",
    "#println(\"only adjecti: \\t\\t\", \n",
    "#@show aa = evalute_on_wsd_challenge(only_of_pos(challenges,'a'), only_of_pos(solutions,'a'), s_am, db)\n",
    "#println(\"only adverbs: \\t\\t\", \n",
    "#@show rr = evalute_on_wsd_challenge(only_of_pos(challenges,'r'), only_of_pos(solutions,'r'), s_am, db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"models/adagram/more_senses.adagram_model.jld\n",
    "### with Adagram Disambig weighting (prior used)\n",
    "### with SemCor data \n",
    "overall: \t\t(0.655408489274304,0.6328779197884531,0.6439461883408072)\n",
    "- nn = evalute_on_wsd_challenge(only_of_pos(challenges,'n'),only_of_pos(solutions,'n'),am,db) = (0.7161410018552876,0.6967509025270758,0.706312900274474)\n",
    "- vv = evalute_on_wsd_challenge(only_of_pos(challenges,'v'),only_of_pos(solutions,'v'),am,db) = (0.5106382978723404,0.4873096446700508,0.4987012987012987)\n",
    "- aa = evalute_on_wsd_challenge(only_of_pos(challenges,'a'),only_of_pos(solutions,'a'),am,db) = (0.6619718309859155,0.649171270718232,0.6555090655509065)\n",
    "- rr = evalute_on_wsd_challenge(only_of_pos(challenges,'r'),only_of_pos(solutions,'r'),am,db) = (0.7268041237113402,0.6778846153846154,0.7014925373134329)\n",
    "\n",
    "### with Adagram Disambig weighting (prior used)\n",
    "### with just glosses \n",
    "\n",
    "overall: \t\t(0.6704701049748973,0.6474217717055972,0.658744394618834)\n",
    "- nn = evalute_on_wsd_challenge(only_of_pos(challenges,'n'),only_of_pos(solutions,'n'),am,db) = (0.7133580705009277,0.694043321299639,0.7035681610247027)\n",
    "- vv = evalute_on_wsd_challenge(only_of_pos(challenges,'v'),only_of_pos(solutions,'v'),am,db) = (0.5780141843971631,0.5516074450084603,0.5645021645021645)\n",
    "- aa = evalute_on_wsd_challenge(only_of_pos(challenges,'a'),only_of_pos(solutions,'a'),am,db) = (0.6535211267605634,0.6408839779005525,0.6471408647140865)\n",
    "- rr = evalute_on_wsd_challenge(only_of_pos(challenges,'r'),only_of_pos(solutions,'r'),am,db) = (0.7319587628865979,0.6826923076923077,0.7064676616915424)\n",
    "\n",
    "\n",
    "\n",
    "# \"semhuff_more_senses.adagram_model.jld\n",
    "\n",
    "### with Adagram Disambig weighting (prior used)\n",
    "### with just glosses \n",
    " - overall: \t\t(0.6704701049748973,0.6474217717055972,0.658744394618834)\n",
    " - nn = evalute_on_wsd_challenge(only_of_pos(challenges,'n'),only_of_pos(solutions,'n'),am,db) = (0.7133580705009277,0.694043321299639,0.7035681610247027)\n",
    " - vv = evalute_on_wsd_challenge(only_of_pos(challenges,'v'),only_of_pos(solutions,'v'),am,db) = (0.5780141843971631,0.5516074450084603,0.5645021645021645)\n",
    " - aa = evalute_on_wsd_challenge(only_of_pos(challenges,'a'),only_of_pos(solutions,'a'),am,db) = (0.6535211267605634,0.6408839779005525,0.6471408647140865)\n",
    " - rr = evalute_on_wsd_challenge(only_of_pos(challenges,'r'),only_of_pos(solutions,'r'),am,db) = (0.7319587628865979,0.6826923076923077,0.7064676616915424)\n",
    " \n",
    " ### with Adagram Disambig weighting (prior used)\n",
    " ### With semcore\n",
    " - overall: \t\t(0.6134185303514377,0.5923314235345968,0.6026905829596412)\n",
    " - nn = evalute_on_wsd_challenge(only_of_pos(challenges,'n'),only_of_pos(solutions,'n'),s_am,db) = (0.6252319109461967,0.6083032490974729,0.6166514181152789)\n",
    " - vv = evalute_on_wsd_challenge(only_of_pos(challenges,'v'),only_of_pos(solutions,'v'),s_am,db) = (0.5638297872340425,0.5380710659898477,0.5506493506493505)\n",
    " - aa = evalute_on_wsd_challenge(only_of_pos(challenges,'a'),only_of_pos(solutions,'a'),s_am,db) = (0.6169014084507042,0.6049723756906077,0.610878661087866)\n",
    " - rr = evalute_on_wsd_challenge(only_of_pos(challenges,'r'),only_of_pos(solutions,'r'),s_am,db) = (0.6855670103092784,0.6394230769230769,0.6616915422885572)\n",
    " \n",
    " \n",
    " # Most Frequent Sense\n",
    " \n",
    "  -  overall: \t\t(0.7783164389598942,0.7783164389598942,0.7783164389598942)\n",
    "  - only nouns  : \t\t(0.7653429602888087,0.7653429602888087,0.7653429602888087)\n",
    "  - only verbs  : \t\t(0.7529610829103215,0.7529610829103215,0.7529610829103215)\n",
    "  - only adjecti: \t\t(0.8038674033149171,0.8038674033149171,0.8038674033149171)\n",
    "  - only adverbs: \t\t(0.875,0.875,0.875)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "println(\"overall: \\t\\t\", evalute_on_wsd_challenge(challenges, solutions, ee, db))\n",
    "\n",
    "#println(\"only nouns  : \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'n'), only_of_pos(solutions,'n'), ee, db))\n",
    "#println(\"only verbs  : \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'v'), only_of_pos(solutions,'v'), ee, db))\n",
    "#println(\"only adjecti: \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'a'), only_of_pos(solutions,'a'), ee, db))\n",
    "#println(\"only adverbs: \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'r'), only_of_pos(solutions,'r'), ee, db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "println(\"overall: \\t\\t\", evalute_on_wsd_challenge_MFS(challenges, solutions, db))\n",
    "\n",
    "#println(\"only nouns  : \\t\\t\", evalute_on_wsd_challenge_MFS(only_of_pos(challenges,'n'), only_of_pos(solutions,'n'), db))\n",
    "#println(\"only verbs  : \\t\\t\", evalute_on_wsd_challenge_MFS(only_of_pos(challenges,'v'), only_of_pos(solutions,'v'), db))\n",
    "#println(\"only adjecti: \\t\\t\", evalute_on_wsd_challenge_MFS(only_of_pos(challenges,'a'), only_of_pos(solutions,'a'), db))\n",
    "#println(\"only adverbs: \\t\\t\", evalute_on_wsd_challenge_MFS(only_of_pos(challenges,'r'), only_of_pos(solutions,'r'), db))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Zero shot WSI for 1 shot WSD\n",
    "using Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rr = FixedWordSenseEmbedding(ee.dimension, random_inited, huffman_tree; initial_nsenses=50)\n",
    "rr.corpus_size = ee.corpus_size\n",
    "rr.distribution = ee.distribution\n",
    "rr.codebook = ee.codebook\n",
    "rr.classification_tree = ee.classification_tree\n",
    "Training.initialize_embedding(rr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rr.embedding[\"us\"] |> length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "println(\"overall: \\t\\t\", evalute_on_wsd_challenge(challenges, solutions, rr, db))\n",
    "\n",
    "println(\"only nouns  : \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'n'), only_of_pos(solutions,'n'), rr, db))\n",
    "println(\"only verbs  : \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'v'), only_of_pos(solutions,'v'), rr, db))\n",
    "println(\"only adjecti: \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'a'), only_of_pos(solutions,'a'), rr, db))\n",
    "println(\"only adverbs: \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'r'), only_of_pos(solutions,'r'), rr, db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hh = deepcopy(rr)\n",
    "for word in keys(rr.embedding)\n",
    "    append!(hh.embedding[word], ee.embedding[word])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "println(\"overall: \\t\\t\", evalute_on_wsd_challenge(challenges, solutions, hh, db))\n",
    "\n",
    "println(\"only nouns  : \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'n'), only_of_pos(solutions,'n'), hh, db))\n",
    "println(\"only verbs  : \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'v'), only_of_pos(solutions,'v'), hh, db))\n",
    "println(\"only adjecti: \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'a'), only_of_pos(solutions,'a'), hh, db))\n",
    "println(\"only adverbs: \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'r'), only_of_pos(solutions,'r'), hh, db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mapping_corpus = load_semcor(\"data/corpora/semcor2.1/brown1/tagfiles/\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agirresAlignment (generic function with 2 methods)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function agirresAlignment(ee, wn::DB, mapping_corpus, hard=true)\n",
    "    maps = Dict{Tuple{String, String, Char}, Matrix{Float32}}()\n",
    "    freqs = Dict{Tuple{String, String, Char}, Vector{Int}}()\n",
    "    \n",
    "    function proc_word(word::TaggedWord, sentence::TaggedSentence)\n",
    "    end\n",
    "    \n",
    "    function proc_word(taggedword::SenseAnnotatedWord, sentence::TaggedSentence)\n",
    "        local wn_sensekeys\n",
    "        pos = pennPOStoWordNetPOS(taggedword.pos)\n",
    "       \n",
    "        try \n",
    "            wn_sensekeys = sensekeys(wn, wn[pos, taggedword.lemma])\n",
    "        catch exception\n",
    "            exception |> typeof <: KeyError || rethrow()\n",
    "            warn(\"Could not find wordnet lemma for $taggedword\")\n",
    "            return\n",
    "        end\n",
    "        \n",
    "        target_wnsn = findfirst(wn_sensekeys .== sensekey(taggedword))\n",
    "        if target_wnsn==0\n",
    "            warn(\"$(sensekey(taggedword)) not in  $(wn_sensekeys).\\n\\nIssue is with $taggedword\")\n",
    "            return\n",
    "        end\n",
    "\n",
    "        wvs = all_word_sense_vectors(ee,taggedword.word)\n",
    "        if length(wvs) == 0\n",
    "            warn(\"No embedding for $(taggedword.word); skipping\")\n",
    "            return\n",
    "        end\n",
    "        \n",
    "        ########\n",
    "        \n",
    "\n",
    "        map = get!(maps, (taggedword.word, taggedword.lemma, pos)) do\n",
    "            zeros(length(wvs), length(wn_sensekeys))\n",
    "        end\n",
    "        \n",
    "        freq = get!(freqs, (taggedword.word, taggedword.lemma, pos)) do \n",
    "            zeros(Int, length(wn_sensekeys))\n",
    "        end\n",
    "        \n",
    "        \n",
    "        context = lowercase.(strip_tags(sentence))\n",
    "        wv_probs = general_wsd(ee,context, wvs)\n",
    "        @assert(length(wv_probs) == length(wvs))\n",
    "        @assert sum(wv_probs) ≈ 1f0\n",
    "        @assert !any(isnan.(wv_probs))\n",
    "        freq[target_wnsn] += 1\n",
    "        if hard\n",
    "            map[indmax(wv_probs),target_wnsn] += 1\n",
    "        else\n",
    "            @assert(length(map[:,target_wnsn]) == length(wv_probs),\n",
    "            \"$(length(map[:,target_wnsn])) != $(length(wv_probs)) for \\\"$(taggedword.lemma)\\\"\"           \n",
    "            )\n",
    "            map[:,target_wnsn] += wv_probs\n",
    "        end\n",
    "        \n",
    "    end\n",
    "    \n",
    "    for sentence in mapping_corpus\n",
    "        for word in sentence\n",
    "            proc_word(word, sentence)\n",
    "        end\n",
    "    end\n",
    " \n",
    "    \n",
    "    for ((word, lem, pos), freq) in freqs\n",
    "        mm = maps[(word, lem, pos)]\n",
    "        mm ./= freq'\n",
    "        mm[isnan.(mm)] = 0f0 #NaNs are just frequency 0 items\n",
    "        @assert(all(isapprox.(sum(mm, 1), 1f0; atol=1f-5) \n",
    "                    | isapprox.(sum(mm, 1), 0f0; atol=1f-5)), \n",
    "                    \"($word , $pos) not sum to one, $(sum(mm,1))\")\n",
    "    end\n",
    "\n",
    "    maps, freqs\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function AdaGramCompat.all_word_sense_vectors(ee::WordSenseEmbedding, word)\n",
    "    get(ee.embedding, word, Vector{Float32}[])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "maps_soft, freqs  = agirresAlignment(ee, db, mapping_corpus, false);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Plots.GRBackend()"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#maps_soft[(\"dark\", \"dark\", 'a')]|> heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#maps_soft_am = deepcopy(maps_soft);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#maps_soft_am[(\"dark\", 'a')] |> heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Tuple{String,Char},Array{Float32,2}}"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maps|> typeof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evalute_on_wsd_challenge (generic function with 3 methods)"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mapped_wsd(challenge, ee, wn::DB, maps::Associative{Tuple{String, String, Char}, Matrix{Float32}})\n",
    "    try\n",
    "        lem = wn[challenge.lemma, challenge.pos]\n",
    "        target_synsets = synsets(wn, lem)\n",
    "        \n",
    "        wvs = all_word_sense_vectors(ee, challenge.word)\n",
    "        length(wvs) > 0 || throw(KeyError(\"No embeddings for \"*challenge.word))\n",
    "        \n",
    "        wv_probs = general_wsd(ee,challenge.context, wvs)\n",
    "\n",
    "        \n",
    "        mm = maps[challenge.word, challenge.lemma, challenge.pos]\n",
    "        mm.+=1.0\n",
    "        probs_of_sense = mm'*wv_probs\n",
    "        probs_of_sense./=sum(probs_of_sense)\n",
    "\n",
    "        \n",
    "        sense_index= indmax(probs_of_sense)        \n",
    "        synset = target_synsets[sense_index]\n",
    "        sk = sensekey(wn, synset, lem)\n",
    "        Nullable(sk)\n",
    "    catch ex\n",
    "        isa(ex, KeyError) || rethrow(ex)\n",
    "        @show ex\n",
    "        Nullable{String}()\n",
    "    end\n",
    "end\n",
    "\n",
    "function evalute_on_wsd_challenge(challenges, solutions, ee, wn::DB, maps)\n",
    "    method = challenge -> mapped_wsd(challenge, ee, wn, maps)\n",
    "    evalute_on_wsd_challenge(challenges, solutions, method)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ex = KeyError((\"homeless\",\"homeless\",'n'))\n",
      "ex = KeyError((\"homelessness\",\"homelessness\",'n'))\n",
      "ex = KeyError((\"homeless\",\"homeless\",'a'))\n",
      "ex = KeyError((\"alcoholics\",\"alcoholic\",'n'))\n",
      "ex = KeyError((\"homeless\",\"homeless\",'a'))\n",
      "Progress:   1%|█                                        |  ETA: 0:00:23ex = KeyError((\"homelessness\",\"homelessness\",'n'))\n",
      "ex = KeyError((\"prevalence\",\"prevalence\",'n'))\n",
      "ex = KeyError((\"alcoholism\",\"alcoholism\",'n'))\n",
      "ex = KeyError((\"homeless\",\"homeless\",'a'))\n",
      "ex = KeyError((\"multitude\",\"multitude\",'n'))\n",
      "ex = KeyError(\"No embeddings for in addition\")\n",
      "ex = KeyError((\"psychiatric\",\"psychiatric\",'a'))\n",
      "ex = KeyError(\"No embeddings for substance abuse\")\n",
      "ex = KeyError((\"malnutrition\",\"malnutrition\",'n'))\n",
      "ex = KeyError(\"No embeddings for aftereffects\")\n",
      "ex = KeyError((\"rape\",\"rape\",'n'))\n",
      "ex = KeyError((\"homeless\",\"homeless\",'a'))\n",
      "ex = KeyError((\"nutrition\",\"nutrition\",'n'))\n",
      "ex = KeyError(\"No embeddings for health care\")\n",
      "ex = KeyError(\"No embeddings for pointed out\")\n",
      "ex = KeyError(\"No embeddings for predispose\")\n",
      "ex = KeyError((\"homelessness\",\"homelessness\",'n'))\n",
      "Progress:   4%|██                                       |  ETA: 0:00:10ex = KeyError((\"homelessness\",\"homelessness\",'n'))\n",
      "ex = KeyError((\"sweeping\",\"sweeping\",'a'))\n",
      "ex = KeyError((\"preventing\",\"prevent\",'v'))\n",
      "ex = KeyError((\"homelessness\",\"homelessness\",'n'))\n",
      "ex = KeyError((\"dynamics\",\"dynamic\",'n'))\n",
      "ex = KeyError((\"homelessness\",\"homelessness\",'n'))\n",
      "Progress:   6%|███                                      |  ETA: 0:00:09ex = KeyError((\"homelessness\",\"homelessness\",'n'))\n",
      "ex = KeyError((\"thread\",\"thread\",'n'))\n",
      "ex = KeyError((\"homeless\",\"homeless\",'a'))\n",
      "ex = KeyError(\"No embeddings for made up\")\n",
      "ex = KeyError((\"homeless\",\"homeless\",'n'))\n",
      "ex = KeyError((\"exhibits\",\"exhibit\",'v'))\n",
      "ex = KeyError((\"according\",\"according\",'a'))\n",
      "ex = KeyError((\"homelessness\",\"homelessness\",'n'))\n",
      "ex = KeyError((\"demographic\",\"demographic\",'a'))\n",
      "Progress:   8%|███                                      |  ETA: 0:00:09ex = KeyError((\"cutbacks\",\"cutback\",'n'))\n",
      "ex = KeyError((\"spending\",\"spending\",'n'))\n",
      "ex = KeyError(\"No embeddings for nuclear family\")\n",
      "Progress:   9%|████                                     |  ETA: 0:00:09ex = KeyError((\"privately\",\"privately\",'r'))\n",
      "ex = KeyError((\"funded\",\"funded\",'a'))\n",
      "ex = KeyError((\"homeless\",\"homeless\",'n'))\n",
      "ex = KeyError((\"homeless\",\"homeless\",'a'))\n",
      "ex = KeyError((\"murdered\",\"murder\",'v'))\n",
      "ex = KeyError((\"deprivation\",\"deprivation\",'n'))\n",
      "ex = KeyError((\"psychiatric\",\"psychiatric\",'a'))\n",
      "Progress:  10%|████                                     |  ETA: 0:00:09ex = KeyError((\"fend\",\"fend\",'v'))\n",
      "ex = KeyError((\"homeless\",\"homeless\",'n'))\n",
      "ex = KeyError((\"pre-existing\",\"pre-existing\",'a'))\n",
      "ex = KeyError((\"addiction\",\"addiction\",'n'))\n",
      "ex = KeyError((\"inverse\",\"inverse\",'n'))\n",
      "Progress:  12%|█████                                    |  ETA: 0:00:08ex = KeyError(\"No embeddings for substance abuse\")\n",
      "ex = KeyError((\"homelessness\",\"homelessness\",'n'))\n",
      "ex = KeyError((\"sponsors\",\"sponsor\",'n'))\n",
      "ex = KeyError((\"homeless\",\"homeless\",'n'))\n",
      "ex = KeyError(\"No embeddings for insinuating\")\n",
      "Progress:  13%|█████                                    |  ETA: 0:00:08ex = KeyError((\"self-serving\",\"self-serving\",'a'))\n",
      "ex = KeyError((\"greed\",\"greed\",'n'))\n",
      "ex = KeyError((\"motive\",\"motive\",'n'))\n",
      "ex = KeyError((\"subscribe\",\"subscribe\",'v'))\n",
      "ex = KeyError((\"advertise\",\"advertise\",'v'))\n",
      "ex = KeyError((\"nonprofit\",\"nonprofit\",'a'))\n",
      "ex = KeyError((\"homeless\",\"homeless\",'n'))\n",
      "ex = KeyError((\"underwent\",\"undergo\",'v'))\n",
      "ex = KeyError((\"psychiatric\",\"psychiatric\",'a'))\n",
      "ex = KeyError((\"executives\",\"executive\",'n'))\n",
      "Progress:  15%|██████                                   |  ETA: 0:00:07ex = KeyError((\"deprived\",\"deprive\",'v'))\n",
      "ex = KeyError((\"phobias\",\"phobia\",'n'))\n",
      "ex = KeyError((\"anxieties\",\"anxiety\",'n'))\n",
      "ex = KeyError(\"No embeddings for substance abuse\")\n",
      "Progress:  16%|███████                                  |  ETA: 0:00:07ex = KeyError((\"preface\",\"preface\",'n'))\n",
      "ex = KeyError((\"co-author\",\"coauthor\",'n'))\n",
      "ex = KeyError(\"No embeddings for high-minded\")\n",
      "ex = KeyError(\"No embeddings for scammers\")\n",
      "ex = KeyError((\"bribe\",\"bribe\",'n'))\n",
      "ex = KeyError((\"bribe\",\"bribe\",'n'))\n",
      "ex = KeyError((\"co-author\",\"coauthor\",'n'))\n",
      "ex = KeyError((\"manufacturing\",\"manufacture\",'v'))\n",
      "Progress:  18%|████████                                 |  ETA: 0:00:07ex = KeyError((\"full-fledged\",\"full-fledged\",'a'))\n",
      "ex = KeyError((\"contractor\",\"contractor\",'n'))\n",
      "ex = KeyError((\"revolves\",\"revolve\",'v'))\n",
      "ex = KeyError((\"founder\",\"founder\",'n'))\n",
      "ex = KeyError(\"No embeddings for get rolling\")\n",
      "Progress:  20%|████████                                 |  ETA: 0:00:07ex = KeyError((\"mandates\",\"mandate\",'v'))\n",
      "ex = KeyError(\"No embeddings for noncompetitively\")\n",
      "ex = KeyError((\"italian\",\"italian\",'a'))\n",
      "ex = KeyError((\"presidential\",\"presidential\",'a'))\n",
      "ex = KeyError((\"rhetoric\",\"rhetoric\",'n'))\n",
      "Progress:  22%|█████████                                |  ETA: 0:00:06ex = KeyError((\"bribing\",\"bribe\",'v'))\n",
      "Progress:  23%|█████████                                |  ETA: 0:00:06ex = KeyError((\"adviser\",\"adviser\",'n'))\n",
      "ex = KeyError(\"No embeddings for attorney general\")\n",
      "ex = KeyError((\"bribery\",\"bribery\",'n'))\n",
      "ex = KeyError((\"peddling\",\"peddling\",'n'))\n",
      "ex = KeyError((\"retaining\",\"retain\",'v'))\n",
      "ex = KeyError((\"confidant\",\"confidant\",'n'))\n",
      "ex = KeyError((\"equity\",\"equity\",'n'))\n",
      "ex = KeyError(\"No embeddings for semiliterate\")\n",
      "Progress:  25%|██████████                               |  ETA: 0:00:06ex = KeyError((\"revelations\",\"revelation\",'n'))\n",
      "ex = KeyError((\"breezy\",\"breezy\",'a'))\n",
      "ex = KeyError((\"tabloid\",\"tabloid\",'n'))\n",
      "ex = KeyError(\"No embeddings for falls short of\")\n",
      "ex = KeyError((\"gripping\",\"gripping\",'a'))\n",
      "ex = KeyError((\"scams\",\"scam\",'n'))\n",
      "ex = KeyError((\"ingenuity\",\"ingenuity\",'n'))\n",
      "ex = KeyError((\"auditors\",\"auditor\",'n'))\n",
      "ex = KeyError(\"No embeddings for scammers\")\n",
      "ex = KeyError((\"bribed\",\"bribe\",'v'))\n",
      "ex = KeyError(\"No embeddings for shut up\")\n",
      "ex = KeyError(\"No embeddings for scammers\")\n",
      "ex = KeyError(\"No embeddings for low lifes\")\n",
      "ex = KeyError((\"consumers\",\"consumer\",'n'))\n",
      "ex = KeyError((\"wrestling\",\"wrestle\",'v'))\n",
      "ex = KeyError(\"No embeddings for at least\")\n",
      "Progress:  28%|███████████                              |  ETA: 0:00:05ex = KeyError((\"pediatrician\",\"pediatrician\",'n'))\n",
      "ex = KeyError((\"gambler\",\"gambler\",'n'))\n",
      "ex = KeyError((\"blackjack\",\"blackjack\",'n'))\n",
      "ex = KeyError(\"No embeddings for in time\")\n",
      "ex = KeyError(\"No embeddings for doling out\")\n",
      "ex = KeyError(\"No embeddings for tidbits\")\n",
      "ex = KeyError(\"No embeddings for gloss over\")\n",
      "ex = KeyError((\"auspices\",\"auspices\",'n'))\n",
      "ex = KeyError(\"No embeddings for took place\")\n",
      "ex = KeyError(\"No embeddings for at least\")\n",
      "ex = KeyError(\"No embeddings for come around\")\n",
      "ex = KeyError(\"No embeddings for affirmative action\")\n",
      "ex = KeyError(\"No embeddings for a little\")\n",
      "ex = KeyError((\"scoop\",\"scoop\",'v'))\n",
      "ex = KeyError(\"No embeddings for take place\")\n",
      "ex = KeyError((\"corruption\",\"corruption\",'n'))\n",
      "Progress:  31%|█████████████                            |  ETA: 0:00:05ex = KeyError(\"No embeddings for belonging to\")\n",
      "ex = KeyError((\"insider\",\"insider\",'n'))\n",
      "ex = KeyError(\"No embeddings for redistributing\")\n",
      "ex = KeyError((\"regulating\",\"regulate\",'v'))\n",
      "ex = KeyError((\"commerce\",\"commerce\",'n'))\n",
      "ex = KeyError((\"influencing\",\"influence\",'v'))\n",
      "ex = KeyError((\"brokering\",\"broker\",'v'))\n",
      "Progress:  32%|█████████████                            |  ETA: 0:00:05ex = KeyError((\"bloc\",\"bloc\",'n'))\n",
      "ex = KeyError(\"No embeddings for nomenklatura\")\n",
      "ex = KeyError((\"line\",\"line\",'v'))\n",
      "ex = KeyError((\"insiders\",\"insider\",'n'))\n",
      "ex = KeyError(\"No embeddings for chief executive officer\")\n",
      "ex = KeyError((\"french\",\"french\",'a'))\n",
      "ex = KeyError((\"monsieur\",\"monsieur\",'n'))\n",
      "ex = KeyError((\"clipboard\",\"clipboard\",'n'))\n",
      "ex = KeyError((\"last-minute\",\"last-minute\",'a'))\n",
      "ex = KeyError((\"attendee\",\"attendee\",'n'))\n",
      "ex = KeyError((\"french\",\"french\",'a'))\n",
      "ex = KeyError(\"No embeddings for so far\")\n",
      "ex = KeyError(\"No embeddings for taken up\")\n",
      "ex = KeyError((\"sleeping\",\"sleeping\",'n'))\n",
      "ex = KeyError((\"clipboard\",\"clipboard\",'n'))\n",
      "ex = KeyError(\"No embeddings for halfhearted\")\n",
      "Progress:  34%|██████████████                           |  ETA: 0:00:04ex = KeyError((\"french\",\"french\",'n'))\n",
      "ex = KeyError(\"No embeddings for comes to\")\n",
      "ex = KeyError((\"diners\",\"diner\",'n'))\n",
      "ex = KeyError(\"No embeddings for scoffed\")\n",
      "ex = KeyError((\"interrupting\",\"interrupt\",'v'))\n",
      "ex = KeyError((\"saturday\",\"saturday\",'n'))\n",
      "ex = KeyError((\"golfing\",\"golf\",'v'))\n",
      "ex = KeyError((\"ballooning\",\"ballooning\",'n'))\n",
      "ex = KeyError((\"french\",\"french\",'a'))\n",
      "ex = KeyError(\"No embeddings for of course\")\n",
      "Progress:  36%|███████████████                          |  ETA: 0:00:04ex = KeyError(\"No embeddings for balloonists\")\n",
      "ex = KeyError(\"No embeddings for chi-chi\")\n",
      "ex = KeyError(\"No embeddings for covetous\")\n",
      "ex = KeyError((\"americans\",\"american\",'n'))\n",
      "ex = KeyError(\"No embeddings for taken to\")\n",
      "ex = KeyError((\"ballooning\",\"ballooning\",'n'))\n",
      "ex = KeyError((\"heady\",\"heady\",'a'))\n",
      "ex = KeyError(\"No embeddings for balloonists\")\n",
      "ex = KeyError(\"No embeddings for lighter-than-air\")\n",
      "ex = KeyError((\"swelled\",\"swell\",'v'))\n",
      "ex = KeyError((\"largest\",\"large\",'a'))\n",
      "ex = KeyError((\"convocation\",\"convocation\",'n'))\n",
      "ex = KeyError((\"enthusiasts\",\"enthusiast\",'n'))\n",
      "ex = KeyError((\"balloons\",\"balloon\",'n'))\n",
      "ex = KeyError((\"condom\",\"condom\",'n'))\n",
      "ex = KeyError((\"condom\",\"condom\",'n'))\n",
      "ex = KeyError(\"No embeddings for enthusiasms\")\n",
      "Progress:  38%|████████████████                         |  ETA: 0:00:04ex = KeyError((\"ballooning\",\"ballooning\",'n'))\n",
      "ex = KeyError(\"No embeddings for de rigueur\")\n",
      "ex = KeyError((\"sunrise\",\"sunrise\",'n'))\n",
      "ex = KeyError((\"imperative\",\"imperative\",'n'))\n",
      "ex = KeyError(\"No embeddings for signed up\")\n",
      "ex = KeyError((\"ballooning\",\"ballooning\",'n'))\n",
      "ex = KeyError((\"zip\",\"zip\",'n'))\n",
      "ex = KeyError(\"No embeddings for derring-do\")\n",
      "ex = KeyError((\"balloon\",\"balloon\",'v'))\n",
      "ex = KeyError(\"No embeddings for at least\")\n",
      "ex = KeyError((\"ascending\",\"ascend\",'v'))\n",
      "ex = KeyError((\"aloft\",\"aloft\",'r'))\n",
      "ex = KeyError((\"canal\",\"canal\",'n'))\n",
      "ex = KeyError((\"pilot\",\"pilot\",'n'))\n",
      "ex = KeyError((\"english\",\"english\",'n'))\n",
      "ex = KeyError((\"maiden\",\"maiden\",'a'))\n",
      "ex = KeyError(\"No embeddings for novitiates\")\n",
      "Progress:  41%|█████████████████                        |  ETA: 0:00:04ex = KeyError(\"No embeddings for soggy\")\n",
      "ex = KeyError((\"flights\",\"flight\",'n'))\n",
      "ex = KeyError((\"lightest\",\"light\",'a'))\n",
      "ex = KeyError((\"between\",\"between\",'r'))\n",
      "ex = KeyError((\"balloons\",\"balloon\",'n'))\n",
      "ex = KeyError((\"inflate\",\"inflate\",'v'))\n",
      "ex = KeyError((\"deciding\",\"deciding\",'n'))\n",
      "ex = KeyError((\"holler\",\"holler\",'v'))\n",
      "ex = KeyError(\"No embeddings for walkie-talkie\")\n",
      "ex = KeyError((\"stretches\",\"stretch\",'n'))\n",
      "ex = KeyError((\"drifting\",\"drifting\",'n'))\n",
      "ex = KeyError((\"mists\",\"mist\",'n'))\n",
      "ex = KeyError((\"french\",\"french\",'a'))\n",
      "ex = KeyError(\"No embeddings for amble\")\n",
      "Progress:  44%|██████████████████                       |  ETA: 0:00:03ex = KeyError(\"No embeddings for bird's-eye\")\n",
      "ex = KeyError((\"plaid\",\"plaid\",'n'))\n",
      "ex = KeyError((\"beret\",\"beret\",'n'))\n",
      "ex = KeyError(\"No embeddings for pointing out\")\n",
      "ex = KeyError((\"french\",\"french\",'a'))\n",
      "ex = KeyError((\"french\",\"french\",'a'))\n",
      "ex = KeyError(\"No embeddings for squinted\")\n",
      "ex = KeyError(\"No embeddings for coming down\")\n",
      "ex = KeyError((\"canal\",\"canal\",'n'))\n",
      "ex = KeyError(\"No embeddings for rule of thumb\")\n",
      "ex = KeyError((\"ballooning\",\"ballooning\",'n'))\n",
      "ex = KeyError((\"steer\",\"steer\",'v'))\n",
      "Progress:  46%|███████████████████                      |  ETA: 0:00:03ex = KeyError((\"pilot\",\"pilot\",'n'))\n",
      "ex = KeyError((\"propane\",\"propane\",'n'))\n",
      "ex = KeyError((\"burner\",\"burner\",'n'))\n",
      "ex = KeyError(\"No embeddings for balloonists\")\n",
      "ex = KeyError((\"average\",\"average\",'v'))\n",
      "ex = KeyError((\"leisurely\",\"leisurely\",'a'))\n",
      "ex = KeyError((\"ascending\",\"ascend\",'v'))\n",
      "ex = KeyError(\"No embeddings for hissed\")\n",
      "ex = KeyError((\"english-speaking\",\"english-speaking\",'a'))\n",
      "ex = KeyError((\"pilot\",\"pilot\",'n'))\n",
      "ex = KeyError((\"canal\",\"canal\",'n'))\n",
      "ex = KeyError((\"leaping\",\"leap\",'v'))\n",
      "ex = KeyError((\"atop\",\"atop\",'r'))\n",
      "ex = KeyError((\"propane\",\"propane\",'n'))\n",
      "ex = KeyError((\"tanks\",\"tank\",'n'))\n",
      "ex = KeyError(\"No embeddings for loafers\")\n",
      "ex = KeyError((\"pilot\",\"pilot\",'n'))\n",
      "ex = KeyError((\"burner\",\"burner\",'n'))\n",
      "ex = KeyError((\"flame\",\"flame\",'n'))\n",
      "ex = KeyError((\"scuttled\",\"scuttle\",'v'))\n",
      "Progress:  50%|████████████████████                     |  ETA: 0:00:03ex = KeyError(\"No embeddings for soggy\")\n",
      "ex = KeyError((\"french\",\"french\",'a'))\n",
      "ex = KeyError((\"ballooning\",\"ballooning\",'n'))\n",
      "ex = KeyError((\"aloft\",\"aloft\",'r'))\n",
      "ex = KeyError(\"No embeddings for get out\")\n",
      "ex = KeyError((\"trailer\",\"trailer\",'n'))\n",
      "ex = KeyError((\"rendezvoused\",\"rendezvous\",'v'))\n",
      "Progress:  51%|█████████████████████                    |  ETA: 0:00:03ex = KeyError(\"No embeddings for disassemble\")\n",
      "ex = KeyError(\"No embeddings for yanking\")\n",
      "ex = KeyError((\"punching\",\"punch\",'v'))\n",
      "ex = KeyError(\"No embeddings for cramming\")\n",
      "ex = KeyError((\"trailer\",\"trailer\",'n'))\n",
      "ex = KeyError((\"driving\",\"driving\",'n'))\n",
      "ex = KeyError(\"No embeddings for watering hole\")\n",
      "ex = KeyError(\"No embeddings for golf course\")\n",
      "ex = KeyError((\"french\",\"french\",'a'))\n",
      "ex = KeyError(\"No embeddings for duffers\")\n",
      "ex = KeyError((\"maul\",\"maul\",'v'))\n",
      "ex = KeyError((\"umbrellas\",\"umbrella\",'n'))\n",
      "ex = KeyError((\"espresso\",\"espresso\",'n'))\n",
      "ex = KeyError((\"ballooning\",\"ballooning\",'n'))\n",
      "ex = KeyError((\"peerless\",\"peerless\",'a'))\n",
      "ex = KeyError((\"pilot\",\"pilot\",'n'))\n",
      "ex = KeyError((\"french-speaking\",\"french-speaking\",'a'))\n",
      "ex = KeyError(\"No embeddings for clambered\")\n",
      "ex = KeyError((\"american\",\"american\",'a'))\n",
      "Progress:  54%|██████████████████████                   |  ETA: 0:00:03ex = KeyError(\"No embeddings for alfresco\")\n",
      "ex = KeyError((\"streaked\",\"streak\",'v'))\n",
      "ex = KeyError((\"gendarme\",\"gendarme\",'n'))\n",
      "ex = KeyError((\"rearing\",\"rear\",'v'))\n",
      "ex = KeyError(\"No embeddings for soggy\")\n",
      "ex = KeyError(\"No embeddings for loafers\")\n",
      "ex = KeyError((\"saluting\",\"salute\",'v'))\n",
      "ex = KeyError((\"free-lance\",\"freelance\",'a'))\n",
      "ex = KeyError((\"computer\",\"computer\",'n'))\n",
      "ex = KeyError((\"computer\",\"computer\",'n'))\n",
      "ex = KeyError(\"No embeddings for source code\")\n",
      "ex = KeyError((\"computer\",\"computer\",'n'))\n",
      "ex = KeyError(\"No embeddings for source code\")\n",
      "ex = KeyError(\"No embeddings for source code\")\n",
      "ex = KeyError((\"algorithms\",\"algorithm\",'n'))\n",
      "Progress:  57%|███████████████████████                  |  ETA: 0:00:03ex = KeyError((\"implement\",\"implement\",'v'))\n",
      "ex = KeyError((\"software\",\"software\",'n'))\n",
      "ex = KeyError(\"No embeddings for regarded as\")\n",
      "ex = KeyError((\"software\",\"software\",'n'))\n",
      "ex = KeyError(\"No embeddings for known as\")\n",
      "ex = KeyError((\"numeric\",\"numeric\",'a'))\n",
      "ex = KeyError(\"No embeddings for machine code\")\n",
      "ex = KeyError((\"executed\",\"execute\",'v'))\n",
      "ex = KeyError((\"ongoing\",\"ongoing\",'a'))\n",
      "ex = KeyError((\"ongoing\",\"ongoing\",'a'))\n",
      "Progress:  59%|████████████████████████                 |  ETA: 0:00:02ex = KeyError((\"linguistics\",\"linguistics\",'n'))\n",
      "ex = KeyError((\"programmers\",\"programmer\",'n'))\n",
      "ex = KeyError((\"computer\",\"computer\",'n'))\n",
      "ex = KeyError((\"programmers\",\"programmer\",'n'))\n",
      "ex = KeyError(\"No embeddings for computer software\")\n",
      "ex = KeyError((\"specification\",\"specification\",'n'))\n",
      "ex = KeyError((\"software\",\"software\",'n'))\n",
      "ex = KeyError((\"compilation\",\"compilation\",'n'))\n",
      "ex = KeyError((\"software\",\"software\",'n'))\n",
      "ex = KeyError((\"documentation\",\"documentation\",'n'))\n",
      "ex = KeyError((\"paradigms\",\"paradigm\",'n'))\n",
      "ex = KeyError(\"No embeddings for at hand\")\n",
      "ex = KeyError((\"trade-offs\",\"trade-off\",'n'))\n",
      "Progress:  61%|█████████████████████████                |  ETA: 0:00:02ex = KeyError((\"programmers\",\"programmer\",'n'))\n",
      "ex = KeyError((\"compilers\",\"compiler\",'n'))\n",
      "ex = KeyError((\"execute\",\"execute\",'v'))\n",
      "ex = KeyError((\"capabilities\",\"capability\",'n'))\n",
      "ex = KeyError(\"No embeddings for jacquard loom\")\n",
      "ex = KeyError(\"No embeddings for pasteboard\")\n",
      "ex = KeyError((\"punched\",\"punch\",'v'))\n",
      "ex = KeyError((\"loom\",\"loom\",'n'))\n",
      "ex = KeyError((\"weaving\",\"weave\",'v'))\n",
      "ex = KeyError((\"loom\",\"loom\",'n'))\n",
      "ex = KeyError((\"refined\",\"refine\",'v'))\n",
      "ex = KeyError(\"No embeddings for punch card\")\n",
      "ex = KeyError(\"No embeddings for data processing\")\n",
      "ex = KeyError((\"programmed\",\"program\",'v'))\n",
      "Progress:  65%|██████████████████████████               |  ETA: 0:00:02ex = KeyError((\"wiring\",\"wiring\",'n'))\n",
      "ex = KeyError(\"No embeddings for plugboards\")\n",
      "ex = KeyError((\"computers\",\"computer\",'n'))\n",
      "ex = KeyError((\"computer\",\"computer\",'n'))\n",
      "ex = KeyError((\"painstakingly\",\"painstakingly\",'r'))\n",
      "ex = KeyError((\"crafted\",\"craft\",'v'))\n",
      "ex = KeyError((\"binary\",\"binary\",'a'))\n",
      "ex = KeyError((\"computer\",\"computer\",'n'))\n",
      "ex = KeyError(\"No embeddings for assembly languages\")\n",
      "ex = KeyError((\"programmer\",\"programmer\",'n'))\n",
      "ex = KeyError((\"format\",\"format\",'n'))\n",
      "Progress:  67%|███████████████████████████              |  ETA: 0:00:02ex = KeyError((\"abbreviations\",\"abbreviation\",'n'))\n",
      "ex = KeyError((\"addresses\",\"address\",'n'))\n",
      "ex = KeyError((\"programmers\",\"programmer\",'n'))\n",
      "ex = KeyError((\"compiler\",\"compiler\",'n'))\n",
      "ex = KeyError(\"No embeddings for punch cards\")\n",
      "ex = KeyError(\"No embeddings for paper tape\")\n",
      "ex = KeyError((\"computer\",\"computer\",'n'))\n",
      "ex = KeyError(\"No embeddings for punch card\")\n",
      "ex = KeyError((\"mass\",\"mass\",'a'))\n",
      "ex = KeyError((\"computer\",\"computer\",'n'))\n",
      "ex = KeyError((\"typing\",\"typing\",'n'))\n",
      "ex = KeyError((\"computers\",\"computer\",'n'))\n",
      "ex = KeyError((\"corrections\",\"correction\",'n'))\n",
      "ex = KeyError(\"No embeddings for punch cards\")\n",
      "ex = KeyError((\"computers\",\"computer\",'n'))\n",
      "Progress:  70%|█████████████████████████████            |  ETA: 0:00:02ex = KeyError(\"No embeddings for brought about\")\n",
      "ex = KeyError((\"additional\",\"additional\",'a'))\n",
      "ex = KeyError((\"computers\",\"computer\",'n'))\n",
      "ex = KeyError(\"No embeddings for brought about\")\n",
      "ex = KeyError((\"earlier\",\"earlier\",'a'))\n",
      "Progress:  72%|█████████████████████████████            |  ETA: 0:00:02ex = KeyError(\"No embeddings for familiar with\")\n",
      "ex = KeyError((\"programmer\",\"programmer\",'n'))\n",
      "ex = KeyError(\"No embeddings for dependent on\")\n",
      "ex = KeyError(\"No embeddings for todays\")\n",
      "Progress:  74%|██████████████████████████████           |  ETA: 0:00:01ex = KeyError((\"subject\",\"subject\",'a'))\n",
      "ex = KeyError((\"importing\",\"import\",'v'))\n",
      "ex = KeyError((\"software\",\"software\",'n'))\n",
      "ex = KeyError((\"wage\",\"wage\",'n'))\n",
      "Progress:  75%|███████████████████████████████          |  ETA: 0:00:01ex = KeyError((\"unclear\",\"unclear\",'a'))\n",
      "ex = KeyError((\"impact\",\"impact\",'v'))\n",
      "ex = KeyError((\"programmer\",\"programmer\",'n'))\n",
      "ex = KeyError((\"programmers\",\"programmer\",'n'))\n",
      "ex = KeyError(\"No embeddings for and so on\")\n",
      "ex = KeyError((\"craftsmanship\",\"craftsmanship\",'n'))\n",
      "ex = KeyError((\"reward\",\"reward\",'v'))\n",
      "ex = KeyError((\"practitioners\",\"practitioner\",'n'))\n",
      "ex = KeyError((\"methodologies\",\"methodology\",'n'))\n",
      "ex = KeyError((\"software\",\"software\",'n'))\n",
      "ex = KeyError(\"No embeddings for a lot\")\n",
      "ex = KeyError((\"database\",\"database\",'n'))\n",
      "Progress:  78%|████████████████████████████████         |  ETA: 0:00:01ex = KeyError((\"procedural\",\"procedural\",'a'))\n",
      "ex = KeyError(\"No embeddings for debuggers\")\n",
      "ex = KeyError((\"executed\",\"execute\",'v'))\n",
      "ex = KeyError((\"assembler\",\"assembler\",'n'))\n",
      "ex = KeyError((\"invalid\",\"invalid\",'a'))\n",
      "ex = KeyError((\"pointers\",\"pointer\",'n'))\n",
      "ex = KeyError((\"pc\",\"pc\",'n'))\n",
      "ex = KeyError((\"desktop\",\"desktop\",'n'))\n",
      "ex = KeyError(\"No embeddings for word processors\")\n",
      "ex = KeyError((\"manipulation\",\"manipulation\",'n'))\n",
      "ex = KeyError(\"No embeddings for operating systems\")\n",
      "ex = KeyError((\"low-level\",\"low-level\",'a'))\n",
      "ex = KeyError((\"assembler\",\"assembler\",'n'))\n",
      "Progress:  80%|█████████████████████████████████        |  ETA: 0:00:01ex = KeyError((\"switching\",\"switching\",'n'))\n",
      "ex = KeyError((\"thread\",\"thread\",'n'))\n",
      "ex = KeyError((\"implemented\",\"implement\",'v'))\n",
      "ex = KeyError((\"optimization\",\"optimization\",'n'))\n",
      "ex = KeyError((\"compilers\",\"compiler\",'n'))\n",
      "ex = KeyError((\"arithmetic\",\"arithmetic\",'n'))\n",
      "ex = KeyError((\"mainframe\",\"mainframe\",'n'))\n",
      "ex = KeyError((\"computers\",\"computer\",'n'))\n",
      "ex = KeyError((\"excel\",\"excel\",'v'))\n",
      "ex = KeyError((\"internet\",\"internet\",'n'))\n",
      "Progress:  82%|██████████████████████████████████       |  ETA: 0:00:01ex = KeyError(\"No embeddings for intranets\")\n",
      "ex = KeyError((\"programmer\",\"programmer\",'n'))\n",
      "ex = KeyError((\"erroneous\",\"erroneous\",'a'))\n",
      "ex = KeyError((\"useless\",\"useless\",'a'))\n",
      "ex = KeyError((\"assembler\",\"assembler\",'n'))\n",
      "ex = KeyError((\"programmers\",\"programmer\",'n'))\n",
      "ex = KeyError((\"modes\",\"mode\",'n'))\n",
      "ex = KeyError((\"pointers\",\"pointer\",'n'))\n",
      "ex = KeyError((\"software\",\"software\",'n'))\n",
      "ex = KeyError((\"programmer\",\"programmer\",'n'))\n",
      "ex = KeyError((\"modes\",\"mode\",'n'))\n",
      "Progress:  85%|███████████████████████████████████      |  ETA: 0:00:01ex = KeyError((\"refined\",\"refined\",'a'))\n",
      "Progress:  86%|███████████████████████████████████      |  ETA: 0:00:01ex = KeyError((\"good-natured\",\"good-natured\",'a'))\n",
      "ex = KeyError((\"payment\",\"payment\",'n'))\n",
      "ex = KeyError(\"No embeddings for taking care\")\n",
      "ex = KeyError((\"tidy\",\"tidy\",'a'))\n",
      "ex = KeyError(\"No embeddings for thought of\")\n",
      "ex = KeyError(\"No embeddings for untidy\")\n",
      "Progress:  89%|████████████████████████████████████     |  ETA: 0:00:01ex = KeyError(\"No embeddings for untidy\")\n",
      "ex = KeyError(\"No embeddings for longings\")\n",
      "ex = KeyError((\"florentine\",\"florentine\",'a'))\n",
      "ex = KeyError(\"No embeddings for passing through\")\n",
      "ex = KeyError((\"heed\",\"heed\",'n'))\n",
      "ex = KeyError(\"No embeddings for untidy\")\n",
      "Progress:  92%|██████████████████████████████████████   |  ETA: 0:00:00ex = KeyError((\"fitter\",\"fit\",'a'))\n",
      "ex = KeyError(\"No embeddings for thinks of\")\n",
      "ex = KeyError((\"nickname\",\"nickname\",'n'))\n",
      "ex = KeyError((\"honoured\",\"honour\",'v'))\n",
      "ex = KeyError(\"No embeddings for heart and soul\")\n",
      "Progress:  94%|██████████████████████████████████████   |  ETA: 0:00:00ex = KeyError(\"No embeddings for at all\")\n",
      "ex = KeyError((\"downwards\",\"downwards\",'r'))\n",
      "ex = KeyError((\"hanging\",\"hang\",'v'))\n",
      "ex = KeyError((\"florentine\",\"florentine\",'a'))\n",
      "ex = KeyError((\"youths\",\"youth\",'n'))\n",
      "Progress:  95%|███████████████████████████████████████  |  ETA: 0:00:00ex = KeyError(\"No embeddings for look like\")\n",
      "ex = KeyError((\"frescoes\",\"fresco\",'n'))\n",
      "Progress:  96%|████████████████████████████████████████ |  ETA: 0:00:00ex = KeyError(\"No embeddings for young man\")\n",
      "ex = KeyError((\"realised\",\"realise\",'v'))\n",
      "ex = KeyError(\"No embeddings for one by one\")\n",
      "ex = KeyError((\"fresco\",\"fresco\",'n'))\n",
      "ex = KeyError(\"No embeddings for baptizing\")\n",
      "ex = KeyError((\"fresco\",\"fresco\",'n'))\n",
      "ex = KeyError(\"No embeddings for more than\")\n",
      "Progress:  99%|████████████████████████████████████████ |  ETA: 0:00:00ex = KeyError((\"learnt\",\"learn\",'v'))\n",
      "ex = KeyError(\"No embeddings for little by little\")\n",
      "ex = KeyError((\"onwards\",\"onwards\",'r'))\n",
      "ex = KeyError((\"shivering\",\"shivering\",'a'))\n",
      "Progress: 100%|█████████████████████████████████████████| Time: 0:00:05\n",
      "notattempted = 442\n",
      "overall: \t\t(0.6628352490421456,0.5337152930806522,0.59130859375)\n"
     ]
    }
   ],
   "source": [
    "println(\"overall: \\t\\t\", evalute_on_wsd_challenge(challenges, solutions, ee, db, maps_soft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.0-rc0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
