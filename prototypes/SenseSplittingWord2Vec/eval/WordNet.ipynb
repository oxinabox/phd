{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using WordNet\n",
    "using AdaGram\n",
    "using AdaGramCompat\n",
    "\n",
    "using CorpusLoaders\n",
    "using CorpusLoaders.Semcor\n",
    "using WordEmbeddings, SoftmaxClassifier\n",
    "using Utils\n",
    "using Query\n",
    "using Distances\n",
    "using Iterators\n",
    "using LightXML\n",
    "using JLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordNet.DB"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const WN_PATH=\"data/corpora/WordNet-2.1/\"\n",
    "#WN_PATH3 = \"/usr/share/nltk_data/corpora/wordnet/\"\n",
    "db = DB(WN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#am = AdaGramCompat.AdaGramModel(load_model(\"models/adagram/v1_d100.adagram_model\")...)\n",
    "#am = AdaGramModel(load_model(\"models/adagram/more_senses.adagram_model\")...)\n",
    "#am = open(deserialize,\"models/adagram/more_senses.adagram_model.jsz\", \"r\");\n",
    "am = load(\"models/adagram/more_senses.adagram_model.jld\", \"am\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ee = restore(\"models/ss/tokenised_lowercase_WestburyLab.wikicorp.201004_100_i1.jld\");\n",
    "ee = load(\"models/ss/tokenised_lowercase_WestburyLab.wikicorp.201004_100_i1.jld\", \"ee\")\n",
    "\n",
    "#ee = restore(\"models/ss/keep/tokenised_lowercase_WestburyLab.wikicorp.201004_50__m170000000.model\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using CorpusLoaders.Semeval2007t7\n",
    "\n",
    "challenges = load_challenges_semeval2007t7(\"data/corpora/wsd/semeval2007_t7/test/eng-coarse-all-words.xml\");\n",
    "solutions = load_solutions_semeval2007t7(\"data/corpora/wsd/semeval2007_t7/key/dataset21.test.key\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "semcor = index_semcor(lazyload_semcor(\"data/corpora/semcor2.1/brown1/tagfiles/\"));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "only_of_pos (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_of_pos(data, pos) = filter(d->d.pos==pos, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sense_frequency (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function sense_frequency(ss::Synset, lem::Lemma)\n",
    "    lem_count = lem.tagsense_count\n",
    "    #lem_count+0.1(sum(values(ss.word_counts))-lem_count) #Do not use Synset's other counts. It owrks out worse\n",
    "    lem_count\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "typealias Usages{S<:AbstractString, V<:AbstractVector{S}} Dict{Synset, Abs }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_all_usages (generic function with 1 method)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Collect up the usages from a indexed tagged source\"\n",
    "function get_usages(usage_index::Dict{String, Vector{Semcor.TaggedSentence}}, key)\n",
    "    if haskey(usage_index, key)\n",
    "        [map(lowercase, strip_tags(sent)) for sent in usage_index[key]]\n",
    "    else\n",
    "        Vector{String}[]\n",
    "    end\n",
    "end\n",
    "\n",
    "function get_usages(synset::Synset)\n",
    "    gloss::Vector{SubString{String}} = map(lowercase, punctuation_space_tokenize(synset.gloss))\n",
    "    [gloss]\n",
    "end\n",
    "\n",
    "function get_all_usages(wn::DB, semcor::Dict{String, Vector{Semcor.TaggedSentence}}, lemma_word, pos)   \n",
    "    lemma = db[pos, lemma_word]\n",
    "    target_synsets::Vector{Synset} = synsets(db, lemma)\n",
    "    \n",
    "    Dict{Synset,AbstractVector{AbstractVector}}(\n",
    "        (synset => [get_usages(semcor, sensekey(db, synset, lemma)); get_usages(synset)]\n",
    "                    for synset in target_synsets)...)  \n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "all_word_sense_vectors (generic function with 2 methods)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function all_word_sense_vectors(ee::WordSenseEmbedding, word)\n",
    "    get(ee.embedding, word, Vector{Float32}[])\n",
    "end\n",
    "\n",
    "function all_word_sense_vectors(am::AdaGramCompat.AdaGramModel, word)\n",
    "    if haskey(am.dict.word2id, word)\n",
    "        wsv_mat = word_sense_vectors(am, word)\n",
    "        [view(wsv_mat,:,ii) for ii in 1:size(wsv_mat,2)]\n",
    "    else\n",
    "        Vector{Float32}[]\n",
    "    end\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lexically_informed_embeddings (generic function with 2 methods)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function normal_probs(logprobs::Vector)\n",
    "    ret = copy(logprobs)\n",
    "    max_lp = maximum(logprobs)\n",
    "    ret.-=max_lp #Bring closer to zero\n",
    "    map!(exp,ret)\n",
    "    denom = sum(ret)\n",
    "    ret./=denom\n",
    "    ret\n",
    "end\n",
    "function weighted_average(logprobs, embeddings)\n",
    "    ret = zeros(first(embeddings))\n",
    "    for (weight, embedding) in zip(normal_probs(logprobs), embeddings)\n",
    "        ret.+= weight.*embedding\n",
    "    end\n",
    "    ret\n",
    "end\n",
    "\n",
    "\n",
    "function synthesize_embedding(ee,context::AbstractVector, word_or_phrase::AbstractString)\n",
    "    words = split(word_or_phrase, \" \")\n",
    "    wvs = vcat((all_word_sense_vectors(ee,w) for w in words)...)\n",
    "    if length(wvs) == 0\n",
    "            throw(KeyError(\"None of $words have embeddings\"))\n",
    "    end\n",
    "    logprobs = [Query.logprob_of_context(ee, context, wv; skip_oov=true, normalise_over_length=true) for wv in wvs]\n",
    "    weighted_average(logprobs, wvs)\n",
    "end\n",
    "\n",
    "\n",
    "all_identical(col) = length(col)==1 || !any(x->x!=col[1],col[2:end])\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "function _lexically_informed_embeddings(wn::DB,ee, word,lemma_word, pos)\n",
    "    indexed_corpus = semcor #TODO: Pass this as a parameter, not as a gloel\n",
    "    target_synset_examples = get_all_usages(wn, indexed_corpus, lemma_word, pos)\n",
    "    target_synsets = collect(keys(target_synset_examples))\n",
    "    lemma = db[lemma_word, pos]\n",
    "        \n",
    "    embeddings = Vector{Vector{Float32}}(length(target_synsets))\n",
    "    for (ii,(synset, examples)) in enumerate(target_synset_examples)\n",
    "        embeddings[ii] = mean(examples) do eg#::AbstractVector\n",
    "        context::Vector{SubString{String}} = filter(w::AbstractString->w!=word, eg)\n",
    "        synthesize_embedding(ee,context, word)\n",
    "        end\n",
    "    end\n",
    "        \n",
    "    \n",
    "    if all_identical(embeddings)\n",
    "        #Use MCWS\n",
    "        score, index = findmax(sense_frequency(ss,lemma) for ss in target_synsets)\n",
    "        target_synsets=[target_synsets[index]] # Throw out others\n",
    "        embeddings=[embeddings[1]]\n",
    "    end\n",
    "        \n",
    "    embeddings,target_synsets,lemma\n",
    "end\n",
    "\n",
    "lexically_informed_embeddings(wn::DB, ee, lemma_word, pos) = lexically_informed_embeddings(db,ee, lemma_word, lemma_word, pos)\n",
    "        \n",
    "_li_embeddings = Dict{Tuple{DB, Any, String, String, Char}, Tuple{Vector{Vector{Float32}}, Vector{Synset}, Lemma}}()\n",
    "function lexically_informed_embeddings(wn::DB, ee, word,lemma_word, pos)\n",
    "    get!(_li_embeddings, (wn, ee, word, lemma_word, pos)) do\n",
    "        _lexically_informed_embeddings(wn, ee, word, lemma_word, pos)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "most_frequent_sense (generic function with 1 method)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function supervised_wsd(challenge, ee, wn::DB)\n",
    "    try\n",
    "        embeddings,target_synsets,lemma = lexically_informed_embeddings(wn,ee,\n",
    "                                                            challenge.word, \n",
    "                                                            challenge.lemma, challenge.pos)\n",
    "        #sense_index = Query.WSD(ee, embeddings, challenge.context; skip_oov=true)\n",
    "        logprobs_of_context = [logprob_of_context(ee,challenge.context, wv; skip_oov=true, normalise_over_length=true) \n",
    "                                    for wv in embeddings] \n",
    "      \n",
    "        sense_index= indmax(logprobs_of_context)\n",
    "\n",
    "        \n",
    "        synset = target_synsets[sense_index]\n",
    "        sk = sensekey(wn, synset, lemma)\n",
    "        Nullable(sk)\n",
    "    catch ex\n",
    "        isa(ex, KeyError) || rethrow(ex)\n",
    "        Nullable{String}()\n",
    "    end\n",
    "end\n",
    "\n",
    "function most_frequent_sense(challenge, wn::DB)\n",
    "    try\n",
    "        lemma = wn[challenge.pos, challenge.lemma]\n",
    "        target_synsets::Vector{Synset} = synsets(db, lemma)\n",
    "        \n",
    "        sense_freqs =  Float32[sense_frequency(ss,lemma) for ss in target_synsets]      \n",
    "        sense_index= indmax(sense_freqs)\n",
    "        synset = target_synsets[sense_index]\n",
    "        \n",
    "        sk = sensekey(wn, synset,  lemma)\n",
    "        Nullable(sk)\n",
    "    catch ex\n",
    "        isa(ex, KeyError) || rethrow(ex)\n",
    "        Nullable{String}()\n",
    "    end\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using ProgressMeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evalute_on_wsd_challenge_MFS (generic function with 1 method)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function evalute_on_wsd_challenge(challenges, solutions, method)\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    notattempted = 0\n",
    "    @showprogress for (challenge, ground_solution) in zip(challenges, solutions)\n",
    "        assert(challenge.id == ground_solution.id)\n",
    "        output_sense = method(challenge)\n",
    "        if isnull(output_sense)\n",
    "            notattempted+=1\n",
    "        else\n",
    "            if get(output_sense) ∈ ground_solution.solutions\n",
    "                correct+=1\n",
    "            else\n",
    "                incorrect+=1\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    precision = correct/(correct+incorrect)\n",
    "    recall = correct/(correct+incorrect+notattempted)\n",
    "    f1 = (2*precision*recall) / (precision+recall)\n",
    "    return precision, recall, f1\n",
    "end\n",
    "    \n",
    "    \n",
    "function evalute_on_wsd_challenge(challenges, solutions, ee, wn::DB)\n",
    "    method = challenge -> supervised_wsd(challenge, ee, wn)\n",
    "    evalute_on_wsd_challenge(challenges, solutions, method)\n",
    "end\n",
    "\n",
    "\n",
    "function evalute_on_wsd_challenge_MFS(challenges, solutions, wn::DB)\n",
    "    method = challenge -> most_frequent_sense(challenge, wn)\n",
    "    evalute_on_wsd_challenge(challenges, solutions, method)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 100%|█████████████████████████████████████████| Time: 0:00:11\n",
      "overall: \t\t(0.6392935982339956,0.6381665932128691,0.6387295985884428)\n",
      "Progress: 100%|█████████████████████████████████████████| Time: 0:00:04\n",
      "nn = evalute_on_wsd_challenge(only_of_pos(challenges,'n'),only_of_pos(solutions,'n'),am,db) = (0.6495031616982837,0.6489169675090253,0.6492099322799098)\n",
      "Progress: 100%|█████████████████████████████████████████| Time: 0:00:05\n",
      "vv = evalute_on_wsd_challenge(only_of_pos(challenges,'v'),only_of_pos(solutions,'v'),am,db) = (0.6016949152542372,0.6006768189509306,0.6011854360711262)\n",
      "Progress: 100%|█████████████████████████████████████████| Time: 0:00:01\n",
      "aa = evalute_on_wsd_challenge(only_of_pos(challenges,'a'),only_of_pos(solutions,'a'),am,db) = (0.6232686980609419,0.6215469613259669,0.6224066390041495)\n",
      "Progress: 100%|█████████████████████████████████████████| Time: 0:00:01\n",
      "rr = evalute_on_wsd_challenge(only_of_pos(challenges,'r'),only_of_pos(solutions,'r'),am,db) = (0.7198067632850241,0.7163461538461539,0.7180722891566265)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7198067632850241,0.7163461538461539,0.7180722891566265)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "println(\"overall: \\t\\t\", evalute_on_wsd_challenge(challenges, solutions, am, db))\n",
    "\n",
    "#println(\"only nouns  : \\t\\t\", \n",
    "@show nn = evalute_on_wsd_challenge(only_of_pos(challenges,'n'), only_of_pos(solutions,'n'), am, db)\n",
    "#println(\"only verbs  : \\t\\t\", \n",
    "@show vv = evalute_on_wsd_challenge(only_of_pos(challenges,'v'), only_of_pos(solutions,'v'), am, db)\n",
    "#println(\"only adjecti: \\t\\t\", \n",
    "@show aa = evalute_on_wsd_challenge(only_of_pos(challenges,'a'), only_of_pos(solutions,'a'), am, db)\n",
    "#println(\"only adverbs: \\t\\t\", \n",
    "@show rr = evalute_on_wsd_challenge(only_of_pos(challenges,'r'), only_of_pos(solutions,'r'), am, db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: ccall HierarchicalSoftmaxNode AbstractChannel\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "ccall((symbol, library) or function_pointer, ReturnType, (ArgumentType1, ...), ArgumentValue1, ...)\n",
       "\\end{verbatim}\n",
       "Call function in C-exported shared library, specified by \\texttt{(function name, library)} tuple, where each component is a string or symbol.\n",
       "Note that the argument type tuple must be a literal tuple, and not a tuple-valued variable or expression. Alternatively, \\texttt{ccall} may also be used to call a function pointer, such as one returned by \\texttt{dlsym}.\n",
       "Each \\texttt{ArgumentValue} to the \\texttt{ccall} will be converted to the corresponding \\texttt{ArgumentType}, by automatic insertion of calls to \\texttt{unsafe_convert(ArgumentType, cconvert(ArgumentType, ArgumentValue))}. (See also the documentation for each of these functions for further details.) In most cases, this simply results in a call to \\texttt{convert(ArgumentType, ArgumentValue)}.\n"
      ],
      "text/markdown": [
       "```\n",
       "ccall((symbol, library) or function_pointer, ReturnType, (ArgumentType1, ...), ArgumentValue1, ...)\n",
       "```\n",
       "\n",
       "Call function in C-exported shared library, specified by `(function name, library)` tuple, where each component is a string or symbol.\n",
       "\n",
       "Note that the argument type tuple must be a literal tuple, and not a tuple-valued variable or expression. Alternatively, `ccall` may also be used to call a function pointer, such as one returned by `dlsym`.\n",
       "\n",
       "Each `ArgumentValue` to the `ccall` will be converted to the corresponding `ArgumentType`, by automatic insertion of calls to `unsafe_convert(ArgumentType, cconvert(ArgumentType, ArgumentValue))`. (See also the documentation for each of these functions for further details.) In most cases, this simply results in a call to `convert(ArgumentType, ArgumentValue)`.\n"
      ],
      "text/plain": [
       "```\n",
       "ccall((symbol, library) or function_pointer, ReturnType, (ArgumentType1, ...), ArgumentValue1, ...)\n",
       "```\n",
       "\n",
       "Call function in C-exported shared library, specified by `(function name, library)` tuple, where each component is a string or symbol.\n",
       "\n",
       "Note that the argument type tuple must be a literal tuple, and not a tuple-valued variable or expression. Alternatively, `ccall` may also be used to call a function pointer, such as one returned by `dlsym`.\n",
       "\n",
       "Each `ArgumentValue` to the `ccall` will be converted to the corresponding `ArgumentType`, by automatic insertion of calls to `unsafe_convert(ArgumentType, cconvert(ArgumentType, ArgumentValue))`. (See also the documentation for each of these functions for further details.) In most cases, this simply results in a call to `convert(ArgumentType, ArgumentValue)`.\n"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?ccall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: MethodError: no method matching length(::Type{Dict{Float64,Int64}})\nClosest candidates are:\n  length(!Matched::SimpleVector) at essentials.jl:168\n  length(!Matched::Base.MethodList) at reflection.jl:256\n  length(!Matched::MethodTable) at reflection.jl:322\n  ...\nwhile loading In[154], in expression starting on line 2",
     "output_type": "error",
     "traceback": [
      "LoadError: MethodError: no method matching length(::Type{Dict{Float64,Int64}})\nClosest candidates are:\n  length(!Matched::SimpleVector) at essentials.jl:168\n  length(!Matched::Base.MethodList) at reflection.jl:256\n  length(!Matched::MethodTable) at reflection.jl:322\n  ...\nwhile loading In[154], in expression starting on line 2",
      "",
      " in include_string(::String, ::String) at ./loading.jl:380",
      " in execute_request_0x535c5df2(::ZMQ.Socket, ::IJulia.Msg) at /home/ubuntu/.julia/v0.5/IJulia/src/execute_request.jl:183",
      " in eventloop(::ZMQ.Socket) at /home/ubuntu/.julia/v0.5/IJulia/src/IJulia.jl:143",
      " in (::IJulia.##26#32)() at ./task.jl:309"
     ]
    }
   ],
   "source": [
    "a = Dict{Float64, Int64}\n",
    "length(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall: \t\t(0.6486486486486487,0.6346408109299251,0.6415682780129205)\n",
      "only nouns  : \t\t(0.6593001841620626,0.6462093862815884,0.6526891522333637)\n",
      "only verbs  : \t\t(0.5785837651122625,0.5668358714043993,0.5726495726495726)\n",
      "only adjecti: \t\t(0.6762177650429799,0.6519337016574586,0.6638537271448665)\n",
      "only adverbs: \t\t(0.7427184466019418,0.7355769230769231,0.7391304347826086)\n"
     ]
    }
   ],
   "source": [
    "println(\"overall: \\t\\t\", evalute_on_wsd_challenge(challenges, solutions, ee, db))\n",
    "\n",
    "println(\"only nouns  : \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'n'), only_of_pos(solutions,'n'), ee, db))\n",
    "println(\"only verbs  : \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'v'), only_of_pos(solutions,'v'), ee, db))\n",
    "println(\"only adjecti: \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'a'), only_of_pos(solutions,'a'), ee, db))\n",
    "println(\"only adverbs: \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'r'), only_of_pos(solutions,'r'), ee, db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall: \t\t(0.7783164389598942,0.7783164389598942,0.7783164389598942)\n",
      "only nouns  : \t\t(0.7653429602888087,0.7653429602888087,0.7653429602888087)\n",
      "only verbs  : \t\t(0.7529610829103215,0.7529610829103215,0.7529610829103215)\n",
      "only adjecti: \t\t(0.8038674033149171,0.8038674033149171,0.8038674033149171)\n",
      "only adverbs: \t\t(0.875,0.875,0.875)\n"
     ]
    }
   ],
   "source": [
    "println(\"overall: \\t\\t\", evalute_on_wsd_challenge_MFS(challenges, solutions, db))\n",
    "\n",
    "println(\"only nouns  : \\t\\t\", evalute_on_wsd_challenge_MFS(only_of_pos(challenges,'n'), only_of_pos(solutions,'n'), db))\n",
    "println(\"only verbs  : \\t\\t\", evalute_on_wsd_challenge_MFS(only_of_pos(challenges,'v'), only_of_pos(solutions,'v'), db))\n",
    "println(\"only adjecti: \\t\\t\", evalute_on_wsd_challenge_MFS(only_of_pos(challenges,'a'), only_of_pos(solutions,'a'), db))\n",
    "println(\"only adverbs: \\t\\t\", evalute_on_wsd_challenge_MFS(only_of_pos(challenges,'r'), only_of_pos(solutions,'r'), db))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Zero shot WSI for 1 shot WSD\n",
    "using Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rr = FixedWordSenseEmbedding(ee.dimension, random_inited, huffman_tree; initial_nsenses=50)\n",
    "rr.corpus_size = ee.corpus_size\n",
    "rr.distribution = ee.distribution\n",
    "rr.codebook = ee.codebook\n",
    "rr.classification_tree = ee.classification_tree\n",
    "Training.initialize_embedding(rr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr.embedding[\"us\"] |> length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall: \t\t(0.6522522522522523,0.6381665932128691,0.6451325462241033)\n",
      "only nouns  : \t\t(0.6869244935543278,0.6732851985559567,0.6800364630811304)\n",
      "only verbs  : \t\t(0.5630397236614854,0.5516074450084603,0.5572649572649573)\n",
      "only adjecti: \t\t(0.667621776504298,0.643646408839779,0.6554149085794655)\n",
      "only adverbs: \t\t(0.6941747572815534,0.6875,0.6908212560386474)\n"
     ]
    }
   ],
   "source": [
    "println(\"overall: \\t\\t\", evalute_on_wsd_challenge(challenges, solutions, rr, db))\n",
    "\n",
    "println(\"only nouns  : \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'n'), only_of_pos(solutions,'n'), rr, db))\n",
    "println(\"only verbs  : \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'v'), only_of_pos(solutions,'v'), rr, db))\n",
    "println(\"only adjecti: \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'a'), only_of_pos(solutions,'a'), rr, db))\n",
    "println(\"only adverbs: \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'r'), only_of_pos(solutions,'r'), rr, db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hh = deepcopy(rr)\n",
    "for word in keys(rr.embedding)\n",
    "    append!(hh.embedding[word], ee.embedding[word])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall: \t\t(0.654054054054054,0.6399294843543412,0.6469146803296949)\n",
      "only nouns  : \t\t(0.6804788213627992,0.6669675090252708,0.6736554238833182)\n",
      "only verbs  : \t\t(0.5544041450777202,0.5431472081218274,0.5487179487179487)\n",
      "only adjecti: \t\t(0.6962750716332379,0.6712707182320442,0.6835443037974684)\n",
      "only adverbs: \t\t(0.7233009708737864,0.7163461538461539,0.7198067632850241)\n"
     ]
    }
   ],
   "source": [
    "println(\"overall: \\t\\t\", evalute_on_wsd_challenge(challenges, solutions, hh, db))\n",
    "\n",
    "println(\"only nouns  : \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'n'), only_of_pos(solutions,'n'), hh, db))\n",
    "println(\"only verbs  : \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'v'), only_of_pos(solutions,'v'), hh, db))\n",
    "println(\"only adjecti: \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'a'), only_of_pos(solutions,'a'), hh, db))\n",
    "println(\"only adverbs: \\t\\t\", evalute_on_wsd_challenge(only_of_pos(challenges,'r'), only_of_pos(solutions,'r'), hh, db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using JLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.0-rc0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
