{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Base.ASCIIString is deprecated, use String instead.\n",
      "  likely near /home/ubuntu/.julia/v0.5/AdaGram/src/AdaGram.jl:49\n",
      "WARNING: Base.ASCIIString is deprecated, use String instead.\n",
      "  likely near /home/ubuntu/.julia/v0.5/AdaGram/src/AdaGram.jl:49\n",
      "WARNING: Base.ASCIIString is deprecated, use String instead.\n",
      "  likely near /home/ubuntu/.julia/v0.5/AdaGram/src/AdaGram.jl:49\n",
      "WARNING: Base.ASCIIString is deprecated, use String instead.\n",
      "  likely near /home/ubuntu/.julia/v0.5/AdaGram/src/AdaGram.jl:49\n",
      "WARNING: Base.ASCIIString is deprecated, use String instead.\n",
      "  likely near /home/ubuntu/.julia/v0.5/AdaGram/src/AdaGram.jl:49\n",
      "WARNING: Base.ASCIIString is deprecated, use String instead.\n",
      "  likely near /home/ubuntu/.julia/v0.5/AdaGram/src/AdaGram.jl:49\n",
      "WARNING: Base.ASCIIString is deprecated, use String instead.\n",
      "  likely near /home/ubuntu/.julia/v0.5/AdaGram/src/AdaGram.jl:49\n",
      "WARNING: Base.ASCIIString is deprecated, use String instead.\n",
      "  likely near /home/ubuntu/.julia/v0.5/AdaGram/src/AdaGram.jl:49\n",
      "WARNING: Base.ASCIIString is deprecated, use String instead.\n",
      "  likely near /home/ubuntu/.julia/v0.5/AdaGram/src/AdaGram.jl:49\n",
      "WARNING: Base.ASCIIString is deprecated, use String instead.\n",
      "  likely near /home/ubuntu/.julia/v0.5/AdaGram/src/AdaGram.jl:49\n",
      "WARNING: Base.ASCIIString is deprecated, use String instead.\n",
      "  likely near /home/ubuntu/.julia/v0.5/AdaGram/src/AdaGram.jl:49\n",
      "WARNING: Base.ASCIIString is deprecated, use String instead.\n",
      "  likely near /home/ubuntu/.julia/v0.5/AdaGram/src/AdaGram.jl:49\n",
      "WARNING: Base.ASCIIString is deprecated, use String instead.\n",
      "  likely near /home/ubuntu/.julia/v0.5/AdaGram/src/AdaGram.jl:49\n",
      "WARNING: Base.ASCIIString is deprecated, use String instead.\n",
      "  likely near /home/ubuntu/.julia/v0.5/AdaGram/src/AdaGram.jl:49\n",
      "WARNING: Base.ASCIIString is deprecated, use String instead.\n",
      "  likely near /home/ubuntu/.julia/v0.5/AdaGram/src/AdaGram.jl:49\n",
      "WARNING: Base.ASCIIString is deprecated, use String instead.\n",
      "  likely near /home/ubuntu/.julia/v0.5/AdaGram/src/AdaGram.jl:49\n",
      "WARNING: Base.ASCIIString is deprecated, use String instead.\n",
      "  likely near /home/ubuntu/.julia/v0.5/AdaGram/src/AdaGram.jl:49\n",
      "WARNING: Base.ASCIIString is deprecated, use String instead.\n",
      "  likely near /home/ubuntu/.julia/v0.5/AdaGram/src/AdaGram.jl:49\n",
      "WARNING: Base.ASCIIString is deprecated, use String instead.\n",
      "  likely near /home/ubuntu/.julia/v0.5/AdaGram/src/AdaGram.jl:49\n",
      "WARNING: Base.ASCIIString is deprecated, use String instead.\n",
      "  likely near /home/ubuntu/.julia/v0.5/AdaGram/src/AdaGram.jl:49\n",
      "WARNING: Base.ASCIIString is deprecated, use String instead.\n",
      "  likely near /home/ubuntu/.julia/v0.5/AdaGram/src/AdaGram.jl:49\n",
      "WARNING: Base.ASCIIString is deprecated, use String instead.\n",
      "  likely near /home/ubuntu/.julia/v0.5/AdaGram/src/AdaGram.jl:49\n",
      "WARNING: Base.ASCIIString is deprecated, use String instead.\n",
      "  likely near /home/ubuntu/.julia/v0.5/AdaGram/src/AdaGram.jl:49\n",
      "WARNING: Base.ASCIIString is deprecated, use String instead.\n",
      "  likely near /home/ubuntu/.julia/v0.5/AdaGram/src/AdaGram.jl:49\n",
      "WARNING: Base.ASCIIString is deprecated, use String instead.\n",
      "  likely near /home/ubuntu/.julia/v0.5/AdaGram/src/AdaGram.jl:49\n",
      "WARNING: Base.ASCIIString is deprecated, use String instead.\n",
      "  likely near /home/ubuntu/.julia/v0.5/AdaGram/src/AdaGram.jl:49\n",
      "WARNING: Base.ASCIIString is deprecated, use String instead.\n",
      "  likely near /home/ubuntu/.julia/v0.5/AdaGram/src/AdaGram.jl:49\n",
      "WARNING: Base.ASCIIString is deprecated, use String instead.\n",
      "  likely near /home/ubuntu/.julia/v0.5/AdaGram/src/AdaGram.jl:49\n",
      "WARNING: Base.ASCIIString is deprecated, use String instead.\n",
      "  likely near /home/ubuntu/.julia/v0.5/AdaGram/src/AdaGram.jl:49\n",
      "WARNING: Base.ASCIIString is deprecated, use String instead.\n",
      "  likely near /home/ubuntu/.julia/v0.5/AdaGram/src/AdaGram.jl:49\n",
      "WARNING: Base.ASCIIString is deprecated, use String instead.\n",
      "  likely near /home/ubuntu/.julia/v0.5/AdaGram/src/AdaGram.jl:49\n",
      "WARNING: Base.ASCIIString is deprecated, use String instead.\n",
      "  likely near /home/ubuntu/.julia/v0.5/AdaGram/src/AdaGram.jl:49\n",
      "WARNING: Base.ASCIIString is deprecated, use String instead.\n",
      "  likely near /home/ubuntu/.julia/v0.5/AdaGram/src/AdaGram.jl:49\n"
     ]
    }
   ],
   "source": [
    "addprocs(10)\n",
    "using AdaGram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "r\"\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fn  =  \"../../eval/data/corpora/WikiCorp/tokenised_lowercase_WestburyLab.wikicorp.201004.txt\" #\"training text data\"\n",
    "output_fn = \"../../eval/models/adagram/v1_d100.adagram_model\"#\"file to save the model (in Julia format)\"\n",
    "dict_fn = \"../../eval/data/corpora/WikiCorp/tokenised_lowercase_WestburyLab.wikicorp.201004.1gram\" #\"dictionary file with word frequencies\"\n",
    "\n",
    "window = 4 #\"(max) window size\"\n",
    "min_freq  = 20 #\"min. frequency of the word\"\n",
    "remove_top_k = 0 #\"remove top K most frequent words\"\n",
    "dim  = 100 #\"dimensionality of representations\"\n",
    "prototypes = 5 #\"number of word prototypes\"\n",
    "alpha = 0.1 #\"prior probability of allocating a new prototype\"\n",
    "d  = 0.0 #\"parameter of Pitman-Yor process\"\n",
    "subsample = 1e-5 #\"subsampling treshold. useful value is 1e-5\"\n",
    "context_cut  = true #\"randomly reduce size of the context\"\n",
    "epochs = 1 #\"number of epochs to train\"\n",
    "initcount = 1. #\"initial weight (count) on first sense for each word\"\n",
    "stopwords =Set{AbstractString}() #\"list of stop words\"\n",
    "sense_treshold = 1e-10 #\"minimal probability of a meaning to contribute into gradients\"\n",
    "save_treshold = 1e-3 #\"minimal probability of a meaning to save after training\"\n",
    "regex = r\"\" #\"ignore words not matching provided regex\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dictionary... Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Building dictionary... \")\n",
    "vm, dict = read_from_file(dict_fn, dim, prototypes, min_freq,remove_top_k, stopwords; regex=regex)\n",
    "println(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vm.alpha = alpha\n",
    "vm.d = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: remotecall(id::Integer,f::Function,args...) is deprecated, use remotecall(f,id::Integer,args...) instead.\n",
      " in depwarn(::String, ::Symbol) at ./deprecated.jl:64\n",
      " in remotecall(::Int64, ::Function, ::Int64, ::Vararg{Int64,N}) at ./deprecated.jl:50\n",
      " in #inplace_train_vectors!#18(::Int64, ::Float64, ::Void, ::Float64, ::Bool, ::Int64, ::Float64, ::Float64, ::AdaGram.#inplace_train_vectors!, ::AdaGram.VectorModel, ::AdaGram.Dictionary, ::String, ::Int64) at /home/ubuntu/.julia/v0.5/AdaGram/src/gradient.jl:154\n",
      " in (::AdaGram.#kw##inplace_train_vectors!)(::Array{Any,1}, ::AdaGram.#inplace_train_vectors!, ::AdaGram.VectorModel, ::AdaGram.Dictionary, ::String, ::Int64) at ./<missing>:0\n",
      " in include_string(::String, ::String) at ./loading.jl:380\n",
      " in execute_request_0x535c5df2(::ZMQ.Socket, ::IJulia.Msg) at /home/ubuntu/.julia/v0.5/IJulia/src/execute_request.jl:183\n",
      " in eventloop(::ZMQ.Socket) at /home/ubuntu/.julia/v0.5/IJulia/src/IJulia.jl:143\n",
      " in (::IJulia.##26#32)() at ./task.jl:309\n",
      "while loading In[5], in expression starting on line 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFrom worker 2:\t64000 words read, 1296374/596129680\n",
      "\tFrom worker 2:\t0.02% -11.1842 0.0250 0.0250 2.14/3.00 3.13 kwords/sec\n",
      "\tFrom worker 2:\t0.02% -11.1178 0.0250 0.0250 2.00/3.00 3.84 kwords/sec\n",
      "\tFrom worker 2:\t0.02% -11.1022 0.0250 0.0250 1.91/3.00 3.90 kwords/sec\n",
      "\tFrom worker 2:\t0.02% -11.0636 0.0250 0.0250 1.84/3.00 3.92 kwords/sec\n",
      "\tFrom worker 3:\t64000 words read, 597414099/1192259360\n",
      "\tFrom worker 2:\t0.03% -11.0132 0.0250 0.0250 1.78/3.00 3.91 kwords/sec\n"
     ]
    }
   ],
   "source": [
    "inplace_train_vectors!(vm, dict, train_fn, window;\n",
    "                       threshold=subsample, context_cut=context_cut,\n",
    "                       epochs=epochs, init_count=initcount, sense_treshold=sense_treshold)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "save_model(output_fn, vm, dict, save_treshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06530734158491676\tTuple{AbstractString,Int64,Float32}[(\"united\",2,0.983088),(\"county\",3,0.90978),(\"statistical\",2,0.900458),(\"cdp\",2,0.897619),(\"census\",1,0.891764),(\"township\",3,0.890909),(\"metropolitan\",1,0.887711),(\"bureau\",1,0.877118),(\"2000\",2,0.875254),(\"minnesota\",1,0.874623)]\n",
      "\n",
      "0.9346925294866518\tTuple{AbstractString,Int64,Float32}[(\"united\",1,0.896622),(\"u.s\",1,0.827811),(\"jackson-vanik\",1,0.7056),(\"jones-shafroth\",1,0.683918),(\"states—the\",1,0.683617),(\"sates\",1,0.682901),(\"rechartering\",1,0.662349),(\"commonwealth’s\",1,0.66137),(\"risenhoover\",1,0.660591),(\"9981\",1,0.657262)]\n",
      "\n",
      "1.1720787006966776e-7\tTuple{AbstractString,Int64,Float32}[(\"orient\",1,0.344258),(\"weymouth\",1,0.339116),(\"rmi\",1,0.338006),(\"rocs\",1,0.335061),(\"barrow-in-furness\",1,0.331527),(\"yachts\",1,0.326889),(\"rc\",1,0.319309),(\"hamworthy\",1,0.317995),(\"faw\",1,0.316552),(\"extend\",1,0.314892)]\n",
      "\n",
      "1.0655055733396529e-8\tTuple{AbstractString,Int64,Float32}[(\"trial\",1,0.395745),(\"extradition\",1,0.387345),(\"six-month\",1,0.386616),(\"heated\",2,0.385005),(\"retrial\",1,0.384413),(\"retried\",1,0.381968),(\"moreno-ocampo\",1,0.381355),(\"retrials\",1,0.380859),(\"rearrested\",1,0.380058),(\"zarakolu\",1,0.379728)]\n",
      "\n",
      "1.065505572399212e-9\tTuple{AbstractString,Int64,Float32}[(\"confidently\",1,0.395955),(\"lamar's\",1,0.381411),(\"heretofore\",1,0.375459),(\"reestablish\",1,0.370734),(\"establish\",2,0.366467),(\"yost\",1,0.359153),(\"franklin's\",1,0.357444),(\"anglo-burmese\",1,0.35571),(\"yost's\",1,0.353357),(\"blumentritt\",1,0.34919)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word = \"apple\"\n",
    "prior_probs = expected_pi(vm, dict.word2id[word])\n",
    "for ii in 1:5\n",
    "    println(prior_probs[ii],\"\\t\",nearest_neighbors(vm, dict, word, ii, 10))\n",
    "    println()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: names fieldnames dirname tempname fullname basename TypeName fieldname\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "names(x::Module[, all=false[, imported=false]])\n",
       "\\end{verbatim}\n",
       "Get an array of the names exported by a \\texttt{Module}, with optionally more \\texttt{Module} globals according to the additional parameters.\n"
      ],
      "text/markdown": [
       "```\n",
       "names(x::Module[, all=false[, imported=false]])\n",
       "```\n",
       "\n",
       "Get an array of the names exported by a `Module`, with optionally more `Module` globals according to the additional parameters.\n"
      ],
      "text/plain": [
       "```\n",
       "names(x::Module[, all=false[, imported=false]])\n",
       "```\n",
       "\n",
       "Get an array of the names exported by a `Module`, with optionally more `Module` globals according to the additional parameters.\n"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expr\n",
      "  head: Symbol block\n",
      "  args: Array{Any}((34,))\n",
      "    1: Expr\n",
      "      head: Symbol line\n",
      "      args: Array{Any}((2,))\n",
      "        1: Int64 2\n",
      "        2: Symbol In[149]\n",
      "      typ: Any\n",
      "    2: Expr\n",
      "      head: Symbol const\n",
      "      args: Array{Any}((1,))\n",
      "        1: Expr\n",
      "          head: Symbol =\n",
      "          args: Array{Any}((2,))\n",
      "            1: Symbol train_fn\n",
      "            2: String \"../../eval/data/corpora/WikiCorp/tokenised_lowercase_WestburyLab.wikicorp.201004.txt\"\n",
      "          typ: Any\n",
      "      typ: Any\n",
      "    3: Expr\n",
      "      head: Symbol line\n",
      "      args: Array{Any}((2,))\n",
      "        1: Int64 3\n",
      "        2: Symbol In[149]\n",
      "      typ: Any\n",
      "    4: Expr\n",
      "      head: Symbol =\n",
      "      args: Array{Any}((2,))\n",
      "        1: Symbol output_fn\n",
      "        2: String \"../../eval/models/adagram/v1_d100.adagram_model\"\n",
      "      typ: Any\n",
      "    5: Expr\n",
      "      head: Symbol line\n",
      "      args: Array{Any}((2,))\n",
      "        1: Int64 4\n",
      "        2: Symbol In[149]\n",
      "      typ: Any\n",
      "    ...\n",
      "    30: Expr\n",
      "      head: Symbol =\n",
      "      args: Array{Any}((2,))\n",
      "        1: Symbol stopwords\n",
      "        2: Expr\n",
      "          head: Symbol call\n",
      "          args: Array{Any}((1,))\n",
      "            1: Expr\n",
      "              head: Symbol curly\n",
      "              args: Array{Any}((2,))\n",
      "                1: Symbol Set\n",
      "                2: Symbol AbstractString\n",
      "              typ: Any\n",
      "          typ: Any\n",
      "      typ: Any\n",
      "    31: Expr\n",
      "      head: Symbol line\n",
      "      args: Array{Any}((2,))\n",
      "        1: Int64 18\n",
      "        2: Symbol In[149]\n",
      "      typ: Any\n",
      "    32: Expr\n",
      "      head: Symbol =\n",
      "      args: Array{Any}((2,))\n",
      "        1: Symbol sense_treshold\n",
      "        2: Float64 1.0e-10\n",
      "      typ: Any\n",
      "    33: Expr\n",
      "      head: Symbol line\n",
      "      args: Array{Any}((2,))\n",
      "        1: Int64 19\n",
      "        2: Symbol In[149]\n",
      "      typ: Any\n",
      "    34: Expr\n",
      "      head: Symbol =\n",
      "      args: Array{Any}((2,))\n",
      "        1: Symbol save_treshold\n",
      "        2: Float64 0.001\n",
      "      typ: Any\n",
      "  typ: Any\n"
     ]
    }
   ],
   "source": [
    "blk = quote\n",
    "    const train_fn  =  \"../../eval/data/corpora/WikiCorp/tokenised_lowercase_WestburyLab.wikicorp.201004.txt\" #\"training text data\"\n",
    "output_fn = \"../../eval/models/adagram/v1_d100.adagram_model\"#\"file to save the model (in Julia format)\"\n",
    "dict_fn = \"../../eval/data/corpora/WikiCorp/tokenised_lowercase_WestburyLab.wikicorp.201004.1gram\" #\"dictionary file with word frequencies\"\n",
    "\n",
    "window = 4 #\"(max) window size\"\n",
    "min_freq  = 20 #\"min. frequency of the word\"\n",
    "remove_top_k = 0 #\"remove top K most frequent words\"\n",
    "dim  = 100 #\"dimensionality of representations\"\n",
    "prototypes = 5 #\"number of word prototypes\"\n",
    "alpha = 0.1 #\"prior probability of allocating a new prototype\"\n",
    "d  = 0.0 #\"parameter of Pitman-Yor process\"\n",
    "subsample = 1e-5 #\"subsampling treshold. useful value is 1e-5\"\n",
    "context_cut  = true #\"randomly reduce size of the context\"\n",
    "epochs = 1 #\"number of epochs to train\"\n",
    "initcount = 1. #\"initial weight (count) on first sense for each word\"\n",
    "stopwords =Set{AbstractString}() #\"list of stop words\"\n",
    "sense_treshold = 1e-10 #\"minimal probability of a meaning to contribute into gradients\"\n",
    "save_treshold = 1e-3 #\"minimal probability of a meaning to save after training\"\n",
    "#regex = r\"\" #\"ignore words not matching provided regex\"\n",
    "    end |> dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36-element Array{Symbol,1}:\n",
       " :AdaGram       \n",
       " :ArrayViews    \n",
       " :Base          \n",
       " :Compat        \n",
       " :Core          \n",
       " :Devectorize   \n",
       " :IJulia        \n",
       " :IPythonDisplay\n",
       " :JSON          \n",
       " :Main          \n",
       " :Nettle        \n",
       " :ZMQ           \n",
       " :add_to_path   \n",
       " :alpha         \n",
       " :blk           \n",
       " :context_cut   \n",
       " :d             \n",
       " :dict          \n",
       " :dict_fn       \n",
       " :dim           \n",
       " :epochs        \n",
       " :initcount     \n",
       " :min_freq      \n",
       " :output_fn     \n",
       " :prior_probs   \n",
       " :prototypes    \n",
       " :regex         \n",
       " :remove_top_k  \n",
       " :save_treshold \n",
       " :sense_treshold\n",
       " :stopwords     \n",
       " :subsample     \n",
       " :train_fn      \n",
       " :vm            \n",
       " :window        \n",
       " :word          "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names(current_module())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: append! apply_gradient!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "append!(collection, collection2) -> collection.\n",
       "\\end{verbatim}\n",
       "Add the elements of \\texttt{collection2} to the end of \\texttt{collection}.\n",
       "\\begin{verbatim}\n",
       "julia> append!([1],[2,3])\n",
       "3-element Array{Int64,1}:\n",
       " 1\n",
       " 2\n",
       " 3\n",
       "\\end{verbatim}\n",
       "\\begin{verbatim}\n",
       "julia> append!([1, 2, 3], [4, 5, 6])\n",
       "6-element Array{Int64,1}:\n",
       " 1\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5\n",
       " 6\n",
       "\\end{verbatim}\n",
       "Use \\href{:func:`push!`}{\\texttt{push!}} to add individual items to \\texttt{collection} which are not already themselves in another collection. The result is of the preceding example is equivalent to \\texttt{push!([1, 2, 3], 4, 5, 6)}.\n"
      ],
      "text/markdown": [
       "```\n",
       "append!(collection, collection2) -> collection.\n",
       "```\n",
       "\n",
       "Add the elements of `collection2` to the end of `collection`.\n",
       "\n",
       "```jldoctest\n",
       "julia> append!([1],[2,3])\n",
       "3-element Array{Int64,1}:\n",
       " 1\n",
       " 2\n",
       " 3\n",
       "```\n",
       "\n",
       "```jldoctest\n",
       "julia> append!([1, 2, 3], [4, 5, 6])\n",
       "6-element Array{Int64,1}:\n",
       " 1\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5\n",
       " 6\n",
       "```\n",
       "\n",
       "Use [`push!`](:func:`push!`) to add individual items to `collection` which are not already themselves in another collection. The result is of the preceding example is equivalent to `push!([1, 2, 3], 4, 5, 6)`.\n"
      ],
      "text/plain": [
       "```\n",
       "append!(collection, collection2) -> collection.\n",
       "```\n",
       "\n",
       "Add the elements of `collection2` to the end of `collection`.\n",
       "\n",
       "```jldoctest\n",
       "julia> append!([1],[2,3])\n",
       "3-element Array{Int64,1}:\n",
       " 1\n",
       " 2\n",
       " 3\n",
       "```\n",
       "\n",
       "```jldoctest\n",
       "julia> append!([1, 2, 3], [4, 5, 6])\n",
       "6-element Array{Int64,1}:\n",
       " 1\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5\n",
       " 6\n",
       "```\n",
       "\n",
       "Use [`push!`](:func:`push!`) to add individual items to `collection` which are not already themselves in another collection. The result is of the preceding example is equivalent to `push!([1, 2, 3], 4, 5, 6)`.\n"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?append!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition names_candidates(Expr) in module Main at In[202]:2 overwritten at In[205]:2.\n",
      "WARNING: Method definition @param_save(ANY<:Any, Expr) in module Main at In[202]:15 overwritten at In[205]:15.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "@param_save (macro with 1 method)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function names_candidates(blk::Expr)\n",
    "    names_in_block = Vector{Symbol}()\n",
    "    for a in blk.args\n",
    "        typeof(a) <: Expr || continue\n",
    "        if a.head == :(=)\n",
    "            push!(names_in_block, a.args[1])\n",
    "        else #Recurse, so we captured things in blocks or behind `const`\n",
    "            append!(names_in_block, names_candidates(a))\n",
    "        end\n",
    "    end\n",
    "    names_in_block\n",
    "end\n",
    "\n",
    "macro param_save(filename, blk::Expr)\n",
    "    names_in_block =  names_candidates(blk)    \n",
    "    quote\n",
    "        $(esc(blk))\n",
    "        names_defined = Set($(names_in_block)) #∩ Set(names(current_module()))\n",
    "        names_and_vals =[(string(name), eval(name)) for name in names_defined]\n",
    "        JLD.save($filename, Base.flatten(names_and_vals)...)\n",
    "        println(\"Paramaters -- saved to $($filename)\")\n",
    "        println(\"----------\")\n",
    "        println(join((\"$n = $v\" for (n,v) in names_and_vals),\"\\n\"))\n",
    "        println(\"----------\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ";rm \"../../eval/models/adagram/v1_d100_2.params.jld\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paramaters -- saved to ../../eval/models/adagram/v1_d100_2.params.jld\n",
      "----------\n",
      "train_fn = ../../eval/data/corpora/WikiCorp/tokenised_lowercase_WestburyLab.wikicorp.201004.txt\n",
      "alpha = 0.1\n",
      "subsample = 1.0e-5\n",
      "sense_treshold = 1.0e-10\n",
      "initcount = 1.0\n",
      "epochs = 1\n",
      "output_fn = ../../eval/models/adagram/v1_d100.adagram_model\n",
      "min_freq = 20\n",
      "prototypes = 5\n",
      "context_cut = true\n",
      "stopwords = Set{AbstractString}()\n",
      "remove_top_k = 0\n",
      "save_treshold = 6\n",
      "wixndow = 4\n",
      "dict_fn = ../../eval/data/corpora/WikiCorp/tokenised_lowercase_WestburyLab.wikicorp.201004.1gram\n",
      "dim = 100\n",
      "d = 0.0\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "#macroexpand(quote\n",
    "@param_save  \"../../eval/models/adagram/v1_d100_2.params.jld\" begin\n",
    "    train_fn  =  \"../../eval/data/corpora/WikiCorp/tokenised_lowercase_WestburyLab.wikicorp.201004.txt\" #\"training text data\"\n",
    "    output_fn = \"../../eval/models/adagram/v1_d100.adagram_model\"#\"file to save the model (in Julia format)\"\n",
    "    dict_fn = \"../../eval/data/corpora/WikiCorp/tokenised_lowercase_WestburyLab.wikicorp.201004.1gram\" #\"dictionary file with word frequencies\"\n",
    "\n",
    "    const wixndow = 4 #\"(max) window size\"\n",
    "    min_freq  = 20 #\"min. frequency of the word\"\n",
    "    remove_top_k = 0 #\"remove top K most frequent words\"\n",
    "    dim  = 100 #\"dimensionality of representations\"\n",
    "    prototypes = 5 #\"number of word prototypes\"\n",
    "    alpha = 0.1 #\"prior probability of allocating a new prototype\"\n",
    "    d  = 0.0 #\"parameter of Pitman-Yor process\"\n",
    "    subsample = 1e-5 #\"subsampling treshold. useful value is 1e-5\"\n",
    "    context_cut  = true #\"randomly reduce size of the context\"\n",
    "    epochs = 1 #\"number of epochs to train\"\n",
    "    initcount = 1. #\"initial weight (count) on first sense for each word\"\n",
    "    stopwords =Set{AbstractString}() #\"list of stop words\"\n",
    "    sense_treshold = 1e-10 #\"minimal probability of a meaning to contribute into gradients\"\n",
    "    save_treshold = 6 #\"minimal probability of a meaning to save after training\"\n",
    "end\n",
    "#end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String,Any} with 1 entry:\n",
       "  \"save_treshold\" => 6"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JLD.load(\"../../eval/models/adagram/v1_d100_2.params.jld\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 11 processors\n"
     ]
    }
   ],
   "source": [
    " println(\"Using \", nprocs(), \" processors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.0-rc0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
