{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pylab as pl\n",
    "%matplotlib inline\n",
    "pl.rcParams['figure.figsize'] = 15, 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import csv\n",
    "import numpy as np\n",
    "import scipy.spatial\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(\"prepared_corpora/msrp_ns_va_nophrase_mfcwsd/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def embedding_distance(embeddings, id1, id2):\n",
    "    ii = id1 - 1  #Change from 1 indexed id, to 0 indexex embedding index\n",
    "    jj = id2 - 1\n",
    "    return scipy.spatial.distance.cosine(embeddings[ii,:], embeddings[jj,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_links(link_filename):\n",
    "    return np.loadtxt(link_filename, delimiter=\",\",skiprows=1, dtype=np.int)\n",
    "\n",
    "def load_link_distances(link_filename, embeddings):\n",
    "    links = load_links(link_filename)\n",
    "    dists = pd.Series()\n",
    "    for link in links:\n",
    "        assert(len(link)==2)\n",
    "        phrase_id = link[0]\n",
    "        var_phrase_id = link[1]\n",
    "        \n",
    "        dists.loc[phrase_id] = embedding_distance(embeddings, phrase_id, var_phrase_id)\n",
    "    return dists\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_dists_table(embedding_filename, max_corruption = 10):\n",
    "    embeddings = np.loadtxt(embedding_filename, delimiter=\",\")\n",
    "    dists = pd.DataFrame()\n",
    "    dists[\"paraphrase\"] = load_link_distances(\"paraphrases.txt\", embeddings)\n",
    "    for corruption_level in range(1,max_corruption+1):\n",
    "        link_filename = str(corruption_level)+\"verb_anto_semantic_corruptions.txt\"\n",
    "        dists[\"verb_anto_\" + str(corruption_level)] = load_link_distances(link_filename, embeddings)\n",
    "        link_filename = str(corruption_level)+\"noun_sym_semantic_corruptions.txt\"\n",
    "        dists[\"noun_sym_\" + str(corruption_level)] = load_link_distances(link_filename, embeddings)\n",
    "    return dists  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1, 1, 0]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=Counter([\"aye\", \"bee\",\"bee\", \"cee\"])\n",
    "b=Counter([\"aye\", \"bee\",\"bee\", \"see\"])\n",
    "keys = list(set(a.keys()).union(b.keys()))\n",
    "avec = [a[key] for key in  keys]\n",
    "avec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bow_dists_table(max_corruption = 10):\n",
    "    from collections import Counter\n",
    "    \n",
    "    bows = [Counter(sent.split()) for sent in open(\"phrases.txt\",'r')]\n",
    "    \n",
    "    def get_dist(linenum1, linenum2):\n",
    "        from distance import jaccard\n",
    "        bow1 = bows[linenum1-1]\n",
    "        bow2 = bows[linenum2-1]\n",
    "        keys = list(set(bow1.keys()).union(bow2.keys()))\n",
    "        vec1 = [bow1[key] for key in  keys]\n",
    "        vec2 = [bow2[key] for key in  keys]\n",
    "        return scipy.spatial.distance.cosine(vec1,vec2)\n",
    "\n",
    "    def get_dists(link_filename):\n",
    "        dists = pd.Series()\n",
    "        for link in load_links(link_filename):\n",
    "            dists.loc[link[0]] = get_dist(link[0],link[1])\n",
    "        return dists\n",
    "        \n",
    "\n",
    "    dists = pd.DataFrame()\n",
    "    dists[\"paraphrase\"] = get_dists(\"paraphrases.txt\")\n",
    "    for corruption_level in range(1,max_corruption+1):\n",
    "        dists[\"verb_anto_\" + str(corruption_level)] = get_dists(str(corruption_level)+\"verb_anto_semantic_corruptions.txt\")\n",
    "        dists[\"noun_sym_\" + str(corruption_level)] = get_dists(str(corruption_level)+\"noun_sym_semantic_corruptions.txt\")\n",
    "    return dists  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_sow_jaccard_dists_table(max_corruption = 10):\n",
    "    \n",
    "    bows = [set(sent.split()) for sent in open(\"phrases.txt\",'r')]\n",
    "    \n",
    "    def get_dist(linenum1, linenum2):\n",
    "        from distance import jaccard\n",
    "        s1 = bows[linenum1-1]\n",
    "        s2 = bows[linenum2-1]\n",
    "        return jaccard(s1,s2)\n",
    "\n",
    "    def get_dists(link_filename):\n",
    "        dists = pd.Series()\n",
    "        for link in load_links(link_filename):\n",
    "            dists.loc[link[0]] = get_dist(link[0],link[1])\n",
    "        return dists\n",
    "        \n",
    "\n",
    "    dists = pd.DataFrame()\n",
    "    dists[\"paraphrase\"] = get_dists(\"paraphrases.txt\")\n",
    "    for corruption_level in range(1,max_corruption+1):\n",
    "        dists[\"verb_anto_\" + str(corruption_level)] = get_dists(str(corruption_level)+\"verb_anto_semantic_corruptions.txt\")\n",
    "        dists[\"noun_sym_\" + str(corruption_level)] = get_dists(str(corruption_level)+\"noun_sym_semantic_corruptions.txt\")\n",
    "    return dists  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/site-packages/numpy/lib/npyio.py:823: UserWarning: loadtxt: Empty input file: \"6verb_anto_semantic_corruptions.txt\"\n",
      "  warnings.warn('loadtxt: Empty input file: \"%s\"' % fname)\n",
      "/usr/local/lib/python3.4/site-packages/numpy/lib/npyio.py:823: UserWarning: loadtxt: Empty input file: \"7verb_anto_semantic_corruptions.txt\"\n",
      "  warnings.warn('loadtxt: Empty input file: \"%s\"' % fname)\n",
      "/usr/local/lib/python3.4/site-packages/numpy/lib/npyio.py:823: UserWarning: loadtxt: Empty input file: \"8verb_anto_semantic_corruptions.txt\"\n",
      "  warnings.warn('loadtxt: Empty input file: \"%s\"' % fname)\n",
      "/usr/local/lib/python3.4/site-packages/numpy/lib/npyio.py:823: UserWarning: loadtxt: Empty input file: \"9verb_anto_semantic_corruptions.txt\"\n",
      "  warnings.warn('loadtxt: Empty input file: \"%s\"' % fname)\n",
      "/usr/local/lib/python3.4/site-packages/numpy/lib/npyio.py:823: UserWarning: loadtxt: Empty input file: \"10verb_anto_semantic_corruptions.txt\"\n",
      "  warnings.warn('loadtxt: Empty input file: \"%s\"' % fname)\n",
      "/usr/local/lib/python3.4/site-packages/numpy/lib/npyio.py:823: UserWarning: loadtxt: Empty input file: \"10noun_sym_semantic_corruptions.txt\"\n",
      "  warnings.warn('loadtxt: Empty input file: \"%s\"' % fname)\n"
     ]
    }
   ],
   "source": [
    "bow_dists = get_bow_dists_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/site-packages/numpy/lib/npyio.py:823: UserWarning: loadtxt: Empty input file: \"6verb_anto_semantic_corruptions.txt\"\n",
      "  warnings.warn('loadtxt: Empty input file: \"%s\"' % fname)\n",
      "/usr/local/lib/python3.4/site-packages/numpy/lib/npyio.py:823: UserWarning: loadtxt: Empty input file: \"7verb_anto_semantic_corruptions.txt\"\n",
      "  warnings.warn('loadtxt: Empty input file: \"%s\"' % fname)\n",
      "/usr/local/lib/python3.4/site-packages/numpy/lib/npyio.py:823: UserWarning: loadtxt: Empty input file: \"8verb_anto_semantic_corruptions.txt\"\n",
      "  warnings.warn('loadtxt: Empty input file: \"%s\"' % fname)\n",
      "/usr/local/lib/python3.4/site-packages/numpy/lib/npyio.py:823: UserWarning: loadtxt: Empty input file: \"9verb_anto_semantic_corruptions.txt\"\n",
      "  warnings.warn('loadtxt: Empty input file: \"%s\"' % fname)\n",
      "/usr/local/lib/python3.4/site-packages/numpy/lib/npyio.py:823: UserWarning: loadtxt: Empty input file: \"10verb_anto_semantic_corruptions.txt\"\n",
      "  warnings.warn('loadtxt: Empty input file: \"%s\"' % fname)\n",
      "/usr/local/lib/python3.4/site-packages/numpy/lib/npyio.py:823: UserWarning: loadtxt: Empty input file: \"10noun_sym_semantic_corruptions.txt\"\n",
      "  warnings.warn('loadtxt: Empty input file: \"%s\"' % fname)\n"
     ]
    }
   ],
   "source": [
    "rae_dists = get_dists_table(\"outVectors_RAE2011.csv\")\n",
    "#wiki_doc2vec_dists = get_dists_table(\"outVectors_wiki_doc2vec.csv\")\n",
    "#hansard_doc2vec_dists = get_dists_table(\"outVectors_hansard_doc2vec.csv\")\n",
    "#wiki_sentence_doc2vec_dists = get_dists_table(\"outVectors_wiki_sentence_doc2vec.csv\")\n",
    "wiki_sentence_concat_doc2vec_dists = get_dists_table(\"outVectors_wiki_sentence_doc2vec.csv\")\n",
    "dbow_dists = get_dists_table(\"outVectors_wiki_sentence_model_dbow.csv\")\n",
    "#random_dists = get_dists_table(\"outVectors_random.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "paraphrase      7800\n",
       "verb_anto_1     3061\n",
       "noun_sym_1      7168\n",
       "verb_anto_2      590\n",
       "noun_sym_2      5503\n",
       "verb_anto_3       82\n",
       "noun_sym_3      3395\n",
       "verb_anto_4       12\n",
       "noun_sym_4      1747\n",
       "verb_anto_5        2\n",
       "noun_sym_5       813\n",
       "verb_anto_6        0\n",
       "noun_sym_6       309\n",
       "verb_anto_7        0\n",
       "noun_sym_7       104\n",
       "verb_anto_8        0\n",
       "noun_sym_8        22\n",
       "verb_anto_9        0\n",
       "noun_sym_9         9\n",
       "verb_anto_10       0\n",
       "noun_sym_10        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_dists.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \t 2829\n",
      "2 \t 449\n",
      "3 \t 46\n",
      "4 \t 4\n",
      "5 \t 0\n",
      "6 \t 0\n",
      "7 \t 0\n",
      "8 \t 0\n",
      "9 \t 0\n",
      "10 \t 0\n"
     ]
    }
   ],
   "source": [
    "for nchanges in range(1,10+1):\n",
    "    verb_antos = bow_dists[\"verb_anto_\"+str(nchanges)]\n",
    "    noun_syms =  bow_dists[\"noun_sym_\"+str(nchanges)]\n",
    "    valid_dists = bow_dists[np.logical_and(pd.notnull(verb_antos), pd.notnull(noun_syms))]\n",
    "    print(nchanges, \"\\t\", len(valid_dists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def n_rel_than_paraphrase(prefix, dists, operation =lambda para_dist,var_dist: var_dist<para_dist, max_changes=10):\n",
    "    \"\"\"\n",
    "    prefix : eg \"verb_anto_\" or  \"noun_sym_\"\n",
    "    \"\"\"\n",
    "\n",
    "    return [operation(dists.paraphrase, dists[prefix+str(nchanges)]).sum()/dists[prefix+str(nchanges)].count() \n",
    "                 for nchanges in range(1,max_changes+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_results_table(\"verb_anto_\", lambda para_dist,var_dist: var_dist>para_dist, 5,\n",
    "                  URAE= rae_dists,\n",
    "                  PVDM = wiki_sentence_concat_doc2vec_dists,\n",
    "                  PVDBOW = dbow_dists,\n",
    "                  BOW = bow_dists\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_results_table(comparator_series_method, max_changes, **model_dists):\n",
    "    \n",
    "    res = pd.DataFrame()\n",
    "    res[\"n_changes\"] = list(range(1,max_changes+1))\n",
    "    \n",
    "    model_names = list(model_dists.keys())\n",
    "    model_names.sort()\n",
    "    model_names.reverse()\n",
    "    for model_name in model_names:\n",
    "        dists = model_dists[model_name]\n",
    "        res[model_name] = comparator_series_method(dists,max_changes)\n",
    "        #n_rel_than_paraphrase(prefix, dists, operation, max_changes)\n",
    "    \n",
    "    return res\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_changes</th>\n",
       "      <th>URAE</th>\n",
       "      <th>PVDM</th>\n",
       "      <th>PVDBOW</th>\n",
       "      <th>BOW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>95%</td>\n",
       "      <td>91%</td>\n",
       "      <td>90%</td>\n",
       "      <td>100%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>91%</td>\n",
       "      <td>84%</td>\n",
       "      <td>82%</td>\n",
       "      <td>99%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>87%</td>\n",
       "      <td>76%</td>\n",
       "      <td>75%</td>\n",
       "      <td>95%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>83%</td>\n",
       "      <td>68%</td>\n",
       "      <td>67%</td>\n",
       "      <td>85%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>79%</td>\n",
       "      <td>58%</td>\n",
       "      <td>57%</td>\n",
       "      <td>66%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>75%</td>\n",
       "      <td>52%</td>\n",
       "      <td>50%</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>75%</td>\n",
       "      <td>36%</td>\n",
       "      <td>39%</td>\n",
       "      <td>34%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>73%</td>\n",
       "      <td>36%</td>\n",
       "      <td>27%</td>\n",
       "      <td>18%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>89%</td>\n",
       "      <td>56%</td>\n",
       "      <td>33%</td>\n",
       "      <td>11%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_changes  URAE  PVDM  PVDBOW  BOW\n",
       "0          1   95%   91%     90% 100%\n",
       "1          2   91%   84%     82%  99%\n",
       "2          3   87%   76%     75%  95%\n",
       "3          4   83%   68%     67%  85%\n",
       "4          5   79%   58%     57%  66%\n",
       "5          6   75%   52%     50%  50%\n",
       "6          7   75%   36%     39%  34%\n",
       "7          8   73%   36%     27%  18%\n",
       "8          9   89%   56%     33%  11%"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.float_format = lambda x: '{:.0f}%'.format(x*100)\n",
    "def noun_sym_lt_para(dists,max_changes):\n",
    "    return n_rel_than_paraphrase(\"noun_sym_\", dists, lambda para_dist,var_dist: var_dist<=para_dist, max_changes)\n",
    "get_results_table(noun_sym_lt_para, 9,\n",
    "                  URAE= rae_dists,\n",
    "                  PVDM = wiki_sentence_concat_doc2vec_dists,\n",
    "                  PVDBOW = dbow_dists,\n",
    "                  BOW = bow_dists\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_changes</th>\n",
       "      <th>URAE</th>\n",
       "      <th>PVDM</th>\n",
       "      <th>PVDBOW</th>\n",
       "      <th>BOW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6%</td>\n",
       "      <td>8%</td>\n",
       "      <td>9%</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10%</td>\n",
       "      <td>13%</td>\n",
       "      <td>15%</td>\n",
       "      <td>1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>21%</td>\n",
       "      <td>22%</td>\n",
       "      <td>20%</td>\n",
       "      <td>1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>17%</td>\n",
       "      <td>17%</td>\n",
       "      <td>58%</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>100%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_changes  URAE  PVDM  PVDBOW  BOW\n",
       "0          1    6%    8%      9%   0%\n",
       "1          2   10%   13%     15%   1%\n",
       "2          3   21%   22%     20%   1%\n",
       "3          4   17%   17%     58%   0%\n",
       "4          5    0%    0%      0% 100%"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.float_format = lambda x: '{:.0f}%'.format(x*100)\n",
    "\n",
    "def verb_anto_gt_para(dists,max_changes):\n",
    "    return n_rel_than_paraphrase(\"verb_anto_\", dists, lambda para_dist,var_dist: var_dist>para_dist, max_changes)\n",
    "\n",
    "get_results_table(verb_anto_gt_para, 5,\n",
    "                  URAE= rae_dists,\n",
    "                  PVDM = wiki_sentence_concat_doc2vec_dists,\n",
    "                  PVDBOW = dbow_dists,\n",
    "                  BOW = bow_dists\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_changes</th>\n",
       "      <th>URAE</th>\n",
       "      <th>PVDM</th>\n",
       "      <th>PVDBOW</th>\n",
       "      <th>BOW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>61%</td>\n",
       "      <td>49%</td>\n",
       "      <td>50%</td>\n",
       "      <td>1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>58%</td>\n",
       "      <td>50%</td>\n",
       "      <td>43%</td>\n",
       "      <td>4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>43%</td>\n",
       "      <td>39%</td>\n",
       "      <td>43%</td>\n",
       "      <td>7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0%</td>\n",
       "      <td>25%</td>\n",
       "      <td>75%</td>\n",
       "      <td>25%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_changes  URAE  PVDM  PVDBOW  BOW\n",
       "0          1   61%   49%     50%   1%\n",
       "1          2   58%   50%     43%   4%\n",
       "2          3   43%   39%     43%   7%\n",
       "3          4    0%   25%     75%  25%"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def anto_gt_sym(dists,max_changes):\n",
    "    def inner():\n",
    "        for nchanges in range(1,max_changes+1):\n",
    "            verb_antos = dists[\"verb_anto_\"+str(nchanges)]\n",
    "            noun_syms =  dists[\"noun_sym_\"+str(nchanges)]\n",
    "            valid_dists = dists[np.logical_and(pd.notnull(verb_antos), pd.notnull(noun_syms))]\n",
    "            yield (verb_antos > noun_syms).sum()/len(valid_dists)\n",
    "    return list(inner())\n",
    "\n",
    "get_results_table(anto_gt_sym, 4,\n",
    "                  URAE= rae_dists,\n",
    "                  PVDM = wiki_sentence_concat_doc2vec_dists,\n",
    "                  PVDBOW = dbow_dists,\n",
    "                  BOW = bow_dists\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_changes</th>\n",
       "      <th>URAE</th>\n",
       "      <th>PVDM</th>\n",
       "      <th>PVDBOW</th>\n",
       "      <th>BOW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>95%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>87%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>87%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>75%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_changes  URAE  PVDM  PVDBOW  BOW\n",
       "0          1    0%    0%      0%  95%\n",
       "1          2    0%    0%      0%  87%\n",
       "2          3    0%    0%      0%  87%\n",
       "3          4    0%    0%      0%  75%"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def anto_eq_sym(dists,max_changes):\n",
    "    def inner():\n",
    "        for nchanges in range(1,max_changes+1):\n",
    "            verb_antos = dists[\"verb_anto_\"+str(nchanges)]\n",
    "            noun_syms =  dists[\"noun_sym_\"+str(nchanges)]\n",
    "            valid_dists = dists[np.logical_and(pd.notnull(verb_antos), pd.notnull(noun_syms))]\n",
    "            yield (verb_antos == noun_syms).sum()/len(valid_dists)\n",
    "    return list(inner())\n",
    "\n",
    "get_results_table(anto_eq_sym, 4,\n",
    "                  URAE= rae_dists,\n",
    "                  PVDM = wiki_sentence_concat_doc2vec_dists,\n",
    "                  PVDBOW = dbow_dists,\n",
    "                  BOW = bow_dists\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_comparative_distances_table(dists, max_changes = 10):\n",
    "    def n_closer_than_paraphrase(prefix):\n",
    "        \"\"\"\n",
    "        prefix : eg \"verb_anto_\" or  \"noun_sym_\"\n",
    "        \"\"\"\n",
    "        return n_rel_than_paraphrase(prefix, dists, lambda para_dist,var_dist: var_dist<para_dist, max_changes)\n",
    "\n",
    "\n",
    "    def compare_sym_anto_distances():\n",
    "        def inner():\n",
    "            for nchanges in range(1,max_changes+1):\n",
    "                verb_antos = dists[\"verb_anto_\"+str(nchanges)]\n",
    "                noun_syms =  dists[\"noun_sym_\"+str(nchanges)]\n",
    "                valid_dists = dists[np.logical_and(pd.notnull(verb_antos), pd.notnull(noun_syms))]\n",
    "                yield (verb_antos > noun_syms).sum()/len(valid_dists)\n",
    "        return list(inner())\n",
    "    \n",
    "    comparative_distances = pd.DataFrame()\n",
    "    comparative_distances[\"n_changes\"] = list(range(1,max_changes+1))\n",
    "    comparative_distances[\"noun_sym_lt_para\"] = n_closer_than_paraphrase(\"noun_sym_\")\n",
    "    comparative_distances[\"verb_anto_lt_para\"] = n_closer_than_paraphrase(\"verb_anto_\")\n",
    "    comparative_distances[\"noun_sym_lt_verb_anto\"] = compare_sym_anto_distances()\n",
    "    return comparative_distances\n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_changes</th>\n",
       "      <th>noun_sym_lt_para</th>\n",
       "      <th>verb_anto_lt_para</th>\n",
       "      <th>noun_sym_lt_verb_anto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.997628</td>\n",
       "      <td>0.996733</td>\n",
       "      <td>0.009544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.987643</td>\n",
       "      <td>0.984746</td>\n",
       "      <td>0.044543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.947570</td>\n",
       "      <td>0.939024</td>\n",
       "      <td>0.065217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.832856</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.654367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.491909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.317308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_changes  noun_sym_lt_para  verb_anto_lt_para  noun_sym_lt_verb_anto\n",
       "0          1          0.997628           0.996733               0.009544\n",
       "1          2          0.987643           0.984746               0.044543\n",
       "2          3          0.947570           0.939024               0.065217\n",
       "3          4          0.832856           1.000000               0.250000\n",
       "4          5          0.654367           0.000000                    NaN\n",
       "5          6          0.491909                NaN                    NaN\n",
       "6          7          0.317308                NaN                    NaN\n",
       "7          8          0.090909                NaN                    NaN\n",
       "8          9          0.111111                NaN                    NaN\n",
       "9         10               NaN                NaN                    NaN"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_comparative_distances_table(bow_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_changes</th>\n",
       "      <th>noun_sym_lt_para</th>\n",
       "      <th>verb_anto_lt_para</th>\n",
       "      <th>noun_sym_lt_verb_anto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.913365</td>\n",
       "      <td>0.917674</td>\n",
       "      <td>0.493107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.839179</td>\n",
       "      <td>0.866102</td>\n",
       "      <td>0.498886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.761414</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.391304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.675444</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.584256</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.517799</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.355769</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_changes  noun_sym_lt_para  verb_anto_lt_para  noun_sym_lt_verb_anto\n",
       "0          1          0.913365           0.917674               0.493107\n",
       "1          2          0.839179           0.866102               0.498886\n",
       "2          3          0.761414           0.780488               0.391304\n",
       "3          4          0.675444           0.833333               0.250000\n",
       "4          5          0.584256           1.000000                    NaN\n",
       "5          6          0.517799                NaN                    NaN\n",
       "6          7          0.355769                NaN                    NaN\n",
       "7          8          0.363636                NaN                    NaN\n",
       "8          9          0.555556                NaN                    NaN\n",
       "9         10               NaN                NaN                    NaN"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_comparative_distances_table(wiki_sentence_doc2vec_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_changes</th>\n",
       "      <th>noun_sym_lt_para</th>\n",
       "      <th>verb_anto_lt_para</th>\n",
       "      <th>noun_sym_lt_verb_anto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.913365</td>\n",
       "      <td>0.917674</td>\n",
       "      <td>0.493107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.839179</td>\n",
       "      <td>0.866102</td>\n",
       "      <td>0.498886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.761414</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.391304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.675444</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.584256</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.517799</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.355769</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_changes  noun_sym_lt_para  verb_anto_lt_para  noun_sym_lt_verb_anto\n",
       "0          1          0.913365           0.917674               0.493107\n",
       "1          2          0.839179           0.866102               0.498886\n",
       "2          3          0.761414           0.780488               0.391304\n",
       "3          4          0.675444           0.833333               0.250000\n",
       "4          5          0.584256           1.000000                    NaN\n",
       "5          6          0.517799                NaN                    NaN\n",
       "6          7          0.355769                NaN                    NaN\n",
       "7          8          0.363636                NaN                    NaN\n",
       "8          9          0.555556                NaN                    NaN\n",
       "9         10               NaN                NaN                    NaN"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_comparative_distances_table(wiki_sentence_concat_doc2vec_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_changes</th>\n",
       "      <th>noun_sym_lt_para</th>\n",
       "      <th>verb_anto_lt_para</th>\n",
       "      <th>noun_sym_lt_verb_anto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.949637</td>\n",
       "      <td>0.936949</td>\n",
       "      <td>0.607635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.905506</td>\n",
       "      <td>0.896610</td>\n",
       "      <td>0.581292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.866274</td>\n",
       "      <td>0.792683</td>\n",
       "      <td>0.434783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.827132</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.788438</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.754045</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_changes  noun_sym_lt_para  verb_anto_lt_para  noun_sym_lt_verb_anto\n",
       "0          1          0.949637           0.936949               0.607635\n",
       "1          2          0.905506           0.896610               0.581292\n",
       "2          3          0.866274           0.792683               0.434783\n",
       "3          4          0.827132           0.833333               0.000000\n",
       "4          5          0.788438           1.000000                    NaN\n",
       "5          6          0.754045                NaN                    NaN\n",
       "6          7          0.750000                NaN                    NaN\n",
       "7          8          0.727273                NaN                    NaN\n",
       "8          9          0.888889                NaN                    NaN\n",
       "9         10               NaN                NaN                    NaN"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_comparative_distances_table(rae_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_comparative_distances_table(wiki_doc2vec_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_comparative_distances_table(hansard_doc2vec_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comparative_distances[\"n_changes\"] = list(range(1,11))\n",
    "#comparative_distances[\"RAE_noun_sym_lt_para\"] = n_closer_than_paraphrase(\"noun_sym_\", rae_dists)\n",
    "#comparative_distances[\"RAE_verb_anto_lt_para\"] = n_closer_than_paraphrase(\"verb_anto_\", rae_dists)\n",
    "comparative_distances[\"wiki_doc2vec_noun_sym_lt_para\"] = n_closer_than_paraphrase(\"noun_sym_\", wiki_doc2vec_dists)\n",
    "comparative_distances[\"wiki_doc2vec_verb_anto_lt_para\"] = n_closer_than_paraphrase(\"verb_anto_\", wiki_doc2vec_dists)\n",
    "#comparative_distances[\"hansard_doc2vec_noun_sym_lt_para\"] = n_closer_than_paraphrase(\"noun_sym_\", hansard_doc2vec_dists)\n",
    "#comparative_distances[\"hansard_doc2vec_verb_anto_lt_para\"] = n_closer_than_paraphrase(\"verb_anto_\", hansard_doc2vec_dists)\n",
    "comparative_distances\n",
    "\n",
    "comparative_distances.loc[0:max_changes-2,\"rae_noun_sym_lt_verb_anto\"] = compare_sym_anto_distances(rae_dists,max_changes)\n",
    "comparative_distances.loc[0:max_changes-2,\"wiki_doc2vec_noun_sym_lt_verb_anto\"] = compare_sym_anto_distances(wiki_doc2vec_dists,max_changes)\n",
    "comparative_distances.loc[0:max_changes-2,\"hansard_doc2vec_noun_sym_lt_verb_anto\"] = compare_sym_anto_distances(hansard_doc2vec_dists,max_changes)\n",
    "comparative_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def drop_null_cols(df):\n",
    "    keep_cols = [col for col in df.columns if not(all(pd.isnull(df.loc[:,col])))]\n",
    "    return df.loc[:,keep_cols]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "drop_null_cols(hansard_doc2vec_dists).hist(sharex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drop_null_cols(wiki_doc2vec_dists).hist(sharex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drop_null_cols(rae_dists).hist(sharex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
