{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have a prototype of they system for corrupting sentences, for different semantic meaning:\n",
    "\n",
    "My process is:\n",
    "\n",
    "1. Tokenize the sentence (Currently using the NLTK regex tokenizer, it seem sufficient)\n",
    "2. Parts of Speech tag (Currently using the Stanford POS Tagger (via NLTK))\n",
    "3. For each word except auxiliary verbs, and words that make up phrases (phrases are checked for by querying wordnet)\n",
    "        1. Use WordNet to find antonyms of the same POS tag  (So \"race\" (Noun, as in a competition) has no antonyms, but \"race\" (Verb, to race the train) has \"linger\" as an antonym.\n",
    "        2. Unstem: WordNet stemming/lemmaisation (of the antonym) removes Tense, Plurality, comparativeness, and superlativeness, so I make use of the POS tag of the original to work those out, then restore them using the Pattern library's tools for this (http://jmlr.csail.mit.edu/papers/volume13/desmedt12a/desmedt12a.pdf)\n",
    "        3. Remove any generated words that are not real (Failures of the Unstemming process, eg saless), by checking against the SCOWL british-insane word list.\n",
    "        4. I remove any suggested antonyms that are short phrases (eg Wordnet suggests that \"take_away\" is an antonym of \"add\", however as adding a work word change the structure of the sentence.)\n",
    "        5. select one randomly if there are multiple.\n",
    "4. I incrementally subsitute one addional antynym until I have run out of words with antonys, saving the sentence at each step. (What I'm currentl;y callign each sentence of different corruption level)\n",
    "5. I repair the indefinite articles ('an' vs 'a')\n",
    "\n",
    "I can check the final sentence by sending it through the POS tagger and seeing if I get the same tags.\n",
    "This is not perfect. Its not bad though.\n",
    "It got a lot better when I changed to using the Stanford POS tagger, as it was more able to tag and retag correctly and thus was most consistent.\n",
    "\n",
    "The whole method is very heurustic.\n",
    "It's not too bad but makes a lot of unnatural sounding sentences.\n",
    "And will sometimes choose the wrong antonym.\n",
    "\n",
    "For example stating with the sentence:\n",
    " - It's not too bad but makes a lot of unnatural sounding sentences.\n",
    " - It 's not too unregretful but makes a lot of unnatural sounding sentences.\n",
    " - It 's not too unregretful but makes a lot of unnatural devoicing sentences.\n",
    " - It 's not too unregretful but makes a lot of unaffected devoicing sentences.\n",
    " - It 's not too unregretful but makes a lot of unaffected devoicing acquittals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from SemanticCorruption import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "import pattern.en as en\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sents = [\"It's not too bad but makes a lot of unnatural sounding sentences.\",\n",
    "'A Washington County man may have the countys first human case of West Nile virus, the health department said Friday',\n",
    "\"It was a dusty, dry, hot day, and the flys were buzzing.\",\n",
    "\"The article is the most common determiner (DT) in English.\",\n",
    "\"We may have a question\",\n",
    "\"Is changing an odd number of verbs, adverbs, adjectives and nouns to their antonyms expected to produce a semantically distant sentence?\",\n",
    "\"Both gerunds and infinitives can be used as the subject or the complement of a sentence.\",\n",
    "\"Shares of Xoma fell 16 percent in early trade, while shares of Genentech, a much larger company with several products on the market, were up 2 percent.\",\n",
    "\"Six months ago, the IMF and Argentina struck a bare-minimum $6.8-billion debt rollover deal that expires in August.\",\n",
    "\"He plans to have dinner with troops at Kosovo's U.S. military headquarters, Camp Bondsteel.\",\n",
    "\"After that, he plans to have dinner at Camp Bondsteel with U.S. troops stationed there.\",\n",
    "\"He added that prosecutors will seek the death penalty.\",\n",
    "\"Who is this man?\",\n",
    "\"Who is that man?\",\n",
    "\"This evil thief stole that car!\",\n",
    "\"The motorist is angry, so the pedestrian is understandably scared\",\n",
    "\"The hero was brave, he defeated the dragon.\",\n",
    "\"The villian was cowardly, he was slain by the dragon.\",\n",
    "\"War and Peace opens in the Russian city of St. Petersburg in 1805, as Napoleon's conquest of western Europe is just beginning to stir fears in Russia.\",\n",
    "\"PCCW's chief operating officer, Mike Butcher, and the Arena brothers, the chief financial officers, will report directly to the police officer.\",\n",
    "\"You sing very well.\",\n",
    "\"We look forward to your talk.\",\n",
    "\"I knew French.\",\n",
    "         \n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def leveled_semantic_corrupt_noun_synonym_sentences(sent):\n",
    "    words, tagged_words = tokenize_and_tag(sent)\n",
    "    short_phrase_indexes = get_phrases_indexes(tagged_words,3)\n",
    "    noun_corrupted_phases = leveled_semantic_corrupt_sentences_from_pretagged(words, tagged_words, get_verb_antos, short_phrase_indexes)\n",
    "    return list(noun_corrupted_phases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "It's not too bad but makes a lot of unnatural sounding sentences.\n",
      "It 's not too bad but makes a lot of unnatural devoicing sentences .\n",
      "It 's not too bad but unmakes a lot of unnatural devoicing sentences .\n",
      "--------------------------------------------------\n",
      "1\n",
      "A Washington County man may have the countys first human case of West Nile virus, the health department said Friday\n",
      "\n",
      "--------------------------------------------------\n",
      "2\n",
      "It was a dusty, dry, hot day, and the flys were buzzing.\n",
      "\n",
      "--------------------------------------------------\n",
      "3\n",
      "The article is the most common determiner (DT) in English.\n",
      "\n",
      "--------------------------------------------------\n",
      "4\n",
      "We may have a question\n",
      "\n",
      "--------------------------------------------------\n",
      "5\n",
      "Is changing an odd number of verbs, adverbs, adjectives and nouns to their antonyms expected to produce a semantically distant sentence?\n",
      "Is staying an odd number of verbs , adverbs , adjectives and nouns to their antonyms expected to produce a semantically distant sentence ?\n",
      "Differs staying an odd number of verbs , adverbs , adjectives and nouns to their antonyms expected to produce a semantically distant sentence ?\n",
      "--------------------------------------------------\n",
      "6\n",
      "Both gerunds and infinitives can be used as the subject or the complement of a sentence.\n",
      "\n",
      "--------------------------------------------------\n",
      "7\n",
      "Shares of Xoma fell 16 percent in early trade, while shares of Genentech, a much larger company with several products on the market, were up 2 percent.\n",
      "Shares of Xoma ascended 16 percent in early trade , while shares of Genentech , a much larger company with several products on the market , were up 2 percent .\n",
      "--------------------------------------------------\n",
      "8\n",
      "Six months ago, the IMF and Argentina struck a bare-minimum $6.8-billion debt rollover deal that expires in August.\n",
      "Six months ago , the IMF and Argentina struck a bare-minimum $ 6.8-billion debt rollover deal that inhales in August .\n",
      "Six months ago , the IMF and Argentina missed a bare-minimum $ 6.8-billion debt rollover deal that inhales in August .\n",
      "--------------------------------------------------\n",
      "9\n",
      "He plans to have dinner with troops at Kosovo's U.S. military headquarters, Camp Bondsteel.\n",
      "\n",
      "--------------------------------------------------\n",
      "10\n",
      "After that, he plans to have dinner at Camp Bondsteel with U.S. troops stationed there.\n",
      "\n",
      "--------------------------------------------------\n",
      "11\n",
      "He added that prosecutors will seek the death penalty.\n",
      "He subtracted that prosecutors will seek the death penalty .\n",
      "--------------------------------------------------\n",
      "12\n",
      "Who is this man?\n",
      "\n",
      "--------------------------------------------------\n",
      "13\n",
      "Who is that man?\n",
      "\n",
      "--------------------------------------------------\n",
      "14\n",
      "This evil thief stole that car!\n",
      "\n",
      "--------------------------------------------------\n",
      "15\n",
      "The motorist is angry, so the pedestrian is understandably scared\n",
      "\n",
      "--------------------------------------------------\n",
      "16\n",
      "The hero was brave, he defeated the dragon.\n",
      "\n",
      "--------------------------------------------------\n",
      "17\n",
      "The villian was cowardly, he was slain by the dragon.\n",
      "\n",
      "--------------------------------------------------\n",
      "18\n",
      "War and Peace opens in the Russian city of St. Petersburg in 1805, as Napoleon's conquest of western Europe is just beginning to stir fears in Russia.\n",
      "War and Peace opens in the Russian city of St. Petersburg in 1805 , as Napoleon 's conquest of western Europe is just ending to stir fears in Russia .\n",
      "War and Peace closes in the Russian city of St. Petersburg in 1805 , as Napoleon 's conquest of western Europe is just ending to stir fears in Russia .\n",
      "--------------------------------------------------\n",
      "19\n",
      "PCCW's chief operating officer, Mike Butcher, and the Arena brothers, the chief financial officers, will report directly to the police officer.\n",
      "\n",
      "--------------------------------------------------\n",
      "20\n",
      "You sing very well.\n",
      "\n",
      "--------------------------------------------------\n",
      "21\n",
      "We look forward to your talk.\n",
      "\n",
      "--------------------------------------------------\n",
      "22\n",
      "I knew French.\n",
      "I ignored French .\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for ii,sent in enumerate(sents):\n",
    "    print(ii)\n",
    "    print(sent)\n",
    "    print(\"\\n\".join(leveled_semantic_corrupt_noun_synonym_sentences(sent)))\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(get_all_antonyms(\"tell\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'PRP', u'VBN', u'VBZ'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = set()\n",
    "for sent in [\"he has gone\"]:# sents[-1:]:\n",
    "    words,tagged_sent = tokenize_and_tag(sent)\n",
    "    tags.update(zip(*tagged_sent)[1])\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Cadets', u'NNS'),\n",
       " (u'were', u'VBD'),\n",
       " (u'ticketted', u'VBN'),\n",
       " (u'for', u'IN'),\n",
       " (u'drinking', u'NN'),\n",
       " (u'alcohol', u'NN'),\n",
       " (u'.', u'.')]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"Cadets were ticketted for drinking alcohol.\"\n",
    "words,tagged_sent = tokenize_and_tag(sent)\n",
    "tagged_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('policeman.n.01.policeman'),\n",
       " Lemma('policeman.n.01.police_officer'),\n",
       " Lemma('policeman.n.01.officer')]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.lemmas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'drinking', u'imbibing', u'imbibition']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(get_all_synonyms_of_most_common('drinking',wn.NOUN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../../Resources/tools/lib/python/pywsd/\")\n",
    "import pywsd\n",
    "from pywsd import disambiguate\n",
    "from pywsd.similarity import max_similarity as maxsim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_pywsd_sent(tagged_words):\n",
    "    return[(word,word,pennPOS2WordnetPOS(tag)) for (word,tag) in tagged_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'Is', u'Is', None)\n",
      "(u'changing', u'changing', u'v')\n",
      "(u'an', u'an', None)\n",
      "(u'odd', u'odd', u'a')\n",
      "(u'number', u'number', u'n')\n",
      "(u'of', u'of', None)\n",
      "(u'verbs', u'verbs', u'n')\n",
      "(u',', u',', None)\n",
      "(u'adverbs', u'adverbs', u'n')\n",
      "(u',', u',', None)\n",
      "(u'adjectives', u'adjectives', u'n')\n",
      "(u'and', u'and', None)\n",
      "(u'nouns', u'nouns', u'n')\n",
      "(u'to', u'to', None)\n",
      "(u'their', u'their', None)\n",
      "(u'antonyms', u'antonyms', u'n')\n",
      "(u'expected', u'expected', u'v')\n",
      "(u'to', u'to', None)\n",
      "(u'produce', u'produce', u'v')\n",
      "(u'a', u'a', None)\n",
      "(u'semantically', u'semantically', u'r')\n",
      "(u'distant', u'distant', u'a')\n",
      "(u'sentence', u'sentence', u'n')\n",
      "(u'?', u'?', None)\n"
     ]
    }
   ],
   "source": [
    "import nltk.wsd\n",
    "\n",
    "\n",
    "sent = sents[5]\n",
    "words, tagged_words = tokenize_and_tag(sent)\n",
    "wsd_sent =make_pywsd_sent(get_tagged_phrases(tagged_words,3))\n",
    "print(\"\\n\".join(map(str,wsd_sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Is', u'VBZ'),\n",
       " (u'changing', u'VBG'),\n",
       " (u'an', u'DT'),\n",
       " (u'odd', u'JJ'),\n",
       " (u'number', u'NN'),\n",
       " (u'of', u'IN'),\n",
       " (u'verbs', u'NNS'),\n",
       " (u',', u','),\n",
       " (u'adverbs', u'NNS'),\n",
       " (u',', u','),\n",
       " (u'adjectives', u'NNS'),\n",
       " (u'and', u'CC'),\n",
       " (u'nouns', u'NNS'),\n",
       " (u'to', u'TO'),\n",
       " (u'their', u'PRP$'),\n",
       " (u'antonyms', u'NNS'),\n",
       " (u'expected', u'VBN'),\n",
       " (u'to', u'TO'),\n",
       " (u'produce', u'VB'),\n",
       " (u'a', u'DT'),\n",
       " (u'semantically', u'RB'),\n",
       " (u'distant', u'JJ'),\n",
       " (u'sentence', u'NN'),\n",
       " (u'?', u'.')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Is', None),\n",
       " (u'changing',\n",
       "  [(0.2, Synset('switch.v.03')),\n",
       "   (0.2, Synset('exchange.v.01')),\n",
       "   (0.2, Synset('change.v.06')),\n",
       "   (0.2, Synset('change.v.03')),\n",
       "   (0.2, Synset('change.v.02')),\n",
       "   (0.0, Synset('transfer.v.06')),\n",
       "   (0.0, Synset('deepen.v.04')),\n",
       "   (0.0, Synset('change.v.10')),\n",
       "   (0.0, Synset('change.v.05')),\n",
       "   (0.0, Synset('change.v.01'))]),\n",
       " (u'an', None),\n",
       " (u'odd', [(1.0, Synset('odd.a.01'))]),\n",
       " (u'number',\n",
       "  [(0.09090909090909091, Synset('phone_number.n.01')),\n",
       "   (0.09090909090909091, Synset('numeral.n.01')),\n",
       "   (0.09090909090909091, Synset('number.n.11')),\n",
       "   (0.09090909090909091, Synset('number.n.10')),\n",
       "   (0.09090909090909091, Synset('number.n.09')),\n",
       "   (0.09090909090909091, Synset('number.n.08')),\n",
       "   (0.09090909090909091, Synset('number.n.07')),\n",
       "   (0.09090909090909091, Synset('number.n.02')),\n",
       "   (0.09090909090909091, Synset('number.n.01')),\n",
       "   (0.09090909090909091, Synset('issue.n.02')),\n",
       "   (0.09090909090909091, Synset('act.n.04'))]),\n",
       " (u'of', None),\n",
       " (u'verbs', [(1.0, Synset('verb.n.02')), (0.0, Synset('verb.n.01'))]),\n",
       " (u',', None),\n",
       " (u'adverbs', None),\n",
       " (u',', None),\n",
       " (u'adjectives', None),\n",
       " (u'and', None),\n",
       " (u'nouns', [(0.5, Synset('noun.n.02')), (0.5, Synset('noun.n.01'))]),\n",
       " (u'to', None),\n",
       " (u'their', None),\n",
       " (u'antonyms', [(1.0, Synset('antonym.n.01'))]),\n",
       " (u'expected', None),\n",
       " (u'to', None),\n",
       " (u'produce',\n",
       "  [(0.2222222222222222, Synset('produce.v.03')),\n",
       "   (0.2222222222222222, Synset('grow.v.07')),\n",
       "   (0.1111111111111111, Synset('produce.v.06')),\n",
       "   (0.1111111111111111, Synset('produce.v.04')),\n",
       "   (0.1111111111111111, Synset('produce.v.02')),\n",
       "   (0.1111111111111111, Synset('produce.v.01')),\n",
       "   (0.1111111111111111, Synset('grow.v.08'))]),\n",
       " (u'a', None),\n",
       " (u'semantically', [(1.0, Synset('semantically.r.01'))]),\n",
       " (u'distant', [(0.5, Synset('distant.a.02')), (0.5, Synset('distant.a.01'))]),\n",
       " (u'sentence',\n",
       "  [(0.3333333333333333, Synset('sentence.n.01')),\n",
       "   (0.3333333333333333, Synset('prison_term.n.01')),\n",
       "   (0.3333333333333333, Synset('conviction.n.02'))]),\n",
       " (u'?', None)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans=disambiguate(wsd_sent, context_is_lemmatized=True, nbest=True, normalizescore=True, keepscore=True, algorithm=pywsd.lesk.simple_lesk)\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Synset.wup_similarity of Synset('conviction.n.02')>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss=ans[-2][1][2][1]\n",
    "ss.wup_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'a string of words satisfying the grammatical rules of a language'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans[-2][1].definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wndomains.Syns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It 's not too_bad but makes a_lot of unnatural sounding sentences .\n",
      "A Washington County man may have the countys first human case of West_Nile_virus , the health department said Friday\n",
      "It was a dusty , dry , hot day , and the flys were buzzing .\n",
      "The article is the most common determiner ( DT ) in English .\n",
      "We may have a question\n",
      "Is changing an odd number of verbs , adverbs , adjectives and nouns to their antonyms expected to produce a semantically distant sentence ?\n",
      "Both gerunds and infinitives can be used as the subject or the complement of a sentence .\n",
      "Shares of Xoma fell 16 percent in early trade , while shares of Genentech , a much larger company with several products on the market , were up 2 percent .\n",
      "Six months ago , the IMF and Argentina struck a bare-minimum $ 6.8-billion debt rollover deal that expires in August .\n",
      "He plans to have dinner with troops at Kosovo 's U.S. military_headquarters , Camp Bondsteel .\n",
      "After that , he plans to have dinner at Camp Bondsteel with U.S. troops stationed there .\n",
      "He added that prosecutors will seek the death_penalty .\n",
      "Who is this man ?\n",
      "Who is that man ?\n",
      "This evil thief stole that car !\n",
      "The motorist is angry , so the pedestrian is understandably scared\n",
      "The hero was brave , he defeated the dragon .\n",
      "The villian was cowardly , he was slain by the dragon .\n",
      "War and Peace opens in the Russian city of St._Petersburg in 1805 , as Napoleon 's conquest of western Europe is just beginning to stir fears in Russia .\n",
      "PCCW 's chief_operating_officer , Mike Butcher , and the Arena brothers , the chief_financial_officers , will report directly to the police_officer .\n"
     ]
    }
   ],
   "source": [
    "for sent in sents:\n",
    "    tagged_phrases = get_tagged_phrases(tokenize_and_tag(sent)[1],3)\n",
    "    phrases = zip(*tagged_phrases)[0]\n",
    "    print \" \".join(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 7, 8]\n",
      "[12, 13, 14]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[11, 12]\n",
      "[]\n",
      "[7, 8]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[9, 10]\n",
      "[2, 3, 4, 15, 16, 17, 24, 25]\n"
     ]
    }
   ],
   "source": [
    "for sent in sents:\n",
    "    indexes = list(get_phrases_indexes(tokenize_and_tag(sent)[1],3))\n",
    "    indexes.sort()\n",
    "    print indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a= set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a.update([\"21\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'21'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('face.n.01'),\n",
       " Synset('expression.n.01'),\n",
       " Synset('face.n.03'),\n",
       " Synset('face.n.04'),\n",
       " Synset('face.n.05'),\n",
       " Synset('side.n.04'),\n",
       " Synset('face.n.07'),\n",
       " Synset('face.n.08'),\n",
       " Synset('grimace.n.01'),\n",
       " Synset('font.n.01'),\n",
       " Synset('face.n.11'),\n",
       " Synset('boldness.n.02'),\n",
       " Synset('face.n.13'),\n",
       " Synset('confront.v.02'),\n",
       " Synset('confront.v.01'),\n",
       " Synset('front.v.01'),\n",
       " Synset('face.v.04'),\n",
       " Synset('face.v.05'),\n",
       " Synset('confront.v.03'),\n",
       " Synset('face.v.07'),\n",
       " Synset('face.v.08'),\n",
       " Synset('face.v.09')]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets(\"face\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('slope.n.01')]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s=wn.synset('bank.n.01')\n",
    "s.hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loading the Wordnet domains.\n",
    "from collections import defaultdict\n",
    "\n",
    "from glob import glob\n",
    "import os.path\n",
    "\n",
    "\n",
    "domain_files = glob('../../../Resources/tools/lib/databases/xwnd-30g/*.ppv')\n",
    "synset2domains = defaultdict(lambda: np.zeros(len(domain_files)))\n",
    "for domain_index,domain_filename in enumerate(domain_files):\n",
    "    domain = os.path.splitext(os.path.basename(domain_filename))[0]\n",
    "    with open(domain_filename,'r') as fh:\n",
    "        for line in list(fh):\n",
    "            ssid, weight = line.split()\n",
    "            weight = float(weight)\n",
    "            #assert not np.isnan(weight)\n",
    "            \n",
    "            synset2domains[ssid][domain_index] = weight \n",
    "\n",
    "\n",
    "def get_domains(synset):\n",
    "    ssid = str(synset.offset()).zfill(8) + \"-\" + synset.pos()\n",
    "    return synset2domains[ssid]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('depository_financial_institution.n.01')"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s=wn.synsets(\"bank\")[1]\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170,)"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doms = get_domain(s)\n",
    "doms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('banking', 0.0150926), ('finance', 0.00172323), ('book_keeping', 0.00112378)]"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doms.most_common(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'a string of words satisfying the grammatical rules of a language'"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c=Counter()\n",
    "c[\"a\"]=0.22\n",
    "c[\"b\"]=0.23\n",
    "c[\"b\"]+=0.13\n",
    "d=Counter()\n",
    "d[\"a\"]=-0.21\n",
    "d[\"b\"]=1.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'Counter' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-312-bbe5c272a63c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0me\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'Counter' and 'int'"
     ]
    }
   ],
   "source": [
    "e=(c+d)\n",
    "e+=c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('b', 0.36)]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.most_common(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def domain_wsd(sent, max_phrase_len=3):\n",
    "    def full_penn2wn_pos(penn):\n",
    "        tag = penn[0].lower()\n",
    "        tag = 'a' if tag =='j' else tag\n",
    "        return tag if tag in ['a','v','r','n'] else None\n",
    "        \n",
    "    words, tagged_words = tokenize_and_tag(sent)\n",
    "    tagged_phrases = get_tagged_phrases(tagged_words,max_phrase_len)\n",
    "    \n",
    "    sentence_domain = np.zeros(len(domain_files))\n",
    "    \n",
    "    for lemma,pos in tagged_phrases:\n",
    "        wn_pos = full_penn2wn_pos(pos)\n",
    "        if wn_pos: \n",
    "            for ss in wn.synsets(lemma, wn_pos):\n",
    "                sentence_domain+=get_domains(ss)\n",
    "    \n",
    "    def get_best_synsets():\n",
    "        for lemma,pos in tagged_phrases:\n",
    "            best_synset = None\n",
    "            wn_pos = full_penn2wn_pos(pos)\n",
    "            if wn_pos:\n",
    "                best_score = -1*np.Inf\n",
    "                for ss in wn.synsets(lemma, pennPOS2WordnetPOS(wn_pos)):\n",
    "                    score = np.dot(get_domains(ss),sentence_domain)\n",
    "                    if score>best_score:\n",
    "                        best_score=score\n",
    "                        best_synset=ss\n",
    "            yield lemma, best_synset, None if best_synset is None else best_synset.definition()\n",
    "            \n",
    "    return list(get_best_synsets())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCCW's chief operating officer, Mike Butcher, and the Arena brothers, the chief financial officers, will report directly to the police officer.\n",
      "--------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(u'PCCW', None, None),\n",
       " (u\"'s\", None, None),\n",
       " (u'chief_operating_officer',\n",
       "  Synset('chief_executive_officer.n.01'),\n",
       "  u'the corporate executive responsible for the operations of the firm; reports to a board of directors; may appoint other managers (including a president)'),\n",
       " (u',', None, None),\n",
       " (u'Mike',\n",
       "  Synset('microphone.n.01'),\n",
       "  u'device for converting sound waves into electrical energy'),\n",
       " (u'Butcher',\n",
       "  Synset('butcher.v.01'),\n",
       "  u'kill (animals) usually for food consumption'),\n",
       " (u',', None, None),\n",
       " (u'and', None, None),\n",
       " (u'the', None, None),\n",
       " (u'Arena',\n",
       "  Synset('sphere.n.01'),\n",
       "  u'a particular environment or walk of life'),\n",
       " (u'brothers',\n",
       "  Synset('brother.n.05'),\n",
       "  u'(Roman Catholic Church) a title given to a monk and used as form of address'),\n",
       " (u',', None, None),\n",
       " (u'the', None, None),\n",
       " (u'chief_financial_officers',\n",
       "  Synset('chief_financial_officer.n.01'),\n",
       "  u'the corporate executive having financial authority to make appropriations and authorize expenditures for a firm'),\n",
       " (u',', None, None),\n",
       " (u'will', None, None),\n",
       " (u'report',\n",
       "  Synset('report.v.01'),\n",
       "  u'to give an account or representation of in words'),\n",
       " (u'directly', Synset('directly.r.01'), u'without deviation'),\n",
       " (u'to', None, None),\n",
       " (u'the', None, None),\n",
       " (u'police_officer', Synset('policeman.n.01'), u'a member of a police force'),\n",
       " (u'.', None, None)]"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = sents[19]\n",
    "print sent\n",
    "print \"--------------\"\n",
    "sent_dom = domain_wsd(sent)\n",
    "sent_dom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master d2da037] =I may have (but probably have not) created a new method for doing word sense disambiguation\r\n",
      " 1 file changed, 496 insertions(+), 7 deletions(-)\r\n"
     ]
    }
   ],
   "source": [
    "!git commit -m=\"I may have (but probably have not) created a new method for doing word sense disambiguation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
