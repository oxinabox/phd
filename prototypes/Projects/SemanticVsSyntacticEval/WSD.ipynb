{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from SemanticCorruption import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "import pattern.en as en\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sents = [\"It's not too bad but makes a lot of unnatural sounding sentences.\",\n",
    "'A Washington County man may have the countys first human case of West Nile virus, the health department said Friday',\n",
    "\"It was a dusty, dry, hot day, and the flys were buzzing.\",\n",
    "\"The article is the most common determiner (DT) in English.\",\n",
    "\"We may have a question\",\n",
    "\"Is changing an odd number of verbs, adverbs, adjectives and nouns to their antonyms expected to produce a semantically distant sentence?\",\n",
    "\"Both gerunds and infinitives can be used as the subject or the complement of a sentence.\",\n",
    "\"Shares of Xoma fell 16 percent in early trade, while shares of Genentech, a much larger company with several products on the market, were up 2 percent.\",\n",
    "\"Six months ago, the IMF and Argentina struck a bare-minimum $6.8-billion debt rollover deal that expires in August.\",\n",
    "\"He plans to have dinner with troops at Kosovo's U.S. military headquarters, Camp Bondsteel.\",\n",
    "\"After that, he plans to have dinner at Camp Bondsteel with U.S. troops stationed there.\",\n",
    "\"He added that prosecutors will seek the death penalty.\",\n",
    "\"Who is this man?\",\n",
    "\"Who is that man?\",\n",
    "\"This evil thief stole that car!\",\n",
    "\"The motorist is angry, so the pedestrian is understandably scared\",\n",
    "\"The hero was brave, he defeated the dragon.\",\n",
    "\"The villian was cowardly, he was slain by the dragon.\",\n",
    "\"War and Peace opens in the Russian city of St. Petersburg in 1805, as Napoleon's conquest of western Europe is just beginning to stir fears in Russia.\",\n",
    "\"PCCW's chief operating officer, Mike Butcher, and the Arena brothers, the chief financial officers, will report directly to the police officer.\",\n",
    "\"You sing very well.\",\n",
    "\"We look forward to your talk.\",\n",
    "\"I knew French.\",\n",
    "         \n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "It's not too bad but makes a lot of unnatural sounding sentences.\n",
      "It 's not too bad but makes a lot of unnatural sounding convictions .\n",
      "--------------------------------------------------\n",
      "1\n",
      "A Washington County man may have the countys first human case of West Nile virus, the health department said Friday\n",
      "a Washington County serviceman may have the countys first human case of West Nile virus , the health department said Friday\n",
      "a Washington County serviceman may have the counties first human case of West Nile virus , the health department said Friday\n",
      "a Washington County serviceman may have the counties first human case of West Nile virus , the health section said Friday\n",
      "a Washington County serviceman may have the counties first human case of West Nile virus , the wellness section said Friday\n",
      "a Washington County serviceman may have the counties first human slip of West Nile virus , the wellness section said Friday\n",
      "--------------------------------------------------\n",
      "2\n",
      "It was a dusty, dry, hot day, and the flys were buzzing.\n",
      "It was a dusty , dry , hot daytime , and the flys were buzzing .\n",
      "It was a dusty , dry , hot daytime , and the flies were buzzing .\n",
      "--------------------------------------------------\n",
      "3\n",
      "The article is the most common determiner (DT) in English.\n",
      "The clause is the most common determiner ( DT ) in English .\n",
      "The clause is the most common determinative ( DT ) in English .\n",
      "--------------------------------------------------\n",
      "4\n",
      "We may have a question\n",
      "We may have an inquiry\n",
      "--------------------------------------------------\n",
      "5\n",
      "Is changing an odd number of verbs, adverbs, adjectives and nouns to their antonyms expected to produce a semantically distant sentence?\n",
      "Is changing an odd number of verbs , adverbs , adjectives and nouns to their opposites expected to produce a semantically distant sentence ?\n",
      "Is changing an odd act of verbs , adverbs , adjectives and nouns to their opposites expected to produce a semantically distant sentence ?\n",
      "Is changing an odd act of verbs , adverbs , adjectives and nouns to their opposites expected to produce a semantically distant time ?\n",
      "--------------------------------------------------\n",
      "6\n",
      "Both gerunds and infinitives can be used as the subject or the complement of a sentence.\n",
      "Both gerunds and infinitives can be used as the content or the complement of a sentence .\n",
      "Both gerunds and infinitives can be used as the content or the complement of a conviction .\n",
      "Both gerunds and infinitives can be used as the content or the accompaniment of a conviction .\n",
      "--------------------------------------------------\n",
      "7\n",
      "Shares of Xoma fell 16 percent in early trade, while shares of Genentech, a much larger company with several products on the market, were up 2 percent.\n",
      "Shares of Xoma fell 16 percent in early trade , while shares of Genentech , a much larger troupe with several products on the market , were up 2 percent .\n",
      "Shares of Xoma fell 16 percent in early trade , while shares of Genentech , a much larger troupe with several products on the mart , were up 2 percent .\n",
      "Shares of Xoma fell 16 percent in early trade , while shares of Genentech , a much larger troupe with several products on the mart , were up 2 percentage .\n",
      "ploughshares of Xoma fell 16 percent in early trade , while shares of Genentech , a much larger troupe with several products on the mart , were up 2 percentage .\n",
      "ploughshares of Xoma fell 16 percentage in early trade , while shares of Genentech , a much larger troupe with several products on the mart , were up 2 percentage .\n",
      "ploughshares of Xoma fell 16 percentage in early trade , while shares of Genentech , a much larger troupe with several intersections on the mart , were up 2 percentage .\n",
      "ploughshares of Xoma fell 16 percentage in early swop , while shares of Genentech , a much larger troupe with several intersections on the mart , were up 2 percentage .\n",
      "ploughshares of Xoma fell 16 percentage in early swop , while contributions of Genentech , a much larger troupe with several intersections on the mart , were up 2 percentage .\n",
      "--------------------------------------------------\n",
      "8\n",
      "Six months ago, the IMF and Argentina struck a bare-minimum $6.8-billion debt rollover deal that expires in August.\n",
      "Six months ago , the IMF and Argentina struck a bare-minimum $ 6.8-billion debt rollover slew that expires in August .\n",
      "--------------------------------------------------\n",
      "9\n",
      "He plans to have dinner with troops at Kosovo's U.S. military headquarters, Camp Bondsteel.\n",
      "He plans to have dinner with flocks at Kosovo 's U.S. military headquarters , Camp Bondsteel .\n",
      "--------------------------------------------------\n",
      "10\n",
      "After that, he plans to have dinner at Camp Bondsteel with U.S. troops stationed there.\n",
      "After that , he plans to have dinner at Camp Bondsteel with U.S. soldieries stationed there .\n",
      "--------------------------------------------------\n",
      "11\n",
      "He added that prosecutors will seek the death penalty.\n",
      "\n",
      "--------------------------------------------------\n",
      "12\n",
      "Who is this man?\n",
      "Who is this gentleman ?\n",
      "--------------------------------------------------\n",
      "13\n",
      "Who is that man?\n",
      "Who is that piece ?\n",
      "--------------------------------------------------\n",
      "14\n",
      "This evil thief stole that car!\n",
      "This evil thief stole that gondola !\n",
      "This evil stealer stole that gondola !\n",
      "--------------------------------------------------\n",
      "15\n",
      "The motorist is angry, so the pedestrian is understandably scared\n",
      "The automobilist is angry , so the pedestrian is understandably scared\n",
      "The automobilist is angry , so the walker is understandably scared\n",
      "--------------------------------------------------\n",
      "16\n",
      "The hero was brave, he defeated the dragon.\n",
      "The fighter was brave , he defeated the dragon .\n",
      "The fighter was brave , he defeated the firedrake .\n",
      "--------------------------------------------------\n",
      "17\n",
      "The villian was cowardly, he was slain by the dragon.\n",
      "The villian was cowardly , he was slain by the tartar .\n",
      "--------------------------------------------------\n",
      "18\n",
      "War and Peace opens in the Russian city of St. Petersburg in 1805, as Napoleon's conquest of western Europe is just beginning to stir fears in Russia.\n",
      "War and Peace opens in the Russian city of St. Petersburg in 1805 , as Napoleon 's conquest of western Europe is just beginning to stir frights in Russia .\n",
      "War and Peace opens in the Russian city of St. Petersburg in 1805 , as Napoleon 's seduction of western Europe is just beginning to stir frights in Russia .\n",
      "War and Peace opens in the Russian metropolis of St. Petersburg in 1805 , as Napoleon 's seduction of western Europe is just beginning to stir frights in Russia .\n",
      "--------------------------------------------------\n",
      "19\n",
      "PCCW's chief operating officer, Mike Butcher, and the Arena brothers, the chief financial officers, will report directly to the police officer.\n",
      "PCCW 's chief operating officer , Mike Butcher , and the Arena buddies , the chief financial officers , will report directly to the police officer .\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for ii,sent in enumerate(sents):\n",
    "    print(ii)\n",
    "    print(sent)\n",
    "    print(\"\\n\".join(leveled_semantic_corrupt_noun_synonym_sentences(sent)))\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../../Resources/tools/lib/python/pywsd/\")\n",
    "import pywsd\n",
    "from pywsd import disambiguate\n",
    "from pywsd.similarity import max_similarity as maxsim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_pywsd_sent(tagged_words):\n",
    "    return[(word,word,pennPOS2WordnetPOS(tag)) for (word,tag) in tagged_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'Is', u'Is', None)\n",
      "(u'changing', u'changing', u'v')\n",
      "(u'an', u'an', None)\n",
      "(u'odd', u'odd', u'a')\n",
      "(u'number', u'number', u'n')\n",
      "(u'of', u'of', None)\n",
      "(u'verbs', u'verbs', u'n')\n",
      "(u',', u',', None)\n",
      "(u'adverbs', u'adverbs', u'n')\n",
      "(u',', u',', None)\n",
      "(u'adjectives', u'adjectives', u'n')\n",
      "(u'and', u'and', None)\n",
      "(u'nouns', u'nouns', u'n')\n",
      "(u'to', u'to', None)\n",
      "(u'their', u'their', None)\n",
      "(u'antonyms', u'antonyms', u'n')\n",
      "(u'expected', u'expected', u'v')\n",
      "(u'to', u'to', None)\n",
      "(u'produce', u'produce', u'v')\n",
      "(u'a', u'a', None)\n",
      "(u'semantically', u'semantically', u'r')\n",
      "(u'distant', u'distant', u'a')\n",
      "(u'sentence', u'sentence', u'n')\n",
      "(u'?', u'?', None)\n"
     ]
    }
   ],
   "source": [
    "import nltk.wsd\n",
    "\n",
    "\n",
    "sent = sents[5]\n",
    "words, tagged_words = tokenize_and_tag(sent)\n",
    "wsd_sent =make_pywsd_sent(get_tagged_phrases(tagged_words,3))\n",
    "ans=disambiguate(wsd_sent, context_is_lemmatized=True, nbest=True, normalizescore=True, keepscore=True, algorithm=pywsd.lesk.simple_lesk)\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loading the Wordnet domains.\n",
    "from collections import defaultdict\n",
    "\n",
    "from glob import glob\n",
    "import os.path\n",
    "\n",
    "\n",
    "domain_files = glob('../../../Resources/tools/lib/databases/xwnd-30g/*.ppv')\n",
    "synset2domains = defaultdict(lambda: np.zeros(len(domain_files)))\n",
    "for domain_index,domain_filename in enumerate(domain_files):\n",
    "    domain = os.path.splitext(os.path.basename(domain_filename))[0]\n",
    "    with open(domain_filename,'r') as fh:\n",
    "        for line in list(fh):\n",
    "            ssid, weight = line.split()\n",
    "            weight = float(weight)\n",
    "            #assert not np.isnan(weight)\n",
    "            \n",
    "            synset2domains[ssid][domain_index] = weight \n",
    "\n",
    "\n",
    "def get_domains(synset):\n",
    "    return synset2domains[get_synset_id(synset)]\n",
    "\n",
    "def get_synset_id(synset):\n",
    "    return str(synset.offset()).zfill(8) + \"-\" + synset.pos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, 16, 81])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.power([1,2,3],4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_scaled_domains(synsets):\n",
    "    def count(synset):\n",
    "        return sum([1.0*lemma.count() for lemma in synset.lemmas()])\n",
    "    \n",
    "    counts = np.asarray([count(ss) for ss in synsets])\n",
    "    counts+=1.0\n",
    "    counts/=counts.sum()\n",
    "    counts = np.power(counts,2)\n",
    "    domains = [counts[ii]*get_domains(ss) for ii,ss in enumerate(synsets)]\n",
    "    return domains\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "synset_misses = set()\n",
    "def try_hard_to_get_synsets(word, pos):\n",
    "    synsets = wn.synsets(word,pos)\n",
    "\n",
    "#    if len(synsets)==0:\n",
    "#        synsets = wn.synsets(word.replace(\".\",\"\"),pos)\n",
    "#    if len(synsets)==0:\n",
    "#        synsets = wn.synsets(word.replace(\"-\",\"_\"),pos)\n",
    "#    if len(synsets)==0:\n",
    "#        synsets = wn.synsets(word.replace(\"-\",\"\"),pos)\n",
    "#    if len(synsets)==0:\n",
    "#        synsets = wn.synsets(word.replace(\"_\",\"\"),pos)\n",
    "#    if len(synsets)==0 and word=='%':\n",
    "#        synsets = wn.synsets('percent',pos)\n",
    "#    if len(synsets)==0:\n",
    "#        synsets = wn.synsets(word.split(\"_\")[-1],pos)\n",
    "#    if len(synsets)==0:\n",
    "#        synsets = wn.synsets(word.split(\"-\")[-1],pos)\n",
    "#    if len(synsets)==0:\n",
    "#        synsets = wn.synsets(word.split(\"_\")[0],pos)\n",
    "#    if len(synsets)==0:\n",
    "#        synsets = wn.synsets(word.split(\"-\")[0],pos)\n",
    "        \n",
    "#    if len(synsets)==0 and not pos is None:\n",
    "#        synsets = try_hard_to_get_synsets(word, None)\n",
    "        \n",
    "#    if len(synsets)==0:\n",
    "#        synset_misses.add((word,pos))\n",
    "    \n",
    "        \n",
    "    return synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def domain_wsd(tagged_phrases):\n",
    "    def tag2wn_pos(tag):\n",
    "        tag = 'a' if tag[0] =='J' else tag\n",
    "        tag = 'n' if tag =='CD' else tag\n",
    "        tag = '*' if tag =='VHP' else tag #Blank it\n",
    "        tag = tag[0].lower()\n",
    "        return tag if tag in ['a','v','r','n'] else None\n",
    "\n",
    "    sentence_domain = np.zeros(len(domain_files))\n",
    "\n",
    "    for lemma,pos in tagged_phrases:\n",
    "        wn_pos = tag2wn_pos(pos)\n",
    "        if wn_pos: \n",
    "            domain_scores=get_scaled_domains(try_hard_to_get_synsets(lemma, wn_pos))\n",
    "            for domain_score in domain_scores:\n",
    "                sentence_domain+=domain_score\n",
    "    \n",
    "    def get_best_synsets():\n",
    "        for lemma,pos in tagged_phrases:\n",
    "            best_synset = None\n",
    "            wn_pos = tag2wn_pos(pos)\n",
    "            if wn_pos:\n",
    "                best_score = -1*np.Inf\n",
    "                synsets = try_hard_to_get_synsets(lemma, wn_pos)\n",
    "                domain_scores=get_scaled_domains(synsets)\n",
    "                for ii,ss in enumerate(synsets):\n",
    "                    score = np.dot(domain_scores[ii],sentence_domain)\n",
    "                    if score>best_score:\n",
    "                        best_score=score\n",
    "                        best_synset=ss\n",
    "            #yield lemma, best_synset, None if best_synset is None else best_synset.definition()\n",
    "            yield lemma, best_synset\n",
    "            \n",
    "    return list(get_best_synsets())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def domain_wsd_on_plaintext(sent, max_phrase_len=3):\n",
    "    words, tagged_words = tokenize_and_tag(sent)\n",
    "    tagged_phrases = get_tagged_phrases(tagged_words,max_phrase_len)\n",
    "    return domain_wsd(tagged_phrases)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCCW's chief operating officer, Mike Butcher, and the Arena brothers, the chief financial officers, will report directly to the police officer.\n",
      "--------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(u'PCCW', None, None),\n",
       " (u\"'s\", None, None),\n",
       " (u'chief_operating_officer',\n",
       "  Synset('chief_executive_officer.n.01'),\n",
       "  u'the corporate executive responsible for the operations of the firm; reports to a board of directors; may appoint other managers (including a president)'),\n",
       " (u',', None, None),\n",
       " (u'Mike',\n",
       "  Synset('microphone.n.01'),\n",
       "  u'device for converting sound waves into electrical energy'),\n",
       " (u'Butcher',\n",
       "  Synset('butcher.v.01'),\n",
       "  u'kill (animals) usually for food consumption'),\n",
       " (u',', None, None),\n",
       " (u'and', None, None),\n",
       " (u'the', None, None),\n",
       " (u'Arena',\n",
       "  Synset('sphere.n.01'),\n",
       "  u'a particular environment or walk of life'),\n",
       " (u'brothers',\n",
       "  Synset('brother.n.05'),\n",
       "  u'(Roman Catholic Church) a title given to a monk and used as form of address'),\n",
       " (u',', None, None),\n",
       " (u'the', None, None),\n",
       " (u'chief_financial_officers',\n",
       "  Synset('chief_financial_officer.n.01'),\n",
       "  u'the corporate executive having financial authority to make appropriations and authorize expenditures for a firm'),\n",
       " (u',', None, None),\n",
       " (u'will', None, None),\n",
       " (u'report',\n",
       "  Synset('report.v.01'),\n",
       "  u'to give an account or representation of in words'),\n",
       " (u'directly', Synset('directly.r.01'), u'without deviation'),\n",
       " (u'to', None, None),\n",
       " (u'the', None, None),\n",
       " (u'police_officer', Synset('policeman.n.01'), u'a member of a police force'),\n",
       " (u'.', None, None)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = sents[19]\n",
    "print sent\n",
    "print \"--------------\"\n",
    "sent_dom = domain_wsd_on_plaintext(sent)\n",
    "sent_dom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_sense_key(synset, lemma):\n",
    "    index = 0\n",
    "    try: #try and do better\n",
    "        index = synset.lemma_names().index(lemma)\n",
    "    except ValueError:\n",
    "        pass #couldn't do better\n",
    "    return synset.lemmas()[index].key()\n",
    "\n",
    "def wsd(text_id, tagged_phrases, indexed_instances):\n",
    "    lemmas_and_synsets = domain_wsd(tagged_phrases)\n",
    "    for ii, id in indexed_instances.items():\n",
    "        #print(id)\n",
    "        lemma, synset = lemmas_and_synsets[ii]\n",
    "        comment = \"!! lemma=\"+''.join([i if ord(i) < 128 else ' ' for i in lemma])\n",
    "        if synset: #If it was even defined in wordnet\n",
    "            sensekey = get_sense_key(synset,lemma)\n",
    "            yield text_id, id, sensekey, comment\n",
    "        else:\n",
    "            yield text_id, id, comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "def tagged_sentences(filename):\n",
    "    xml = ET.ElementTree(file=filename)\n",
    "    for text in xml.getroot():\n",
    "        text_id = text.get('id')\n",
    "        \n",
    "        for sentence in text:\n",
    "            tagged_phrases = []\n",
    "            indexed_instances = dict()\n",
    "            for ii,phrase in enumerate(sentence):\n",
    "                lemma = phrase.get('lemma')\n",
    "                lemma = phrase.text if lemma==\"@card@\" else lemma  #correct it to use the text if it was a number\n",
    "                \n",
    "                tagged_phrases.append((lemma,phrase.get('pos')))\n",
    "                if 'id' in phrase.keys():\n",
    "                    indexed_instances[ii] = phrase.get('id')\n",
    "            yield text_id, tagged_phrases, indexed_instances    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus_filename = \"./SemEval13_task12_data/test.en.xml\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "answers = list(itertools.chain(*[wsd(*tti) for tti in tagged_sentences(corpus_filename)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('-RRB-', None),\n",
       " ('-RRB-', 'n'),\n",
       " ('0,6', None),\n",
       " ('0,6', 'n'),\n",
       " ('0,9', None),\n",
       " ('0,9', 'n'),\n",
       " ('0.03', None),\n",
       " ('0.03', 'n'),\n",
       " ('0.37', None),\n",
       " ('0.37', 'n'),\n",
       " ('0.55', None),\n",
       " ('0.55', 'n'),\n",
       " ('0.63', None),\n",
       " ('0.63', 'n'),\n",
       " ('102', None),\n",
       " ('102', 'n'),\n",
       " ('106', None),\n",
       " ('106', 'n'),\n",
       " ('106.41', None),\n",
       " ('106.41', 'n'),\n",
       " ('126', None),\n",
       " ('126', 'n'),\n",
       " ('127', None),\n",
       " ('127', 'n'),\n",
       " ('13,000', None),\n",
       " ('13,000', 'n'),\n",
       " ('14.2', None),\n",
       " ('14.2', 'n'),\n",
       " ('140,000', None),\n",
       " ('140,000', 'n'),\n",
       " ('150,000', None),\n",
       " ('150,000', 'n'),\n",
       " ('190.31', None),\n",
       " ('190.31', 'n'),\n",
       " ('1966', None),\n",
       " ('1966', 'n'),\n",
       " ('1976', None),\n",
       " ('1976', 'n'),\n",
       " ('1990', None),\n",
       " ('1990', 'n'),\n",
       " ('1995', None),\n",
       " ('1995', 'n'),\n",
       " ('20.5', None),\n",
       " ('20.5', 'n'),\n",
       " ('2001', None),\n",
       " ('2001', 'n'),\n",
       " ('2002', None),\n",
       " ('2002', 'n'),\n",
       " ('2003', None),\n",
       " ('2003', 'n'),\n",
       " ('2005', None),\n",
       " ('2005', 'n'),\n",
       " ('2007', None),\n",
       " ('2007', 'n'),\n",
       " ('2008', None),\n",
       " ('2008', 'n'),\n",
       " ('2009', None),\n",
       " ('2009', 'n'),\n",
       " ('2011', None),\n",
       " ('2011', 'n'),\n",
       " ('2012', None),\n",
       " ('2012', 'n'),\n",
       " ('2020', None),\n",
       " ('2020', 'n'),\n",
       " ('2050', None),\n",
       " ('2050', 'n'),\n",
       " ('3.482', None),\n",
       " ('3.482', 'n'),\n",
       " ('3.540', None),\n",
       " ('3.540', 'n'),\n",
       " ('352', None),\n",
       " ('352', 'n'),\n",
       " ('3:05', None),\n",
       " ('3:05', 'n'),\n",
       " ('4.06', None),\n",
       " ('4.06', 'n'),\n",
       " ('4.492', None),\n",
       " ('4.492', 'n'),\n",
       " ('4.497', None),\n",
       " ('4.497', 'n'),\n",
       " ('471.50', None),\n",
       " ('471.50', 'n'),\n",
       " ('4C', None),\n",
       " ('4C', 'n'),\n",
       " ('65.67', None),\n",
       " ('65.67', 'n'),\n",
       " ('67.4', None),\n",
       " ('67.4', 'n'),\n",
       " ('73.4', None),\n",
       " ('73.4', 'n'),\n",
       " ('900,000', None),\n",
       " ('900,000', 'n'),\n",
       " ('Alavan', None),\n",
       " ('Alavan', 'n'),\n",
       " ('Alavas', None),\n",
       " ('Alavas', 'n'),\n",
       " ('Anbar', None),\n",
       " ('Anbar', 'n'),\n",
       " ('Ariel', None),\n",
       " ('Ariel', 'n'),\n",
       " ('Artur', None),\n",
       " ('Artur', 'n'),\n",
       " ('Auxerre', None),\n",
       " ('Auxerre', 'n'),\n",
       " ('Azulgrana', None),\n",
       " ('Azulgrana', 'n'),\n",
       " ('Barac', None),\n",
       " ('Barac', 'n'),\n",
       " ('Baskonia', None),\n",
       " ('Baskonia', 'n'),\n",
       " ('Blicksilver', None),\n",
       " ('Blicksilver', 'n'),\n",
       " ('CNBC', None),\n",
       " ('CNBC', 'n'),\n",
       " ('CONCACAF', None),\n",
       " ('CONCACAF', 'n'),\n",
       " ('Cameron', None),\n",
       " ('Cameron', 'n'),\n",
       " ('Casillas', None),\n",
       " ('Casillas', 'n'),\n",
       " ('Cheshire', None),\n",
       " ('Cheshire', 'n'),\n",
       " ('Citigroup', None),\n",
       " ('Citigroup', 'n'),\n",
       " ('Cockell', None),\n",
       " ('Cockell', 'n'),\n",
       " ('Coequyt', None),\n",
       " ('Coequyt', 'n'),\n",
       " ('ConocoPhillips', None),\n",
       " ('ConocoPhillips', 'n'),\n",
       " ('Cutajar', None),\n",
       " ('Cutajar', 'n'),\n",
       " ('Debbie', None),\n",
       " ('Debbie', 'n'),\n",
       " ('Donohue', None),\n",
       " ('Donohue', 'n'),\n",
       " ('EUR', None),\n",
       " ('EUR', 'n'),\n",
       " ('Edder', None),\n",
       " ('Edder', 'n'),\n",
       " ('Eidson', None),\n",
       " ('Eidson', 'n'),\n",
       " ('Eliyahu', None),\n",
       " ('Eliyahu', 'n'),\n",
       " ('Exxon-Mobil', None),\n",
       " ('Exxon-Mobil', 'n'),\n",
       " ('FHFA', None),\n",
       " ('FHFA', 'n'),\n",
       " ('FIFA', None),\n",
       " ('FIFA', 'n'),\n",
       " ('Fitzpatrick', None),\n",
       " ('Fitzpatrick', 'n'),\n",
       " ('Gazprom', None),\n",
       " ('Gazprom', 'n'),\n",
       " ('Geoffrey', None),\n",
       " ('Geoffrey', 'n'),\n",
       " ('Ginni', None),\n",
       " ('Ginni', 'n'),\n",
       " ('Giovanni', None),\n",
       " ('Giovanni', 'n'),\n",
       " ('Hayley', None),\n",
       " ('Hayley', 'n'),\n",
       " ('Herrmann', None),\n",
       " ('Herrmann', 'n'),\n",
       " ('Huertas', None),\n",
       " ('Huertas', 'n'),\n",
       " ('Husari', None),\n",
       " ('Husari', 'n'),\n",
       " ('Intel', None),\n",
       " ('Intel', 'n'),\n",
       " ('Ivanovic', None),\n",
       " ('Ivanovic', 'n'),\n",
       " ('Ivonic', None),\n",
       " ('Ivonic', 'n'),\n",
       " ('Jamie', None),\n",
       " ('Jamie', 'n'),\n",
       " ('Jon', None),\n",
       " ('Jon', 'n'),\n",
       " ('Kagan', None),\n",
       " ('Kagan', 'n'),\n",
       " ('Keilor', None),\n",
       " ('Keilor', 'n'),\n",
       " (u'Latinobar\\xf3metro', None),\n",
       " (u'Latinobar\\xf3metro', 'n'),\n",
       " (u'Lib\\xe9ration', None),\n",
       " (u'Lib\\xe9ration', 'n'),\n",
       " ('Lukoil', None),\n",
       " ('Lukoil', 'n'),\n",
       " ('Maccabee', None),\n",
       " ('Maccabee', 'n'),\n",
       " ('Maccabees', None),\n",
       " ('Maccabees', 'n'),\n",
       " ('Mai', None),\n",
       " ('Mai', 'n'),\n",
       " ('Marblehead', None),\n",
       " ('Marblehead', 'n'),\n",
       " ('Marza', None),\n",
       " ('Marza', 'n'),\n",
       " ('Matz', None),\n",
       " ('Matz', 'n'),\n",
       " ('Michaela', None),\n",
       " ('Michaela', 'n'),\n",
       " ('Micov', None),\n",
       " ('Micov', 'n'),\n",
       " ('Mizra', None),\n",
       " ('Mizra', 'n'),\n",
       " ('Moreal', None),\n",
       " ('Moreal', 'a'),\n",
       " ('Mourinho', None),\n",
       " ('Mourinho', 'n'),\n",
       " ('NCUA', None),\n",
       " ('NCUA', 'n'),\n",
       " ('Navas', None),\n",
       " ('Navas', 'n'),\n",
       " ('Obama', None),\n",
       " ('Obama', 'n'),\n",
       " ('Oleson', None),\n",
       " ('Oleson', 'n'),\n",
       " ('Our', None),\n",
       " ('Our', 'n'),\n",
       " ('Paypal', None),\n",
       " ('Paypal', 'n'),\n",
       " ('Pnini', None),\n",
       " ('Pnini', 'n'),\n",
       " ('Ramos', None),\n",
       " ('Ramos', 'n'),\n",
       " ('Ribas', None),\n",
       " ('Ribas', 'n'),\n",
       " ('Rican', None),\n",
       " ('Rican', 'a'),\n",
       " ('Ruba', None),\n",
       " ('Ruba', 'n'),\n",
       " ('Runge-Metzger', None),\n",
       " ('Runge-Metzger', 'n'),\n",
       " ('Scalia', None),\n",
       " ('Scalia', 'n'),\n",
       " ('Schalke', None),\n",
       " ('Schalke', 'n'),\n",
       " ('Sheppard', None),\n",
       " ('Sheppard', 'n'),\n",
       " ('Teletovic', None),\n",
       " ('Teletovic', 'n'),\n",
       " ('Teltovic', None),\n",
       " ('Teltovic', 'n'),\n",
       " ('Ticos', None),\n",
       " ('Ticos', 'n'),\n",
       " ('UEFA', None),\n",
       " ('UEFA', 'n'),\n",
       " ('USD', None),\n",
       " ('USD', 'a'),\n",
       " ('Ulate', None),\n",
       " ('Ulate', 'n'),\n",
       " ('Ullmann', None),\n",
       " ('Ullmann', 'n'),\n",
       " ('Vitora', None),\n",
       " ('Vitora', 'n'),\n",
       " ('Vitorian', None),\n",
       " ('Vitorian', 'n'),\n",
       " ('Vitorians', None),\n",
       " ('Vitorians', 'n'),\n",
       " ('Xavi', None),\n",
       " ('Xavi', 'n'),\n",
       " ('Zubizarreta', None),\n",
       " ('Zubizarreta', 'n'),\n",
       " ('alvaro_arbeloa', None),\n",
       " ('alvaro_arbeloa', 'n'),\n",
       " ('andoni_zubizarreta', None),\n",
       " ('andoni_zubizarreta', 'n'),\n",
       " ('andres_iniesta', None),\n",
       " ('andres_iniesta', 'n'),\n",
       " ('antonin_scalia', None),\n",
       " ('antonin_scalia', 'n'),\n",
       " ('anybody', None),\n",
       " ('anybody', 'n'),\n",
       " ('anyone', None),\n",
       " ('anyone', 'n'),\n",
       " ('anything', None),\n",
       " ('anything', 'n'),\n",
       " ('bancroft_pllc', None),\n",
       " ('bancroft_pllc', 'n'),\n",
       " ('caja_laboral', None),\n",
       " ('caja_laboral', 'n'),\n",
       " ('carles_puyol', None),\n",
       " ('carles_puyol', 'n'),\n",
       " ('cesc_fabregas', None),\n",
       " ('cesc_fabregas', 'n'),\n",
       " ('constitutionality', None),\n",
       " ('constitutionality', 'n'),\n",
       " ('decidedand', None),\n",
       " ('decidedand', 'n'),\n",
       " ('dusko_ivanovic', None),\n",
       " ('dusko_ivanovic', 'n'),\n",
       " ('eBay', None),\n",
       " ('eBay', 'n'),\n",
       " ('elena_kagan', None),\n",
       " ('elena_kagan', 'n'),\n",
       " ('else', None),\n",
       " ('else', 'r'),\n",
       " ('fernando_torres', None),\n",
       " ('fernando_torres', 'n'),\n",
       " (u'fran\\xe7ois_hollande', None),\n",
       " (u'fran\\xe7ois_hollande', 'n'),\n",
       " ('fundrais', None),\n",
       " ('fundrais', 'v'),\n",
       " (u'gerard_piqu\\xe9', None),\n",
       " (u'gerard_piqu\\xe9', 'n'),\n",
       " ('ian_goldin', None),\n",
       " ('ian_goldin', 'n'),\n",
       " ('iker_casillas', None),\n",
       " ('iker_casillas', 'n'),\n",
       " ('jacques_chirac', None),\n",
       " ('jacques_chirac', 'n'),\n",
       " ('jairam_ramesh', None),\n",
       " ('jairam_ramesh', 'n'),\n",
       " ('jennifer_hawke-petit', None),\n",
       " ('jennifer_hawke-petit', 'n'),\n",
       " ('jordi_alba', None),\n",
       " ('jordi_alba', 'n'),\n",
       " ('jose_luis_lopez', None),\n",
       " ('jose_luis_lopez', 'n'),\n",
       " ('jose_mourinho', None),\n",
       " ('jose_mourinho', 'n'),\n",
       " ('josef_ackermann', None),\n",
       " ('josef_ackermann', 'n'),\n",
       " ('michel_rocard', None),\n",
       " ('michel_rocard', 'n'),\n",
       " ('mitch_mcconnell', None),\n",
       " ('mitch_mcconnell', 'n'),\n",
       " (\"n't\", None),\n",
       " (\"n't\", 'r'),\n",
       " ('nicolas_sarkozy', None),\n",
       " ('nicolas_sarkozy', 'n'),\n",
       " ('pend', None),\n",
       " ('pend', 'v'),\n",
       " ('policymaker', None),\n",
       " ('policymaker', 'n'),\n",
       " ('pp', None),\n",
       " ('pp', 'n'),\n",
       " ('randall_azofeifa', None),\n",
       " ('randall_azofeifa', 'n'),\n",
       " ('raul_albiol', None),\n",
       " ('raul_albiol', 'n'),\n",
       " ('raul_gonzalez', None),\n",
       " ('raul_gonzalez', 'n'),\n",
       " ('roy_myrie', None),\n",
       " ('roy_myrie', 'n'),\n",
       " ('san_emeterio', None),\n",
       " ('san_emeterio', 'n'),\n",
       " ('santi_cazorla', None),\n",
       " ('santi_cazorla', 'n'),\n",
       " ('sergio_busquets', None),\n",
       " ('sergio_busquets', 'n'),\n",
       " ('sergio_ramos', None),\n",
       " ('sergio_ramos', 'n'),\n",
       " ('that', None),\n",
       " ('that', 'r'),\n",
       " ('the', None),\n",
       " ('the', 'n'),\n",
       " ('unimagin', None),\n",
       " ('unimagin', 'v'),\n",
       " ('xavi_hernandez', None),\n",
       " ('xavi_hernandez', 'n'),\n",
       " ('zammit', None),\n",
       " ('zammit', 'n')}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synset_misses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"./SemEval13_task12_data/my_answers_test.txt\",'w') as fh:\n",
    "    for answer_parts in answers:\n",
    "        fh.write(\" \".join(answer_parts)+'\\n')\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'drug_war%1:04:00::'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'colombia%1:15:00::'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets(\"colombia\")[0].lemmas()[0].key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', 1)\n",
      "('b', '2')\n"
     ]
    }
   ],
   "source": [
    "for i,j in {\"a\":1,\"b\":\"2\" }.items():\n",
    "    print (i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'month%1:28:01::'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss=wn.synsets(\"month\")[0]\n",
    "ss.lemmas()[1].key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'find'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-130-d74bb3f8585c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemma_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'month'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'find'"
     ]
    }
   ],
   "source": [
    "ss.lemma_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#key   = emission%1:27:00::\n",
    "#guess = emission%1:04:00::/1.000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'emission%1:04:00::'"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sense_key(wn.synsets(\"emission\")[0], \"emission\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'emission%1:27:00::'"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sense_key(wn.synsets(\"emission\")[1], \"emission\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'the act of emitting; causing to flow forth'"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets(\"emission\")[0].definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'a substance that is emitted or released'"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets(\"emission\")[1].definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'the official currency issued by a government or national bank'"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets(\"money\")[2].definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'money%1:21:01::'"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets(\"money\")[2].lemmas()[0].key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets(\"money\")[2].lemmas()[0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('united_nations.n.01')]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets(\"UN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
