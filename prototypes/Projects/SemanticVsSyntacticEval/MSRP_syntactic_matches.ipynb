{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"prepared_corpora/msrp_matching/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "from __future__ import division\n",
    "\n",
    "import itertools\n",
    "import codecs\n",
    "from os import path\n",
    "import csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_MSRP(filename):\n",
    "    with codecs.open(filename,'r', b\"utf-8\" ) as fh:\n",
    "        nlines = 0\n",
    "        for line in fh.readlines():\n",
    "            nlines+=1\n",
    "            if nlines==1:\n",
    "                continue\n",
    "            isparaphrase, id1, id2, str1, str2 = line.split(\"\\t\") #the quality fielld is 1 for phraphrases and 0 for not\n",
    "            yield(int(isparaphrase)==1, (int(id1),str1.strip()),(int(id2),str2.strip()))\n",
    "\n",
    "            \n",
    "            \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_eval_corpora(base_paraphrases, folder, max_corruption_level=10):\n",
    "    \"\"\"We want to create the baseline corpus as a new line seperated sentences, so that it works well with Sorchers URAE system.\n",
    "    Thus all the metadata is stored in seperate files referencing the line numbers\"\"\"\n",
    "    \n",
    "    global phrase_line_num \n",
    "    phrase_line_num = 0 #line numebrs are always refered to after icrementing them\n",
    "    openned_filehandles = []\n",
    "    try:\n",
    "        phrases_fh = codecs.open(path.join(folder, \"phrases.txt\"),'w', b\"utf-8\" )\n",
    "        openned_filehandles.append(phrases_fh)\n",
    "\n",
    "        microsoft_ids_fh = open(path.join(folder, \"microsoft_ids.txt\"),'w')\n",
    "        openned_filehandles.append(microsoft_ids_fh)\n",
    "        microsoft_ids_csv = csv.writer(microsoft_ids_fh)\n",
    "        microsoft_ids_csv.writerow([\"phrase_line_number\",\"microsoft_id\"])\n",
    "\n",
    "        paraphrases_fh = open(path.join(folder, \"paraphrases.txt\"),\"w\")\n",
    "        openned_filehandles.append(paraphrases_fh)\n",
    "        paraphrases_csv = csv.writer(paraphrases_fh)\n",
    "        paraphrases_csv.writerow([\"phrase_line_num\", \"paraphrase_line_num\"])\n",
    "\n",
    "        ##Recorder Functions\n",
    "        def add_phrase(phrase):\n",
    "            global phrase_line_num\n",
    "            phrases_fh.write(phrase)\n",
    "            phrases_fh.write(\"\\n\")\n",
    "            phrase_line_num+=1\n",
    "            return phrase_line_num\n",
    "        \n",
    "   \n",
    "        for (isparaphrase,(m_id1,phrase1),(m_id2,phrase2)) in base_paraphrases:\n",
    "            #Add the phrases, and the corruptions\n",
    "            ln1 = add_phrase(phrase1)\n",
    "            ln2 = add_phrase(phrase2)\n",
    "            #add to the record of microsoft ids\n",
    "            microsoft_ids_csv.writerow([ln1,m_id1])\n",
    "            microsoft_ids_csv.writerow([ln2,m_id2])\n",
    "\n",
    "            if (isparaphrase):\n",
    "                #add the paraphases, in both directions\n",
    "                paraphrases_csv.writerow([ln1,ln2])\n",
    "                paraphrases_csv.writerow([ln2,ln1])\n",
    "            \n",
    "    finally:\n",
    "        for fh in openned_filehandles:\n",
    "            fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corp_gen = itertools.chain(\n",
    "        load_MSRP(\"../../base_corpora/MSRP/msr_paraphrase_test.txt\"),\n",
    "        load_MSRP(\"../../base_corpora/MSRP/msr_paraphrase_train.txt\")\n",
    ")\n",
    "\n",
    "create_eval_corpora(corp_gen,\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Here one must go and generate the Parsed versions (and while at it make the embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_reader = nltk.corpus.BracketParseCorpusReader(\".\",[\"parsed.txt\"])\n",
    "parse_trees = np.array(corpus_reader.parsed_sents(), dtype=object).squeeze();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def labels_only(tree):\n",
    "    if isinstance(tree, nltk.Tree):\n",
    "        labels = [tree.label()]\n",
    "        \n",
    "        for child in tree:\n",
    "            child_label = labels_only(child)\n",
    "            if child_label:\n",
    "                labels.append(child_label)\n",
    "        return tuple(labels)\n",
    "            \n",
    "    else:\n",
    "        return None\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 10212, 2: 564, 3: 56, 4: 8, 7: 2, 11: 2, 6: 1, 8: 1, 12: 1})"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "count = collections.Counter([labels_only(tree) for id,tree in enumerate(parse_trees)])\n",
    "collections.Counter(count.values())\n",
    "#~700 syntactic matches idk how many are already paraphrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "structures = collections.defaultdict(set)\n",
    "\n",
    "for id,tree in enumerate(parse_trees,1):\n",
    "    struct = labels_only(tree) \n",
    "    structures[struct].add(id)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "para_ids = np.loadtxt(\"./paraphrases.txt\", delimiter=\",\",skiprows=1, dtype=np.int)\n",
    "para_id_map = {row[0]:row[1] for row in para_ids}\n",
    "\n",
    "structural_matches = []\n",
    "for struct_set in structures.values():\n",
    "    if len(struct_set)>1:\n",
    "        for id in struct_set:\n",
    "            for other_id in struct_set.difference({id}):\n",
    "                if not (id in para_id_map) or para_id_map[id]!=other_id:\n",
    "                    leaves1 = set(parse_trees[id-1].leaves())\n",
    "                    leaves2 = parse_trees[other_id-1].leaves()\n",
    "                    if len(leaves1.intersection(leaves2))/len(leaves1) < 0.70: # must be 50% difference in bag of words \n",
    "                        structural_matches.append((id,other_id))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(structural_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2546, 6130), (6130, 2546)]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structural_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Trish',\n",
       " u'York',\n",
       " u',',\n",
       " u'a',\n",
       " u'spokeswoman',\n",
       " u'for',\n",
       " u'Boeing',\n",
       " u',',\n",
       " u'declined',\n",
       " u'to',\n",
       " u'comment',\n",
       " u'on',\n",
       " u'the',\n",
       " u'deal',\n",
       " u'.']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_trees[2546-1].leaves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Anthony',\n",
       " u'Citrano',\n",
       " u',',\n",
       " u'a',\n",
       " u'representative',\n",
       " u'for',\n",
       " u'WhenU',\n",
       " u',',\n",
       " u'declined',\n",
       " u'to',\n",
       " u'comment',\n",
       " u'on',\n",
       " u'the',\n",
       " u'case',\n",
       " u'.']"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_trees[6130-1].leaves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
