{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import itertools\n",
    "import codecs\n",
    "from os import path\n",
    "import csv\n",
    "\n",
    "from SemanticCorruption import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_MSRP(filename):\n",
    "    with codecs.open(filename,'r', b\"utf-8\" ) as fh:\n",
    "        nlines = 0\n",
    "        for line in fh.readlines():\n",
    "            nlines+=1\n",
    "            if nlines==1:\n",
    "                continue\n",
    "            isparaphrase, id1, id2, str1, str2 = line.split(\"\\t\") #the quality fielld is 1 for phraphrases and 0 for not\n",
    "            if int(isparaphrase)== 1:\n",
    "                yield((int(id1),str1.strip()),(int(id2),str2.strip()))\n",
    "\n",
    "            \n",
    "            \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_eval_corpora(base_paraphrases, folder, max_corruption_level=10):\n",
    "    \"\"\"We want to create the baseline corpus as a new line seperated sentences, so that it works well with Sorchers URAE system.\n",
    "    Thus all the metadata is stored in seperate files referencing the line numbers\"\"\"\n",
    "    \n",
    "    global phrase_line_num \n",
    "    phrase_line_num = 0 #line numebrs are always refered to after icrementing them\n",
    "    openned_filehandles = []\n",
    "    try:\n",
    "        phrases_fh = codecs.open(path.join(folder, \"phrases.txt\"),'w', b\"utf-8\" )\n",
    "        openned_filehandles.append(phrases_fh)\n",
    "\n",
    "        microsoft_ids_fh = open(path.join(folder, \"microsoft_ids.txt\"),'w')\n",
    "        openned_filehandles.append(microsoft_ids_fh)\n",
    "        microsoft_ids_csv = csv.writer(microsoft_ids_fh)\n",
    "        microsoft_ids_csv.writerow([\"phrase_line_number\",\"microsoft_id\"])\n",
    "\n",
    "        paraphases_fh = open(path.join(folder, \"paraphases.txt\"),\"w\")\n",
    "        openned_filehandles.append(paraphases_fh)\n",
    "        paraphases_csv = csv.writer(paraphases_fh)\n",
    "        paraphases_csv.writerow([\"phrase_line_num\", \"paraphase_line_num\"])\n",
    "\n",
    "        #Open all the alway open files\n",
    "        semantic_corruption_csvs=[]\n",
    "        for level in range(1,max_corruption_level+1):\n",
    "            sc_fh = open(path.join(folder, str(level)+\"_semantic_corruptions.txt\"),\"w\") \n",
    "            openned_filehandles.append(sc_fh)\n",
    "            sc_csv = csv.writer(sc_fh)                                         \n",
    "            sc_csv.writerow([\"uncorrupt_phrase_line_num\", \"corrupt_phrase_line_num\"])\n",
    "            semantic_corruption_csvs.append(sc_csv)\n",
    "\n",
    "        ##Recorder Functions\n",
    "        def add_phrase(phrase):\n",
    "            global phrase_line_num\n",
    "            phrases_fh.write(phrase)\n",
    "            phrases_fh.write(\"\\n\")\n",
    "            phrase_line_num+=1\n",
    "            return phrase_line_num\n",
    "        \n",
    "        def add_corruptions(phrase, phrase_ln):\n",
    "            global phrase_line_num\n",
    "            corrupted_phases = leveled_semantic_corrupt_sentences(phrase)\n",
    "            for corruption, level_sc_csv in zip(corrupted_phases, semantic_corruption_csvs):\n",
    "                phrases_fh.write(corruption)\n",
    "                phrases_fh.write(\"\\n\")\n",
    "                phrase_line_num+=1\n",
    "                \n",
    "                level_sc_csv.writerow([phrase_ln, phrase_line_num])\n",
    "        \n",
    "    \n",
    "        for ((m_id1,phrase1),(m_id2,phrase2)) in base_paraphrases:\n",
    "            #Add the phrases, and the corruptions\n",
    "            ln1 = add_phrase(phrase1)\n",
    "            add_corruptions(phrase1, ln1)\n",
    "            \n",
    "            ln2 = add_phrase(phrase2)\n",
    "            add_corruptions(phrase2, ln2)\n",
    "\n",
    "            #add to the record of microsoft ids\n",
    "            microsoft_ids_csv.writerow([ln1,m_id1])\n",
    "            microsoft_ids_csv.writerow([ln2,m_id2])\n",
    "\n",
    "            #add the paraphases, in both directions\n",
    "            paraphases_csv.writerow([ln1,ln2])\n",
    "            paraphases_csv.writerow([ln2,ln1])\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "    finally:\n",
    "        for fh in openned_filehandles:\n",
    "            fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corp_gen = itertools.chain(\n",
    "        load_MSRP(\"base_corpora/MSRP/msr_paraphrase_test.txt\"),\n",
    "        load_MSRP(\"base_corpora/MSRP/msr_paraphrase_train.txt\")\n",
    ")\n",
    "\n",
    "create_eval_corpora(corp_gen,\"prepared_corpora/msrp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corp_gen_mini = itertools.islice(itertools.chain(\n",
    "        load_MSRP(\"base_corpora/MSRP/msr_paraphrase_test.txt\"),\n",
    "        load_MSRP(\"base_corpora/MSRP/msr_paraphrase_train.txt\")\n",
    "), 0,5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "create_eval_corpora(corp_gen_mini,\"prepared_corpora/testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
