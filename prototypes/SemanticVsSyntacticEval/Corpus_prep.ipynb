{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "import itertools\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def restem_fun(pos_tag):\n",
    "    \"\"\"\n",
    "    Handles the restemming of a particular POS tag after it has been converted to a Stem via wordnet lemmaisation.\n",
    "\n",
    "    pos_tag is from https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html eg VBD\n",
    "    \n",
    "    This can be extended as required from https://www.nodebox.net/code/index.php/Linguistics\n",
    "    \"\"\"\n",
    "    import pattern.en as en\n",
    "    restem_fun = {frozenset(['NNS', 'NNPS']) : en.pluralize,\n",
    "                  frozenset(['RBR', 'JJR']) : en.comparative,\n",
    "                  frozenset(['JJS']) : en.superlative, #Skip RBS, as (\"Most\") not changed by WordNet\n",
    "                  frozenset(['VBD', 'VBN']) :  lambda w: en.conjugate(w, en.PAST) # A lot more of these can be made with en.conugate\n",
    "                 }\n",
    "    \n",
    "    for category in restem_fun.keys():\n",
    "        if pos_tag in category:\n",
    "            return restem_fun[category]\n",
    "    else:\n",
    "        return lambda x: x\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_all_antonyms(word, pos=None):\n",
    "    synsets = wn.synsets(word, pos=pos)\n",
    "    for synset in synsets:\n",
    "        for lemma in synset.lemmas():\n",
    "            for anto in lemma.antonyms():\n",
    "                yield anto.name()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#These constants define the types that I am interested in, as well as what POS tags they have for what wordnet tags\n",
    "NOUN_POS_TAGS = frozenset([\"NN\", \"NNS\"])\n",
    "ADJ_POS_TAGS = frozenset([\"JJ\",\"JJS\", \"JSR\", \"VBN\"]) #VBN is here because it is hard to tell the difference between a VERB PAST PARTICPANT and an ADJECTIVE\n",
    "VERB_POS_TAGS = frozenset([\"VB\",\"VBS\", \"VBN\",\"VBG\"]) #Not VBD as that tends to be 'had' or 'were'\n",
    "ADVERB_POS_TAGS = frozenset([\"RB\",\"RBS\"])\n",
    "\n",
    "\n",
    "def get_pos_sub_function(pos_tag_set, wordnet_tag):\n",
    "    def inner(words, index = False):\n",
    "        for ii,(pword,p_pos_tag) in enumerate(nltk.pos_tag(words)):\n",
    "            if p_pos_tag in pos_tag_set:\n",
    "                restem = restem_fun(p_pos_tag)\n",
    "\n",
    "                antos =  get_all_antonyms(pword, wordnet_tag)\n",
    "                antos = map(restem,antos)\n",
    "                antos = list(antos)\n",
    "                if len(antos)>0:\n",
    "                    if index:\n",
    "                        yield(ii, antos)\n",
    "                    else:\n",
    "                        yield(pword, antos)\n",
    "\n",
    "    return inner\n",
    "\n",
    "\n",
    "#Define the functions: all take sequence of words as parameter\n",
    "get_noun_subs = get_pos_sub_function(NOUN_POS_TAGS, wn.NOUN)\n",
    "get_adj_subs = get_pos_sub_function(ADJ_POS_TAGS, wn.ADJ)\n",
    "get_verb_subs = get_pos_sub_function(VERB_POS_TAGS, wn.VERB)\n",
    "get_adverb_subs = get_pos_sub_function(ADVERB_POS_TAGS, wn.ADV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mr.', 'NNP'),\n",
       " ('Jones', 'NNP'),\n",
       " ('had', 'VBD'),\n",
       " ('never', 'RB'),\n",
       " ('thought', 'VBN')]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_sent = \"Mr. Jones had never thought\"\n",
    "base_words = nltk.tokenize.word_tokenize(base_sent)\n",
    "nltk.pos_tag(base_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.randint(0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def semantic_corruptions(sent):\n",
    "    words = nltk.tokenize.word_tokenize(sent)\n",
    "    corruptions = dict(itertools.chain(get_adj_subs(words, index=True),\n",
    "                    get_noun_subs(words, index=True),\n",
    "                    get_adverb_subs(words, index=True),\n",
    "                    get_verb_subs(words, index=True),\n",
    "                   ))\n",
    "    for corrupt_index in corruptions.keys():\n",
    "        antos = corruptions[corrupt_index]\n",
    "        anto_index = random.randint(0,len(antos)-1)\n",
    "        words[corrupt_index] = antos[anto_index]\n",
    "        \n",
    "    return \" \".join(words)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'The article is the least uncommon determiner ( DT ) in English .'"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_corruptions(\"The article is the most common determiner (DT) in English.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'We may abstain a problem'"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_corruptions(\"We may have a problem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('article', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('most', 'RBS'),\n",
       " ('common', 'JJ'),\n",
       " ('determiner', 'NN'),\n",
       " ('(', ':'),\n",
       " ('DT', 'NNP'),\n",
       " (')', ':'),\n",
       " ('in', 'IN'),\n",
       " ('English', 'NNP'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(nltk.tokenize.word_tokenize(\"The article is the most common determiner (DT) in English.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'fewest', u'least', u'least']"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(get_all_antonyms(\"most\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('most.a.01'),\n",
       " Synset('most.a.02'),\n",
       " Synset('most.r.01'),\n",
       " Synset('most.r.02'),\n",
       " Synset('about.r.07')]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets(\"most\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def is_clear_adjective(word):\n",
    "    \"\"\"To be clear:\n",
    "         - Synsets must all be adjective, or sattilite adjgective (ie no noun or verb form)\n",
    "         - must only be one adjective synset (ie not two senses)\n",
    "    \"\"\"\n",
    "    \n",
    "    synsets = wn.synsets(word)\n",
    "    if all(map(lambda ss: ss.pos==wn.ADJ or ss.pos==wn.ADJ_SAT, synsets)):\n",
    "        adj_sets = filter(lambda ss: ss.pos==wn.ADJ, synsets)\n",
    "        if len(adj_sets)==1:\n",
    "            adj_ss = adj_sets[1]\n",
    "            return adj_ss\n",
    "            \n",
    "            \n",
    "            \n",
    "        else: #Has either no Adjective cases or multiple\n",
    "            return []\n",
    "    else: #Has mixed POS uses \n",
    "        return [] \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n', 'n', 'n', 'n']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word=\"children\"\n",
    "list(map(lambda ss: ss.pos(), wn.synsets(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ss= wn.synsets(word) [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('child.n.02.child'), Lemma('child.n.02.kid')]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.lemmas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tree() missing 1 required positional argument: 'rel'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-114-e82d203fc7e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: tree() missing 1 required positional argument: 'rel'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll.antonyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sss=list(wn.synsets(\"hot\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'used of physical heat; having a high or higher than desirable temperature or giving off heat or feeling or causing a sensation of heat or burning'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sss[0].definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ss=sss[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'extended meanings; especially of psychological heat; marked by intensity or vehemence especially of passion or enthusiasm'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function any in module builtins:\n",
      "\n",
      "any(...)\n",
      "    any(iterable) -> bool\n",
      "    \n",
      "    Return True if bool(x) is True for any x in the iterable.\n",
      "    If the iterable is empty, return False.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
