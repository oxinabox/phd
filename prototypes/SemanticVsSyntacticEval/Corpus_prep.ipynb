{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have a prototype of they system for corrupting sentences, for different semantic meaning:\n",
    "\n",
    "My process is:\n",
    "\n",
    "     Tokenize the sentence (Currently using the NLTK regex tokenizer, it seem sufficient)\n",
    "     Parts of Speech tag (Currently using the Stanford POS Tagger (via NLTK))\n",
    "     For each word that is not blacklisted (I have blacklisted \"had\", \"were\", \"have\", \"was\", and \"be\", as they are unusual verbs with strange antoymns, further more the are rather syntatic)\n",
    "         Use WordNet to find antonyms of the same POS tag  (So \"Larger\" (Noun, as in beer) has no antonyms, but \"larger\" (Ajd) has \"Little\" as an anytonym.\n",
    "        Unstem: WordNet stemming/lemmaisation (of the antonym) removes Tense, Plurality, comparativeness, and superlativeness, so I make use the POS tag of the original to work those out, then restore them using the Pattern library's tools for this (http://jmlr.csail.mit.edu/papers/volume13/desmedt12a/desmedt12a.pdf)\n",
    "         I remove any suggested antonyms that are short phrases (eg Wordnet suggests that \"take_away\" is an antonym of \"add\", however adding a work word change the structure of the sentence.)\n",
    "     I substitute the antonyms in selecting randomly if there are multiple choices. (I still need to decide how many, putting in an even number often results in a double negative)\n",
    "    I repair the indefinite articles ('an' vs 'a')\n",
    "    I check the final sentence by sending it through the POS tagger and seeing if I get the same tags.\n",
    "\n",
    "\n",
    "This final step is not perfect. Its not bad though.\n",
    "It got a lot better when I changed to using the Stanford POS tagger, as it was more able to tag and retag correctly and thus was most consistent.\n",
    "\n",
    "I have attached a (printout) of my method script.  At the the bottom you can see some examples of it's use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "import pattern.en as en\n",
    "\n",
    "import itertools\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from nltk.parse import stanford\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tag.stanford import POSTagger\n",
    "os.environ['CLASSPATH'] = '/home/wheel/oxinabox/nltk_data/standford_models/stanford-postagger/stanford-postagger.jar'\n",
    "os.environ['STANFORD_MODELS'] = '/home/wheel/oxinabox/nltk_data/standford_models/stanford-postagger/models/'\n",
    "\n",
    "standford_pos_tagger = POSTagger(\"english-bidirectional-distsim.tagger\")\n",
    "def pos_tag(words):\n",
    "    return standford_pos_tagger.tag(words)[0]\n",
    "    \n",
    "def tok_and_tag(sent):\n",
    "    return pos_tag(nltk.tokenize.word_tokenize(sent))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'a', u'yak']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "referenced = en.referenced(\"yak\") #Smarter than\n",
    "referenced.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fix_indefinite_articles(words):\n",
    "    \"\"\"Alters a list of words in place so that the indefinate articles are correct. Eg replacing \"An man\" with \"A man\" \"\"\"\n",
    "    for ii in range(0,len(words)-1): #don't do the last word, as it can't ne an 'an' or an 'a'\n",
    "        if words[ii] in frozenset(['an','a','An','A']):\n",
    "            referenced_form = en.referenced(words[ii]) #Smarter than simple vowel match eg \"a yak\" not \"an yak\"\n",
    "            replacement_article = referenced_form.split()[0] #'an' or 'a'\n",
    "            if words[ii][0]=='A':\n",
    "                replacement_article[0] == 'A' #Uppercase it\n",
    "            words[ii]=replacement_article\n",
    "\n",
    "    return words\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def unstem_fun(pos_tag):\n",
    "    \"\"\"\n",
    "    Handles the restemming of a particular POS tag after it has been converted to a Stem via wordnet lemmaisation.\n",
    "\n",
    "    pos_tag is from https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html eg VBD\n",
    "    \n",
    "    This can be extended as required from https://www.nodebox.net/code/index.php/Linguistics\n",
    "    \"\"\"\n",
    "\n",
    "    unstem_funs = {frozenset(['NNS', 'NNPS']) : en.pluralize,\n",
    "                  frozenset(['RBR', 'JJR']) : en.comparative,\n",
    "                  frozenset(['JJS']) : en.superlative, #Skip RBS, as (\"Most\") not changed by WordNet\n",
    "                  frozenset(['VBD', 'VBN']) :  lambda w: en.conjugate(w, en.PAST), # A lot more of these can be made with en.conugate\n",
    "                  frozenset(['VBG']) :  lambda w: en.conjugate(w,en.PRESENT,aspect=en.PROGRESSIVE ),\n",
    "                 }\n",
    "    \n",
    "    for category in unstem_funs.keys():\n",
    "        if pos_tag in category:\n",
    "            return unstem_funs[category]\n",
    "    else:\n",
    "        return lambda x: x\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_all_antonyms(word, pos=None):\n",
    "    synsets = wn.synsets(word, pos=pos)\n",
    "    for synset in synsets:\n",
    "        for lemma in synset.lemmas():\n",
    "            for anto in lemma.antonyms():\n",
    "                yield anto.name()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#These constants define the types that I am interested in, as well as what POS tags they have for what wordnet tags\n",
    "NOUN_POS_TAGS = frozenset([\"NN\", \"NNS\"])\n",
    "ADJ_POS_TAGS = frozenset([\"JJ\",\"JJS\", \"JJR\", \"VBN\"]) #VBN is here because it is hard to tell the difference between a VERB PAST PARTICPANT and an ADJECTIVE\n",
    "VERB_POS_TAGS = frozenset([\"VB\",\"VBS\", \"VBN\",\"VBG\", \"VBD\"]) \n",
    "ADVERB_POS_TAGS = frozenset([\"RB\",\"RBS\"])\n",
    "\n",
    "banned_inputs_to_sub = frozenset([\"had\", \"were\", \"have\", \"be\", \"was\"]) #Changing these words tends to have huge impact on sentence, and they are had to change correctly\n",
    "\n",
    "def get_pos_sub_function(pos_tag_set, wordnet_tag):\n",
    "    def inner(tagged_words):\n",
    "        for ii,(pword,p_pos_tag) in enumerate(tagged_words):\n",
    "            if p_pos_tag in pos_tag_set and not(pword in banned_inputs_to_sub):\n",
    "                unstem = unstem_fun(p_pos_tag)\n",
    "\n",
    "                antos =  get_all_antonyms(pword, wordnet_tag)\n",
    "                antos = map(unstem,antos)\n",
    "                antos = filter(lambda w:not('_' in w), antos) #some WordNet lemmas are not single words. We don't use them.\n",
    "                antos = list(antos)\n",
    "                if len(antos)>0:\n",
    "                    yield(ii, antos)\n",
    "    return inner\n",
    "\n",
    "\n",
    "#Define the functions: all take sequence of words as parameter\n",
    "get_noun_subs = get_pos_sub_function(NOUN_POS_TAGS, wn.NOUN)\n",
    "get_adj_subs = get_pos_sub_function(ADJ_POS_TAGS, wn.ADJ)\n",
    "get_verb_subs = get_pos_sub_function(VERB_POS_TAGS, wn.VERB)\n",
    "get_adverb_subs = get_pos_sub_function(ADVERB_POS_TAGS, wn.ADV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def semantic_corruptions(sent):\n",
    "    words = nltk.tokenize.word_tokenize(sent)\n",
    "    tagged_words = pos_tag(words)\n",
    "    corruptions = dict(itertools.chain(get_adj_subs(tagged_words),\n",
    "                    get_noun_subs(tagged_words),\n",
    "                    get_adverb_subs(tagged_words),\n",
    "                    get_verb_subs(tagged_words),\n",
    "                   ))\n",
    "    for corrupt_index in corruptions.keys():\n",
    "        antos = corruptions[corrupt_index]\n",
    "        anto_index = random.randint(0,len(antos)-1)\n",
    "        words[corrupt_index] = antos[anto_index]\n",
    "    fix_indefinite_articles(words)\n",
    "    return \" \".join(words)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def checked_corruption(sent):\n",
    "    original_words, original_pos_tags = zip(*tok_and_tag(sent))\n",
    "    corrupted_sent = semantic_corruptions(sent)\n",
    "    corupted_words, corrupted_pos_tags = zip(*tok_and_tag(corrupted_sent))\n",
    "    \n",
    "    for (ii,(o_tag,c_tag)) in enumerate(zip(original_pos_tags,corrupted_pos_tags)):\n",
    "        if o_tag != c_tag:\n",
    "            print(\"failed on: (%s) %s  != %s (%s)\" % (original_words[ii], o_tag, c_tag, corupted_words[ii]))\n",
    "       \n",
    "    return corrupted_sent\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed on: (most) RBS  != JJS (least)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "u'The article is the least individual determiner ( DT ) in English .'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checked_corruption(\"The article is the most common determiner (DT) in English.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'We may have an answer'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checked_corruption(\"We may have a question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed on: (expected) VBN  != JJ (unexpected)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "u'Is staying an even number of verbs , adverbs , adjectives and nouns to their synonyms unexpected to produce an semantically close acquittal ?'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent=\"Is changing an odd number of verbs, adverbs, adjectives and nouns to their antonyms expected to produce a semantically distant sentence?\"\n",
    "checked_corruption(sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Both gerunds and infinitives can be misused as the subject or the complement of an acquittal .'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checked_corruption(\"Both gerunds and infinitives can be used as the subject or the complement of a sentence.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Shares of Xoma ascended 16 percent in middle trade , while shares of Genentech , an much less company with several products on the market , were down 2 percent .'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"Shares of Xoma fell 16 percent in early trade, while shares of Genentech, a much larger company with several products on the market, were up 2 percent.\"\n",
    "checked_corruption(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Six months ago , the IMF and Argentina missed an bare-minimum $ 6.8-billion debt rollover deal that expires in August .'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checked_corruption(\"Six months ago, the IMF and Argentina struck a bare-minimum $6.8-billion debt rollover deal that expires in August.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"He plans to have dinner with troops at Kosovo 's U.S. unmilitary headquarters , Camp Bondsteel .\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checked_corruption(\"He plans to have dinner with troops at Kosovo's U.S. military headquarters, Camp Bondsteel.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed on: (stationed) VBD  != VBN (stationed)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "u'After that , he plans to have dinner at Camp Bondsteel with U.S. troops stationed here .'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checked_corruption(\"After that, he plans to have dinner at Camp Bondsteel with U.S. troops stationed there.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'He subtracted that prosecutors will seek the birth reward .'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checked_corruption(\"He added that prosecutors will seek the death penalty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Who is this woman ?'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checked_corruption(\"Who is this man?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Who is that woman ?'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checked_corruption(\"Who is that man?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'This good thief stole that car !'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checked_corruption(\"This evil thief stole that car!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'The motorist is unangry , so the pedestrian is unintelligibly scared'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checked_corruption(\"The motorist is angry, so the pedestrian is understandably scared\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
