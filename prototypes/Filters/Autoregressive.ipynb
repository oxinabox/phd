{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using Iterators\n",
    "using Pipe\n",
    "\n",
    "macro hcat(expr)\n",
    "    :(hcat($expr...))\n",
    "end\n",
    "macro vcat(expr)\n",
    "    :(vcat($expr...))\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "macro printval(ee)\n",
    "    ee_expr = @sprintf \"%s\" string(ee)\n",
    "    esc(:(println($ee_expr,\" = \", $ee)))\n",
    "end\n",
    "\n",
    "macro pz(ee)\n",
    "    ee_expr = @sprintf \"%s\" string(ee)\n",
    "    esc(:(println($ee_expr,\"\\t\\t\",typeof($ee), \"\\t\", size($ee))))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using StatsBase\n",
    "using SpecialMatrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "push! (generic function with 32 methods)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Base.push!\n",
    "function push!(X::Matrix, x::Vector)\n",
    "    ncols = size(X, 2)\n",
    "    for col=2:ncols\n",
    "        X[:, col-1] = X[:, col]\n",
    "    end\n",
    "    X[:,end]=x\n",
    "    X\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lab2_ar_signal! (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function random_walk1!(xs::Matrix)\n",
    "    step = rand(-1:1,size(xs,1))\n",
    "    new_x = xs[:,end]+step\n",
    "    push!(xs,new_x)\n",
    "end\n",
    "\n",
    "function lab2_ar_signal!(xs)\n",
    "    u = randn(size(xs,1))\n",
    "    new_x = 1.8xs[end]-0.81xs[end-1]+0.1u\n",
    "    push!(xs,new_x)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_samples (generic function with 2 methods)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_samples!(transfer!::Function, xs::Matrix)\n",
    "    for _ in 1:size(xs,2)\n",
    "        transfer!(xs)\n",
    "    end\n",
    "    xs\n",
    "end\n",
    "function get_samples(transfer!::Function, n::Int, k::Int=1)\n",
    "    xs = zeros(k,n)\n",
    "    get_samples!(transfer!,xs)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "yule_walker_fit_AR (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function yule_walker_fit_AR(xs::Vector, p::Int)\n",
    "    γ=autocor(xs,0:p,demean=true)\n",
    "    γ_sym = [γ[end:-1:1], γ[2:end]] #Autocovarience is syemtrical about zero\n",
    "    Γ = Toeplitz(γ_sym[2:end-1])  #Don't use p and -p indexes, in the gamma\n",
    "    full(Γ)\\γ[2:end]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Float64,1}:\n",
       "  1.4445  \n",
       " -0.454494"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs = get_samples(lab2_ar_signal!,100)[:];\n",
    "yule_walker_fit_AR(xs, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$y_{t}=c+A_{1}y_{{t-1}}+A_{2}y_{{t-2}}+\\cdots +A_{p}y_{{t-p}}+e_{t},\\,$$\n",
    "\n",
    "Where each $y_i$ is a vector of length $k$ and each $A_i$ is a $k × k$ matrix.\n",
    "\n",
    "$${\\begin{bmatrix}y_{{1,t}}\\\\y_{{2,t}}\\\\\\vdots \\\\y_{{k,t}}\\end{bmatrix}}={\\begin{bmatrix}c_{{1}}\\\\c_{{2}}\\\\\\vdots \\\\c_{{k}}\\end{bmatrix}}+{\\begin{bmatrix}a_{{1,1}}^{1}&a_{{1,2}}^{1}&\\cdots &a_{{1,k}}^{1}\\\\a_{{2,1}}^{1}&a_{{2,2}}^{1}&\\cdots &a_{{2,k}}^{1}\\\\\\vdots &\\vdots &\\ddots &\\vdots \\\\a_{{k,1}}^{1}&a_{{k,2}}^{1}&\\cdots &a_{{k,k}}^{1}\\end{bmatrix}}{\\begin{bmatrix}y_{{1,t-1}}\\\\y_{{2,t-1}}\\\\\\vdots \\\\y_{{k,t-1}}\\end{bmatrix}}+\\cdots +{\\begin{bmatrix}a_{{1,1}}^{p}&a_{{1,2}}^{p}&\\cdots &a_{{1,k}}^{p}\\\\a_{{2,1}}^{p}&a_{{2,2}}^{p}&\\cdots &a_{{2,k}}^{p}\\\\\\vdots &\\vdots &\\ddots &\\vdots \\\\a_{{k,1}}^{p}&a_{{k,2}}^{p}&\\cdots &a_{{k,k}}^{p}\\end{bmatrix}}{\\begin{bmatrix}y_{{1,t-p}}\\\\y_{{2,t-p}}\\\\\\vdots \\\\y_{{k,t-p}}\\end{bmatrix}}+{\\begin{bmatrix}e_{{1,t}}\\\\e_{{2,t}}\\\\\\vdots \\\\e_{{k,t}}\\end{bmatrix}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "least_squares_fit (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_next(ys::Matrix{Float64}, c::Vector{Float64}, As::Vector{Matrix{Float64}})\n",
    "    yn = c\n",
    "    for t in 1:length(As)\n",
    "        yn+=As[t]*ys[:,end-t+1] \n",
    "    end\n",
    "    yn\n",
    "end\n",
    "function applyTransition!(ys::Matrix{Float64}, c::Vector{Float64}, As::Vector{Matrix{Float64}})\n",
    "    yn = get_next(ys,c,As)\n",
    "    push!(ys,yn)\n",
    "end\n",
    "\n",
    "function least_squares_fit(ys::Matrix, p::Int)\n",
    "    #Each colunmf of ys is a differnt point in time\n",
    "    #Each row of ys is a differen variable\n",
    "    #ys is first observation first\n",
    "    #Y=BZ + U, B= [c A_1 A_2 ...]\n",
    "    nVars, nObservationsTotal = size(ys)\n",
    "    nObservations = nObservationsTotal-p\n",
    "    \n",
    "    Y = ys[:,p+1:end] #end is the most recent observation\n",
    "    Z_col(t) = [1; vec(ys[:, p+t:-1: t+1])]\n",
    "    Z = hcat([Z_col(t) for t in 0:nObservations-1]...)\n",
    "    B̂=Y*Z'*(pinv(Z*Z'))\n",
    "    \n",
    "    Ŷ=B̂*Z\n",
    "    R²=cor(vec(Y),vec(Ŷ))^2\n",
    "        \n",
    "    c=B̂[:,1]\n",
    "    function A(t)\n",
    "        start = 1+(t-1)*nVars\n",
    "        B̂[:,1+start:start+nVars]\n",
    "    end\n",
    "\n",
    "    (c, map(A, 1:p), R²)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v_motion (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function constant_velocity_motion!(ys::Matrix, v::Vector)\n",
    "    yn = ys[:,end].+v + 0.1randn(length(v))\n",
    "    push!(ys,yn)\n",
    "end\n",
    "\n",
    "function motion(ys::Matrix)\n",
    "    #x = ys[1,\n",
    "    #v = ys[2,\n",
    "    #a = ys[3,\n",
    "    A= [1 1 0; 0 1 1; 0 0 1]\n",
    "    yn = A*ys[:,end] + 1*randn(3)\n",
    "    push!(ys,yn)\n",
    "end\n",
    "\n",
    "\n",
    "function v_motion(ys::Matrix)\n",
    "    v = ys[:,end]- ys[:,end-1]\n",
    "    yn = ys[:,end]+v + 0.1randn(length(v))\n",
    "    push!(ys,yn)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-0.213747,-0.0822762,2.99581],[\n",
       "3x3 Array{Float64,2}:\n",
       "  1.0002        0.995903    0.056392\n",
       " -1.0723e-5     0.999717    1.01518 \n",
       " -0.000141832  -0.00257041  0.74435 ],0.9999998755369578)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys = [zeros(3,50) [0; 0; 9.8] ]\n",
    "get_samples!(motion, ys)\n",
    "least_squares_fit(ys, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/nltk/app/__init__.py:45: UserWarning: nltk.app.wordfreq not loaded (requires the pylab library).\n",
      "  warnings.warn(\"nltk.app.wordfreq not loaded \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tokenize (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using PyCall\n",
    "@pyimport nltk\n",
    "function tokenize(sentence::String)\n",
    "    convert(Array{String,1},nltk.word_tokenize(sentence))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Union(ASCIIString,UTF8String),1}:\n",
       " \"/root/buildFromSource/julia/usr/local/share/julia/site/v0.3\"\n",
       " \"/root/buildFromSource/julia/usr/share/julia/site/v0.3\"      \n",
       " \"../word-embeddings2\"                                        "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "push!(LOAD_PATH, \"../word-embeddings2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using WordEmbeddings\n",
    "we = @pipe load_embeddings(\"../word-embeddings2/embeddings-scaled.EMBEDDING_SIZE=50.txt\") |> WE(_...);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "multi_least_squares_fit (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function multi_least_squares_fit(yss, p::Int)\n",
    "    #Each colunmf of ys is a differnt point in time\n",
    "    #Each row of ys is a differen variable\n",
    "    #ys is first observation first\n",
    "    #Y=BZ + U, B= [c A_1 A_2 ...]\n",
    "    \n",
    "    function get_model(ys::Matrix)\n",
    "        nVars, nObservationsTotal = size(ys)\n",
    "        nObservations = nObservationsTotal-p\n",
    "        Y = ys[:,p+1:end] #end is the most recent observation\n",
    "        Z_col(t) = [1; vec(ys[:, p+t:-1: t+1])]\n",
    "        Z = hcat([Z_col(t) for t in 0:nObservations-1]...)\n",
    "        Y, Z\n",
    "    end\n",
    "    YZs = map(get_model, yss)\n",
    "    Y=hcat(map(x->x[1],YZs)...)\n",
    "    Z=hcat(map(x->x[2],YZs)...)\n",
    "    B̂=Y*Z'*(pinv(Z*Z'))\n",
    "\n",
    "    Ŷ=B̂*Z\n",
    "    R²=cor(vec(Y),vec(Ŷ))^2\n",
    "        \n",
    "    c=B̂[:,1]\n",
    "    function A(t)\n",
    "        nVars=size(Y,1)\n",
    "        start = 1+(t-1)*nVars\n",
    "        B̂[:,1+start:start+nVars]\n",
    "    end\n",
    "\n",
    "    (c, map(A, 1:p), R²)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@pyimport nltk.corpus as nltk_corpus\n",
    "n_training = 20000\n",
    "training_sents = @pipe (nltk_corpus.brown[:sents]() \n",
    "                            |> filter(s->10<length(s)<=10, _) \n",
    "                            #|> filter(s->s[2]==\"was\"||s[2]==\"is\"||s[2]==\"are\",_)\n",
    "                            |> take(_,n_training)  \n",
    "                            |> collect |> convert(Vector{Vector{String}},_));\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xss\t\tArray{Array{String,1},1}\t(0,)\n"
     ]
    }
   ],
   "source": [
    "xss = map(x-> eval_word_embeddings(we,x, false), training_sents);\n",
    "@pz xss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "type: eye: in apply, expected Function, got Type{None}\nwhile loading In[113], in expression starting on line 1",
     "output_type": "error",
     "traceback": [
      "type: eye: in apply, expected Function, got Type{None}\nwhile loading In[113], in expression starting on line 1",
      "",
      " in eye at array.jl:176",
      " in svdfact! at linalg/factorization.jl:672",
      " in svdfact at linalg/factorization.jl:678",
      " in pinv at linalg/dense.jl:422",
      " in multi_least_squares_fit at In[14]:18"
     ]
    }
   ],
   "source": [
    "c,As, RR = multi_least_squares_fit(xss, 5);\n",
    "RR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xs = eval_word_embeddings(we, [[\"We\", \"must\", \"never\"]]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20x2 Array{Any,2}:\n",
       " \".\"        0.84\n",
       " \"thought\"  0.75\n",
       " \"put\"      0.74\n",
       " \"here\"     0.73\n",
       " \"away\"     0.72\n",
       " \"abroad\"   0.72\n",
       " \"say\"      0.72\n",
       " \"--\"       0.71\n",
       " \"either\"   0.71\n",
       " \"dies\"     0.7 \n",
       " \"calls\"    0.7 \n",
       " \"work\"     0.69\n",
       " \"even\"     0.69\n",
       " \"know\"     0.69\n",
       " \"surgery\"  0.69\n",
       " \"what\"     0.69\n",
       " \"steps\"    0.69\n",
       " \"down\"     0.69\n",
       " \"clear\"    0.69\n",
       " \"...\"      0.69"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xn=get_next(xs, c,As)\n",
    "WordEmbeddings.show_best(we, xn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20x2 Array{Any,2}:\n",
       " \".\"           0.96\n",
       " \"?\"           0.81\n",
       " \"...\"         0.79\n",
       " \":\"           0.76\n",
       " \";\"           0.73\n",
       " \"today.\"      0.72\n",
       " \"here\"        0.71\n",
       " \"down.\"       0.71\n",
       " \"alone\"       0.71\n",
       " \"there.\"      0.7 \n",
       " \"away\"        0.69\n",
       " \"yesterday.\"  0.69\n",
       " \"--\"          0.68\n",
       " \"because\"     0.67\n",
       " \"here.\"       0.67\n",
       " \"down\"        0.67\n",
       " \"today\"       0.67\n",
       " \"!\"           0.66\n",
       " \"-\"           0.66\n",
       " \"abroad\"      0.66"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "push!(xs,xn)\n",
    "xn=get_next(xs, c,As)\n",
    "WordEmbeddings.show_best(we, xn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07854030683334139"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c |> var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Array{Float64,2},1}:\n",
       " 50x50 Array{Float64,2}:\n",
       "  0.0648472     0.0758701   -0.0317492   …  -0.0336552     0.107034  \n",
       " -0.00355749    0.00541685   0.00633831      0.00562672    0.00837982\n",
       " -0.0203564     0.00413503  -0.00969851     -0.0202983     0.0084813 \n",
       "  0.0361519     0.0186559   -0.0305165      -0.025819      0.00930714\n",
       " -0.0733171     0.011071    -0.0148443       0.00999717    0.00234524\n",
       "  0.00592348    0.0614763   -0.0473626   …   0.00540978    0.0972364 \n",
       " -0.00508223   -0.0497306    0.0382472      -0.00381313   -0.0336308 \n",
       "  0.0462311     0.085421    -0.0029227       0.0287976     0.0981407 \n",
       " -0.0290627    -0.0270584   -0.0209602      -0.00964684   -0.019825  \n",
       "  0.0318975     0.0433611   -0.0341913      -0.0208791     0.091581  \n",
       "  0.000861176   0.00525056   0.0176642   …   0.0311334     0.0131887 \n",
       " -0.0155731     0.00353059  -0.022953       -0.00488004    0.0675929 \n",
       "  0.00842677    0.0295661   -0.0387072       0.0342073     0.0264478 \n",
       "  ⋮                                      ⋱                           \n",
       " -0.0192835     0.00501026   0.0112671       0.0102477    -0.0569797 \n",
       "  0.00668114   -0.0113059   -0.0622649      -0.000786024   0.0463696 \n",
       "  0.0560081     0.0608655   -0.0752013   …   0.00496516    0.114733  \n",
       " -0.0375163     0.0143539   -0.0318821      -0.0313373     0.025785  \n",
       " -0.0438473    -0.00545993  -0.00773777      0.00494428   -0.0308693 \n",
       "  0.0179571    -0.0615357    0.0151354      -0.0102989    -0.0877955 \n",
       " -0.0123838    -0.0166713    0.0282185       0.0161893    -0.0251573 \n",
       "  0.00504412    0.0153802   -0.0220427   …   0.0141217     0.00758692\n",
       " -9.35189e-5   -0.0449143    0.0323629       0.00253085   -0.0466478 \n",
       "  0.0065353    -0.0144289   -0.0224105      -0.01077       0.015639  \n",
       "  0.00691927    0.0157774   -0.076767       -0.00856511    0.0421898 \n",
       " -0.00550971   -0.0255135    0.012572       -0.0146427     0.0168558                                                     \n",
       " 50x50 Array{Float64,2}:\n",
       "  0.0339551     0.0187489    -0.0404623    …   0.00582213   0.123823   \n",
       " -0.0154368    -0.00580994    0.000777138     -0.0372271   -0.0309429  \n",
       " -0.00742596    0.00445121    0.00981368      -0.0195208   -0.00926    \n",
       "  0.00676088    0.0167485    -0.0358612        0.0314662    0.0196906  \n",
       " -0.00862547    0.0105524    -0.026501         0.0349144    0.0568664  \n",
       " -0.00162626    0.0010341    -0.0374587    …   0.0334156    0.0792392  \n",
       "  0.00564529    0.00939369    0.0067275        0.00419321  -0.0486089  \n",
       " -0.000310958  -0.00329239   -0.0430978        0.0678038    0.139567   \n",
       "  0.00249107    0.00099517    0.0250568       -0.00415531  -0.0117482  \n",
       "  0.0368912     0.0139078    -0.00841775      -0.00978829   0.0219081  \n",
       " -0.00318192   -0.0137649     0.0408694    …  -0.0473098   -0.0304     \n",
       "  0.00488689    0.00406249   -0.0125269        0.0281457    0.0540751  \n",
       " -0.00232864   -0.00499966   -0.00432638       0.0118324    0.0367188  \n",
       "  ⋮                                        ⋱                           \n",
       " -0.0145977    -0.0310296     0.0261752        0.00186925  -0.0417962  \n",
       " -0.0047338    -0.00348534   -0.0317171       -0.00682339  -0.00337042 \n",
       "  0.00851187    0.00480024   -0.047095     …   0.038737     0.0928011  \n",
       " -0.00072079   -0.00161086   -0.0269016        0.0591045    0.0847754  \n",
       " -0.0131266    -0.0106533     0.00678771      -0.0411198   -0.00887053 \n",
       "  0.00334266   -0.00310826    0.00408454       0.00539306  -0.0724664  \n",
       "  0.0135327     0.00377366   -0.068781         0.0469949    0.0255744  \n",
       " -0.00457879    0.0223984    -0.0276745    …  -0.00314723   0.0196735  \n",
       "  0.00792909    0.0120963     0.0285452        0.0173881   -0.0479983  \n",
       " -0.0075149     0.000208193   0.0271806       -0.0355427   -0.000835034\n",
       " -4.63959e-5    0.00861844   -0.022107        -0.0114729    0.0112487  \n",
       " -0.00492978    0.00581178    0.00396017      -0.00406615  -0.0157757  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "As"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20x2 Array{Any,2}:\n",
       " \"Domenico\"        0.56\n",
       " \"NedEnterprise\"   0.53\n",
       " \"CompUSA\"         0.53\n",
       " \"GEHE\"            0.52\n",
       " \"locals\"          0.52\n",
       " \"hieiroglyphics\"  0.52\n",
       " \"NOK\"             0.52\n",
       " \"DRAMs\"           0.51\n",
       " \"acedemia\"        0.51\n",
       " \"compressing\"     0.51\n",
       " \"Amistar\"         0.51\n",
       " \"sheep.\"          0.51\n",
       " \"bond-stripping\"  0.5 \n",
       " \"Bandai\"          0.5 \n",
       " \"Hyannis\"         0.5 \n",
       " \"housewives\"      0.5 \n",
       " \"Schon\"           0.5 \n",
       " \"Parcell\"         0.5 \n",
       " \"AZCO\"            0.5 \n",
       " \"Tchibo\"          0.49"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WordEmbeddings.show_best(we, As[2][:,15][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.3.8",
   "language": "julia",
   "name": "julia-0.3"
  },
  "language_info": {
   "name": "julia",
   "version": "0.3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
