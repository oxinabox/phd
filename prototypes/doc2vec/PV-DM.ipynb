{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using Compat\n",
    "using Docile\n",
    "using Iterators\n",
    "using Pipe\n",
    "using Devectorize\n",
    "\n",
    "macro printval(ee)\n",
    "    ee_expr = @sprintf \"%s\" string(ee)\n",
    "    esc(:(println($ee_expr,\" = \", $ee)))\n",
    "end\n",
    "\n",
    "macro pz(ee)\n",
    "    ee_expr = @sprintf \"%s\" string(ee)\n",
    "    esc(:(println($ee_expr,\"\\t\\t\",typeof($ee), \"\\t\", size($ee))))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unzip (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function unzip(xs)\n",
    "    [zip(xs...)...]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11-element Array{Union(ASCIIString,UTF8String),1}:\n",
       " \"/root/buildFromSource/julia/usr/local/share/julia/site/v0.3\"\n",
       " \"/root/buildFromSource/julia/usr/share/julia/site/v0.3\"      \n",
       " \"../Corpus\"                                                  \n",
       " \"../doc2vec\"                                                 \n",
       " \"../Models\"                                                  \n",
       " \"../Optimisation\"                                            \n",
       " \"../recursive_embeddings\"                                    \n",
       " \"../summaristation\"                                          \n",
       " \"../tools\"                                                   \n",
       " \"../util\"                                                    \n",
       " \"../word-embedding3\"                                         "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "push!(LOAD_PATH, map(x->\"../\"*x, filter(fn-> !(contains(fn,\".\")),readdir(\"..\")))...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using WordEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\t\tArray{Array{String,1},1}\t(6097,)\n"
     ]
    }
   ],
   "source": [
    "training = open(\"../Corpus/serialised/opinosis_train_dev_plain.jsz\",\"r\") do fs\n",
    "    deserialize(fs)\n",
    "end\n",
    "@pz training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000-element Array{Array{String,1},1}:\n",
       " String[\"being\",\"able\",\"to\",\"change\",\"the\",\"*UNKNOWN*\",\"sizes\",\"is\",\"awesome\",\"!\"]                                                                                            \n",
       " String[\"for\",\"whatever\",\"reason\",\",\",\"*UNKNOWN*\",\"decided\",\"to\",\"make\",\"the\",\"*UNKNOWN*\",\"on\",\"the\",\"home\",\"screen\",\"than\",\"on\",\"the\",\"*UNKNOWN*\",\".\"]                       \n",
       " String[\"i\",\"found\",\"myself\",\"constantly\",\"changing\",\"the\",\"angle\",\"of\",\"the\",\"body\"  …  \"up\",\"and\",\"down\",\"and\",\"the\",\"distance\",\"away\",\"from\",\"me\",\".\"]                     \n",
       " String[\"i\",\"was\",\"an\",\"avid\",\"reader\",\"but\",\"increasing\",\"age\",\"has\",\"made\"  …  \"and\",\"very\",\"light\",\"weight\",\"has\",\"made\",\"reading\",\"fun\",\"again\",\".\"]                      \n",
       " String[\"what\",\"'s\",\"more\",\",\",\"it\",\"'s\",\"easy\",\"to\",\"change\",\"*UNKNOWN*\",\"size\",\".\"]                                                                                         \n",
       " String[\"the\",\"*UNKNOWN*\",\"does\",\"not\",\"recognize\",\"page\",\"numbers\",\",\",\"since\",\"they\"  …  \"provides\",\"the\",\"notion\",\"of\",\"location\",\"which\",\"is\",\"display\",\"independent\",\".\"]\n",
       " String[\"i\",\"just\",\"crank\",\"the\",\"*UNKNOWN*\",\"up\",\"a\",\"notch\",\"or\",\"two\",\"and\",\"leave\",\"the\",\"readers\",\"behind\",\".\"]                                                          \n",
       " String[\"my\",\"*UNKNOWN*\",\"is\",\"fine\",\",\",\"but\",\"i\",\"can\",\"choose\",\"the\",\"*UNKNOWN*\",\"size\",\"that\",\"suits\",\"me\",\"best\",\".\"]                                                    \n",
       " String[\"*UNKNOWN*\",\"easy\",\",\",\"on\",\",\",\"the\",\",\",\"eyes\",\"'\",\"reading\"  …  \"still\",\"not\",\"big\",\"enough\",\"for\",\"people\",\"with\",\"vision\",\"problems\",\".\"]                        \n",
       " String[\"one\",\"or\",\"two\",\"larger\",\"*UNKNOWN*\",\"sizes\",\"would\",\"have\",\"benefited\",\"the\",\"visually\",\"*UNKNOWN*\",\".\"]                                                            \n",
       " String[\"downloading\",\"books\",\"is\",\"easy\",\",\",\"the\",\"screen\",\"is\",\"not\",\"too\"  …  \"*UNKNOWN*\",\"and\",\"the\",\"*UNKNOWN*\",\"customer\",\"service\",\"support\",\"is\",\"terrific\",\".\"]     \n",
       " String[\"the\",\"text\",\"appears\",\"slightly\",\"*UNKNOWN*\",\"and\",\"i\",\"have\",\"to\",\"increase\",\"the\",\"*UNKNOWN*\",\"size\",\"to\",\"read\",\"it\",\"comfortably\",\".\"]                           \n",
       " String[\"and\",\"with\",\"the\",\"*UNKNOWN*\",\",\",\"i\",\"can\",\"adjust\",\"the\",\"*UNKNOWN*\"  …  \"importance\",\"to\",\"those\",\"with\",\"poor\",\"vision\",\"or\",\"tired\",\"eyes\",\".\"]                 \n",
       " ⋮                                                                                                                                                                            \n",
       " String[\"near\",\"a\",\"tube\",\"station\",\"that\",\"services\",\"three\",\"subway\",\"lines\",\",\",\"for\",\"starters\",\".\"]                                                                      \n",
       " String[\"we\",\"are\",\"low\",\"maintenance\",\"so\",\"we\",\"did\",\"n't\",\"have\",\"to\"  …  \"much\",\",\",\"but\",\"when\",\"we\",\"did\",\"it\",\"was\",\"fine\",\".\"]                                        \n",
       " String[\"not\",\"too\",\"happy\",\"with\",\"the\",\"service\",\"from\",\"*UNKNOWN*\",\",\",\"*UNKNOWN*\",\"and\",\"*UNKNOWN*\",\".\"]                                                                  \n",
       " String[\"i\",\"ordered\",\"room\",\"service\",\"one\",\"night\",\",\",\"and\",\"the\",\"food\"  …  \"delightful\",\",\",\"and\",\"the\",\"service\",\"was\",\"fast\",\"and\",\"friendly\",\".\"]                     \n",
       " String[\"if\",\"you\",\"need\",\"a\",\"hotel\",\"with\",\"services\",\"like\",\"access\",\"to\"  …  \"price\",\"tickets\",\"to\",\"events\",\"then\",\"do\",\"n't\",\"stay\",\"here\",\".\"]                         \n",
       " String[\"however\",\"the\",\"hotel\",\"is\",\"very\",\"large\",\"and\",\"loses\",\"some\",\"personal\"  …  \"priority\",\"club\",\"rewards\",\"status\",\",\",\"and\",\"slow\",\"room\",\"service\",\".\"]           \n",
       " String[\"for\",\"a\",\"little\",\"extra\",\"money\",\",\",\"the\",\"soon\",\"to\",\"be\"  …  \"the\",\"same\",\"great\",\"location\\nonly\",\"*UNKNOWN*\",\"is\",\"their\",\"breakfast\",\"service\",\".\"]           \n",
       " String[\"convenient\",\"location\",\"great\",\"*UNKNOWN*\",\"service\",\".\"]                                                                                                            \n",
       " String[\"i\",\"would\",\"definitely\",\"stay\",\"here\",\"again\",\"for\",\"the\",\"location\",\"and\",\"the\",\"great\",\"customer\",\"service\",\".\"]                                                   \n",
       " String[\"talking\",\"about\",\"food\",\",\",\"something\",\"worth\",\"noticing\",\"is\",\"that\",\"there\"  …  \",\",\"bar\",\"service\",\"beverages\",\",\",\"which\",\"completely\",\"filled\",\"it\",\".\"]       \n",
       " String[\"the\",\"service\",\"was\",\"the\",\"worst\",\"service\",\"we\",\"have\",\"ever\",\"recieved\",\"in\",\"my\",\"life\",\"the\",\"worst\",\".\"]                                                       \n",
       " String[\"*UNKNOWN*\",\",\",\"service\",\"finished\",\"at\",\"*UNKNOWN*\",\",\",\"there\",\"was\",\"a\"  …  \"breakfast\",\"was\",\"*UNKNOWN*\",\",\",\"the\",\"ingredients\",\"seemed\",\"poor\",\"quality\",\".\"]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training=training[1:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pad (generic function with 2 methods)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "function pad{S<:String}(sent::Vector{S}, padded_length, pad_word=\"*STARTPAD*\")\n",
    "    if length(sent) <= padded_length\n",
    "        ret =  fill(pad_word,padded_length)\n",
    "        ret[end-length(sent)+1:end] = sent\n",
    "        ret\n",
    "    else\n",
    "        sent\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "add_all_words! (generic function with 4 methods)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import WordEmbeddings.WE\n",
    "function WE(N::DataType,S::DataType, embedding_width::Int)\n",
    "    L=Array(N,(embedding_width,0))\n",
    "    word_index=Dict{S,Int}()\n",
    "    indexed_words=S[]\n",
    "    WE(L,word_index,indexed_words)\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "@doc \"Gets the word index, or creates one if it doesn't already exist\" ->\n",
    "function get_word_index!{N,S, S2}(we::WE{N,S}, word::S2, word_varience = 0.01)\n",
    "    if (word in keys(we.word_index))\n",
    "        we.word_index[word]\n",
    "    else\n",
    "        index = length(we.indexed_words)+1\n",
    "        we.word_index[word]=index\n",
    "        push!(we.indexed_words,word)\n",
    "        \n",
    "        embedding = convert(Vector{N},word_varience.*randn(size(we.L,1)))\n",
    "        we.L = hcat(we.L,embedding)\n",
    "        index\n",
    "    end\n",
    "end\n",
    "\n",
    "function add_all_words!{N,S}(we::WE{N,S}, words::Vector{S}, word_varience=0.01)\n",
    "    for word in words\n",
    "        get_word_index!(we, word, word_varience)\n",
    "    end\n",
    "    we\n",
    "end\n",
    "function add_all_words!{N,S}(we::WE{N,S}, paras::Vector{Vector{S}}, word_varience=0.01)\n",
    "    for para in paras\n",
    "        add_all_words!(we, para, word_varience)\n",
    "    end\n",
    "    we\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PVDM{N<:Number,S<:String} (constructor with 2 methods)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type PVDM{N<:Number, S<:AbstractString}\n",
    "    we::WE\n",
    "    pe::WE #use a word embedder for Paragraphs too\n",
    "    \n",
    "    W::AbstractMatrix{N}\n",
    "    b::AbstractVector{N}\n",
    "\n",
    "    window_length::Int\n",
    "    varience::N\n",
    "end\n",
    "\n",
    "function PVDM{N,S}(we::WE{N,S}, window_length::Int, varience=0.001)\n",
    "    \n",
    "    emb_width,n_words = size(we.L)\n",
    "    concat_layer_width = emb_width*(window_length+1)\n",
    "    const W = convert(Matrix{N}, varience*randn(n_words,concat_layer_width))\n",
    "    const b = convert(Vector{N}, varience*randn(n_words))\n",
    "    \n",
    "    pe = WE(N,Vector{S},emb_width)\n",
    "    \n",
    "    PVDM{N,S}( we, pe, W,b, window_length, varience)\n",
    "end\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pack (generic function with 2 methods)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@doc \"This assumes the number of works and paragraphs known remains constant\" ->\n",
    "function unpack!(pvdm::PVDM, θ::Vector)\n",
    "    start=0\n",
    "    item=pvdm.we.L\n",
    "    len_total=length(item)\n",
    "    pvdm.we.L = @pipe θ[1+start:start+len_total]|>reshape(_,size(item)...)\n",
    "    \n",
    "    start+=length(item)\n",
    "    item=pvdm.pe.L\n",
    "    len_total+=length(item)\n",
    "    @printval start\n",
    "    @printval len_total\n",
    "    @pz item\n",
    "    pvdm.pe.L = @pipe θ[1+start:start+len_total]|>reshape(_,size(item)...)\n",
    "    \n",
    "    start+=length(item)\n",
    "    item=pvdm.W \n",
    "    len_total+=length(item)\n",
    "    pvdm.W = @pipe θ[1+start:start+len_total]|>reshape(_,size(item)...)\n",
    "    \n",
    "    start+=length(item)\n",
    "    item=pvdm.b \n",
    "    len_total+=length(item)\n",
    "    pvdm.b = @pipe θ[1+start:start+len_total]\n",
    "    \n",
    "    pvdm\n",
    "end\n",
    "\n",
    "\n",
    "@doc \"This assumes the number of works and paragraphs known remains constant\" ->\n",
    "function pack{N}(L::AbstractMatrix{N}, D::AbstractMatrix{N}, W::AbstractMatrix{N},b::AbstractVector{N})\n",
    "    vcat(vec(L),vec(D), vec(W),b)\n",
    "end\n",
    "\n",
    "@doc \"This assumes the number of works and paragraphs known remains constant\" ->\n",
    "function pack(pvdm::PVDM)\n",
    "    pack(pvdm.we.L, pvdm.pe.L, pvdm.W, pvdm.b)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pvdm2.pe.L\t\tArray{Float32,2}\t(200,971)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "194200"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@pz pvdm2.pe.L\n",
    "length(pvdm2.pe.L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start = 449800\n",
      "len_total = 644000\n",
      "item\t\tArray{Float32,2}\t(200,971)\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "DimensionMismatch(\"new dimensions (200,971) must be consistent with array size 644000\")\nwhile loading In[113], in expression starting on line 3",
     "output_type": "error",
     "traceback": [
      "DimensionMismatch(\"new dimensions (200,971) must be consistent with array size 644000\")\nwhile loading In[113], in expression starting on line 3",
      "",
      " in reshape at array.jl:100",
      " in reshape at abstractarray.jl:127",
      " in unpack! at In[109]:14"
     ]
    }
   ],
   "source": [
    "#pvdm2= deepcopy(pvdm)\n",
    "θ=pack(pvdm)\n",
    "unpack!(pvdm,θ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const WINDOW_LEN = 8 \n",
    "training = Vector{String}[pad(para, WINDOW_LEN+1) for para in training]\n",
    "\n",
    "we_outer = WE(Float32,String, 200)\n",
    "add_all_words!(we_outer, training)\n",
    "pvdm = PVDM(we_outer, WINDOW_LEN);\n",
    "we_outer=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_para_training_cases! (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@doc \"\"\"gets the training cases as vector of (paraIndex, [word_indexes], label_word_index),\n",
    "cycling by the window length.\n",
    "Adds the paragraph if it does not already have an index\n",
    "\"\"\" ->\n",
    "function get_para_training_cases!{S<:String}(pvdm::PVDM, para::Vector{S})\n",
    "    para_ind = get_word_index!(pvdm.pe, para)\n",
    "    \n",
    "    Task() do \n",
    "        @assert length(para)>=pvdm.window_length+1\n",
    "        for offset in 0:length(para)-(pvdm.window_length+1)\n",
    "            window_iis = [1:pvdm.window_length;]+offset\n",
    "            label_ii = pvdm.window_length+1+offset\n",
    "            \n",
    "            window_words = para[window_iis]\n",
    "            label_word = para[label_ii]\n",
    "                        \n",
    "            windows_indexes = map(word->get_word_index(pvdm.we, word), window_words)\n",
    "            label_index = get_word_index(pvdm.we, label_word)\n",
    "            \n",
    "            produce(Int64[para_ind, windows_indexes..., label_index])\n",
    "        end\n",
    "    end\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_indexes = @pipe chain(map(para -> get_para_training_cases!(pvdm, para), training)...) |> hcat(_...)\n",
    "para_indexes_o = training_indexes[1,:] |> vec\n",
    "window_indexes_o = training_indexes[2:end-1,:] \n",
    "label_indexes_o = training_indexes[end,:] |> vec;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "onehot (generic function with 2 methods)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function onehot{I<:Int}(indexes::Vector{I}, dim::I, N::DataType)\n",
    "    ys = zeros(N,(dim,length(indexes)))\n",
    "    for ii in indexes\n",
    "        @inbounds ys[ii,indexes[ii]]=one(N)\n",
    "    end\n",
    "    ys\n",
    "end\n",
    "\n",
    "function onehot{I,N,S}(indexes::Vector{I}, pvdm::PVDM{N,S})\n",
    "    onehot(label_indexes_o, length(pvdm.we.indexed_words), N)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_input_layers (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_input_layer(pvdm::PVDM, para_index::Int, window_indexes::Vector{Int})\n",
    "    @inbounds [pvdm.pe.L[:,para_index], vec(pvdm.we.L[:,window_indexes])]\n",
    "end \n",
    "\n",
    "function get_input_layers{N,S, I<:Int}(pvdm::PVDM{N,S}, para_indexes::Vector{I}, window_indexeses::Matrix{I})\n",
    "    const emb_width = size(pvdm.we.L,1)\n",
    "    const n_training = length(para_indexes)\n",
    "    \n",
    "    xs = Array(N,(emb_width * (pvdm.window_length+1),n_training))\n",
    "    @inbounds xs[1:emb_width,:] = pvdm.pe.L[:,para_indexes]\n",
    "    for training_case in 1:n_training\n",
    "        @inbounds const window_indexes = window_indexeses[:,training_case]\n",
    "        @inbounds xs[emb_width+1:end,training_case] = vec(pvdm.we.L[:,window_indexes])\n",
    "    end\n",
    "    xs\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feedforward (generic function with 1 method)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function softmax(zs)\n",
    "    (1./sum(exp(zs),1)).*exp(zs)\n",
    "end\n",
    "\n",
    "function feedforward{N,S, I<:Int}(pvdm::PVDM{N,S}, para_indexes::Vector{I}, window_indexeses::Matrix{I})\n",
    "    xs = get_input_layers(pvdm, para_indexes, window_indexeses)\n",
    "    \n",
    "    \n",
    "    #Speed optimised version of `zs = pvdm.W*xs .+ pvdm.b`\n",
    "    zs = pvdm.W*xs \n",
    "    const n_training = length(para_indexes)\n",
    "    for ii in 1:n_training\n",
    "        @inbounds zs[:,ii]+= pvdm.b\n",
    "    end\n",
    "    ŷs = softmax(zs)\n",
    "    ŷs, xs\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "backprop (generic function with 1 method)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function backprop{N,S,I}(pvdm::PVDM{N,S}, ys::Matrix{N}, ŷs::Matrix{N}, xs::Matrix{N} , para_indexes::Vector{I}, window_indexeses::Matrix{I} )\n",
    "    const emb_width = size(pvdm.we.L,1)\n",
    "    const n_training = length(para_indexes)\n",
    "    const window_len = pvdm.window_length \n",
    "    #Δb = zeros(pvdm.b)\n",
    "    #ΔW = zeros(pvdm.W)\n",
    "    ΔL = zeros(pvdm.we.L) #Word Vector Changes\n",
    "    ΔD = zeros(pvdm.pe.L) #Paragraph Vector Changes\n",
    "     \n",
    "        \n",
    "    δ_top_s = ŷs.-ys\n",
    "\n",
    "    Δb = sum(δ_top_s,2) |> vec\n",
    "    ΔW = (δ_top_s * xs')\n",
    "    δ_input_s= (pvdm.W'*δ_top_s) #the activation function of the layer below dxs=d(1*D[ii];L[iis]) =1\n",
    "    \n",
    "    #Paragraph vector Error\n",
    "    for ii in 1:n_training #Add sequentially, reather than via in a += as that would only allow one add for repreased index\n",
    "        @inbounds ΔD[:,para_indexes[ii]] += δ_input_s[1:emb_width,ii]\n",
    "    end\n",
    "    \n",
    "    #word vectors\n",
    "    for ii in 1:n_training\n",
    "        for ww in 1:window_len\n",
    "            const offset=ww*emb_width\n",
    "            @inbounds ΔL[:,window_indexeses[ww,ii]]+=δ_input_s[offset+1:offset+emb_width, ii]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "   \n",
    "    ΔL, ΔD, ΔW,Δb\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test (generic function with 1 method)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ŷs,xs = feedforward(pvdm, para_indexes_o, window_indexes_o)\n",
    "ys=onehot(label_indexes_o, pvdm)\n",
    "ΔW,Δb, ΔL, ΔD = backprop(pvdm, ys, ŷs,xs, para_indexes_o, window_indexes_o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "δ_input_s not defined\nwhile loading In[19], in expression starting on line 1",
     "output_type": "error",
     "traceback": [
      "δ_input_s not defined\nwhile loading In[19], in expression starting on line 1",
      ""
     ]
    }
   ],
   "source": [
    "@pz δ_input_s\n",
    "emb_width = size(pvdm.we.L,1)\n",
    "@pz δ_input_s[1:emb_width,1]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.3.9-pre",
   "language": "julia",
   "name": "julia-0.3"
  },
  "language_info": {
   "name": "julia",
   "version": "0.3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
