{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#addprocs(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{ByteString,1}:\n",
       " \"/home/ubuntu/build/julia-master/usr/local/share/julia/site/v0.5\"\n",
       " \"/home/ubuntu/build/julia-master/usr/share/julia/site/v0.5\"      \n",
       " \".\"                                                              \n",
       " \"../util/\"                                                       "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import FunctionalCollections\n",
    "import Iterators\n",
    "import Pipe\n",
    "import Compat\n",
    "import JLD\n",
    "@everywhere using FunctionalCollections\n",
    "@everywhere using Iterators\n",
    "@everywhere using Pipe\n",
    "@everywhere using Compat\n",
    "@everywhere using JLD\n",
    "\n",
    "macro printval(ee)\n",
    "    ee_expr = @sprintf \"%s\" string(ee)\n",
    "    esc(:(println($ee_expr,\" = \", $ee)))\n",
    "end\n",
    "\n",
    "macro pz(ee)\n",
    "    ee_expr = @sprintf \"%s\" string(ee)\n",
    "    esc(:(println($ee_expr,\"\\t\\t\",typeof($ee), \"\\t\", size($ee))))\n",
    "end\n",
    "\n",
    "push!(LOAD_PATH, \".\")\n",
    "push!(LOAD_PATH, \"../util/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#shuffled_indexes = 1:length(ground_sents) |> collect |> shuffle!\n",
    "#nfolds=10\n",
    "#fold_indexes = Vector{Int}[\n",
    "#    shuffled_indexes[(ii-1)*end÷nfolds + 1: ii*end÷nfolds]\n",
    "#    for ii in 1:nfolds]\n",
    "\n",
    "#@save(\"brown_glove_folds.jld\", fold_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@everywhere fold_indexes=load(\"brown_glove_folds.jld\",\"fold_indexes\")\n",
    "\n",
    "@everywhere function fold_split(fold_ii, raw_bow_res)\n",
    "    ground_sents = Vector{ASCIIString}[rset[1] for rset in raw_bow_res]\n",
    "    reconstructed_bows = Vector{ASCIIString}[rset[2] for rset in raw_bow_res]\n",
    "    \n",
    "    test_indexes = fold_indexes[fold_ii]\n",
    "    training_indexes = trues(ground_sents)\n",
    "    training_indexes[test_indexes]=false\n",
    "\n",
    "    test_unordered_sents = reconstructed_bows[test_indexes]\n",
    "    test_ground = ground_sents[test_indexes]\n",
    "    training_sents = ground_sents[training_indexes]\n",
    "    test_unordered_sents,test_ground, training_sents\n",
    "end\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/nltk/app/__init__.py:29: UserWarning: nltk.app package not loaded (please install Tkinter library).\n",
      "  warnings.warn(\"nltk.app package not loaded \"\n",
      "/usr/local/lib/python2.7/dist-packages/nltk/draw/__init__.py:15: UserWarning: nltk.draw package not loaded (please install Tkinter library).\n",
      "  warnings.warn(\"nltk.draw package not loaded \"\n"
     ]
    }
   ],
   "source": [
    "@everywhere typealias S ASCIIString\n",
    "@everywhere typealias State{T} Tuple{T,T}\n",
    "\n",
    "import PyCall\n",
    "@everywhere using PyCall\n",
    "#http://www.nltk.org/howto/probability.html\n",
    "@everywhere @pyimport nltk\n",
    "@everywhere @pyimport nltk.probability as nltk_prob\n",
    "\n",
    "@everywhere function train_language_model{T}(train_corpus::Vector{Vector{T}})\n",
    "    function py_collect(xs::PyObject)\n",
    "        xst = []\n",
    "        for x in xs\n",
    "            push!(xst,x)\n",
    "        end\n",
    "        xst\n",
    "    end\n",
    "    function trigram_buffer(sent)\n",
    "        [START_MARKER1, START_MARKER2, sent..., END_MARKER1, END_MARKER2] \n",
    "    end\n",
    "\n",
    "    training_trigrams = vcat([py_collect(nltk.trigrams(trigram_buffer(sent))) for sent in train_corpus]...)\n",
    "    kn_prob_dist = nltk_prob.KneserNeyProbDist(pycall(nltk_prob.FreqDist, PyObject, training_trigrams))\n",
    "    \n",
    "    function trigram_model(given1::S, given2::S, event::S)\n",
    "        kn_prob_dist[:prob]((given1, given2, event))\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "@everywhere const START_MARKER1 = \"**START1**\"\n",
    "@everywhere const START_MARKER2 = \"**START2**\"\n",
    "@everywhere const END_MARKER1 = \"**END1**\"\n",
    "@everywhere const END_MARKER2 = \"**END2**\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@everywhere function best_order(unordered_words::Vector{S}, languauge_model::Function; beam_width=Inf)\n",
    "    function transition_prob(cur_state::State{S}, next_word::S)\n",
    "        languauge_model(cur_state[1],cur_state[2], next_word)\n",
    "    end\n",
    "        \n",
    "    \n",
    "    function get_options(cur_state::State{S}, remaining_words)\n",
    "        if length(remaining_words)==0\n",
    "            #Final Step -- leaf node\n",
    "            tp = transition_prob(cur_state, END_MARKER1)\n",
    "            # Given P(END_MARKER2 | curstatep[2]==END_MARKER1) = 1.0\n",
    "            # Do not need to consider P(END_MARKER2 | curstatep[2]==END_MARKER1, curstatep[1])\n",
    "            next_state = (cur_state[2],END_MARKER1)\n",
    "            return [(tp, next_state, S[])]\n",
    "        end\n",
    "        #Otherwise -- nonfinal step, get all childreen\n",
    "        map(1:length(remaining_words)) do ii\n",
    "            next_word = remaining_words[ii]\n",
    "            tp = transition_prob(cur_state, next_word)           \n",
    "            still_remaining_words = sub(remaining_words,[1:ii-1; ii+1:length(remaining_words)])\n",
    "            next_state = (cur_state[2],next_word)\n",
    "            (tp, next_state, still_remaining_words)\n",
    "        end\n",
    "    end\n",
    "                \n",
    "    \n",
    "    initial_state = (START_MARKER1, START_MARKER2)\n",
    "    initial_node = (1.0, EmptyList{S}(), initial_state, unordered_words)\n",
    "    pending = Collections.PriorityQueue(Tuple{Float64, FunctionalCollections.AbstractList{S}, State{S}, Vector{S}},Float64, Base.Order.Reverse)     \n",
    "    pending[initial_node]=1.0\n",
    "    \n",
    "    #At end of search pending contains all the partway steps that have not yet been explored fully\n",
    "    #But that can't be more optimal than the returned solution, we don't do anything with them right now\n",
    "    while(true)\n",
    "        (sofar_prob, sofar_words, state, remaining_words) = Collections.dequeue!(pending)\n",
    "        \n",
    "        is_terminal = state[2]==END_MARKER1\n",
    "        if is_terminal\n",
    "            @assert length(remaining_words)==0\n",
    "            return sofar_words|> tail |> collect |> reverse!, sofar_prob #Note: We take the tail of the sofar words before reversing to cut off then end marker\n",
    "        end\n",
    "        \n",
    "        #Nontermial, ie has children, even if it is just the single terminal child\n",
    "        for (tp, next_state, still_remaining_words) in get_options(state, remaining_words)\n",
    "            if tp==0.0 \n",
    "                continue\n",
    "            end\n",
    "            total_next_prob = sofar_prob*tp\n",
    "            next_sofar_words = cons(next_state[2], sofar_words)\n",
    "            new_node = (total_next_prob, next_sofar_words, next_state, still_remaining_words)\n",
    "            pending[new_node] = total_next_prob\n",
    "        end\n",
    "        if length(pending)==0\n",
    "            #All Paths failed, return the best we could do so far, with the unsortable on the end\n",
    "            sorted = sofar_words |> collect |> reverse!\n",
    "            return ([sorted...; remaining_words...], length(sorted)*1.0)\n",
    "        end\n",
    "    end \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trigram_model (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@pyimport nltk.corpus as nltk_corpus\n",
    "corpus_reader=nltk_corpus.brown\n",
    "corpus = Vector{ASCIIString}[[lowercase(word) for word in sent] for sent in (corpus_reader[:sents]()|> collect)]\n",
    "lm = train_language_model(corpus)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#bow_res=load(\"results/bags/brown_glove300_res.jld\", \"res\")\n",
    "#@time best_order(bow_res[8][2], lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using JuMP\n",
    "using CoinOptServices\n",
    "using AmplNLWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Any[\"it\",\"is\",\"so\",\"very\",\"good\",\".\"],6.803934689506605e-11)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.113396 seconds (22.27 k allocations: 594.922 KB)\n"
     ]
    }
   ],
   "source": [
    "#test_bag =  shuffle([\"this\",\"is\",\"the\" ,\"basis\",\"of\",\"a\" ,\"comedy\" ,\"of\",\"manners\",\"first\",\"performed\",\"in\",\"1892\", \".\"])\n",
    "#test_bag =  shuffle([\"this\",\"is\",\"the\" ,\"basis\",\"of\",\"a\" ,\"comedy\", \".\"])\n",
    "test_bag =  shuffle([\"it\", \"is\", \"so\", \"very\", \"good\", \".\"])\n",
    "#test_bag =  shuffle([\"it\", \"is\", \"very\", \"good\", \".\"])\n",
    "#test_bag =  shuffle([\"it\", \"is\", \"good\", \".\"])\n",
    "#test_bag =  shuffle([\"no\", \"way\", \".\"])\n",
    "#test_bag =  shuffle([\"no\", \".\"])\n",
    "@time best_order(test_bag, lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 0."
     ]
    },
    {
     "data": {
      "text/plain": [
       "44x44 sparse matrix with 93 Float64 entries:\n",
       "\t[1 ,  3]  =  0.000928671\n",
       "\t[1 ,  4]  =  0.0355816\n",
       "\t[1 ,  5]  =  0.000353157\n",
       "\t[1 ,  6]  =  0.00382368\n",
       "\t[1 ,  7]  =  0.000335717\n",
       "\t[1 ,  8]  =  0.00110307\n",
       "\t[3 ,  9]  =  0.986111\n",
       "\t[16,  9]  =  0.998689\n",
       "\t[28,  9]  =  0.984694\n",
       "\t[34,  9]  =  0.984694\n",
       "\t⋮\n",
       "\t[20, 42]  =  0.00493197\n",
       "\t[32, 42]  =  0.00257591\n",
       "\t[38, 42]  =  0.00180212\n",
       "\t[8 , 43]  =  0.00126222\n",
       "\t[20, 43]  =  0.0042517\n",
       "\t[32, 43]  =  0.00287896\n",
       "\t[38, 43]  =  0.00201413\n",
       "\t[8 , 44]  =  0.00046503\n",
       "\t[20, 44]  =  0.00221088\n",
       "\t[32, 44]  =  0.00106067\n",
       "\t[38, 44]  =  0.000742049"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272657926 seconds\n",
      "length(unordered_markers) = 9\n",
      "length(m.linconstr) = 1858\n"
     ]
    }
   ],
   "source": [
    "tic()\n",
    "m=Model(solver=BonminNLSolver())\n",
    "number_of_constraints=0\n",
    "_lm = Dict{Tuple{S,S,S},Float64}()\n",
    "function cached_lm(w1,w2,w3)\n",
    "    get!(_lm, (w1,w2,w3)) do\n",
    "       lm(w1,w2,w3)\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "unordered_words  = test_bag\n",
    "unordered_markers = [START_MARKER1; START_MARKER2; END_MARKER1; unordered_words...]\n",
    "#Note that this lacks END_MARKER2\n",
    "\n",
    "nodes = State{Int}[] #Named by word index\n",
    "\n",
    "node_indexes_for_1st = Dict{Int, Vector{Int}}()\n",
    "node_indexes_for_2nd = Dict{Int, Vector{Int}}()\n",
    "\n",
    "function add_node!(ii,jj)\n",
    "    push!(nodes, (ii,jj))\n",
    "\n",
    "    node_indexes_for_i_1st = get!(()->Int[], node_indexes_for_1st, ii)\n",
    "    push!(node_indexes_for_i_1st, length(nodes))\n",
    "\n",
    "    node_indexes_for_j_2nd = get!(()->Int[], node_indexes_for_2nd, jj) \n",
    "    push!(node_indexes_for_j_2nd, length(nodes))\n",
    "    #println(\"node:$(length(nodes)) |  $(unordered_markers[ii])($ii), $(unordered_markers[jj])($jj)\")\n",
    "end\n",
    "\n",
    "add_node!(1, 2) #That is START_MARKER1-> STARTMARKER2\n",
    "\n",
    "for ii in 1:length(unordered_markers)\n",
    "    wi = unordered_markers[ii]\n",
    "    if wi==END_MARKER1 || wi==START_MARKER1 continue end \n",
    "        #No node for the transition from END_MARKER1 to anything (not even END_MARKER2 as we do not have to model that as it is a constant prob 1)\n",
    "        #No transition for START_MARKER1 to anyting but start maker 2\n",
    "    for jj in [1:length(unordered_markers)]\n",
    "        if ii==jj continue end\n",
    "        wj = unordered_markers[jj]\n",
    "        if wj==START_MARKER1 || wj==START_MARKER2 continue end\n",
    "        add_node!(ii,jj)\n",
    "    end\n",
    "end\n",
    "\n",
    "@defVar(m, x[1:length(nodes), 1:length(nodes)], Bin)\n",
    "\n",
    "for class_index in 1:length(unordered_markers)\n",
    "    w_class =  unordered_markers[class_index]\n",
    "    if !(w_class==START_MARKER1 || w_class==START_MARKER2)#Not rquired to have either START_MARKER ever occur in second position\n",
    "        @addConstraint(m, sum{x[ii,jj],ii=1:length(nodes), jj=node_indexes_for_2nd[class_index]}==1)\n",
    "    end\n",
    "    \n",
    "    if !(w_class==END_MARKER1)#Not rquired to have END_MARKER ever occur in fist position\n",
    "        @addConstraint(m, sum{x[ii,jj], ii=node_indexes_for_1st[class_index],jj=1:length(nodes)}==1)\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "trans_prob = spzeros(length(nodes), length(nodes))\n",
    "for (from_node_index, from_node) in enumerate(nodes)\n",
    "    w1 = unordered_markers[from_node[1]]\n",
    "    w2 = unordered_markers[from_node[2]]\n",
    "    #If what was in the second state element does not end up in the first state element then it is not allowed.\n",
    "    can_transition_to = Set(get(node_indexes_for_1st, from_node[2], Int[]))\n",
    "        #You can transition to any node which has your second element as its first element\n",
    "    for (to_node_index, to_node) in enumerate(nodes)\n",
    "        if to_node_index in can_transition_to\n",
    "            @assert(from_node[2]==to_node[1])\n",
    "            w3= unordered_markers[to_node[2]]\n",
    "            tp = cached_lm(w1,w2,w3)\n",
    "            if tp>0.0\n",
    "                trans_prob[from_node_index, to_node_index] = tp\n",
    "                continue\n",
    "            else\n",
    "                #Banned as prob zero transitions not allowed\n",
    "                @addConstraint(m, x[from_node_index,to_node_index]==0)\n",
    "            end\n",
    "            \n",
    "        else\n",
    "            #It is not a legal transition\n",
    "            @addConstraint(m, x[from_node_index,to_node_index]==0)\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "iis, jjs, tp_values = findnz(trans_prob)\n",
    "@setNLObjective(m, Max, prod{max((x[i,j]-1)^2, trans_prob[i,j]), i=iis, j=jjs})\n",
    "#Note: max((x[i,j]-1)^2, trans_prob[i,j]) is trick for: x[i,j] ? trans_prob[i,j] : 1\n",
    "toc()#34 seconds\n",
    "@printval length(unordered_markers)\n",
    "@printval length(m.linconstr)\n",
    "trans_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonmin 1.8.2 using Cbc 2.9.1 and Ipopt 3.12.1\n",
      "bonmin: \n",
      "\n",
      "******************************************************************************\n",
      "This program contains Ipopt, a library for large-scale nonlinear optimization.\n",
      " Ipopt is released as open source code under the Eclipse Public License (EPL).\n",
      "         For more information visit http://projects.coin-or.org/Ipopt\n",
      "******************************************************************************\n",
      "\n",
      "NLP0012I \n",
      "              Num      Status      Obj             It       time                 Location\n",
      "NLP0014I             1      INFEAS 0.24447294       17 7.277\n",
      "NLP0014I             2      INFEAS 0.24447294       17 7.191517\n",
      "Cbc0006I The LP relaxation is infeasible or too expensive\n",
      "\b\b\b\b\b\b\b\b\n",
      " \t\"Finished\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Not solved to optimality, status: Infeasible\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective value: 0\n",
      "x = [NaN"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Variable value not defined for component of x. Check that the model was properly solved.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1936-element Array{Tuple{Int64,Int64},1}:\n",
       " (1,1)  \n",
       " (2,1)  \n",
       " (3,1)  \n",
       " (4,1)  \n",
       " (5,1)  \n",
       " (6,1)  \n",
       " (7,1)  \n",
       " (8,1)  \n",
       " (9,1)  \n",
       " (10,1) \n",
       " (11,1) \n",
       " (12,1) \n",
       " (13,1) \n",
       " ⋮      \n",
       " (33,44)\n",
       " (34,44)\n",
       " (35,44)\n",
       " (36,44)\n",
       " (37,44)\n",
       " (38,44)\n",
       " (39,44)\n",
       " (40,44)\n",
       " (41,44)\n",
       " (42,44)\n",
       " (43,44)\n",
       " (44,44)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
      " NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
      " NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
      " NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
      " NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
      " NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
      " NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
      " NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
      " NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
      " NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
      " NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
      " NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
      " NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
      " NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
      " NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
      " NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
      " NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
      " NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
      " NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
      " NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
      " NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
      " NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
      " NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
      " NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
      " NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
      " NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
      " NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
      " NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
      " NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
      " NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
      " NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
      " NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
      " NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
      " NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
      " NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
      " NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
      " NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
      " NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
      " NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
      " NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
      " NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
      " NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
      " NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN\n",
      " NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN]\n"
     ]
    }
   ],
   "source": [
    "solve(m)\n",
    "println(\"Objective value: \", getObjectiveValue(m))\n",
    "x_val = getValue(x)\n",
    "println(\"x = \", x_val)\n",
    "x_iis,x_jjs, _  = findnz(x_val)\n",
    "zip(x_iis,x_jjs) |> collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function get_prod(x, iis, jjs)\n",
    "    net = 1.0\n",
    "    for i in 1:size(x,1) \n",
    "        for j in 1:size(x,2)\n",
    "            println(i,\",\", j, \" =\", x[i,j], \" \", trans_prob[i,j])\n",
    "            net*=max((x[i,j]-1)^2, trans_prob[i,j])\n",
    "        end\n",
    "    end\n",
    "    net\n",
    "end\n",
    "values = falses(size(x))\n",
    "values[1,3] = 1\n",
    "values[3,6] = 1\n",
    "values[6,7] = 1\n",
    "println(\"----------\\n\")\n",
    "get_prod(values, iis,jjs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "node_indexes_for_1st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "node_indexes_for_2nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function get_transition_probs(unordered_words::Vector{S}, languauge_model::Function; beam_width=Inf)\n",
    "    \n",
    "    trans_prob = Dict(Tuple{Int,Int},Vector{Float64})\n",
    "    unordered_tokens = S[unordered_words...; END_MARKER1]\n",
    "    i_start1 = -1\n",
    "    i_start2 = 0\n",
    "    \n",
    "    trans_prob[(i_start1,i_start2)] = Float64[languauge_model(START_MARKER1,START_MARKER2, wi) for wi inunordered_tokens]\n",
    "    \n",
    "    for i1,i2,i3 in permutations(1:length(unordered_words),3)\n",
    "        w1 = unordered_words[i1]\n",
    "        w2 = unordered_words[i2]\n",
    "        w3 = unordered_words[i3]\n",
    "        \n",
    "        tps = get!(trans_prob, (i1,i2)) do\n",
    "            tps=zeros(length(unordered_tokens))\n",
    "            tps[end] = languauge_model(w1,w2, END_MARKER1)\n",
    "        end\n",
    "        tps[i3] = languauge_model(w1,w2, w3)\n",
    "    end\n",
    "    trans_prob\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for ii in [1:3;5:6]\n",
    "    println(ii)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[1,1,1,2,3,4,5],3) |> collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Prepare Oracle Results -- no regen\n",
    "test_set = load(\"results/data/brown_glove300.jld\")[\"corpus\"]\n",
    "oracle_res = pmap(test_set, err_stop=true) do target_sent\n",
    "    score=0.0\n",
    "    sol = shuffle(target_sent)\n",
    "    (target_sent, sol, score)\n",
    "end\n",
    "@save \"results/bags/oracle_res.jld\" oracle_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@everywhere const len_cap = 18\n",
    "@everywhere raw_bow_res = load(\"results/bags/oracle_res.jld\", \"oracle_res\")\n",
    "\n",
    "function process_fold(fold_ii)\n",
    "    test_bows, test_ground_order, train = fold_split(fold_ii,raw_bow_res)\n",
    "    \n",
    "    #Avoid \"serialising a pointer\" by getting each process to create their own copy of Language model\n",
    "    #This also means that the language models are independent (as under the hood they are not readonly, readomg them changes them as they have cache)\n",
    "    r_language_models =Dict([pid=>remotecall(pid, train_language_model, train) for pid in workers()])\n",
    "    pmap(test_ground_order, test_bows, err_stop=true) do ground_order, bow\n",
    "        lm = fetch(r_language_models[myid()])\n",
    "        generated_order, prob = if length(ground_order)<=len_cap\n",
    "            best_order(bow, lm; beam_width=5)\n",
    "        else\n",
    "            (bow, NaN)\n",
    "        end\n",
    "        (ground_order, generated_order, prob)\n",
    "    end\n",
    "end\n",
    "\n",
    "jldopen(\"results/ordered/oracle_orderedv2.jld\", \"w\") do file\n",
    "    for fold_ii in 1:length(fold_indexes)\n",
    "        res = process_fold(fold_ii)\n",
    "        write(file, \"fold_$(fold_ii)\", res)\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ordered_res = map(bow_res) do rt\n",
    "    ground_order, bow, score = rt\n",
    "    generated_order, prob = best_order(bow, lm; beam_width=5)\n",
    "    println(generated_order)\n",
    "    (ground_order, generated_order, prob)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_bows, test_ground_order, train = fold_split(2,raw_bow_res)\n",
    "language_model = train_language_model(train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@time ord, prob = best_order(test_bows[4110], language_model; beam_width=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = pmap(test_bow, err_stop=true) do bow\n",
    "    order, prob = best_order(bow, language_model; beam_width=5)\n",
    "    (target_sent, sol, score)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "5^20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@pipe test |> map(x->length(x)==50, _) |> find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@time best_order(test[60], language_model, beam_width=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ground_sents[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_trigrams = [nltk.trigrams(sent)|>collect for sent in train]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "map(examples) do unordered_words\n",
    "    order(unordered_words, ASCIIString[])\n",
    "    end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "short_cases = Bool[length(ws) <=20 for ws in unordered_output]\n",
    "\n",
    "true_ordered_sents = test_set[short_cases]\n",
    "ordered_sents_and_probs = pmap(unordered_output[short_cases]) do unordered_words\n",
    "    order(unordered_words, zeroed_words)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ordered_sents = map(op->op[1], ordered_sents_and_probs, be)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "perfect_matches = Bool[]  \n",
    "for ii in 1:length(ordered_sents)\n",
    "    ordered_words = ordered_sents[ii]\n",
    "    actual_words = true_ordered_sents[ii]\n",
    "    \n",
    "    match = ordered_words == actual_words\n",
    "    push!(perfect_matches, match)\n",
    "    #println(\"$ii - $match\")\n",
    "end\n",
    "mean(perfect_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@pyimport nltk\n",
    "@pyimport nltk.translate.bleu_score as nltk_bleu\n",
    "\n",
    "function bleu_score(candidate, reference)\n",
    "    reference = reference |> collect\n",
    "    candidate = candidate |> collect\n",
    "    \n",
    "    if reference==candidate #Perfect Match\n",
    "        1.0\n",
    "    else\n",
    "        weights = [1,1,1,1]/4\n",
    "        nltk_bleu.bleu(Any[reference],candidate, weights)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "map(bleu_score, ordered_sents,true_ordered_sents) |> mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bleu_score(true_ordered_sents[3], true_ordered_sents[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "true_ordered_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ordered_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ordered_sents[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unordered_output[short_cases][eval_cases][50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "true_ordered_sents[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#x= [\"A\", \"B\", \"C\", \"D\"]\n",
    "#y= UTF8String[\"A\", \"B\", \"C\", \"D\"]\n",
    "x = true_ordered_sents[10]\n",
    "y=ordered_sents[10] |> collect\n",
    "pycall(nltk_bleu.bleu, PyAny, Any[x], y, Any[0.25, 0.25, 0.25, 0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Any[true_ordered_sents[1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nltk_bleu._modified_precision(Any[reference1, reference2, reference3],candidate1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@pyimport pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pdb.runcall(nltk_bleu._modified_precision, [reference1, reference2, reference3],candidate1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# I think I have to reimplement BLEU in julia as for some reason it does not play nice with PyCall\n",
    "# Can basically port http://www.nltk.org/_modules/nltk/align/bleu_score.html#bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pycall(nltk_bleu.bleu, Int, candidate1, [reference1], weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@pyimport nltk.util as nltk_util\n",
    "nltk_util.ngrams(candidate1,2) |> py_collections.Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@pyimport collections as py_collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@pyimport nltk.util as nltk_util\n",
    "ngs = nltk_util.ngrams(candidate1,2)\n",
    "pycall(py_collections.Counter, PyObject, ngs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.0-dev",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
