{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: module DataStructuresExtended should explicitly import == from Base\n"
     ]
    }
   ],
   "source": [
    "# import FunctionalCollections\n",
    "push!(LOAD_PATH, \".\")\n",
    "push!(LOAD_PATH, \"../util/\")\n",
    "import Iterators\n",
    "import Pipe\n",
    "import Compat\n",
    "import JLD\n",
    "import DataStructures\n",
    "import DataStructuresExtended\n",
    "@everywhere using FunctionalCollections\n",
    "@everywhere using Iterators\n",
    "@everywhere using Pipe\n",
    "@everywhere using Compat\n",
    "@everywhere using JLD\n",
    "@everywhere using DataStructures\n",
    "@everywhere using DataStructuresExtended\n",
    "\n",
    "macro printval(ee)\n",
    "    ee_expr = @sprintf \"%s\" string(ee)\n",
    "    esc(:(println($ee_expr,\" = \", $ee)))\n",
    "end\n",
    "\n",
    "macro pz(ee)\n",
    "    ee_expr = @sprintf \"%s\" string(ee)\n",
    "    esc(:(println($ee_expr,\"\\t\\t\",typeof($ee), \"\\t\", size($ee))))\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@everywhere const START_MARKER1 = Symbol(\"**START1**\")\n",
    "@everywhere const START_MARKER2 = Symbol(\"**START2**\")\n",
    "@everywhere const END_MARKER1 = Symbol(\"**END1**\")\n",
    "@everywhere const END_MARKER2 = Symbol(\"**END2**\")\n",
    "@everywhere typealias S Symbol\n",
    "@everywhere typealias State{T} Tuple{T,T}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_counts (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function load_counts(filename)\n",
    "    counts = Dict{Tuple{Symbol,Symbol,Symbol},Int}()\n",
    "    open(filename, \"r\") do fh\n",
    "        for line in eachline(fh)\n",
    "            word1,word2,word3,occurrences = split(line)\n",
    "            trigram = (Symbol(word1),Symbol(word2),Symbol(word3))\n",
    "            counts[trigram] = parse(Int,occurrences)\n",
    "        end\n",
    "    end\n",
    "    counts\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Kneser-Ney estimate of a probability distribution. This is a version of\n",
    "    back-off that counts how likely an n-gram is provided the n-1-gram had\n",
    "    been seen in training. Extends the ProbDistI interface, requires a trigram\n",
    "    FreqDist instance to train on. Optionally, a different from default discount\n",
    "    value can be specified. The default discount is set to 0.75.\n",
    "    #Adapted from: http://www.nltk.org/_modules/nltk/probability.html\n",
    "\"\"\"\n",
    "type KneserNeyProbDist{T}\n",
    "    \n",
    "    trigrams :: Accumulator{Tuple{T,T,T},Int}\n",
    "    bigrams  :: Accumulator{Tuple{T,T},Int}\n",
    "    trigrams_contain :: Accumulator{T,Int}\n",
    "    discount :: Float64\n",
    "    wordtypes_after :: Accumulator{Tuple{T,T},Int}\n",
    "    wordtypes_before :: Accumulator{Tuple{T,T},Int}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prob (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    ":param trigrams: The trigram frequency distribution upon which to base\n",
    "    the estimation\n",
    ":param discount: The discount applied when retrieving counts of\n",
    "    trigrams\n",
    "\"\"\"\n",
    "function KneserNeyProbDist{T}(trigrams :: Dict{Tuple{T,T,T},Int}, discount=0.75)\n",
    "\n",
    "    # helper dictionaries used to calculate probabilities\n",
    "    trigrams_contain = counter(T)\n",
    "    bigrams  = counter(Tuple{T,T})\n",
    "    wordtypes_after = counter(Tuple{T,T})\n",
    "    wordtypes_before = counter(Tuple{T,T})\n",
    "\n",
    "    for ((w0, w1, w2),n) in trigrams\n",
    "        push!(trigrams_contain, w1)\n",
    "        push!(bigrams, (w0,w1), n)\n",
    "        push!(wordtypes_after,(w0,w1))  \n",
    "        push!(wordtypes_before,(w1,w2))\n",
    "    end\n",
    "    KneserNeyProbDist{T}(counter(trigrams), bigrams, trigrams_contain, discount, wordtypes_after, wordtypes_before)\n",
    "end\n",
    "    \n",
    "\n",
    "function prob{T}(self::KneserNeyProbDist{T}, w0::T,w1::T, w2::T)\n",
    "    # if the sample trigram was seen during training\n",
    "    if (w0, w1,w2) in keys(self.trigrams)\n",
    "        @assert self.trigrams[(w0,w1,w2)]>self.discount\n",
    "        (self.trigrams[(w0,w1,w2)] - self.discount)/self.bigrams[(w0, w1)]\n",
    "    # else if the 'rougher' environment was seen during training\n",
    "    elseif (w0,w1) in keys(self.bigrams) && (w1,w2) in keys(self.wordtypes_before)\n",
    "        aftr = self.wordtypes_after[(w0, w1)]\n",
    "        bfr = self.wordtypes_before[(w1, w2)]\n",
    "\n",
    "        # the probability left over from alphas\n",
    "        leftover_prob = aftr * self.discount  / self.bigrams[(w0, w1)]\n",
    "        @assert leftover_prob>0\n",
    "        # the beta (including normalization)\n",
    "        beta = bfr / (self.trigrams_contain[w1] - aftr)\n",
    "        @assert beta>0\n",
    "        leftover_prob * beta\n",
    "    # else the sample was completely unseen during training\n",
    "    else\n",
    "        0.0\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccs = load_counts(\"results/data/books/train_books_corpus.3gram\")\n",
    "kn_lm = KneserNeyProbDist(ccs)\n",
    "ccs=0\n",
    "kn_lm.trigrams |> length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.129023866814073e-6"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000044 seconds (10 allocations: 320 bytes)\n"
     ]
    }
   ],
   "source": [
    "@time prob(kn_lm, symbol(\"'m\"), :so, :fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.129023866814073e-6"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000022 seconds (10 allocations: 320 bytes)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Base.SparseMatrix is deprecated.\n",
      "  likely near /home/ubuntu/.julia/v0.5/GLPK/src/GLPK.jl:812\n"
     ]
    }
   ],
   "source": [
    "using JuMP\n",
    "using MathProgBase\n",
    "using GLPKMathProgInterface\n",
    "using Gurobi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_hyperclass (generic function with 1 method)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "returns the a vector of sets of node indexes, each set is a subtour\n",
    "The First subtour returned is the nonconnected one -- the path\n",
    "\"\"\"\n",
    "function get_subtours(x::Matrix{JuMP.Variable})\n",
    "    x_val = getValue(x)\n",
    "    x_iis,x_jjs, _  = findnz(x_val .>= 1 - 1e-6) #It just has to be close to 1 to be true\n",
    "    nodes_chain = Dict([ii=>jj for (ii,jj) in zip(x_iis,x_jjs)])\n",
    "\n",
    "    subtours = IntSet[]\n",
    "    ii = START_NODE_INDEX\n",
    "    push!(subtours, IntSet(END_NODE_INDEX)) #The END Node is always in the same subtour as the start node\n",
    "    while(true)\n",
    "        while(true) #Cycle through current subtour\n",
    "            \n",
    "            push!(subtours[end],ii) \n",
    "            \n",
    "            jj = nodes_chain[ii]\n",
    "            println(ii,\" \", jj)\n",
    "            delete!(nodes_chain,ii)\n",
    "            if jj∈subtours[end] \n",
    "                break \n",
    "            end\n",
    "            ii=jj\n",
    "        end   \n",
    "\n",
    "        if length(nodes_chain)>0\n",
    "            ii = first(keys(nodes_chain)) #start new subtour\n",
    "            push!(subtours,IntSet())\n",
    "        else\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    subtours\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Core tour goes from start to end,\n",
    "Does not include the end node in the tour\n",
    "\"\"\"\n",
    "function get_coretours(x_links)\n",
    "    nodes_chain = Dict([ii=>jj for (ii,jj) in x_links])\n",
    "\n",
    "    coretour = IntSet()\n",
    "    ii = START_NODE_INDEX\n",
    "    while(ii!=END_NODE_INDEX)            \n",
    "        push!(coretour,ii) \n",
    "        jj = nodes_chain[ii]\n",
    "    end   \n",
    "    coretour\n",
    "end\n",
    "\n",
    "function get_hyperclass(subtour)\n",
    "    tour_hyper_class_nodes=IntSet()\n",
    "    for ii in subtour\n",
    "        w1,w2 = nodes[ii]\n",
    "        #println(unordered_markers[w1])\n",
    "        class_nodes = node_indexes_for_1st[w1]\n",
    "        union!(tour_hyper_class_nodes,class_nodes) \n",
    "    end\n",
    "    tour_hyper_class_nodes\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9-element Array{Symbol,1}:\n",
       " :this  \n",
       " :a     \n",
       " :fine  \n",
       " :basis \n",
       " :comedy\n",
       " :.     \n",
       " :the   \n",
       " :of    \n",
       " :is    "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_bag = shuffle(corpus[1022]) #length 28\n",
    "#test_bag = shuffle(corpus[1028]) #length 20  (Gurodi 4.2, GLTK : 2064.6 seconds)\n",
    "#test_bag = shuffle(corpus[1122]) #length 19 \n",
    "#est_bag = shuffle(corpus[1000]) #length 17 (Gurbodi: 5.8 sconds. GLTK:  569.9seconds)\n",
    "#test_bag =  shuffle([\"this\",\"is\",\"the\" ,\"basis\",\"of\",\"a\" ,\"comedy\" ,\"of\",\"manners\",\"first\",\"performed\",\"in\",\"1892\", \".\"])\n",
    "#test_bag =  shuffle([\"this\",\"is\",\"the\" ,\"basis\",\"of\",\"a\" ,\"comedy\" ,\"of\",\"manners\",\".\"])\n",
    "test_bag =  shuffle([\"this\",\"is\",\"the\" ,\"basis\",\"of\",\"a\",\"fine\",\"comedy\", \".\"])\n",
    "#^length 9, Gurodi 1.0, GLTK 5.3\n",
    "#test_bag =  shuffle([\"this\",\"is\",\"the\" ,\"basis\",\"of\",\"a\" ,\"comedy\", \".\"])\n",
    "#test_bag =  shuffle([\"it\", \"is\", \"so\", \"very\", \"good\", \".\"])\n",
    "#test_bag =  shuffle([\"it\", \"is\", \"very\", \"good\", \".\"])\n",
    "#test_bag =  shuffle([\"it\", \"is\", \"good\", \".\"])\n",
    "#test_bag =  [\"no\", \"way\", \".\"]\n",
    "#test_bag =  shuffle([\"no\", \".\"])\n",
    "#@time best_order(test_bag, lm, mem_limit=1000)\n",
    "test_bag = map(symbol, test_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 0."
     ]
    },
    {
     "data": {
      "text/plain": [
       "103x103 sparse matrix with 516 Float64 entries:\n",
       "\t[68 ,   2]  =  -1.63369e-8\n",
       "\t[1  ,   4]  =  -5.10737\n",
       "\t[1  ,   5]  =  -4.51714\n",
       "\t[1  ,   6]  =  -8.55479\n",
       "\t[1  ,   7]  =  -16.2465\n",
       "\t[1  ,   8]  =  -14.5636\n",
       "\t[1  ,   9]  =  -6.82135\n",
       "\t[1  ,  10]  =  -3.11045\n",
       "\t[1  ,  11]  =  -6.56127\n",
       "\t[1  ,  12]  =  -6.46561\n",
       "\t⋮\n",
       "\t[85 , 102]  =  -2.48491\n",
       "\t[94 , 102]  =  -2.45292\n",
       "\t[12 , 103]  =  -10.6282\n",
       "\t[31 , 103]  =  -8.12024\n",
       "\t[40 , 103]  =  -7.75982\n",
       "\t[49 , 103]  =  -7.14859\n",
       "\t[58 , 103]  =  -7.10347\n",
       "\t[67 , 103]  =  -7.31459\n",
       "\t[76 , 103]  =  -7.63411\n",
       "\t[85 , 103]  =  -7.50893\n",
       "\t[94 , 103]  =  -8.47637"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469729891 seconds\n",
      "length(unordered_markers) = 13\n",
      "length(m.linconstr) = 10205\n"
     ]
    }
   ],
   "source": [
    "function lm(w0,w1,w2)\n",
    "    prob(kn_lm,w0,w1,w2)\n",
    "end\n",
    "\n",
    "\n",
    "tic()\n",
    "m=Model(solver=GurobiSolver())\n",
    "#m=Model(solver=GLPKSolverMIP())\n",
    "\n",
    "\n",
    "\n",
    "unordered_words  = test_bag\n",
    "unordered_markers = [START_MARKER1; START_MARKER2; END_MARKER1; END_MARKER2; unordered_words...]\n",
    "#Note that this lacks END_MARKER2\n",
    "const START_NODE_INDEX = 1\n",
    "const END_NODE_INDEX = 2\n",
    "\n",
    "nodes = State{Int}[] #Named by word index\n",
    "\n",
    "node_indexes_for_1st = Dict{Int, Vector{Int}}()\n",
    "node_indexes_for_2nd = Dict{Int, Vector{Int}}()\n",
    "\n",
    "function add_node!(ii,jj)\n",
    "    push!(nodes, (ii,jj))\n",
    "\n",
    "    node_indexes_for_i_1st = get!(()->Int[], node_indexes_for_1st, ii)\n",
    "    push!(node_indexes_for_i_1st, length(nodes))\n",
    "\n",
    "    node_indexes_for_j_2nd = get!(()->Int[], node_indexes_for_2nd, jj) \n",
    "    push!(node_indexes_for_j_2nd, length(nodes))\n",
    "    #println(\"node:$(length(nodes)) |  $(unordered_markers[ii])($ii), $(unordered_markers[jj])($jj)\")\n",
    "end\n",
    "\n",
    "add_node!(1, 2) #That is START_MARKER1-> START_MARKER2\n",
    "add_node!(3, 4) #That is END_MARKER1-> END_MARKER2\n",
    "\n",
    "for ii in 1:length(unordered_markers)\n",
    "    wi = unordered_markers[ii]\n",
    "    if wi∈(END_MARKER1,START_MARKER1) continue end  #Covered these\n",
    "        \n",
    "    for jj in [1:length(unordered_markers)]\n",
    "        if ii==jj continue end\n",
    "        wj = unordered_markers[jj]\n",
    "        if wj∉(START_MARKER1,START_MARKER2,END_MARKER2)\n",
    "            #but wj can be  END_MARKER1\n",
    "            add_node!(ii,jj)\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "@defVar(m, x[1:length(nodes), 1:length(nodes)], Bin)\n",
    "\n",
    "#If you enter a node you must also leave it\n",
    "for (cc, center_node) in enumerate(nodes)\n",
    "    if cc ∉ (START_NODE_INDEX, END_NODE_INDEX) #the beginning and end done have this requiement\n",
    "        #Everything that enters this node, must leave this node\n",
    "        @addConstraint(m, sum{x[ii,cc], ii=1:length(nodes)} == sum{x[cc,jj], jj=1:length(nodes)})\n",
    "    end\n",
    "end\n",
    "\n",
    "for class_index in 1:length(unordered_markers)\n",
    "    w_class =  unordered_markers[class_index]\n",
    "    if w_class∉(START_MARKER1,START_MARKER2)\n",
    "        #Not rquired to make a transition so that START_MARKER1 or 2 ever occur in second position\n",
    "        jjs = node_indexes_for_2nd[class_index]\n",
    "        @addConstraint(m, sum{x[ii,jj],ii=1:length(nodes), jj=jjs}==1)\n",
    "    end\n",
    "    \n",
    "    #The following constraint is not required, as if it shows uo in the second position other rules make it certain to show up in the first\n",
    "    #if w_class∉(END_MARKER1,END_MARKER2)\n",
    "    #    #Not rquired to make a transition so that END_MARKER1 or 2 ever occur in second position\n",
    "    #    iis=node_indexes_for_1st[class_index]\n",
    "    #    @addConstraint(m, sum{x[ii,jj], ii=iis,jj=1:length(nodes)}==1)\n",
    "    #    rules[w_class*\"*\"]=Set(product(iis,1:length(nodes)))\n",
    "    #end\n",
    "end\n",
    "\n",
    "banned_trans_prob = Set{State{Int}}()\n",
    "banned_trans_state = Set{State{Int}}()\n",
    "log_trans_prob = spzeros(length(nodes), length(nodes))\n",
    "for (from_node_index, from_node) in enumerate(nodes)\n",
    "    w1 = unordered_markers[from_node[1]]\n",
    "    w2 = unordered_markers[from_node[2]]\n",
    "    #If what was in the second state element does not end up in the first state element then it is not allowed.\n",
    "    can_transition_to = Set(get(node_indexes_for_1st, from_node[2], Int[]))\n",
    "        #You can transition to any node which has your second element as its first element\n",
    "    for (to_node_index, to_node) in enumerate(nodes)\n",
    "        if to_node_index in can_transition_to\n",
    "            @assert(from_node[2]==to_node[1])\n",
    "            w3= unordered_markers[to_node[2]]\n",
    "            log_tp = log(lm(w1,w2,w3))\n",
    "            if log_tp>-Inf\n",
    "                log_trans_prob[from_node_index, to_node_index] = log_tp\n",
    "                continue\n",
    "            else\n",
    "                #Banned as prob zero transitions not allowed\n",
    "                @addConstraint(m, x[from_node_index,to_node_index]==0)\n",
    "                push!(banned_trans_prob, (from_node_index,to_node_index))\n",
    "            end\n",
    "            \n",
    "        else\n",
    "            #It is not a legal transition\n",
    "            @addConstraint(m, x[from_node_index,to_node_index]==0)\n",
    "            push!(banned_trans_state, (from_node_index,to_node_index))\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "function eleminate_subtours(cb)\n",
    "    x_val = getValue(x)\n",
    "    x_iis,x_jjs, _  = findnz(x_val .>= 1 - 1e-6) #It just has to be close to 1 to be true\n",
    "    x_links=zip(x_iis,x_jjs)\n",
    "    coretour = get_coretours(x_links)\n",
    "    if length(coretour)==length(x_links)\n",
    "        #no subtour to eleminate\n",
    "        return\n",
    "    end\n",
    "    core_hyperclass = get_hyperclass(coretour)\n",
    "    \n",
    "    #Also the First subtour must go to one of the other subtours \n",
    "    arcs_outof_coretour = AffExpr()\n",
    "    for ii in core_hyperclass\n",
    "        for jj in 1:length(nodes)\n",
    "            if jj∉core_hyperclass\n",
    "                arcs_outof_coretour += x[ii,jj]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    @addLazyConstraint(cb, arcs_outof_coretour >=1)\n",
    "end\n",
    "\n",
    "addLazyCallback(m, eleminate_subtours,fractional=false)\n",
    "\n",
    "#new Linear way using logprobs\n",
    "@setObjective(m, Max, sum{log_trans_prob[i,j]*x[i,j], i=1:length(nodes), j=1:length(nodes)})\n",
    "\n",
    "toc()\n",
    "@printval length(unordered_markers)\n",
    "@printval length(m.linconstr)\n",
    "log_trans_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tic()\n",
    "solve(m)\n",
    "time_to_solve = toc()\n",
    "println(\"Objective value: \", getObjectiveValue(m))\n",
    "println(\"Prob: \", e^getObjectiveValue(m))\n",
    "x_val = getValue(x)\n",
    "#println(\"x = \", x_val)\n",
    "x_iis,x_jjs, _  = findnz(x_val.>1-1e-6)\n",
    "zip(x_iis,x_jjs) |> collect |> println"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_to_solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nodes_chain = Dict([ii=>jj for (ii,jj) in zip(x_iis,x_jjs)])\n",
    "node_index=1\n",
    "visitted = Set{Int}()\n",
    "while(node_index!=END_NODE_INDEX)\n",
    "    push!(visitted, node_index)\n",
    "    println(unordered_markers[nodes[node_index][1]])\n",
    "    #println(node_index, \" \", unordered_markers[nodes[node_index][1]],\" \", unordered_markers[nodes[node_index][2]])\n",
    "    node_index = nodes_chain[node_index]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_val = getValue(x)\n",
    "x_iis,x_jjs, _  = findnz(x_val)\n",
    "nodes_chain = Dict([ii=>jj for (ii,jj) in zip(x_iis,x_jjs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "collect(1:100)[[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sts = get_subtours(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for tran in union(banned_trans_prob, banned_trans_state)\n",
    "    for rule in values(rules)\n",
    "        delete!(rule, tran)\n",
    "    end\n",
    "end\n",
    "rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rules[\"fine*\"] ∩ keys(nodes_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function get_prod(x, iis, jjs)\n",
    "    net = 1.0\n",
    "    for i in 1:size(x,1) \n",
    "        for j in 1:size(x,2)\n",
    "            println(i,\",\", j, \" =\", x[i,j], \" \", trans_prob[i,j])\n",
    "            net*=max((x[i,j]-1)^2, trans_prob[i,j])\n",
    "        end\n",
    "    end\n",
    "    net\n",
    "end\n",
    "values = falses(size(x))\n",
    "values[1,3] = 1\n",
    "values[3,6] = 1\n",
    "values[6,7] = 1\n",
    "println(\"----------\\n\")\n",
    "get_prod(values, iis,jjs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@pyimport nltk.corpus as nltk_corpus\n",
    "corpus_reader=nltk_corpus.brown\n",
    "corpus = Vector{ASCIIString}[[lowercase(word) for word in sent] for sent in (corpus_reader[:sents]()|> collect)]\n",
    "const log_lm = train_language_model(corpus, loglikelyhood=true)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.0-dev",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
