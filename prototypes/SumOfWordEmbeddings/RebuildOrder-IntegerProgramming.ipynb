{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11-element Array{Int64,1}:\n",
       "  2\n",
       "  3\n",
       "  4\n",
       "  5\n",
       "  6\n",
       "  7\n",
       "  8\n",
       "  9\n",
       " 10\n",
       " 11\n",
       " 12"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addprocs(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: module DataStructuresExtended should explicitly import == from Base\n",
      "WARNING: module DataStructuresExtended should explicitly import == from Base\n",
      "WARNING: module DataStructuresExtended should explicitly import == from Base\n",
      "WARNING: module DataStructuresExtended should explicitly import == from Base\n",
      "WARNING: module DataStructuresExtended should explicitly import == from Base\n",
      "WARNING: module DataStructuresExtended should explicitly import == from Base\n",
      "WARNING: module DataStructuresExtended should explicitly import == from Base\n",
      "WARNING: module DataStructuresExtended should explicitly import == from Base\n",
      "WARNING: module DataStructuresExtended should explicitly import == from Base\n",
      "WARNING: module DataStructuresExtended should explicitly import == from Base\n",
      "WARNING: module DataStructuresExtended should explicitly import == from Base\n",
      "WARNING: module DataStructuresExtended should explicitly import == from Base\n",
      "WARNING: replacing module FunctionalCollections\n",
      "WARNING: replacing module FunctionalCollections\n",
      "WARNING: replacing module FunctionalCollections\n",
      "WARNING: replacing module FunctionalCollections\n",
      "WARNING: replacing module FunctionalCollections\n",
      "WARNING: replacing module FunctionalCollections\n",
      "WARNING: replacing module FunctionalCollections\n",
      "WARNING: replacing module FunctionalCollections\n",
      "WARNING: replacing module FunctionalCollections\n",
      "WARNING: replacing module FunctionalCollections\n",
      "WARNING: replacing module FunctionalCollections\n"
     ]
    }
   ],
   "source": [
    "# import FunctionalCollections\n",
    "push!(LOAD_PATH, \".\")\n",
    "push!(LOAD_PATH, \"../util/\")\n",
    "import Iterators\n",
    "import Pipe\n",
    "import Compat\n",
    "import JLD\n",
    "import DataStructures\n",
    "import DataStructuresExtended\n",
    "@everywhere using FunctionalCollections\n",
    "@everywhere using Iterators\n",
    "@everywhere using Pipe\n",
    "@everywhere using Compat\n",
    "@everywhere using JLD\n",
    "@everywhere using DataStructures\n",
    "@everywhere using DataStructuresExtended\n",
    "\n",
    "macro printval(ee)\n",
    "    ee_expr = @sprintf \"%s\" string(ee)\n",
    "    esc(:(println($ee_expr,\" = \", $ee)))\n",
    "end\n",
    "\n",
    "macro pz(ee)\n",
    "    ee_expr = @sprintf \"%s\" string(ee)\n",
    "    esc(:(println($ee_expr,\"\\t\\t\",typeof($ee), \"\\t\", size($ee))))\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@everywhere const START_MARKER1 = Symbol(\"**START1**\")\n",
    "@everywhere const START_MARKER2 = Symbol(\"**START2**\")\n",
    "@everywhere const END_MARKER1 = Symbol(\"**END1**\")\n",
    "@everywhere const END_MARKER2 = Symbol(\"**END2**\")\n",
    "@everywhere typealias S Symbol\n",
    "@everywhere typealias State{T} Tuple{T,T}\n",
    "@everywhere const START_NODE_INDEX = 1\n",
    "@everywhere const END_NODE_INDEX = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_counts (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function load_counts(filename)\n",
    "    counts = Dict{Tuple{Symbol,Symbol,Symbol},Int}()\n",
    "    open(filename, \"r\") do fh\n",
    "        for line in eachline(fh)\n",
    "            word1,word2,word3,occurrences = split(line)\n",
    "            trigram = (Symbol(word1),Symbol(word2),Symbol(word3))\n",
    "            counts[trigram] = parse(Int,occurrences)\n",
    "        end\n",
    "    end\n",
    "    counts\n",
    "end\n",
    "#kn_lm = KneserNeyProbDist(ccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@everywhere type KneserNeyProbDist{T}\n",
    "    \"\"\"\n",
    "    Kneser-Ney estimate of a probability distribution. This is a version of\n",
    "    back-off that counts how likely an n-gram is provided the n-1-gram had\n",
    "    been seen in training. Extends the ProbDistI interface, requires a trigram\n",
    "    FreqDist instance to train on. Optionally, a different from default discount\n",
    "    value can be specified. The default discount is set to 0.75.\n",
    "    #Adapted from: http://www.nltk.org/_modules/nltk/probability.html\n",
    "    \"\"\"\n",
    "    \n",
    "    trigrams :: Accumulator{Tuple{T,T,T},Int}\n",
    "    bigrams  :: Accumulator{Tuple{T,T},Int}\n",
    "    trigrams_contain :: Accumulator{T,Int}\n",
    "    discount :: Float64\n",
    "    wordtypes_after :: Accumulator{Tuple{T,T},Int}\n",
    "    wordtypes_before :: Accumulator{Tuple{T,T},Int}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@everywhere function KneserNeyProbDist{T}(trigrams :: Dict{Tuple{T,T,T},Int}, discount=0.75)\n",
    "    \"\"\"\n",
    "    :param trigrams: The trigram frequency distribution upon which to base\n",
    "        the estimation\n",
    "    :param discount: The discount applied when retrieving counts of\n",
    "        trigrams\n",
    "    \"\"\"\n",
    "    # helper dictionaries used to calculate probabilities\n",
    "    trigrams_contain = counter(T)\n",
    "    bigrams  = counter(Tuple{T,T})\n",
    "    wordtypes_after = counter(Tuple{T,T})\n",
    "    wordtypes_before = counter(Tuple{T,T})\n",
    "\n",
    "    for ((w0, w1, w2),n) in trigrams\n",
    "        push!(trigrams_contain, w1)\n",
    "        push!(bigrams, (w0,w1), n)\n",
    "        push!(wordtypes_after,(w0,w1))  \n",
    "        push!(wordtypes_before,(w1,w2))\n",
    "    end\n",
    "    KneserNeyProbDist{T}(counter(trigrams), bigrams, trigrams_contain, discount, wordtypes_after, wordtypes_before)\n",
    "end\n",
    "    \n",
    "\n",
    "@everywhere function prob{T}(self::KneserNeyProbDist{T}, w0::T,w1::T, w2::T)\n",
    "    # if the sample trigram was seen during training\n",
    "    if (w0, w1,w2) in keys(self.trigrams)\n",
    "        @assert self.trigrams[(w0,w1,w2)]>self.discount\n",
    "        (self.trigrams[(w0,w1,w2)] - self.discount)/self.bigrams[(w0, w1)]\n",
    "    # else if the 'rougher' environment was seen during training\n",
    "    elseif (w0,w1) in keys(self.bigrams) && (w1,w2) in keys(self.wordtypes_before)\n",
    "        aftr = self.wordtypes_after[(w0, w1)]\n",
    "        bfr = self.wordtypes_before[(w1, w2)]\n",
    "\n",
    "        # the probability left over from alphas\n",
    "        leftover_prob = aftr * self.discount  / self.bigrams[(w0, w1)]\n",
    "        @assert leftover_prob>0\n",
    "        # the beta (including normalization)\n",
    "        beta = bfr / (self.trigrams_contain[w1] - aftr)\n",
    "        @assert beta>0\n",
    "        leftover_prob * beta\n",
    "    # else the sample was completely unseen during training\n",
    "    else\n",
    "        0.0\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kn_lm = open(deserialize, \"results/data/books/train_books_corpus.kn3gram.jsz\", \"r\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@spawn prob(kn_lm, symbol(\"'m\"), :so, :fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import JuMP\n",
    "import MathProgBase\n",
    "#import GLPKMathProgInterface\n",
    "import Gurobi\n",
    "@everywhere using JuMP\n",
    "@everywhere using MathProgBase\n",
    "#@everywhere using GLPKMathProgInterface\n",
    "@everywhere using Gurobi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@everywhere function get_subtours(x::Matrix{JuMP.Variable})\n",
    "    \"\"\"\n",
    "    returns the a vector of sets of node indexes, each set is a subtour\n",
    "    The First subtour returned is the nonconnected one -- the path\n",
    "    \"\"\"\n",
    "    x_val = getValue(x)\n",
    "    x_iis,x_jjs, _  = findnz(x_val .>= 1 - 1e-6) #It just has to be close to 1 to be true\n",
    "    nodes_chain = Dict([ii=>jj for (ii,jj) in zip(x_iis,x_jjs)])\n",
    "\n",
    "    subtours = IntSet[]\n",
    "    ii = START_NODE_INDEX\n",
    "    push!(subtours, IntSet(END_NODE_INDEX)) #The END Node is always in the same subtour as the start node\n",
    "    while(true)\n",
    "        while(true) #Cycle through current subtour\n",
    "            \n",
    "            push!(subtours[end],ii) \n",
    "            \n",
    "            jj = nodes_chain[ii]\n",
    "            println(ii,\" \", jj)\n",
    "            delete!(nodes_chain,ii)\n",
    "            if jj∈subtours[end] \n",
    "                break \n",
    "            end\n",
    "            ii=jj\n",
    "        end   \n",
    "\n",
    "        if length(nodes_chain)>0\n",
    "            ii = first(keys(nodes_chain)) #start new subtour\n",
    "            push!(subtours,IntSet())\n",
    "        else\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    subtours\n",
    "end\n",
    "\n",
    "@everywhere function get_coretours(x_links)\n",
    "    \"\"\"\n",
    "    Core tour goes from start to end (inclusive)\n",
    "    \"\"\"\n",
    "    nodes_chain = Dict([ii=>jj for (ii,jj) in x_links])\n",
    "\n",
    "    coretour = IntSet()\n",
    "    ii = START_NODE_INDEX\n",
    "    while(ii!=END_NODE_INDEX)            \n",
    "        push!(coretour,ii) \n",
    "        ii = nodes_chain[ii]\n",
    "    end   \n",
    "    push!(coretour, END_NODE_INDEX)\n",
    "    coretour\n",
    "end\n",
    "\n",
    "@everywhere function get_hyperclass(subtour,nodes,node_indexes_for_1st)\n",
    "    tour_hyper_class_nodes=IntSet()\n",
    "    for ii in subtour\n",
    "        w1,w2 = nodes[ii]\n",
    "        #println(unordered_markers[w1])\n",
    "        class_nodes = node_indexes_for_1st[w1]\n",
    "        union!(tour_hyper_class_nodes,class_nodes) \n",
    "    end\n",
    "    tour_hyper_class_nodes\n",
    "end\n",
    "\n",
    "@everywhere function get_sentence{T}(x_val::Matrix,unordered_markers::T,nodes::Vector{State{Int}})\n",
    "    x_iis,x_jjs, _  = findnz(x_val.>1-1e-6)\n",
    "    nodes_chain = Dict([ii=>jj for (ii,jj) in zip(x_iis,x_jjs)])\n",
    "    node_index=nodes_chain[START_NODE_INDEX]\n",
    "    node_index=nodes_chain[node_index] #Skip the first two as they are the start nodes\n",
    "    sent=T()\n",
    "    while(node_index!=END_NODE_INDEX)\n",
    "        node = nodes[node_index]\n",
    "        push!(sent, unordered_markers[node[1]])\n",
    "        node_index=nodes_chain[node_index]\n",
    "    end\n",
    "    sent\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eg_corpus = @pipe [\"name this 1922 novel about leopold bloom written by james joyce\",#* \" .\",\n",
    "    \"ralph waldo emerson dismissed this poet as the jingle man and james russell lowell called him three-fifths genius and two-fifths sheer fudge\",# * \" .\",\n",
    "    \"this is the basis of a comedy of manners first performed in 1892\",#*\" .\",\n",
    "    \"in a third novel a sailor abandons the patna and meets marlow who in another novel meets kurtz in the congo\",\n",
    "    \"thus she leaves her husband and child for aleksei vronsky but all ends sadly when she leaps in front of a train\",\n",
    "    \"we looked out at the setting sun .\",\n",
    "    \" i went to the kitchen .\",\n",
    "    \"how are you doing ?\"\n",
    "    ] |>map(split,_) |> map(shuffle,_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_bag=eg_corpus[end]\n",
    "\n",
    "#test_bag = shuffle(corpus[1022]) #length 28\n",
    "#test_bag = shuffle(corpus[1028]) #length 20  (Gurodi 4.2, GLTK : 2064.6 seconds)\n",
    "#test_bag = shuffle(corpus[1122]) #length 19 \n",
    "#test_bag = shuffle(corpus[1000]) #length 17 (Gurbodi: 5.8 sconds. GLTK:  569.9seconds)\n",
    "#test_bag = shuffle([\"he was the greatest of man , a hero to many .\"|> split])\n",
    "#est_bag = shuffle([\"this is but a silly joke -- that could never happen !\"|> split])\n",
    "#test_bag =  shuffle([\"this\",\"is\",\"the\" ,\"basis\",\"of\",\"a\" ,\"comedy\" ,\"of\",\"manners\",\"first\",\"performed\",\"in\",\"1892\", \".\"])\n",
    "#test_bag =  shuffle([\"this\",\"is\",\"the\" ,\"basis\",\"of\",\"a\" ,\"comedy\" ,\"of\",\"manners\",\".\"])\n",
    "#test_bag =  shuffle([\"this\",\"is\",\"the\" ,\"basis\",\"of\",\"a\",\"fine\",\"comedy\", \".\"])\n",
    "#^length 9, Gurodi 1.0, GLTK 5.3\n",
    "#test_bag =  shuffle([\"this\",\"is\",\"the\" ,\"basis\",\"of\",\"a\" ,\"comedy\", \".\"])\n",
    "#test_bag =  shuffle([\"it\", \"is\", \"so\", \"very\", \"good\", \".\"])\n",
    "#test_bag =  shuffle([\"it\", \"is\", \"very\", \"good\", \".\"])\n",
    "#test_bag =  shuffle([\"it\", \"is\", \"good\", \".\"])\n",
    "#test_bag =  [\"no\", \"way\", \".\"]\n",
    "#test_bag =  shuffle([\"no\", \".\"])\n",
    "#@time best_order(test_bag, lm, mem_limit=1000)\n",
    "test_bag = map(symbol, test_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@everywhere function prepare_model(unordered_words::Vector, lm::Function, silent=true)\n",
    "    m=Model(solver=GurobiSolver(OutputFlag=silent? 0:1, Threads=1))\n",
    "\n",
    "    unordered_markers = [START_MARKER1; START_MARKER2; END_MARKER1; END_MARKER2; unordered_words...]\n",
    "    #Note that this lacks END_MARKER2\n",
    "    @assert START_NODE_INDEX == 1\n",
    "    @assert END_NODE_INDEX == 2\n",
    "\n",
    "    nodes = State{Int}[] #Named by word index\n",
    "\n",
    "    node_indexes_for_1st = Dict{Int, Vector{Int}}()\n",
    "    node_indexes_for_2nd = Dict{Int, Vector{Int}}()\n",
    "\n",
    "    function add_node!(ii,jj)\n",
    "        push!(nodes, (ii,jj))\n",
    "\n",
    "        node_indexes_for_i_1st = get!(()->Int[], node_indexes_for_1st, ii)\n",
    "        push!(node_indexes_for_i_1st, length(nodes))\n",
    "\n",
    "        node_indexes_for_j_2nd = get!(()->Int[], node_indexes_for_2nd, jj) \n",
    "        push!(node_indexes_for_j_2nd, length(nodes))\n",
    "        #println(\"node:$(length(nodes)) |  $(unordered_markers[ii])($ii), $(unordered_markers[jj])($jj)\")\n",
    "    end\n",
    "\n",
    "    add_node!(1, 2) #That is START_MARKER1-> START_MARKER2\n",
    "    add_node!(3, 4) #That is END_MARKER1-> END_MARKER2\n",
    "\n",
    "    for ii in 1:length(unordered_markers)\n",
    "        wi = unordered_markers[ii]\n",
    "        if wi∈(END_MARKER1,START_MARKER1) continue end  #Covered these\n",
    "\n",
    "        for jj in 1:length(unordered_markers)\n",
    "            if ii==jj continue end\n",
    "            wj = unordered_markers[jj]\n",
    "            if wj∉(START_MARKER1,START_MARKER2,END_MARKER2)\n",
    "                #but wj can be  END_MARKER1\n",
    "                add_node!(ii,jj)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    @defVar(m, x[1:length(nodes), 1:length(nodes)], Bin)\n",
    "\n",
    "    #If you enter a node you must also leave it\n",
    "    for (cc, center_node) in enumerate(nodes)\n",
    "        if cc ∉ (START_NODE_INDEX, END_NODE_INDEX) #the beginning and end done have this requiement\n",
    "            #Everything that enters this node, must leave this node\n",
    "            @addConstraint(m, sum{x[ii,cc], ii=1:length(nodes)} == sum{x[cc,jj], jj=1:length(nodes)})\n",
    "        end\n",
    "    end\n",
    "\n",
    "    for class_index in 1:length(unordered_markers)\n",
    "        w_class =  unordered_markers[class_index]\n",
    "        if w_class∉(START_MARKER1,START_MARKER2)\n",
    "            #Not rquired to make a transition so that START_MARKER1 or 2 ever occur in second position\n",
    "            jjs = node_indexes_for_2nd[class_index]\n",
    "            @addConstraint(m, sum{x[ii,jj],ii=1:length(nodes), jj=jjs}==1)\n",
    "        end\n",
    "\n",
    "        #The following constraint is not required, as if it shows uo in the second position other rules make it certain to show up in the first\n",
    "        #if w_class∉(END_MARKER1,END_MARKER2)\n",
    "        #    #Not rquired to make a transition so that END_MARKER1 or 2 ever occur in second position\n",
    "        #    iis=node_indexes_for_1st[class_index]\n",
    "        #    @addConstraint(m, sum{x[ii,jj], ii=iis,jj=1:length(nodes)}==1)\n",
    "        #    rules[w_class*\"*\"]=Set(product(iis,1:length(nodes)))\n",
    "        #end\n",
    "    end\n",
    "\n",
    "    log_trans_prob = spzeros(length(nodes), length(nodes))\n",
    "    for (from_node_index, from_node) in enumerate(nodes)\n",
    "        w1 = unordered_markers[from_node[1]]\n",
    "        w2 = unordered_markers[from_node[2]]\n",
    "        #If what was in the second state element does not end up in the first state element then it is not allowed.\n",
    "        can_transition_to = Set(get(node_indexes_for_1st, from_node[2], Int[]))\n",
    "            #You can transition to any node which has your second element as its first element\n",
    "        for (to_node_index, to_node) in enumerate(nodes)\n",
    "            if to_node_index in can_transition_to\n",
    "                @assert(from_node[2]==to_node[1])\n",
    "                w3= unordered_markers[to_node[2]]\n",
    "                log_tp = log(lm(w1,w2,w3))\n",
    "                if log_tp>-Inf\n",
    "                    log_trans_prob[from_node_index, to_node_index] = log_tp\n",
    "                    continue\n",
    "                else\n",
    "                    #Banned as prob zero transitions not allowed\n",
    "                    @addConstraint(m, x[from_node_index,to_node_index]==0)\n",
    "                end\n",
    "\n",
    "            else\n",
    "                #It is not a legal transition\n",
    "                @addConstraint(m, x[from_node_index,to_node_index]==0)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    function eleminate_subtours(cb)\n",
    "        x_val = getValue(x)\n",
    "        x_iis,x_jjs, _  = findnz(x_val .>= 1 - 1e-6) #It just has to be close to 1 to be true\n",
    "        x_links=zip(x_iis,x_jjs)\n",
    "        coretour = get_coretours(x_links)\n",
    "        if length(coretour)==length(x_links)+1\n",
    "            #no subtour to eleminate\n",
    "            return\n",
    "        end\n",
    "        core_hyperclass = get_hyperclass(coretour, nodes, node_indexes_for_1st)\n",
    "\n",
    "        #Also the First subtour must go to one of the other subtours \n",
    "        arcs_outof_coretour = AffExpr()\n",
    "        for ii in core_hyperclass\n",
    "            for jj in 1:length(nodes)\n",
    "                if jj∉core_hyperclass\n",
    "                    arcs_outof_coretour += x[ii,jj]\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        @addLazyConstraint(cb, arcs_outof_coretour >=1)\n",
    "    end\n",
    "\n",
    "    addLazyCallback(m, eleminate_subtours,fractional=false)\n",
    "\n",
    "    #new Linear way using logprobs\n",
    "    @setObjective(m, Max, sum{log_trans_prob[i,j]*x[i,j], i=1:length(nodes), j=1:length(nodes)})\n",
    "    \n",
    "    m,x, nodes,unordered_markers\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@everywhere function lm(w0,w1,w2)\n",
    "    prob(kn_lm,w0,w1,w2)\n",
    "end\n",
    "@everywhere function remote_lm(w0,w1,w2)\n",
    "    remotecall_fetch(lm, 1, w0,w1,w2) #Ask processor 1 to tell us the prob\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@everywhere function best_order(unordered_words::Vector, lm::Function, silent=true)\n",
    "    tic()\n",
    "    m,x,nodes,unordered_markers = prepare_model(unordered_words, lm, silent)\n",
    "\n",
    "    status = solve(m,suppress_warnings=silent)\n",
    "    time_to_solve = toq()\n",
    "    solution_prob = e^getObjectiveValue(m)\n",
    "    generated_order = if status==:Optimal\n",
    "        x_val = getValue(x)\n",
    "        get_sentence(x_val, unordered_markers, nodes)\n",
    "    else\n",
    "        unordered_words \n",
    "    end\n",
    "    (generated_order, solution_prob, time_to_solve, status)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fetch(@spawnat 2 best_order([:he, :is, :the, :yo, :king, Symbol(\".\")], remote_lm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{ByteString,Any} with 100 entries:\n",
       "  \"32\" => [(ASCIIString[\"she\",\"reached\",\"up\",\"and\",\"followed\",\"his\",\"fingers\",\"…\n",
       "  \"29\" => [(ASCIIString[\"i\",\"said\",\",\",\"you\",\"know\",\"youre\",\"going\",\"to\",\"get\",…\n",
       "  \"1\"  => [(ASCIIString[\"``\",\"you\",\"would\",\"destroy\",\"a\",\"book\",\"that\",\"even\",\"…\n",
       "  \"54\" => [(ASCIIString[\"thorpe\",\"rose\",\",\",\"agitated\",\".\"],ASCIIString[\"thorpe…\n",
       "  \"78\" => [(ASCIIString[\"dirk\",\"remarks\",\"as\",\"i\",\"swing\",\"a\",\"right\",\"leg\",\"an…\n",
       "  \"81\" => [(ASCIIString[\"they\",\"shook\",\"hands\",\",\",\"while\",\"ron\",\"turned\",\"towa…\n",
       "  \"2\"  => [(ASCIIString[\"the\",\"representation\",\"of\",\"the\",\"body\",\"of\",\"christ\",…\n",
       "  \"74\" => [(ASCIIString[\"but\",\"the\",\"enormous\",\"interests\",\"at\",\"stake\",\"here\",…\n",
       "  \"41\" => [(ASCIIString[\"this\",\"meant\",\"i\",\"knew\",\"that\",\"my\",\"people\",\"did\",\"n…\n",
       "  \"65\" => [(ASCIIString[\"i\",\"really\",\"hoped\",\"they\",\"'d\",\"be\",\"on\",\"their\",\"bes…\n",
       "  \"51\" => [(ASCIIString[\"i\",\"stood\",\",\",\"tightening\",\"the\",\"belt\",\"of\",\"my\",\"ro…\n",
       "  \"53\" => [(ASCIIString[\"her\",\"hair\",\"moved\",\",\",\"and\",\"he\",\"could\",\"see\",\"the\"…\n",
       "  \"27\" => [(ASCIIString[\"go\",\"!\"],ASCIIString[\"go\",\"!\"],1.0f0),(ASCIIString[\"we…\n",
       "  \"75\" => [(ASCIIString[\"she\",\"wrapped\",\"his\",\"wrists\",\"together\",\"behind\",\"him…\n",
       "  \"42\" => [(ASCIIString[\"i\",\"do\",\"n't\",\"need\",\"her\",\"help\",\",\",\"do\",\"n't\",\"even…\n",
       "  \"33\" => [(ASCIIString[\"ty\",\"poured\",\"a\",\"bud\",\"from\",\"the\",\"tap\",\"and\",\"hande…\n",
       "  \"28\" => [(ASCIIString[\"granted\",\"access\",\"to\",\"their\",\"network\",\".\"],ASCIIStr…\n",
       "  \"50\" => [(ASCIIString[\"``\",\"it\",\"'s\",\"an\",\"apa\",\".\",\"''\"],ASCIIString[\"``\",\"i…\n",
       "  \"52\" => [(ASCIIString[\"but\",\"try\",\"as\",\"she\",\"might\",\",\",\"she\",\"could\",\"n't\",…\n",
       "  \"63\" => [(ASCIIString[\"so\",\"why\",\"the\",\"sudden\",\"change\",\"of\",\"heart\",\"?\"],AS…\n",
       "  \"92\" => [(ASCIIString[\"she\",\"had\",\"teased\",\"and\",\"flirted\",\"shamelessly\",\",\",…\n",
       "  \"88\" => [(ASCIIString[\"the\",\"door\",\"to\",\"trent\",\"'s\",\"office\",\"closed\",\",\",\"a…\n",
       "  \"93\" => [(ASCIIString[\"she\",\"knew\",\"what\",\"the\",\"smell\",\"was\",\",\",\"knew\",\"wha…\n",
       "  \"26\" => [(ASCIIString[\"the\",\"crocodiles\",\"!\"],ASCIIString[\"the\",\"crocodiles\",…\n",
       "  \"10\" => [(ASCIIString[\"``\",\"he\",\"was\",\"raised\",\"to\",\"the\",\"peerage\",\"for\",\"se…\n",
       "  ⋮    => ⋮"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_name = \"books_corpus_0.001_of_test_oracle\"#\"books_corpus_0.001_of_test_glove300\"\n",
    "test_set_blocks = load(\"results/bags/$(corpus_name).jld\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Base.FS is deprecated.\n",
      "  likely near /home/ubuntu/.julia/v0.5/Blocks/src/Blocks.jl:3\n",
      "WARNING: Base.FS is deprecated.\n",
      "  likely near /home/ubuntu/.julia/v0.5/Blocks/src/Blocks.jl:3\n",
      "WARNING: WARNING: Base.FS is deprecated.\n",
      "  likely near /home/ubuntu/.julia/v0.5/Blocks/src/Blocks.jl:3\n",
      "Base.FS is deprecated.\n",
      "  likely near /home/ubuntu/.julia/v0.5/Blocks/src/Blocks.jl:3\n",
      "WARNING: Base.FS is deprecated.\n",
      "  likely near /home/ubuntu/.julia/v0.5/Blocks/src/Blocks.jl:3\n",
      "WARNING: Base.FS is deprecated.\n",
      "  likely near /home/ubuntu/.julia/v0.5/Blocks/src/Blocks.jl:3\n",
      "WARNING: Base.FS is deprecated.\n",
      "  likely near /home/ubuntu/.julia/v0.5/Blocks/src/Blocks.jl:3\n",
      "WARNING: Base.FS is deprecated.\n",
      "  likely near /home/ubuntu/.julia/v0.5/Blocks/src/Blocks.jl:3\n",
      "WARNING: WARNING: Base.FS is deprecated.\n",
      "  likely near /home/ubuntu/.julia/v0.5/Blocks/src/Blocks.jl:3\n",
      "Base.FS is deprecated.\n",
      "  likely near /home/ubuntu/.julia/v0.5/Blocks/src/Blocks.jl:3\n",
      "WARNING: Base.FS is deprecated.\n",
      "  likely near /home/ubuntu/.julia/v0.5/Blocks/src/Blocks.jl:3\n",
      "WARNING: Base.FS is deprecated.\n",
      "  likely near /home/ubuntu/.julia/v0.5/Blocks/src/Blocks.jl:3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "jldopen_append (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Blocks\n",
    "using Lumberjack\n",
    "add_truck(LumberjackTruck(\"ordering_$(corpus_name).log\"), \"file-logger\")\n",
    "function jldopen_append(func::Function, filename::AbstractString)\n",
    "    mode = isfile(filename) ? \"r+\" : \"w\" #Only open with \"w\" if it does't already exist\n",
    "    jldopen(func, filename, mode)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "run (generic function with 2 methods)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const res_type = Tuple{Array{Symbol,1},Array{Symbol,1},Float64,Float64,Symbol}\n",
    "\n",
    "function result_log(ii, block_res)\n",
    "    num_optimal=0\n",
    "    num_infeasible=0\n",
    "    num_noattempted=0\n",
    "    for res in block_res\n",
    "        status = res[end]\n",
    "        if status==:Optimal\n",
    "            num_optimal+=1\n",
    "        elseif status==:Infeasible\n",
    "            num_infeasible+=1\n",
    "        elseif status==:NotAttempted\n",
    "            num_noattempted+=1\n",
    "        else\n",
    "            error(\"Unexpected stats $(status)\")\n",
    "        end\n",
    "    end\n",
    "\n",
    "    Lumberjack.info(\"$ii done: Opt:$(num_optimal/length(block_res)*100)%, \"*\n",
    "                                \"Infeas:$(num_infeasible/length(block_res)*100)%, \"*\n",
    "                                \"NAttpt:$(num_noattempted/length(block_res)*100)%\")\n",
    "end\n",
    "\n",
    "function run(test_set_blocks, save_path=\"ordering.jld\")\n",
    "    try\n",
    "        Lumberjack.info(\"Began ordering\")\n",
    "        ii = 0 \n",
    "        map(@pipe test_set_blocks |> keys |> map(key->parse(Int,key),_) |>  sort |> map(string,_)) do (ii)\n",
    "            block = test_set_blocks[ii]\n",
    "\n",
    "            block_res::Vector{res_type} = pmap(block,err_stop=true) do bow_data\n",
    "                (ground_order_s, bow_s, selection_score) = bow_data\n",
    "                bow=map(Symbol, bow_s)\n",
    "                ground_order = map(Symbol,ground_order_s)\n",
    "                if length(ground_order_s)<=18\n",
    "                    #(ground_order, generated_order, solution_prob, time_to_solve, status)\n",
    "                    res = best_order(bow, remote_lm)\n",
    "                    (ground_order, res...)\n",
    "                else\n",
    "                    (ground_order, bow, NaN, 0.0, :NotAttempted)\n",
    "                end\n",
    "            end\n",
    "            result_log(ii,block_res)\n",
    "            \n",
    "            jldopen_append(save_path) do fh\n",
    "                write(fh,ii, block_res)\n",
    "            end\n",
    "            Lumberjack.debug(\"$ii written to disc\")\n",
    "        end\n",
    "    catch err\n",
    "        Lumberjack.error(\"Unhandled Error\", base_exception=err)\n",
    "    end\n",
    "    Lumberjack.info(\"complete selection\")\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-02-03T20:02:52 - info: Began ordering\n",
      "2016-02-03T20:03:46 - info: 1 done: Opt:70.1492537313433%, Infeas:1.4925373134328357%, NAttpt:28.35820895522388%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: both Lumberjack and Base export \"error\"; uses of it in module Main must be qualified\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-02-03T20:03:48 - debug: 1 written to disc\n",
      "2016-02-03T20:05:13 - info: 2 done: Opt:76.11940298507463%, Infeas:0.0%, NAttpt:23.88059701492537%\n",
      "2016-02-03T20:05:13 - debug: 2 written to disc\n",
      "2016-02-03T20:06:19 - info: 3 done: Opt:76.11940298507463%, Infeas:2.9850746268656714%, NAttpt:20.8955223880597%\n",
      "2016-02-03T20:06:19 - debug: 3 written to disc\n",
      "2016-02-03T20:08:18 - info: 4 done: Opt:85.07462686567165%, Infeas:1.4925373134328357%, NAttpt:13.432835820895523%\n",
      "2016-02-03T20:08:18 - debug: 4 written to disc\n",
      "2016-02-03T20:13:09 - info: 5 done: Opt:77.61194029850746%, Infeas:0.0%, NAttpt:22.388059701492537%\n",
      "2016-02-03T20:13:09 - debug: 5 written to disc\n",
      "2016-02-03T20:13:52 - info: 6 done: Opt:74.6268656716418%, Infeas:1.4925373134328357%, NAttpt:23.88059701492537%\n",
      "2016-02-03T20:13:52 - debug: 6 written to disc\n",
      "2016-02-03T20:14:49 - info: 7 done: Opt:82.08955223880598%, Infeas:1.4925373134328357%, NAttpt:16.417910447761194%\n",
      "2016-02-03T20:14:49 - debug: 7 written to disc\n",
      "2016-02-03T20:15:14 - info: 8 done: Opt:86.56716417910447%, Infeas:0.0%, NAttpt:13.432835820895523%\n",
      "2016-02-03T20:15:14 - debug: 8 written to disc\n",
      "2016-02-03T20:16:33 - info: 9 done: Opt:83.5820895522388%, Infeas:0.0%, NAttpt:16.417910447761194%\n",
      "2016-02-03T20:16:33 - debug: 9 written to disc\n",
      "2016-02-03T20:18:27 - info: 10 done: Opt:83.5820895522388%, Infeas:0.0%, NAttpt:16.417910447761194%\n",
      "2016-02-03T20:18:27 - debug: 10 written to disc\n",
      "2016-02-03T20:20:26 - info: 11 done: Opt:82.08955223880598%, Infeas:0.0%, NAttpt:17.91044776119403%\n",
      "2016-02-03T20:20:26 - debug: 11 written to disc\n",
      "2016-02-03T20:24:38 - info: 12 done: Opt:80.59701492537313%, Infeas:0.0%, NAttpt:19.402985074626866%\n",
      "2016-02-03T20:24:38 - debug: 12 written to disc\n",
      "2016-02-03T20:26:41 - info: 13 done: Opt:77.61194029850746%, Infeas:0.0%, NAttpt:22.388059701492537%\n",
      "2016-02-03T20:26:42 - debug: 13 written to disc\n",
      "2016-02-03T20:28:28 - info: 14 done: Opt:86.56716417910447%, Infeas:0.0%, NAttpt:13.432835820895523%\n",
      "2016-02-03T20:28:29 - debug: 14 written to disc\n",
      "2016-02-03T20:30:04 - info: 15 done: Opt:76.11940298507463%, Infeas:0.0%, NAttpt:23.88059701492537%\n",
      "2016-02-03T20:30:05 - debug: 15 written to disc\n",
      "2016-02-03T20:33:18 - info: 16 done: Opt:83.5820895522388%, Infeas:0.0%, NAttpt:16.417910447761194%\n",
      "2016-02-03T20:33:18 - debug: 16 written to disc\n",
      "2016-02-03T20:36:44 - info: 17 done: Opt:71.64179104477611%, Infeas:0.0%, NAttpt:28.35820895522388%\n",
      "2016-02-03T20:36:44 - debug: 17 written to disc\n",
      "2016-02-03T20:38:26 - info: 18 done: Opt:79.1044776119403%, Infeas:0.0%, NAttpt:20.8955223880597%\n",
      "2016-02-03T20:38:26 - debug: 18 written to disc\n",
      "2016-02-03T20:39:15 - info: 19 done: Opt:80.59701492537313%, Infeas:2.9850746268656714%, NAttpt:16.417910447761194%\n",
      "2016-02-03T20:39:15 - debug: 19 written to disc\n",
      "2016-02-03T20:40:54 - info: 20 done: Opt:77.61194029850746%, Infeas:1.4925373134328357%, NAttpt:20.8955223880597%\n",
      "2016-02-03T20:40:54 - debug: 20 written to disc\n",
      "2016-02-03T20:42:50 - info: 21 done: Opt:77.61194029850746%, Infeas:0.0%, NAttpt:22.388059701492537%\n",
      "2016-02-03T20:42:50 - debug: 21 written to disc\n",
      "2016-02-03T20:44:12 - info: 22 done: Opt:77.61194029850746%, Infeas:0.0%, NAttpt:22.388059701492537%\n",
      "2016-02-03T20:44:12 - debug: 22 written to disc\n",
      "2016-02-03T20:45:10 - info: 23 done: Opt:67.16417910447761%, Infeas:0.0%, NAttpt:32.83582089552239%\n",
      "2016-02-03T20:45:10 - debug: 23 written to disc\n",
      "2016-02-03T20:46:37 - info: 24 done: Opt:79.1044776119403%, Infeas:2.9850746268656714%, NAttpt:17.91044776119403%\n",
      "2016-02-03T20:46:37 - debug: 24 written to disc\n",
      "2016-02-03T20:47:47 - info: 25 done: Opt:70.1492537313433%, Infeas:0.0%, NAttpt:29.850746268656714%\n",
      "2016-02-03T20:47:47 - debug: 25 written to disc\n",
      "2016-02-03T20:49:05 - info: 26 done: Opt:80.59701492537313%, Infeas:0.0%, NAttpt:19.402985074626866%\n",
      "2016-02-03T20:49:05 - debug: 26 written to disc\n",
      "2016-02-03T20:51:00 - info: 27 done: Opt:85.07462686567165%, Infeas:1.4925373134328357%, NAttpt:13.432835820895523%\n",
      "2016-02-03T20:51:00 - debug: 27 written to disc\n",
      "2016-02-03T20:51:43 - info: 28 done: Opt:77.61194029850746%, Infeas:0.0%, NAttpt:22.388059701492537%\n",
      "2016-02-03T20:51:43 - debug: 28 written to disc\n",
      "2016-02-03T20:53:12 - info: 29 done: Opt:83.5820895522388%, Infeas:1.4925373134328357%, NAttpt:14.925373134328357%\n",
      "2016-02-03T20:53:12 - debug: 29 written to disc\n",
      "2016-02-03T20:53:52 - info: 30 done: Opt:91.04477611940298%, Infeas:0.0%, NAttpt:8.955223880597014%\n",
      "2016-02-03T20:53:52 - debug: 30 written to disc\n",
      "2016-02-03T20:56:09 - info: 31 done: Opt:79.1044776119403%, Infeas:0.0%, NAttpt:20.8955223880597%\n",
      "2016-02-03T20:56:09 - debug: 31 written to disc\n",
      "2016-02-03T20:57:29 - info: 32 done: Opt:89.55223880597015%, Infeas:0.0%, NAttpt:10.44776119402985%\n",
      "2016-02-03T20:57:30 - debug: 32 written to disc\n",
      "2016-02-03T20:58:09 - info: 33 done: Opt:85.07462686567165%, Infeas:0.0%, NAttpt:14.925373134328357%\n",
      "2016-02-03T20:58:09 - debug: 33 written to disc\n",
      "2016-02-03T20:59:22 - info: 34 done: Opt:79.1044776119403%, Infeas:0.0%, NAttpt:20.8955223880597%\n",
      "2016-02-03T20:59:23 - debug: 34 written to disc\n",
      "2016-02-03T21:00:17 - info: 35 done: Opt:80.59701492537313%, Infeas:0.0%, NAttpt:19.402985074626866%\n",
      "2016-02-03T21:00:18 - debug: 35 written to disc\n",
      "2016-02-03T21:01:00 - info: 36 done: Opt:79.1044776119403%, Infeas:0.0%, NAttpt:20.8955223880597%\n",
      "2016-02-03T21:01:01 - debug: 36 written to disc\n",
      "2016-02-03T21:03:55 - info: 37 done: Opt:85.07462686567165%, Infeas:0.0%, NAttpt:14.925373134328357%\n",
      "2016-02-03T21:03:56 - debug: 37 written to disc\n",
      "2016-02-03T21:04:23 - info: 38 done: Opt:86.56716417910447%, Infeas:0.0%, NAttpt:13.432835820895523%\n",
      "2016-02-03T21:04:23 - debug: 38 written to disc\n",
      "2016-02-03T21:05:32 - info: 39 done: Opt:88.05970149253731%, Infeas:0.0%, NAttpt:11.940298507462686%\n",
      "2016-02-03T21:05:33 - debug: 39 written to disc\n",
      "2016-02-03T21:06:32 - info: 40 done: Opt:73.13432835820896%, Infeas:0.0%, NAttpt:26.865671641791046%\n",
      "2016-02-03T21:06:33 - debug: 40 written to disc\n",
      "2016-02-03T21:07:12 - info: 41 done: Opt:80.59701492537313%, Infeas:0.0%, NAttpt:19.402985074626866%\n",
      "2016-02-03T21:07:13 - debug: 41 written to disc\n",
      "2016-02-03T21:07:47 - info: 42 done: Opt:77.61194029850746%, Infeas:0.0%, NAttpt:22.388059701492537%\n",
      "2016-02-03T21:07:48 - debug: 42 written to disc\n",
      "2016-02-03T21:08:17 - info: 43 done: Opt:80.59701492537313%, Infeas:1.4925373134328357%, NAttpt:17.91044776119403%\n",
      "2016-02-03T21:08:18 - debug: 43 written to disc\n",
      "2016-02-03T21:09:11 - info: 44 done: Opt:77.61194029850746%, Infeas:0.0%, NAttpt:22.388059701492537%\n",
      "2016-02-03T21:09:12 - debug: 44 written to disc\n",
      "2016-02-03T21:10:08 - info: 45 done: Opt:83.5820895522388%, Infeas:0.0%, NAttpt:16.417910447761194%\n",
      "2016-02-03T21:10:09 - debug: 45 written to disc\n",
      "2016-02-03T21:12:12 - info: 46 done: Opt:86.56716417910447%, Infeas:1.4925373134328357%, NAttpt:11.940298507462686%\n",
      "2016-02-03T21:12:13 - debug: 46 written to disc\n",
      "2016-02-03T21:12:42 - info: 47 done: Opt:77.61194029850746%, Infeas:0.0%, NAttpt:22.388059701492537%\n",
      "2016-02-03T21:12:43 - debug: 47 written to disc\n",
      "2016-02-03T21:13:46 - info: 48 done: Opt:82.08955223880598%, Infeas:1.4925373134328357%, NAttpt:16.417910447761194%\n",
      "2016-02-03T21:13:48 - debug: 48 written to disc\n",
      "2016-02-03T21:15:53 - info: 49 done: Opt:76.11940298507463%, Infeas:2.9850746268656714%, NAttpt:20.8955223880597%\n",
      "2016-02-03T21:15:55 - debug: 49 written to disc\n",
      "2016-02-03T21:16:38 - info: 50 done: Opt:82.08955223880598%, Infeas:0.0%, NAttpt:17.91044776119403%\n",
      "2016-02-03T21:16:39 - debug: 50 written to disc\n",
      "2016-02-03T21:18:26 - info: 51 done: Opt:88.05970149253731%, Infeas:0.0%, NAttpt:11.940298507462686%\n",
      "2016-02-03T21:18:28 - debug: 51 written to disc\n",
      "2016-02-03T21:19:38 - info: 52 done: Opt:86.56716417910447%, Infeas:0.0%, NAttpt:13.432835820895523%\n",
      "2016-02-03T21:19:40 - debug: 52 written to disc\n",
      "2016-02-03T21:22:08 - info: 53 done: Opt:71.64179104477611%, Infeas:0.0%, NAttpt:28.35820895522388%\n",
      "2016-02-03T21:22:10 - debug: 53 written to disc\n",
      "2016-02-03T21:22:43 - info: 54 done: Opt:77.61194029850746%, Infeas:0.0%, NAttpt:22.388059701492537%\n",
      "2016-02-03T21:22:45 - debug: 54 written to disc\n",
      "2016-02-03T21:24:07 - info: 55 done: Opt:68.65671641791045%, Infeas:1.4925373134328357%, NAttpt:29.850746268656714%\n",
      "2016-02-03T21:24:09 - debug: 55 written to disc\n",
      "2016-02-03T21:26:01 - info: 56 done: Opt:85.07462686567165%, Infeas:0.0%, NAttpt:14.925373134328357%\n",
      "2016-02-03T21:26:02 - debug: 56 written to disc\n",
      "2016-02-03T21:27:34 - info: 57 done: Opt:70.1492537313433%, Infeas:0.0%, NAttpt:29.850746268656714%\n",
      "2016-02-03T21:27:36 - debug: 57 written to disc\n",
      "2016-02-03T21:28:15 - info: 58 done: Opt:85.07462686567165%, Infeas:0.0%, NAttpt:14.925373134328357%\n",
      "2016-02-03T21:28:17 - debug: 58 written to disc\n",
      "2016-02-03T21:40:29 - info: 59 done: Opt:79.1044776119403%, Infeas:0.0%, NAttpt:20.8955223880597%\n",
      "2016-02-03T21:40:32 - debug: 59 written to disc\n",
      "2016-02-03T21:41:09 - info: 60 done: Opt:85.07462686567165%, Infeas:0.0%, NAttpt:14.925373134328357%\n",
      "2016-02-03T21:41:11 - debug: 60 written to disc\n",
      "2016-02-03T21:43:08 - info: 61 done: Opt:79.1044776119403%, Infeas:0.0%, NAttpt:20.8955223880597%\n",
      "2016-02-03T21:43:11 - debug: 61 written to disc\n",
      "2016-02-03T21:44:13 - info: 62 done: Opt:76.11940298507463%, Infeas:0.0%, NAttpt:23.88059701492537%\n",
      "2016-02-03T21:44:15 - debug: 62 written to disc\n",
      "2016-02-03T21:45:07 - info: 63 done: Opt:77.61194029850746%, Infeas:0.0%, NAttpt:22.388059701492537%\n",
      "2016-02-03T21:45:09 - debug: 63 written to disc\n",
      "2016-02-03T21:47:11 - info: 64 done: Opt:80.59701492537313%, Infeas:0.0%, NAttpt:19.402985074626866%\n",
      "2016-02-03T21:47:14 - debug: 64 written to disc\n",
      "2016-02-03T21:48:25 - info: 65 done: Opt:83.5820895522388%, Infeas:0.0%, NAttpt:16.417910447761194%\n",
      "2016-02-03T21:48:28 - debug: 65 written to disc\n",
      "2016-02-03T21:49:57 - info: 66 done: Opt:88.05970149253731%, Infeas:1.4925373134328357%, NAttpt:10.44776119402985%\n",
      "2016-02-03T21:49:59 - debug: 66 written to disc\n",
      "2016-02-03T21:50:47 - info: 67 done: Opt:83.5820895522388%, Infeas:0.0%, NAttpt:16.417910447761194%\n",
      "2016-02-03T21:50:50 - debug: 67 written to disc\n",
      "2016-02-03T21:51:33 - info: 68 done: Opt:80.59701492537313%, Infeas:1.4925373134328357%, NAttpt:17.91044776119403%\n",
      "2016-02-03T21:51:36 - debug: 68 written to disc\n",
      "2016-02-03T21:52:10 - info: 69 done: Opt:68.65671641791045%, Infeas:1.4925373134328357%, NAttpt:29.850746268656714%\n",
      "2016-02-03T21:52:13 - debug: 69 written to disc\n",
      "2016-02-03T21:53:01 - info: 70 done: Opt:74.6268656716418%, Infeas:2.9850746268656714%, NAttpt:22.388059701492537%\n",
      "2016-02-03T21:53:04 - debug: 70 written to disc\n",
      "2016-02-03T21:53:49 - info: 71 done: Opt:77.61194029850746%, Infeas:4.477611940298507%, NAttpt:17.91044776119403%\n",
      "2016-02-03T21:53:52 - debug: 71 written to disc\n",
      "2016-02-03T21:55:20 - info: 72 done: Opt:73.13432835820896%, Infeas:0.0%, NAttpt:26.865671641791046%\n",
      "2016-02-03T21:55:23 - debug: 72 written to disc\n",
      "2016-02-03T21:58:24 - info: 73 done: Opt:86.56716417910447%, Infeas:0.0%, NAttpt:13.432835820895523%\n",
      "2016-02-03T21:58:27 - debug: 73 written to disc\n",
      "2016-02-03T22:00:40 - info: 74 done: Opt:80.59701492537313%, Infeas:0.0%, NAttpt:19.402985074626866%\n",
      "2016-02-03T22:00:43 - debug: 74 written to disc\n",
      "2016-02-03T22:02:17 - info: 75 done: Opt:85.07462686567165%, Infeas:0.0%, NAttpt:14.925373134328357%\n",
      "2016-02-03T22:02:20 - debug: 75 written to disc\n",
      "2016-02-03T22:03:36 - info: 76 done: Opt:85.07462686567165%, Infeas:0.0%, NAttpt:14.925373134328357%\n",
      "2016-02-03T22:03:39 - debug: 76 written to disc\n",
      "2016-02-03T22:06:23 - info: 77 done: Opt:82.08955223880598%, Infeas:1.4925373134328357%, NAttpt:16.417910447761194%\n",
      "2016-02-03T22:06:26 - debug: 77 written to disc\n",
      "2016-02-03T22:07:44 - info: 78 done: Opt:86.36363636363636%, Infeas:0.0%, NAttpt:13.636363636363635%\n",
      "2016-02-03T22:07:48 - debug: 78 written to disc\n",
      "2016-02-03T22:09:36 - info: 79 done: Opt:78.78787878787878%, Infeas:0.0%, NAttpt:21.21212121212121%\n",
      "2016-02-03T22:09:40 - debug: 79 written to disc\n",
      "2016-02-03T22:10:55 - info: 80 done: Opt:75.75757575757575%, Infeas:0.0%, NAttpt:24.242424242424242%\n",
      "2016-02-03T22:10:58 - debug: 80 written to disc\n",
      "2016-02-03T22:13:21 - info: 81 done: Opt:87.87878787878788%, Infeas:0.0%, NAttpt:12.121212121212121%\n",
      "2016-02-03T22:13:25 - debug: 81 written to disc\n",
      "2016-02-03T22:13:59 - info: 82 done: Opt:74.24242424242425%, Infeas:3.0303030303030303%, NAttpt:22.727272727272727%\n",
      "2016-02-03T22:14:02 - debug: 82 written to disc\n",
      "2016-02-03T22:16:27 - info: 83 done: Opt:74.24242424242425%, Infeas:0.0%, NAttpt:25.757575757575758%\n",
      "2016-02-03T22:16:31 - debug: 83 written to disc\n",
      "2016-02-03T22:17:57 - info: 84 done: Opt:74.24242424242425%, Infeas:0.0%, NAttpt:25.757575757575758%\n",
      "2016-02-03T22:18:02 - debug: 84 written to disc\n",
      "2016-02-03T22:19:50 - info: 85 done: Opt:84.84848484848484%, Infeas:1.5151515151515151%, NAttpt:13.636363636363635%\n",
      "2016-02-03T22:19:54 - debug: 85 written to disc\n",
      "2016-02-03T22:21:18 - info: 86 done: Opt:77.27272727272727%, Infeas:1.5151515151515151%, NAttpt:21.21212121212121%\n",
      "2016-02-03T22:21:22 - debug: 86 written to disc\n",
      "2016-02-03T22:22:08 - info: 87 done: Opt:69.6969696969697%, Infeas:0.0%, NAttpt:30.303030303030305%\n",
      "2016-02-03T22:22:12 - debug: 87 written to disc\n",
      "2016-02-03T22:23:00 - info: 88 done: Opt:78.78787878787878%, Infeas:0.0%, NAttpt:21.21212121212121%\n",
      "2016-02-03T22:23:05 - debug: 88 written to disc\n",
      "2016-02-03T22:27:53 - info: 89 done: Opt:83.33333333333334%, Infeas:0.0%, NAttpt:16.666666666666664%\n",
      "2016-02-03T22:27:59 - debug: 89 written to disc\n",
      "2016-02-03T22:35:51 - info: 90 done: Opt:77.27272727272727%, Infeas:0.0%, NAttpt:22.727272727272727%\n",
      "2016-02-03T22:35:56 - debug: 90 written to disc\n",
      "2016-02-03T22:36:40 - info: 91 done: Opt:71.21212121212122%, Infeas:0.0%, NAttpt:28.78787878787879%\n",
      "2016-02-03T22:36:45 - debug: 91 written to disc\n",
      "2016-02-03T22:37:53 - info: 92 done: Opt:75.75757575757575%, Infeas:0.0%, NAttpt:24.242424242424242%\n",
      "2016-02-03T22:37:58 - debug: 92 written to disc\n",
      "2016-02-03T22:39:17 - info: 93 done: Opt:81.81818181818183%, Infeas:0.0%, NAttpt:18.181818181818183%\n",
      "2016-02-03T22:39:22 - debug: 93 written to disc\n",
      "2016-02-03T22:40:07 - info: 94 done: Opt:78.78787878787878%, Infeas:0.0%, NAttpt:21.21212121212121%\n",
      "2016-02-03T22:40:12 - debug: 94 written to disc\n",
      "2016-02-03T22:42:13 - info: 95 done: Opt:86.36363636363636%, Infeas:0.0%, NAttpt:13.636363636363635%\n",
      "2016-02-03T22:42:18 - debug: 95 written to disc\n",
      "2016-02-03T22:43:05 - info: 96 done: Opt:75.75757575757575%, Infeas:0.0%, NAttpt:24.242424242424242%\n",
      "2016-02-03T22:43:10 - debug: 96 written to disc\n",
      "2016-02-03T22:44:04 - info: 97 done: Opt:81.81818181818183%, Infeas:0.0%, NAttpt:18.181818181818183%\n",
      "2016-02-03T22:44:09 - debug: 97 written to disc\n",
      "2016-02-03T22:45:34 - info: 98 done: Opt:81.81818181818183%, Infeas:0.0%, NAttpt:18.181818181818183%\n",
      "2016-02-03T22:45:39 - debug: 98 written to disc\n",
      "2016-02-03T22:46:18 - info: 99 done: Opt:84.84848484848484%, Infeas:0.0%, NAttpt:15.151515151515152%\n",
      "2016-02-03T22:46:24 - debug: 99 written to disc\n",
      "2016-02-03T22:47:07 - info: 100 done: Opt:83.33333333333334%, Infeas:0.0%, NAttpt:16.666666666666664%\n",
      "2016-02-03T22:47:13 - debug: 100 written to disc\n",
      "2016-02-03T22:47:13 - info: complete selection\n"
     ]
    }
   ],
   "source": [
    "run(test_set_blocks, \"results/ordered/$(corpus_name).jld\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample = typeof(test_set_blocks)()\n",
    "sample[\"1\"]=test_set_blocks[\"1\"][1:5]\n",
    "sample[\"2\"]=test_set_blocks[\"2\"][1:5]\n",
    "run(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "load(\"failed_ordering.jld\", 1 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "function get_irreducible_inconsistent_subsystem(m::JuMP.Model)    \n",
    "    grb_model = m.internalModel.inner\n",
    "    num_constrs = Gurobi.num_constrs(grb_model)\n",
    "    Gurobi.computeIIS(grb_model)\n",
    "    iis_constrs = Gurobi.get_intattrarray(grb_model, \"IISConstr\",  1, num_constrs)\n",
    "    m.linconstr[find(iis_constrs)]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iis = get_irreducible_inconsistent_subsystem(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count,constraint_index = indmax([length(constrant.terms.coeffs) for constrant in iis])\n",
    "constraint = iis[constraint_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m=Model(solver=GurobiSolver())\n",
    "@defVar(m,x, Int)\n",
    "@defVar(m,y, Int)\n",
    "@addConstraint(m,y<=1000) #This one won't cause problems\n",
    "@addConstraint(m,x>=6)    #This will\n",
    "@addConstraint(m,y>=6)    #This will \n",
    "#@addConstraint(m,x+y<=11) #This will\n",
    "\n",
    "status = solve(m)\n",
    "\n",
    "#@assert status==:Infeasible\n",
    "#get_irreducible_inconsistent_subsystem(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "getObjectiveV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function get_prod(x, iis, jjs)\n",
    "    net = 1.0\n",
    "    for i in 1:size(x,1) \n",
    "        for j in 1:size(x,2)\n",
    "            println(i,\",\", j, \" =\", x[i,j], \" \", trans_prob[i,j])\n",
    "            net*=max((x[i,j]-1)^2, trans_prob[i,j])\n",
    "        end\n",
    "    end\n",
    "    net\n",
    "end\n",
    "values = falses(size(x))\n",
    "values[1,3] = 1\n",
    "values[3,6] = 1\n",
    "values[6,7] = 1\n",
    "println(\"----------\\n\")\n",
    "get_prod(values, iis,jjs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@pyimport nltk.corpus as nltk_corpus\n",
    "corpus_reader=nltk_corpus.brown\n",
    "corpus = Vector{ASCIIString}[[lowercase(word) for word in sent] for sent in (corpus_reader[:sents]()|> collect)]\n",
    "const log_lm = train_language_model(corpus, loglikelyhood=true)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.0-dev",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
