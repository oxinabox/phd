{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11-element Array{Int64,1}:\n",
       "  2\n",
       "  3\n",
       "  4\n",
       "  5\n",
       "  6\n",
       "  7\n",
       "  8\n",
       "  9\n",
       " 10\n",
       " 11\n",
       " 12"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addprocs(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: module DataStructuresExtended should explicitly import == from Base\n",
      "WARNING: module DataStructuresExtended should explicitly import == from Base\n",
      "WARNING: module DataStructuresExtended should explicitly import == from Base\n",
      "WARNING: module DataStructuresExtended should explicitly import == from Base\n",
      "WARNING: module DataStructuresExtended should explicitly import == from Base\n",
      "WARNING: module DataStructuresExtended should explicitly import == from Base\n",
      "WARNING: module DataStructuresExtended should explicitly import == from Base\n",
      "WARNING: module DataStructuresExtended should explicitly import == from Base\n",
      "WARNING: module DataStructuresExtended should explicitly import == from Base\n",
      "WARNING: module DataStructuresExtended should explicitly import == from Base\n",
      "WARNING: module DataStructuresExtended should explicitly import == from Base\n",
      "WARNING: module DataStructuresExtended should explicitly import == from Base\n",
      "WARNING: replacing module FunctionalCollections\n",
      "WARNING: replacing module FunctionalCollections\n",
      "WARNING: replacing module FunctionalCollections\n",
      "WARNING: replacing module FunctionalCollections\n",
      "WARNING: replacing module FunctionalCollections\n",
      "WARNING: replacing module FunctionalCollections\n",
      "WARNING: replacing module FunctionalCollections\n",
      "WARNING: replacing module FunctionalCollections\n",
      "WARNING: replacing module FunctionalCollections\n",
      "WARNING: replacing module FunctionalCollections\n",
      "WARNING: replacing module FunctionalCollections\n"
     ]
    }
   ],
   "source": [
    "# import FunctionalCollections\n",
    "push!(LOAD_PATH, \".\")\n",
    "push!(LOAD_PATH, \"../util/\")\n",
    "import Iterators\n",
    "import Pipe\n",
    "import Compat\n",
    "import JLD\n",
    "import DataStructures\n",
    "import DataStructuresExtended\n",
    "@everywhere using FunctionalCollections\n",
    "@everywhere using Iterators\n",
    "@everywhere using Pipe\n",
    "@everywhere using Compat\n",
    "@everywhere using JLD\n",
    "@everywhere using DataStructures\n",
    "@everywhere using DataStructuresExtended\n",
    "\n",
    "macro printval(ee)\n",
    "    ee_expr = @sprintf \"%s\" string(ee)\n",
    "    esc(:(println($ee_expr,\" = \", $ee)))\n",
    "end\n",
    "\n",
    "macro pz(ee)\n",
    "    ee_expr = @sprintf \"%s\" string(ee)\n",
    "    esc(:(println($ee_expr,\"\\t\\t\",typeof($ee), \"\\t\", size($ee))))\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@everywhere const START_MARKER1 = Symbol(\"**START1**\")\n",
    "@everywhere const START_MARKER2 = Symbol(\"**START2**\")\n",
    "@everywhere const END_MARKER1 = Symbol(\"**END1**\")\n",
    "@everywhere const END_MARKER2 = Symbol(\"**END2**\")\n",
    "@everywhere typealias S Symbol\n",
    "@everywhere typealias State{T} Tuple{T,T}\n",
    "@everywhere const START_NODE_INDEX = 1\n",
    "@everywhere const END_NODE_INDEX = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_counts (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function load_counts(filename)\n",
    "    counts = Dict{Tuple{Symbol,Symbol,Symbol},Int}()\n",
    "    open(filename, \"r\") do fh\n",
    "        for line in eachline(fh)\n",
    "            word1,word2,word3,occurrences = split(line)\n",
    "            trigram = (Symbol(word1),Symbol(word2),Symbol(word3))\n",
    "            counts[trigram] = parse(Int,occurrences)\n",
    "        end\n",
    "    end\n",
    "    counts\n",
    "end\n",
    "#kn_lm = KneserNeyProbDist(ccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@everywhere type KneserNeyProbDist{T}\n",
    "    \"\"\"\n",
    "    Kneser-Ney estimate of a probability distribution. This is a version of\n",
    "    back-off that counts how likely an n-gram is provided the n-1-gram had\n",
    "    been seen in training. Extends the ProbDistI interface, requires a trigram\n",
    "    FreqDist instance to train on. Optionally, a different from default discount\n",
    "    value can be specified. The default discount is set to 0.75.\n",
    "    #Adapted from: http://www.nltk.org/_modules/nltk/probability.html\n",
    "    \"\"\"\n",
    "    \n",
    "    trigrams :: Accumulator{Tuple{T,T,T},Int}\n",
    "    bigrams  :: Accumulator{Tuple{T,T},Int}\n",
    "    trigrams_contain :: Accumulator{T,Int}\n",
    "    discount :: Float64\n",
    "    wordtypes_after :: Accumulator{Tuple{T,T},Int}\n",
    "    wordtypes_before :: Accumulator{Tuple{T,T},Int}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@everywhere function KneserNeyProbDist{T}(trigrams :: Dict{Tuple{T,T,T},Int}, discount=0.75)\n",
    "    \"\"\"\n",
    "    :param trigrams: The trigram frequency distribution upon which to base\n",
    "        the estimation\n",
    "    :param discount: The discount applied when retrieving counts of\n",
    "        trigrams\n",
    "    \"\"\"\n",
    "    # helper dictionaries used to calculate probabilities\n",
    "    trigrams_contain = counter(T)\n",
    "    bigrams  = counter(Tuple{T,T})\n",
    "    wordtypes_after = counter(Tuple{T,T})\n",
    "    wordtypes_before = counter(Tuple{T,T})\n",
    "\n",
    "    for ((w0, w1, w2),n) in trigrams\n",
    "        push!(trigrams_contain, w1)\n",
    "        push!(bigrams, (w0,w1), n)\n",
    "        push!(wordtypes_after,(w0,w1))  \n",
    "        push!(wordtypes_before,(w1,w2))\n",
    "    end\n",
    "    KneserNeyProbDist{T}(counter(trigrams), bigrams, trigrams_contain, discount, wordtypes_after, wordtypes_before)\n",
    "end\n",
    "    \n",
    "\n",
    "@everywhere function prob{T}(self::KneserNeyProbDist{T}, w0::T,w1::T, w2::T)\n",
    "    # if the sample trigram was seen during training\n",
    "    if (w0, w1,w2) in keys(self.trigrams)\n",
    "        @assert self.trigrams[(w0,w1,w2)]>self.discount\n",
    "        (self.trigrams[(w0,w1,w2)] - self.discount)/self.bigrams[(w0, w1)]\n",
    "    # else if the 'rougher' environment was seen during training\n",
    "    elseif (w0,w1) in keys(self.bigrams) && (w1,w2) in keys(self.wordtypes_before)\n",
    "        aftr = self.wordtypes_after[(w0, w1)]\n",
    "        bfr = self.wordtypes_before[(w1, w2)]\n",
    "\n",
    "        # the probability left over from alphas\n",
    "        leftover_prob = aftr * self.discount  / self.bigrams[(w0, w1)]\n",
    "        @assert leftover_prob>0\n",
    "        # the beta (including normalization)\n",
    "        beta = bfr / (self.trigrams_contain[w1] - aftr)\n",
    "        @assert beta>0\n",
    "        leftover_prob * beta\n",
    "    # else the sample was completely unseen during training\n",
    "    else\n",
    "        0.0\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kn_lm = open(deserialize, \"results/data/books/train_books_corpus.kn3gram.jsz\", \"r\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@spawn prob(kn_lm, symbol(\"'m\"), :so, :fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import JuMP\n",
    "import MathProgBase\n",
    "#import GLPKMathProgInterface\n",
    "import Gurobi\n",
    "@everywhere using JuMP\n",
    "@everywhere using MathProgBase\n",
    "#@everywhere using GLPKMathProgInterface\n",
    "@everywhere using Gurobi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@everywhere function get_subtours(x::Matrix{JuMP.Variable})\n",
    "    \"\"\"\n",
    "    returns the a vector of sets of node indexes, each set is a subtour\n",
    "    The First subtour returned is the nonconnected one -- the path\n",
    "    \"\"\"\n",
    "    x_val = getValue(x)\n",
    "    x_iis,x_jjs, _  = findnz(x_val .>= 1 - 1e-6) #It just has to be close to 1 to be true\n",
    "    nodes_chain = Dict([ii=>jj for (ii,jj) in zip(x_iis,x_jjs)])\n",
    "\n",
    "    subtours = IntSet[]\n",
    "    ii = START_NODE_INDEX\n",
    "    push!(subtours, IntSet(END_NODE_INDEX)) #The END Node is always in the same subtour as the start node\n",
    "    while(true)\n",
    "        while(true) #Cycle through current subtour\n",
    "            \n",
    "            push!(subtours[end],ii) \n",
    "            \n",
    "            jj = nodes_chain[ii]\n",
    "            println(ii,\" \", jj)\n",
    "            delete!(nodes_chain,ii)\n",
    "            if jj∈subtours[end] \n",
    "                break \n",
    "            end\n",
    "            ii=jj\n",
    "        end   \n",
    "\n",
    "        if length(nodes_chain)>0\n",
    "            ii = first(keys(nodes_chain)) #start new subtour\n",
    "            push!(subtours,IntSet())\n",
    "        else\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    subtours\n",
    "end\n",
    "\n",
    "@everywhere function get_coretours(x_links)\n",
    "    \"\"\"\n",
    "    Core tour goes from start to end (inclusive)\n",
    "    \"\"\"\n",
    "    nodes_chain = Dict([ii=>jj for (ii,jj) in x_links])\n",
    "\n",
    "    coretour = IntSet()\n",
    "    ii = START_NODE_INDEX\n",
    "    while(ii!=END_NODE_INDEX)            \n",
    "        push!(coretour,ii) \n",
    "        ii = nodes_chain[ii]\n",
    "    end   \n",
    "    push!(coretour, END_NODE_INDEX)\n",
    "    coretour\n",
    "end\n",
    "\n",
    "@everywhere function get_hyperclass(subtour,nodes,node_indexes_for_1st)\n",
    "    tour_hyper_class_nodes=IntSet()\n",
    "    for ii in subtour\n",
    "        w1,w2 = nodes[ii]\n",
    "        #println(unordered_markers[w1])\n",
    "        class_nodes = node_indexes_for_1st[w1]\n",
    "        union!(tour_hyper_class_nodes,class_nodes) \n",
    "    end\n",
    "    tour_hyper_class_nodes\n",
    "end\n",
    "\n",
    "@everywhere function get_sentence{T}(x_val::Matrix,unordered_markers::T,nodes::Vector{State{Int}})\n",
    "    x_iis,x_jjs, _  = findnz(x_val.>1-1e-6)\n",
    "    nodes_chain = Dict([ii=>jj for (ii,jj) in zip(x_iis,x_jjs)])\n",
    "    node_index=nodes_chain[START_NODE_INDEX]\n",
    "    node_index=nodes_chain[node_index] #Skip the first two as they are the start nodes\n",
    "    sent=T()\n",
    "    while(node_index!=END_NODE_INDEX)\n",
    "        node = nodes[node_index]\n",
    "        push!(sent, unordered_markers[node[1]])\n",
    "        node_index=nodes_chain[node_index]\n",
    "    end\n",
    "    sent\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eg_corpus = @pipe [\"name this 1922 novel about leopold bloom written by james joyce\",#* \" .\",\n",
    "    \"ralph waldo emerson dismissed this poet as the jingle man and james russell lowell called him three-fifths genius and two-fifths sheer fudge\",# * \" .\",\n",
    "    \"this is the basis of a comedy of manners first performed in 1892\",#*\" .\",\n",
    "    \"in a third novel a sailor abandons the patna and meets marlow who in another novel meets kurtz in the congo\",\n",
    "    \"thus she leaves her husband and child for aleksei vronsky but all ends sadly when she leaps in front of a train\",\n",
    "    \"we looked out at the setting sun .\",\n",
    "    \" i went to the kitchen .\",\n",
    "    \"how are you doing ?\"\n",
    "    ] |>map(split,_) |> map(shuffle,_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_bag=eg_corpus[end]\n",
    "\n",
    "#test_bag = shuffle(corpus[1022]) #length 28\n",
    "#test_bag = shuffle(corpus[1028]) #length 20  (Gurodi 4.2, GLTK : 2064.6 seconds)\n",
    "#test_bag = shuffle(corpus[1122]) #length 19 \n",
    "#test_bag = shuffle(corpus[1000]) #length 17 (Gurbodi: 5.8 sconds. GLTK:  569.9seconds)\n",
    "#test_bag = shuffle([\"he was the greatest of man , a hero to many .\"|> split])\n",
    "#est_bag = shuffle([\"this is but a silly joke -- that could never happen !\"|> split])\n",
    "#test_bag =  shuffle([\"this\",\"is\",\"the\" ,\"basis\",\"of\",\"a\" ,\"comedy\" ,\"of\",\"manners\",\"first\",\"performed\",\"in\",\"1892\", \".\"])\n",
    "#test_bag =  shuffle([\"this\",\"is\",\"the\" ,\"basis\",\"of\",\"a\" ,\"comedy\" ,\"of\",\"manners\",\".\"])\n",
    "#test_bag =  shuffle([\"this\",\"is\",\"the\" ,\"basis\",\"of\",\"a\",\"fine\",\"comedy\", \".\"])\n",
    "#^length 9, Gurodi 1.0, GLTK 5.3\n",
    "#test_bag =  shuffle([\"this\",\"is\",\"the\" ,\"basis\",\"of\",\"a\" ,\"comedy\", \".\"])\n",
    "#test_bag =  shuffle([\"it\", \"is\", \"so\", \"very\", \"good\", \".\"])\n",
    "#test_bag =  shuffle([\"it\", \"is\", \"very\", \"good\", \".\"])\n",
    "#test_bag =  shuffle([\"it\", \"is\", \"good\", \".\"])\n",
    "#test_bag =  [\"no\", \"way\", \".\"]\n",
    "#test_bag =  shuffle([\"no\", \".\"])\n",
    "#@time best_order(test_bag, lm, mem_limit=1000)\n",
    "test_bag = map(symbol, test_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@everywhere function prepare_model(unordered_words::Vector, lm::Function, silent=true)\n",
    "    m=Model(solver=GurobiSolver(OutputFlag=silent? 0:1, Threads=1))\n",
    "\n",
    "    unordered_markers = [START_MARKER1; START_MARKER2; END_MARKER1; END_MARKER2; unordered_words...]\n",
    "    #Note that this lacks END_MARKER2\n",
    "    @assert START_NODE_INDEX == 1\n",
    "    @assert END_NODE_INDEX == 2\n",
    "\n",
    "    nodes = State{Int}[] #Named by word index\n",
    "\n",
    "    node_indexes_for_1st = Dict{Int, Vector{Int}}()\n",
    "    node_indexes_for_2nd = Dict{Int, Vector{Int}}()\n",
    "\n",
    "    function add_node!(ii,jj)\n",
    "        push!(nodes, (ii,jj))\n",
    "\n",
    "        node_indexes_for_i_1st = get!(()->Int[], node_indexes_for_1st, ii)\n",
    "        push!(node_indexes_for_i_1st, length(nodes))\n",
    "\n",
    "        node_indexes_for_j_2nd = get!(()->Int[], node_indexes_for_2nd, jj) \n",
    "        push!(node_indexes_for_j_2nd, length(nodes))\n",
    "        #println(\"node:$(length(nodes)) |  $(unordered_markers[ii])($ii), $(unordered_markers[jj])($jj)\")\n",
    "    end\n",
    "\n",
    "    add_node!(1, 2) #That is START_MARKER1-> START_MARKER2\n",
    "    add_node!(3, 4) #That is END_MARKER1-> END_MARKER2\n",
    "\n",
    "    for ii in 1:length(unordered_markers)\n",
    "        wi = unordered_markers[ii]\n",
    "        if wi∈(END_MARKER1,START_MARKER1) continue end  #Covered these\n",
    "\n",
    "        for jj in 1:length(unordered_markers)\n",
    "            if ii==jj continue end\n",
    "            wj = unordered_markers[jj]\n",
    "            if wj∉(START_MARKER1,START_MARKER2,END_MARKER2)\n",
    "                #but wj can be  END_MARKER1\n",
    "                add_node!(ii,jj)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    @defVar(m, x[1:length(nodes), 1:length(nodes)], Bin)\n",
    "\n",
    "    #If you enter a node you must also leave it\n",
    "    for (cc, center_node) in enumerate(nodes)\n",
    "        if cc ∉ (START_NODE_INDEX, END_NODE_INDEX) #the beginning and end done have this requiement\n",
    "            #Everything that enters this node, must leave this node\n",
    "            @addConstraint(m, sum{x[ii,cc], ii=1:length(nodes)} == sum{x[cc,jj], jj=1:length(nodes)})\n",
    "        end\n",
    "    end\n",
    "\n",
    "    for class_index in 1:length(unordered_markers)\n",
    "        w_class =  unordered_markers[class_index]\n",
    "        if w_class∉(START_MARKER1,START_MARKER2)\n",
    "            #Not rquired to make a transition so that START_MARKER1 or 2 ever occur in second position\n",
    "            jjs = node_indexes_for_2nd[class_index]\n",
    "            @addConstraint(m, sum{x[ii,jj],ii=1:length(nodes), jj=jjs}==1)\n",
    "        end\n",
    "\n",
    "        #The following constraint is not required, as if it shows uo in the second position other rules make it certain to show up in the first\n",
    "        #if w_class∉(END_MARKER1,END_MARKER2)\n",
    "        #    #Not rquired to make a transition so that END_MARKER1 or 2 ever occur in second position\n",
    "        #    iis=node_indexes_for_1st[class_index]\n",
    "        #    @addConstraint(m, sum{x[ii,jj], ii=iis,jj=1:length(nodes)}==1)\n",
    "        #    rules[w_class*\"*\"]=Set(product(iis,1:length(nodes)))\n",
    "        #end\n",
    "    end\n",
    "\n",
    "    log_trans_prob = spzeros(length(nodes), length(nodes))\n",
    "    for (from_node_index, from_node) in enumerate(nodes)\n",
    "        w1 = unordered_markers[from_node[1]]\n",
    "        w2 = unordered_markers[from_node[2]]\n",
    "        #If what was in the second state element does not end up in the first state element then it is not allowed.\n",
    "        can_transition_to = Set(get(node_indexes_for_1st, from_node[2], Int[]))\n",
    "            #You can transition to any node which has your second element as its first element\n",
    "        for (to_node_index, to_node) in enumerate(nodes)\n",
    "            if to_node_index in can_transition_to\n",
    "                @assert(from_node[2]==to_node[1])\n",
    "                w3= unordered_markers[to_node[2]]\n",
    "                log_tp = log(lm(w1,w2,w3))\n",
    "                if log_tp>-Inf\n",
    "                    log_trans_prob[from_node_index, to_node_index] = log_tp\n",
    "                    continue\n",
    "                else\n",
    "                    #Banned as prob zero transitions not allowed\n",
    "                    @addConstraint(m, x[from_node_index,to_node_index]==0)\n",
    "                end\n",
    "\n",
    "            else\n",
    "                #It is not a legal transition\n",
    "                @addConstraint(m, x[from_node_index,to_node_index]==0)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    function eleminate_subtours(cb)\n",
    "        x_val = getValue(x)\n",
    "        x_iis,x_jjs, _  = findnz(x_val .>= 1 - 1e-6) #It just has to be close to 1 to be true\n",
    "        x_links=zip(x_iis,x_jjs)\n",
    "        coretour = get_coretours(x_links)\n",
    "        if length(coretour)==length(x_links)+1\n",
    "            #no subtour to eleminate\n",
    "            return\n",
    "        end\n",
    "        core_hyperclass = get_hyperclass(coretour, nodes, node_indexes_for_1st)\n",
    "\n",
    "        #Also the First subtour must go to one of the other subtours \n",
    "        arcs_outof_coretour = AffExpr()\n",
    "        for ii in core_hyperclass\n",
    "            for jj in 1:length(nodes)\n",
    "                if jj∉core_hyperclass\n",
    "                    arcs_outof_coretour += x[ii,jj]\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        @addLazyConstraint(cb, arcs_outof_coretour >=1)\n",
    "    end\n",
    "\n",
    "    addLazyCallback(m, eleminate_subtours,fractional=false)\n",
    "\n",
    "    #new Linear way using logprobs\n",
    "    @setObjective(m, Max, sum{log_trans_prob[i,j]*x[i,j], i=1:length(nodes), j=1:length(nodes)})\n",
    "    \n",
    "    m,x, nodes,unordered_markers\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@everywhere function lm(w0,w1,w2)\n",
    "    prob(kn_lm,w0,w1,w2)\n",
    "end\n",
    "@everywhere function remote_lm(w0,w1,w2)\n",
    "    remotecall_fetch(lm, 1, w0,w1,w2) #Ask processor 1 to tell us the prob\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@everywhere function best_order(unordered_words::Vector, lm::Function, silent=true)\n",
    "    tic()\n",
    "    m,x,nodes,unordered_markers = prepare_model(unordered_words, lm, silent)\n",
    "\n",
    "    status = solve(m,suppress_warnings=silent)\n",
    "    time_to_solve = toq()\n",
    "    solution_prob = e^getObjectiveValue(m)\n",
    "    generated_order = if status==:Optimal\n",
    "        x_val = getValue(x)\n",
    "        get_sentence(x_val, unordered_markers, nodes)\n",
    "    else\n",
    "        unordered_words \n",
    "    end\n",
    "    (generated_order, solution_prob, time_to_solve, status)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fetch(@spawnat 2 best_order([:he, :is, :the, :yo, :king, Symbol(\".\")], remote_lm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{ByteString,Any} with 1000 entries:\n",
       "  \"1\"   => [([:okay,symbol(\",\"),:i,:said,symbol(\",\"),:this,:is,:going,:to,:be,:…\n",
       "  \"519\" => [([:in,:our,:bedroom,:.,symbol(\"''\")],[:our,:in,:bedroom,:.,symbol(\"…\n",
       "  \"788\" => [([:im,:sorry,symbol(\",\"),:she,:rushed,:.],[:she,:im,:rushed,:.,:sor…\n",
       "  \"774\" => [([:i,:couldnt,:read,:his,:thoughts,:.],[:i,:read,:thoughts,:couldnt…\n",
       "  \"599\" => [([symbol(\"``\"),:no,symbol(\",\"),:it,symbol(\"'s\"),:not,:an,:excuse,sy…\n",
       "  \"491\" => [([symbol(\"``\"),:that,:could,symbol(\"n't\"),:have,:been,:easy,:for,:h…\n",
       "  \"228\" => [([:pizza,:and,:a,:coke,:.],[:a,:pizza,:and,:coke,:.],-5.608263f-7),…\n",
       "  \"332\" => [([symbol(\"``\"),:what,symbol(\"'s\"),:the,:point,:of,:this,:assignment…\n",
       "  \"190\" => [([:he,:set,:it,:down,:for,:a,:moment,:.],[:it,:for,:a,:he,:down,:se…\n",
       "  \"227\" => [([:he,:realised,:his,:question,:must,:have,:sounded,symbol(\"heavy-h…\n",
       "  \"980\" => [([symbol(\"``\"),:why,:do,:they,:have,:to,:be,:so,:sloppy,:?,symbol(\"…\n",
       "  \"297\" => [([:his,:stomach,:cramped,:.],[:his,:stomach,:cramped,:.],-0.0f0),([…\n",
       "  \"605\" => [([symbol(\"``\"),:no,:.,symbol(\"''\")],[symbol(\"``\"),symbol(\"''\"),:no,…\n",
       "  \"24\"  => [([:in,:that,:lodge,:all,:of,:the,:servants,:and,:maids,:slept  …  :…\n",
       "  \"928\" => [([symbol(\"``\"),:look,:in,:your,:sink,:.,symbol(\"''\")],[:your,symbol…\n",
       "  \"204\" => [([:the,:answer,symbol(\",\"),:simply,symbol(\",\"),:is,:i,:ca,symbol(\"n…\n",
       "  \"416\" => [([symbol(\"``\"),:hey,:!],[:!,symbol(\"``\"),:hey],-6.283f-7),([:the,:e…\n",
       "  \"23\"  => [([:ethan,:stopped,:cold,:as,:he,:noticed,:her,:expression,:go,:stun…\n",
       "  \"160\" => [([:she,:laughed,:at,:that,:.],[:she,:at,:that,:laughed,:.],-1.05092…\n",
       "  \"561\" => [([:instead,:of,:finding,:magic,symbol(\",\"),:she,:was,:selling,:her,…\n",
       "  \"859\" => [([:i,:just,:want,:to,:talk,:...,:.,:butch,:had,symbol(\"n't\")  …  sy…\n",
       "  \"891\" => [([:sam,:got,:us,:two,:bottles,:of,:water,:from,:the,:trailer,:refri…\n",
       "  \"815\" => [([:the,:cold,:damp,:wind,:immediately,:pounced,symbol(\",\"),:pulling…\n",
       "  \"981\" => [([:that,:sounded,:like,:something,:he,:would,:enjoy,:.],[:that,:he,…\n",
       "  \"253\" => [([:this,:is,:madness,:.],[:this,:is,:madness,:.],-0.0f0),([:the,:fi…\n",
       "  ⋮     => ⋮"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_name = \"books_corpus_0.01_of_test\"\n",
    "test_set_blocks = load(\"results/bags/$(corpus_name).jld\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jldopen_append (generic function with 1 method)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Blocks\n",
    "using Lumberjack\n",
    "add_truck(LumberjackTruck(\"ordering_$(corpus_name).log\"), \"file-logger\")\n",
    "function jldopen_append(func::Function, filename::AbstractString)\n",
    "    mode = isfile(filename) ? \"r+\" : \"w\" #Only open with \"w\" if it does't already exist\n",
    "    jldopen(func, filename, mode)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "run (generic function with 2 methods)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const res_type = Tuple{Array{Symbol,1},Array{Symbol,1},Float64,Float64,Symbol}\n",
    "\n",
    "function result_log(ii, block_res)\n",
    "    num_optimal=0\n",
    "    num_infeasible=0\n",
    "    num_noattempted=0\n",
    "    for res in block_res\n",
    "        status = res[end]\n",
    "        if status==:Optimal\n",
    "            num_optimal+=1\n",
    "        elseif status==:Infeasible\n",
    "            num_infeasible+=1\n",
    "        elseif status==:NotAttempted\n",
    "            num_noattempted+=1\n",
    "        else\n",
    "            error(\"Unexpected stats $(status)\")\n",
    "        end\n",
    "    end\n",
    "\n",
    "    Lumberjack.info(\"$ii done: Opt:$(num_optimal/length(block_res)*100)%, \"*\n",
    "                                \"Infeas:$(num_infeasible/length(block_res)*100)%, \"*\n",
    "                                \"NAttpt:$(num_noattempted/length(block_res)*100)%\")\n",
    "end\n",
    "\n",
    "function run(test_set_blocks, save_path=\"ordering.jld\")\n",
    "    try\n",
    "        Lumberjack.info(\"Began ordering\")\n",
    "        ii = 0 \n",
    "        map(@pipe test_set_blocks |> keys |> map(key->parse(Int,key),_) |>  sort |> map(string,_)) do (ii)\n",
    "            block = test_set_blocks[ii]\n",
    "\n",
    "            block_res::Vector{res_type} = pmap(block,err_stop=true) do bow_data\n",
    "                (ground_order_s, bow_s, selection_score) = bow_data\n",
    "                bow=map(Symbol, bow_s)\n",
    "                ground_order = map(Symbol,ground_order_s)\n",
    "                if length(ground_order_s)<=18\n",
    "                    #(ground_order, generated_order, solution_prob, time_to_solve, status)\n",
    "                    res = best_order(bow, remote_lm)\n",
    "                    (ground_order, res...)\n",
    "                else\n",
    "                    (ground_order, bow, NaN, 0.0, :NotAttempted)\n",
    "                end\n",
    "            end\n",
    "            result_log(ii,block_res)\n",
    "            \n",
    "            jldopen_append(save_path) do fh\n",
    "                write(fh,ii, block_res)\n",
    "            end\n",
    "            Lumberjack.debug(\"$ii written to disc\")\n",
    "        end\n",
    "    catch err\n",
    "        Lumberjack.error(\"Unhandled Error\", base_exception=err)\n",
    "    end\n",
    "    Lumberjack.info(\"complete selection\")\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-02-06T22:18:37 - info: Began ordering\n",
      "2016-02-06T22:20:51 - info: 1 done: Opt:58.2089552238806%, Infeas:5.970149253731343%, NAttpt:35.82089552238806%\n",
      "2016-02-06T22:20:52 - debug: 1 written to disc\n",
      "2016-02-06T22:22:53 - info: 2 done: Opt:76.11940298507463%, Infeas:5.970149253731343%, NAttpt:17.91044776119403%\n",
      "2016-02-06T22:22:53 - debug: 2 written to disc\n",
      "2016-02-06T22:27:07 - info: 3 done: Opt:65.67164179104478%, Infeas:10.44776119402985%, NAttpt:23.88059701492537%\n",
      "2016-02-06T22:27:07 - debug: 3 written to disc\n",
      "2016-02-06T22:29:18 - info: 4 done: Opt:74.6268656716418%, Infeas:7.462686567164178%, NAttpt:17.91044776119403%\n",
      "2016-02-06T22:29:18 - debug: 4 written to disc\n",
      "2016-02-06T22:33:33 - info: 5 done: Opt:62.68656716417911%, Infeas:10.44776119402985%, NAttpt:26.865671641791046%\n",
      "2016-02-06T22:33:33 - debug: 5 written to disc\n",
      "2016-02-06T22:34:19 - info: 6 done: Opt:68.65671641791045%, Infeas:7.462686567164178%, NAttpt:23.88059701492537%\n",
      "2016-02-06T22:34:19 - debug: 6 written to disc\n"
     ]
    }
   ],
   "source": [
    "run(test_set_blocks, \"results/ordered/$(corpus_name).jld\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample = typeof(test_set_blocks)()\n",
    "sample[\"1\"]=test_set_blocks[\"1\"][1:5]\n",
    "sample[\"2\"]=test_set_blocks[\"2\"][1:5]\n",
    "run(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "load(\"failed_ordering.jld\", 1 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "function get_irreducible_inconsistent_subsystem(m::JuMP.Model)    \n",
    "    grb_model = m.internalModel.inner\n",
    "    num_constrs = Gurobi.num_constrs(grb_model)\n",
    "    Gurobi.computeIIS(grb_model)\n",
    "    iis_constrs = Gurobi.get_intattrarray(grb_model, \"IISConstr\",  1, num_constrs)\n",
    "    m.linconstr[find(iis_constrs)]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iis = get_irreducible_inconsistent_subsystem(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count,constraint_index = indmax([length(constrant.terms.coeffs) for constrant in iis])\n",
    "constraint = iis[constraint_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m=Model(solver=GurobiSolver())\n",
    "@defVar(m,x, Int)\n",
    "@defVar(m,y, Int)\n",
    "@addConstraint(m,y<=1000) #This one won't cause problems\n",
    "@addConstraint(m,x>=6)    #This will\n",
    "@addConstraint(m,y>=6)    #This will \n",
    "#@addConstraint(m,x+y<=11) #This will\n",
    "\n",
    "status = solve(m)\n",
    "\n",
    "#@assert status==:Infeasible\n",
    "#get_irreducible_inconsistent_subsystem(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "getObjectiveV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function get_prod(x, iis, jjs)\n",
    "    net = 1.0\n",
    "    for i in 1:size(x,1) \n",
    "        for j in 1:size(x,2)\n",
    "            println(i,\",\", j, \" =\", x[i,j], \" \", trans_prob[i,j])\n",
    "            net*=max((x[i,j]-1)^2, trans_prob[i,j])\n",
    "        end\n",
    "    end\n",
    "    net\n",
    "end\n",
    "values = falses(size(x))\n",
    "values[1,3] = 1\n",
    "values[3,6] = 1\n",
    "values[6,7] = 1\n",
    "println(\"----------\\n\")\n",
    "get_prod(values, iis,jjs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@pyimport nltk.corpus as nltk_corpus\n",
    "corpus_reader=nltk_corpus.brown\n",
    "corpus = Vector{ASCIIString}[[lowercase(word) for word in sent] for sent in (corpus_reader[:sents]()|> collect)]\n",
    "const log_lm = train_language_model(corpus, loglikelyhood=true)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.0-dev",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
