{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using FunctionalCollections\n",
    "using Iterators\n",
    "using Pipe\n",
    "using Compat\n",
    "\n",
    "@everywhere macro printval(ee)\n",
    "    ee_expr = @sprintf \"%s\" string(ee)\n",
    "    esc(:(println($ee_expr,\" = \", $ee)))\n",
    "end\n",
    "\n",
    "macro pz(ee)\n",
    "    ee_expr = @sprintf \"%s\" string(ee)\n",
    "    esc(:(println($ee_expr,\"\\t\\t\",typeof($ee), \"\\t\", size($ee))))\n",
    "end\n",
    "\n",
    "push!(LOAD_PATH, \".\")\n",
    "push!(LOAD_PATH, \"../util/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "addprocs(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@everywhere using JLD\n",
    "@everywhere data = load(\"results/data/books/books300d.jld\")\n",
    "corpus_filename = \"test_books_corpus_0.001_of_test\"\n",
    "test_set = open(deserialize, \"results/data/books/\"*corpus_filename*\".jsz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#@everywhere using Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@everywhere function lookup_sowe(data, sent)\n",
    "    lookup_sowe(data, sent |> split)\n",
    "end\n",
    "\n",
    "@everywhere function lookup_sowe{S}(data, sent::Vector{S})\n",
    "    sum([data[\"LL\"][:,data[\"word_indexes\"][word]] for word in sent]) \n",
    "end\n",
    "\n",
    "@everywhere function lookup_words(data, path)\n",
    "    ASCIIString[data[\"indexed_words\"][ii] for ii in path]\n",
    "end\n",
    "\n",
    "@everywhere function lookup_indexes{S}(data, sent::Vector{S})\n",
    "    Int[data[\"word_indexes\"][word] for word in sent]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@everywhere const ϵ = 10.0^-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@everywhere @inline function get_end(LL, ws::AbstractVector{Int})\n",
    "    @inbounds sofar = length(ws)>0 ? sum([sub(LL,(:,ii)) for ii in ws]) : zeros(size(LL,1))\n",
    "    sofar\n",
    "end\n",
    "\n",
    "@everywhere function score_possible_additions(LL, target, end_point)\n",
    "    #-(sumabs(LL.+(end_point.-target),1)) #City Block\n",
    "    -sqrt(sumabs2(LL.+(end_point.-target),1)) #Eculidean\n",
    "    \n",
    "end   \n",
    "\n",
    "@everywhere  @inline function fitness(target, end_point)\n",
    "    #Fitter is larger\n",
    "    #-sumabs(end_point.-target) #city block\n",
    "    -norm(end_point.-target) #euclidean\n",
    "    \n",
    "end\n",
    "\n",
    "@everywhere function greedy_addition{F<:AbstractFloat}(LL::Matrix{F},\n",
    "                         target::Vector{F},\n",
    "                         initial_word_set::AbstractVector{Int},\n",
    "                         max_additions = Inf)\n",
    "    best_word_set = convert(Vector{Int},initial_word_set)\n",
    "    end_point = get_end(LL, best_word_set)\n",
    "    best_score = fitness(target, end_point)\n",
    "    \n",
    "    cur_additions = 0\n",
    "    while(cur_additions<max_additions)   \n",
    "        cur_additions+=1\n",
    "        addition_scores = score_possible_additions(LL, target, end_point)\n",
    "        addition_score, addition = findmax(addition_scores)\n",
    "        if addition_score>best_score+ϵ\n",
    "            #println(\"!add: $addition $best_score\")\n",
    "            best_score=addition_score\n",
    "            push!(best_word_set, addition)\n",
    "            end_point += sub(LL,(:,addition))\n",
    "        else \n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    best_word_set,best_score\n",
    "end\n",
    "\n",
    "\n",
    "@everywhere function word_swap_refinement{F<:AbstractFloat}(LL::Matrix{F},\n",
    "                              target::Vector{F},\n",
    "                              initial_word_set::AbstractVector{Int})\n",
    "    \n",
    "    best_word_set = copy(initial_word_set)\n",
    "    end_point = get_end(LL, initial_word_set)\n",
    "    best_score = fitness(target, end_point)\n",
    "    function update_best!(word_set,score)\n",
    "        if score>best_score+ϵ #scores are negative\n",
    "            best_score=score\n",
    "            best_word_set = word_set\n",
    "            #println(\"*swap, new set: $word_set $score\")\n",
    "        end\n",
    "    end\n",
    "    n_words_initial = length(initial_word_set)\n",
    "    for ii in 1:n_words_initial-1 #Don't need to consider last word added as it was added greedily\n",
    "        word_set = sub(initial_word_set,[1:ii-1; ii+1:n_words_initial])\n",
    "        sub_endpoint = end_point - sub(LL,(:,initial_word_set[ii]))\n",
    "        subset_score = fitness(target, sub_endpoint)\n",
    "        update_best!(word_set, subset_score)\n",
    "        \n",
    "\n",
    "        add_word_set, add_score = greedy_addition(LL, target, word_set, 1) #Try adding just one greedily\n",
    "        update_best!(add_word_set, add_score)\n",
    "    end\n",
    "\n",
    "    best_word_set,best_score\n",
    "        \n",
    "end\n",
    "\n",
    "\n",
    "@everywhere function greedy_search{F<:AbstractFloat}(data::Dict, target::Vector{F}; rounds=1000, log=false)\n",
    "    get_words(word_iis) = [data[\"indexed_words\"][ii] for ii in word_iis]\n",
    "    \n",
    "    word_iis = Int[]\n",
    "    best_word_iis = word_iis\n",
    "    best_score=-Inf\n",
    "    for round in 1:rounds\n",
    "        word_iis, add_score = greedy_addition(data[\"LL\"], target, word_iis)\n",
    "        log && println(\"POST_ADD_STEP: $add_score $(get_words(word_iis))\")\n",
    "        @assert add_score + ϵ >= best_score || best_word_iis == word_iis \"$add_score vs $best_score $(get_words(word_iis))\"\n",
    "        best_word_iis = word_iis\n",
    "        \n",
    "        if add_score>= 0.0 \n",
    "            best_score = add_score\n",
    "            break \n",
    "        end        \n",
    "        \n",
    "\n",
    "        \n",
    "        word_iis, swap_score = word_swap_refinement(data[\"LL\"], target, word_iis)\n",
    "        log && println(\"POST_SWAP_STEP: $swap_score $(get_words(word_iis))\")\n",
    "        @assert swap_score + ϵ >= add_score || best_word_iis == word_iis\n",
    "        best_word_iis = word_iis\n",
    "        \n",
    "        converged = best_score - ϵ<swap_score<best_score + ϵ || swap_score>=-ϵ\n",
    "        best_score=swap_score\n",
    "        if converged\n",
    "            break \n",
    "        end       \n",
    "    end\n",
    "    get_words(word_iis),best_score\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "@everywhere function greedy_search{S}(data::Dict, target_sent::Vector{S}; kwargs...)\n",
    "    target = lookup_sowe(data,target_sent)\n",
    "    greedy_search(data, target; kwargs...)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_sentence = ASCIIString[\"a\",\"few\",\"folks\",\"around\",\"here\",\"dont\",\"like\",\"you\",\",\",\"you\",\"know\",\",\",\"jake\",\",\",\"said\",\"the\",\"pastor\",\".\"]\n",
    "test_sentence = map(symbol,test_sentence)\n",
    "@time greedy_search(data_sym, test_sentence, rounds=10_000, log=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using Blocks\n",
    "using Lumberjack\n",
    "add_truck(LumberjackTruck(\"selection.log\"), \"file-logger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_set_blocks = Block(test_set, 1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function jldopen_append(func::Function, filename::AbstractString)\n",
    "    mode = isfile(filename) ? \"r+\" : \"w\" #Only open with \"w\" if it does't already exist\n",
    "    jldopen(func, filename, mode)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "const res_type = Tuple{Array{ASCIIString,1},Array{ASCIIString,1},Float32}\n",
    "function run(save_path=\"selection.jld\")\n",
    "    try\n",
    "        Lumberjack.info(\"Began selection\")\n",
    "        ii = 0 \n",
    "        map(test_set_blocks) do block\n",
    "            net_score = 0.0f0\n",
    "\n",
    "            block_res::Vector{res_type} = pmap(block,err_stop=true) do target_sent\n",
    "                target_sent=map(string, target_sent)\n",
    "                sol, score = greedy_search(data, target_sent, rounds=10_000, log=false)\n",
    "                net_score+=score\n",
    "                (target_sent, sol, score)\n",
    "            end\n",
    "            ii+=1\n",
    "            avg_score = net_score/length(block)\n",
    "            Lumberjack.info(\"$ii done: $avg_score\")\n",
    "            jldopen_append(save_path) do fh\n",
    "                write(fh,string(ii), block_res)\n",
    "            end\n",
    "            Lumberjack.debug(\"$ii written to disc\")\n",
    "        end\n",
    "    catch err\n",
    "        Lumberjack.error(\"Unhandled Error\", base_exception=err)\n",
    "    end\n",
    "    Lumberjack.info(\"complete selection\")\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run(\"results/bags/books_corpus_0.001_of_test_glove300.jld\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_sentence = ASCIIString[\"a\",\"few\",\"folks\",\"around\",\"here\",\"dont\",\"like\",\"you\",\",\",\"you\",\"know\",\",\",\"jake\",\",\",\"said\",\"the\",\"pastor\",\".\"]\n",
    "@time greedy_search(data, map(string,test_sentence), rounds=10_000, log=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[\"LL\"][:,data[\"word_indexes\"][\"_____________\"]] |> norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@save \"results/data/books/books300d_sym.jld\" data_sym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "?@save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[a=>2*b for (a,b) in [(1,2),(4,5)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = pmap(test_set[1:20], err_stop=true) do target_sent\n",
    "#res = map(test_set) do target_sent\n",
    "    target_sent=map(string, target_sent)\n",
    "    sol, score = greedy_search(data, target_sent, rounds=10_000, log=false)\n",
    "    (target_sent, sol, score)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using JLD\n",
    "@save \"results/bags/books300d.jld\" res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res[1] |> typeof |> typeof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_sent = test_set[67]\n",
    "target_sowe = lookup_sowe(data,target_sent)\n",
    "println(target_sent)\n",
    "println(\"-------------\")\n",
    "best_words, best_score  = greedy_search(data, target_sent, log=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########\n",
    "# Experimental\n",
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "methodswith(pset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=push(pset(),3)\n",
    "union(a, 5,4) |> length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function word_delete_refinement(LL::Matrix{Float64},\n",
    "                              target::Vector{Float64},\n",
    "                              best_word_set::Vector{Int},\n",
    "                              max_remove = 2\n",
    "        )\n",
    "    \n",
    "    initial_word_set = pset(best_word_set)\n",
    "    initial_end_point = get_end(LL, best_word_set)\n",
    "    best_score = fitness(target, initial_end_point)\n",
    "    \n",
    "    function inner(removed, endpoint)\n",
    "        #println(removed)\n",
    "        if length(removed)>max_remove\n",
    "            return\n",
    "        end\n",
    "        remaining =  setdiff(initial_word_set, removed)\n",
    "        \n",
    "        for del_word in remaining\n",
    "            new_endpoint = endpoint - sub(LL,(:,del_word))\n",
    "            del_score = fitness(target, new_endpoint)\n",
    "            \n",
    "            if del_score>best_score + ϵ\n",
    "                @inbounds best_word_set = remaining\n",
    "                best_score = del_score\n",
    "            end\n",
    "            \n",
    "            \n",
    "            inner(push(removed, del_word), endpoint)\n",
    "        end\n",
    "        \n",
    "    end\n",
    "    \n",
    "    inner(pset{Int}(),initial_end_point)\n",
    "\n",
    "    best_word_set,best_score\n",
    "        \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "before_words = [\"not\",\"after\",\"said\",\"election\",\"to\",\"the\",\",\",\"calls\",\"williams\",\"due\",\"bill\", \"anonymous\",\",\",\"subjected\",\"opens\",\"consisted\",\"snodgrass\",\".\",\"folks\",\"meanwhile\",\"truculent\",\"was\",\"soon\", \"he\"]\n",
    "before_word_iis = lookup_indexes(data, before_words)\n",
    "fitness(target_sowe, get_end(data[\"LL\"], before_word_iis))\n",
    "word_delete_refinement(data[\"LL\"], target_sowe, before_word_iis, 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fitness(target_sowe, get_end(data[\"LL\"], before_word_iis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Shorter Longer Refinement, for replaceing n words with m other words\n",
    "# Either the words in our current set are too short, so we can limit our search to words that are longer than the sum of our shortest\n",
    "# Or too long then we do the reverse\n",
    "\n",
    "#We are removing something, and planning to get closer to the path by adding something\n",
    "#things longer by adding a finite number more elements\n",
    "function make_longer_refinement2(LL::Matrix{Float64},\n",
    "                              target::Vector{Float64},\n",
    "                              best_word_set::Vector{Int},\n",
    "                              remove_indexes::Vector{Int},\n",
    "                              m_add::Int)\n",
    "    @assert(m_add>=0)\n",
    "    \n",
    "    rem_indexes = trues(best_word_set)\n",
    "    rem_indexes[remove_indexes] = false\n",
    "    \n",
    "    cur_word_set = best_word_set[rem_indexes]\n",
    "    cur_end_point = get_end(LL, cur_word_set)\n",
    "\n",
    "    cur_lengths = -score_possible_additions(LL[:,best_word_set], target, get_end(LL, Int[])) |> vec\n",
    "\n",
    "    length_removed = -fitness(target, get_end(LL,best_word_set)) -fitness(target, cur_end_point)\n",
    "        \n",
    "    @printval length_removed\n",
    "    LL_scores = -score_possible_additions(m_add*LL, target, get_end(LL, Int[]))\n",
    "    \n",
    "    valid_replacers = find((m_add-1)*maximum(LL_scores) + LL_scores.>=length_removed)   \n",
    "    valid_replacers\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "make_longer_refinement2(data[\"LL\"], target_sowe, best_wordset, [1:39;], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[\"indexed_words\"][40482]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "342/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LLscores = -score_possible_additions(3*data[\"LL\"], target_sowe, get_end(data[\"LL\"], Int[]))\n",
    "find(LLscores.<120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@everywhere function greedy_addition_with_backtrack_prep(LL::Matrix{Float64},\n",
    "                         target::Vector{Float64},\n",
    "                         best_word_set::Vector{Int},\n",
    "                         keep_per_word = 50,\n",
    "                         max_additions = Inf, \n",
    "                         \n",
    "    )\n",
    "    \n",
    "    end_point = get_end(LL, best_word_set)\n",
    "    best_score = fitness(target, end_point)\n",
    "    good_ideas = Set{Int}()\n",
    "    sizehint!(good_ideas, 10*keep_per_word) #Most sentences in most corpora have at least 10 words\n",
    "    did_improve = true\n",
    "    cur_additions = 0\n",
    "    while(did_improve && cur_additions<max_additions)\n",
    "        \n",
    "        cur_additions+=1\n",
    "        did_improve=false\n",
    "        \n",
    "        addition_scores = score_possible_additions(LL, target, end_point)\n",
    "        \n",
    "        high_scores = select!(collect(enumerate(addition_scores)), 1:keep_per_word, by=ii_score->ii_score[2])\n",
    "        \n",
    "        union!(good_ideas, map(ii_score->ii_score[1],high_scores))\n",
    "        \n",
    "        addition,addition_score = high_scores[1]\n",
    "        if addition_score>best_score+ϵ\n",
    "            #println(\"!add: $addition $best_score\")\n",
    "            best_score=addition_score\n",
    "            best_word_set = [best_word_set...,addition]\n",
    "            end_point += LL[:,addition]\n",
    "            did_improve=true\n",
    "        end\n",
    "    end\n",
    "    best_word_set,best_score,good_ideas\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_word_set,best_score,good_ideas  = greedy_addition_with_backtrack_prep(data[\"LL\"], target_sowe, Int[], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#@pipe good_ideas |> map(println,_)\n",
    "length(good_ideas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_delete_refinement(data[\"LL\"], target_sowe, best_wordset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "length(best_wordset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function double_word_swap_refinement(LL::Matrix{Float64},\n",
    "                              LL2::Matrix{Float64}, LL2_index,\n",
    "                              target::Vector{Float64},\n",
    "                              best_word_set::Vector{Int})\n",
    "    \n",
    "    initial_word_set = copy(best_word_set)\n",
    "    initial_end_point = get_end(LL, initial_word_set)\n",
    "    best_score = fitness(LL, target, best_word_set)\n",
    "    \n",
    "    for ii in 1:length(initial_word_set)\n",
    "        for jj in ii+1:length(initial_word_set)\n",
    "            @inbounds end_point = initial_end_point - LL[:,initial_word_set[ii]] - LL[:,initial_word_set[jj]]\n",
    "            addition_score, addition_index = findmax(score_possible_additions(LL2, target, end_point))\n",
    "            if addition_score>best_score + ϵ\n",
    "                #println(\"+= $(LL2_index[addition_index,:])\")\n",
    "                @inbounds word_subset = initial_word_set[[1:ii-1; ii+1:jj-1; jj+1:end]]\n",
    "                @inbounds best_word_set = [word_subset..., LL2_index[addition_index,:]...]\n",
    "                best_score = addition_score\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    best_word_set,best_score\n",
    "        \n",
    "end\n",
    "\n",
    "function get_LL2(LL)\n",
    "    len_LL2 = (size(LL,2).^2  + size(LL,2))÷ 2\n",
    "    LL2_index = Matrix{Int}(len_LL2, 2)\n",
    "    @printval(len_LL2)\n",
    "    LL2 = Matrix{Float64}(size(LL,1), len_LL2)\n",
    "    kk=0\n",
    "    for ii in 1:size(LL,2)\n",
    "        for jj in 1:ii\n",
    "            kk+=1\n",
    "            LL2_index[kk,:] = [ii,jj]\n",
    "            LL2[:,kk] = LL[:,ii]+LL[:,jj]\n",
    "        end\n",
    "    end\n",
    "    LL2, LL2_index\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LL2=get_LL2(data[\"LL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[\"LL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "819416403*50*2/ 1000_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_sowe = lookup_sowe(data,target_sent)\n",
    "@time new_best_words, new_best_score =double_word_swap_refinement(LL, LL2, LL2_index, target_sowe, best_wordset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_sent = test_set[12]\n",
    "println(target_sent)\n",
    "target_sowe = lookup_sowe(data,target_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for ii in 1:10\n",
    "    sample_sowe = (randn!(similar(target_sowe)) + target_sowe)\n",
    "    print(greedy_search(data, sample_sowe, 1,100, log=false)[1])\n",
    "    println(\",\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = pmap([1:length(test_set);], test_set) do ii,target_sent\n",
    "    sol, score = greedy_search(data, target_sent, 1, 100, log=false)\n",
    "    (sol, score, ii)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "open(\"atis2_res_glove.jsz\",\"w\") do fh\n",
    "    serialize(fh, (Vector{ASCIIString}[sol for (sol, score, ii) in res], test_set)\n",
    "    )    \n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "se = lookup_sowe(atis_data, [\"flights\",\"serve\",\"lunch\",\"which\"])\n",
    "se=se*0.6\n",
    "greedy_search(atis_data, se, 1, 5, log=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hard_cases = find(x->x[2]<0, res)\n",
    "res[hard_cases]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_set[hard_cases]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hard_set =  test_set[hard_cases]\n",
    "\n",
    "hard_res = pmap([1:length(hard_set);], hard_set) do ii,target_sent\n",
    "    sol, score = greedy_search(atis_data, target_sent, 2,5, log=false)\n",
    "    (sol, score, ii)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "very_hard_cases = find(x->x[2]<0.0, hard_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "factorial(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hard_res[very_hard_cases]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for (ii,target_sent) in enumerate(test_set)\n",
    "    sol, score = greedy_search(atis_data, target_sent, log=false)\n",
    "    if score>0\n",
    "        print(\"$ii - \")\n",
    "        println(join(target_sent, \" \"))\n",
    "    end\n",
    "end\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enumerate(test_set) |> collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.0-dev",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
