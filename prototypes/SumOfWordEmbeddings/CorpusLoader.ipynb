{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{ByteString,1}:\n",
       " \"/home/ubuntu/build/julia-master/usr/local/share/julia/site/v0.5\"\n",
       " \"/home/ubuntu/build/julia-master/usr/share/julia/site/v0.5\"      \n",
       " \".\"                                                              \n",
       " \"../util\"                                                        "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Iterators\n",
    "using DataStructures\n",
    "using Pipe\n",
    "using Compat\n",
    "\n",
    "macro printval(ee)\n",
    "    ee_expr = @sprintf \"%s\" string(ee)\n",
    "    esc(:(println($ee_expr,\" = \", $ee)))\n",
    "end\n",
    "\n",
    "macro pz(ee)\n",
    "    ee_expr = @sprintf \"%s\" string(ee)\n",
    "    esc(:(println($ee_expr,\"\\t\\t\",typeof($ee), \"\\t\", size($ee))))\n",
    "end\n",
    "\n",
    "push!(LOAD_PATH, \".\")\n",
    "push!(LOAD_PATH, \"../util\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using Packing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clean (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function clean(ss)\n",
    "    @pipe (ss \n",
    "    |> replace(_, r\"\\[.*?\\] ?\",\"\")  #Remove Nonword sounds\n",
    "    |> replace(_, r\"\\<.*?\\> \",\"\")  #Remove Verbal Deltions\n",
    "    |> replace(_, r\"\\*(.*?)\\*\",s\"\\1\") #Remove mispronounciation marks\n",
    "    |> replace(_,r\"\\:|\\-\\s\\.\\s\\-\", \"\") #remove intraword pauses\n",
    "    |> replace(_,r\"\\w+\\- \",\"\") #remove stuttered words\n",
    "    |> replace(_, r\"[!\\.,\\?]\",\"\")        #Remove punctation as it is not used traditionally (see sro spec)\n",
    "    \n",
    "    |> replace(_, r\"\\s+\",' ') #Remove repeated spaces\n",
    "    #|> replace(_, r\"([A-Z])\\s([A-Z])\", s\"\\1\\2\") #Merge len(2) abbrev\n",
    "    |> replace(_, r\".*[~\\(\\)\\-\\<\\>#'].*\",\"\")#Remove everything if anything unfixable found\n",
    "    |> lowercase\n",
    "    |> strip \n",
    "    )\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"**END**\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const START_MARKER = \"**START**\"\n",
    "const END_MARKER = \"**END**\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path=\"../../Resources/corpora/atis2_text/\"\n",
    "function valid(ss)\n",
    "    typeof(ss) <: ASCIIString  && length(ss)>0\n",
    "end\n",
    "    \n",
    "corpus = @pipe readdir(path)[1:4]  |> filter!(fn -> splitext(fn)[2]==\".sro\", _) |> map(_) do fn\n",
    "    try open(readall, path*fn) end\n",
    "    end |> filter!(valid,_) |> map(clean,_) |> filter!(valid,_) |> map(s->split(s),_);\n",
    "corpus_vocab = @pipe corpus |> map(Set,_) |> reduce(union,_)\n",
    "length(corpus_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using WordEmbeddings\n",
    "LL, word_indexes, indexed_words = load_word2vec_embeddings(\"word_emb_data/GoogleNews-vectors-negative300.bin\", length(corpus_vocab), corpus_vocab);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{UTF8String,1}:\n",
       " \"to\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setdiff(corpus_vocab,indexed_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300x17 Array{Float64,2}:\n",
       "  0.00374603   0.0746853    0.0348454    …  -0.0964167   0.0  0.0  0.0  0.0\n",
       " -0.0389198    0.0979106   -0.00010466       0.0181234   0.0  0.0  0.0  0.0\n",
       "  0.0913317    0.0464506    0.0456797        0.0547328   0.0  0.0  0.0  0.0\n",
       "  0.0120003    0.0498661    0.0319173        0.0739436   0.0  0.0  0.0  0.0\n",
       " -0.0705745   -0.062845     0.0150802       -0.026279    0.0  0.0  0.0  0.0\n",
       "  0.105343    -0.112483     0.012518     …  -0.0349782   0.0  0.0  0.0  0.0\n",
       "  0.0599364    0.0327887   -0.0415803       -0.104391    0.0  0.0  0.0  0.0\n",
       " -0.0573418   -0.110662    -0.0796467        0.0424088   0.0  0.0  0.0  0.0\n",
       "  0.0381414    0.0409858   -0.0415803        0.0025033   0.0  0.0  0.0  0.0\n",
       "  0.0110921    0.0281208    0.0983872        0.00602604  0.0  0.0  0.0  0.0\n",
       " -0.0653852   -0.0530539   -0.0629561    …  -0.0424088   0.0  0.0  0.0  0.0\n",
       " -0.0313953   -0.0710421   -0.0480223       -0.0366093   0.0  0.0  0.0  0.0\n",
       "  0.0537093    0.0120111   -0.0325029       -0.131939    0.0  0.0  0.0  0.0\n",
       "  ⋮                                      ⋱                         ⋮       \n",
       "  0.0555255   -0.0664881   -0.0281106       -0.0122333   0.0  0.0  0.0  0.0\n",
       " -0.00668123  -0.0833379   -0.0151534       -0.0764809   0.0  0.0  0.0  0.0\n",
       " -0.124024    -0.0664881   -0.178034     …   0.103666    0.0  0.0  0.0  0.0\n",
       " -0.0193302   -0.0281208    0.0351383        0.0757559   0.0  0.0  0.0  0.0\n",
       " -0.0498173   -0.012125     0.000947086     -0.0020049   0.0  0.0  0.0  0.0\n",
       "  0.09704      0.0152558    0.0093702        0.0132301   0.0  0.0  0.0  0.0\n",
       "  0.0144003   -0.0170774   -0.00585638       0.0357032   0.0  0.0  0.0  0.0\n",
       "  0.0679799    0.0138327    0.0819893    …  -0.0554577   0.0  0.0  0.0  0.0\n",
       " -0.0131679    0.00466783   0.0667627       -0.0971416   0.0  0.0  0.0  0.0\n",
       "  0.0059677    0.00341549   0.00607599      -0.0949668   0.0  0.0  0.0  0.0\n",
       "  0.0871803    0.0444013    0.0386521       -0.00282046  0.0  0.0  0.0  0.0\n",
       "  0.0568229   -0.0642112   -0.0177887        0.0227449   0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Kind of the opposite of a stop word. This word has little meaning (So zero value), but much structural importance\n",
    "forcewords = [\"and\", \"a\", \"of\", \"to\"]\n",
    "for word in forcewords\n",
    "    @assert(!(word in indexed_words))\n",
    "    push!(indexed_words, word)\n",
    "    word_indexes[word] = length(indexed_words)\n",
    "end\n",
    "LL = [LL zeros(size(LL,1),length(forcewords))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300x19 Array{Float64,2}:\n",
       "  0.00374603   0.0746853    0.0348454    …  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " -0.0389198    0.0979106   -0.00010466      0.0  0.0  0.0  0.0  0.0  0.0\n",
       "  0.0913317    0.0464506    0.0456797       0.0  0.0  0.0  0.0  0.0  0.0\n",
       "  0.0120003    0.0498661    0.0319173       0.0  0.0  0.0  0.0  0.0  0.0\n",
       " -0.0705745   -0.062845     0.0150802       0.0  0.0  0.0  0.0  0.0  0.0\n",
       "  0.105343    -0.112483     0.012518     …  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "  0.0599364    0.0327887   -0.0415803       0.0  0.0  0.0  0.0  0.0  0.0\n",
       " -0.0573418   -0.110662    -0.0796467       0.0  0.0  0.0  0.0  0.0  0.0\n",
       "  0.0381414    0.0409858   -0.0415803       0.0  0.0  0.0  0.0  0.0  0.0\n",
       "  0.0110921    0.0281208    0.0983872       0.0  0.0  0.0  0.0  0.0  0.0\n",
       " -0.0653852   -0.0530539   -0.0629561    …  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " -0.0313953   -0.0710421   -0.0480223       0.0  0.0  0.0  0.0  0.0  0.0\n",
       "  0.0537093    0.0120111   -0.0325029       0.0  0.0  0.0  0.0  0.0  0.0\n",
       "  ⋮                                      ⋱            ⋮                 \n",
       "  0.0555255   -0.0664881   -0.0281106       0.0  0.0  0.0  0.0  0.0  0.0\n",
       " -0.00668123  -0.0833379   -0.0151534       0.0  0.0  0.0  0.0  0.0  0.0\n",
       " -0.124024    -0.0664881   -0.178034     …  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " -0.0193302   -0.0281208    0.0351383       0.0  0.0  0.0  0.0  0.0  0.0\n",
       " -0.0498173   -0.012125     0.000947086     0.0  0.0  0.0  0.0  0.0  0.0\n",
       "  0.09704      0.0152558    0.0093702       0.0  0.0  0.0  0.0  0.0  0.0\n",
       "  0.0144003   -0.0170774   -0.00585638      0.0  0.0  0.0  0.0  0.0  0.0\n",
       "  0.0679799    0.0138327    0.0819893    …  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " -0.0131679    0.00466783   0.0667627       0.0  0.0  0.0  0.0  0.0  0.0\n",
       "  0.0059677    0.00341549   0.00607599      0.0  0.0  0.0  0.0  0.0  0.0\n",
       "  0.0871803    0.0444013    0.0386521       0.0  0.0  0.0  0.0  0.0  0.0\n",
       "  0.0568229   -0.0642112   -0.0177887       0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@assert(!(START_MARKER in indexed_words))\n",
    "push!(indexed_words, START_MARKER)\n",
    "word_indexes[START_MARKER] = length(indexed_words)\n",
    "\n",
    "@assert(!(END_MARKER in indexed_words))\n",
    "push!(indexed_words, END_MARKER)\n",
    "word_indexes[END_MARKER] = length(indexed_words)\n",
    "LL = [LL zeros(size(LL,1),2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "known_vocab = Set(indexed_words)\n",
    "known_corpus = filter(corpus) do sent\n",
    "    for word in sent\n",
    "        if !( word in known_vocab)\n",
    "            return false\n",
    "        end\n",
    "    end\n",
    "    true\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################LOADING Done, Now processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using DataStructures\n",
    "\n",
    "function Base.sum(acc::Accumulator)\n",
    "    sum(values(acc.map))\n",
    "end\n",
    "\n",
    "function Base.sum(acc::Dict)\n",
    "    sum(values(acc))\n",
    "end\n",
    "\n",
    "function freq2prob{T,V<:Number}(acc::Union{Accumulator{T,V},Dict{T,V}})\n",
    "    \n",
    "    ret=Dict{T,Float64}()\n",
    "    total = sum(acc)\n",
    "    for (k,v) in acc\n",
    "        ret[k]=v/total\n",
    "    end\n",
    "    ret\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "function collect_grams_stats(sentences)\n",
    "    unigrams = counter(AbstractString)\n",
    "    bigrams = DefaultDict(()->counter(AbstractString))\n",
    "    \n",
    "    for sent in sentences\n",
    "        push!(bigrams[START_MARKER], sent[1])\n",
    "        for ii in 1:length(sent)-1\n",
    "            push!(unigrams,sent[ii])\n",
    "            push!(bigrams[sent[ii]], sent[ii+1])    \n",
    "        end\n",
    "        push!(unigrams,sent[end])\n",
    "        push!(bigrams[sent[end]], END_MARKER)\n",
    "    end\n",
    "    \n",
    "    \n",
    "    [k=>v.map for (k,v) in bigrams], unigrams.map\n",
    "end\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using StatsBase\n",
    "# modified from https://github.com/JoFrhwld/GoodTuring.jl/blob/master/GoodTuring.jl\n",
    "function simpleGoodTuring(speciesCountDict::Dict)\n",
    "    speciesCountVec = collect(values(speciesCountDict))\n",
    "        \n",
    "    totalCounts = sum(speciesCountVec)\n",
    "    cofcDict = countmap(speciesCountVec)\n",
    "    r = sort(collect(keys(cofcDict)))\n",
    "\n",
    "    N = size(r,1)\n",
    "    Nr = [cofcDict[r[i]] for i in 1:N]\n",
    "\n",
    "    p0 = haskey(cofcDict, 1.0) ? cofcDict[1.0] / totalCounts : 0.0\n",
    "    \n",
    "    Z = sgtZ(r,Nr)\n",
    "    logr = map(log,r)\n",
    "    logZ = map(log,Z)\n",
    "\n",
    "    X = hcat(ones(N), logr)\n",
    "    Y = copy(logZ )\n",
    "    coefs = X\\Y\n",
    "    intercept = coefs[1]\n",
    "    slope = coefs[2]\n",
    "\n",
    "    useY = false\n",
    "    rSmooth = Array{Float64}(N)\n",
    "    for i in 1:N\n",
    "        @inbounds thisr = r[i]\n",
    "        \n",
    "        #y = ((thisr+1.0)^(slope+1.0))/(thisr^slope)\n",
    "        #The above is the much simplified form of the below (Performance identical output differs by 10^-16)\n",
    "        y = (thisr+1.0) * exp(slope * log(thisr+1.0) + intercept) / exp(slope * log(thisr) + intercept)\n",
    "\n",
    "        if !in(thisr+1, r)\n",
    "            useY = true\n",
    "        end\n",
    "\n",
    "        if useY\n",
    "            rSmooth[i] = y\n",
    "        else\n",
    "            x = (thisr+1) * cofcDict[thisr + 1]/cofcDict[thisr]\n",
    "            thisNr = cofcDict[thisr]\n",
    "            thisNr1 = cofcDict[thisr+1]\n",
    "\n",
    "            t = 1.96 * ((thisr+1)^2) * (thisNr1 / thisNr^2) * (1 + (thisNr1 / thisNr))\n",
    "\n",
    "            if abs(x-y) > t\n",
    "                @inbounds rSmooth[i] = x\n",
    "            else\n",
    "                useY = true\n",
    "                @inbounds rSmooth[i] = y\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    smoothTot = sum(Nr.*rSmooth)\n",
    "    sgtProb  = (1.0 - p0) .* (rSmooth/smoothTot)\n",
    "    sgtProbDict = Dict([r[i] => sgtProb[i] for i in 1:N])\n",
    "    sgtDict = Dict([sp=>sgtProbDict[speciesCountDict[sp]] for sp in keys(speciesCountDict)])\n",
    "\n",
    "    sgtDict, sgtProbDict, p0\n",
    "end\n",
    "\n",
    "\n",
    "function sgtZ(r::Array, Nr::Array)\n",
    "    j = r\n",
    "    i = [0; j[1:end-1]]\n",
    "    lastK = 2*j[end] - i[end]\n",
    "    k = [j[2:end]; lastK]\n",
    "    Float64[(2*Nr[iter])/(k[iter]-i[iter]) for iter = 1:length(j)]\n",
    "end\n",
    "\n",
    "function simpleGoodTuring(speciesCountVec::Vector)\n",
    "    sgtD = simpleGoodTuring(Dict([ii=>v for (ii,vv) in enumerate(speciesCountVec)]))\n",
    "    [sgtD[ii] for ii in 1:length(speciesCountVec)]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function katz_bigrams(bigram_freq::Dict, unigrams_freq::Dict)\n",
    "    k_bigrams = Dict()\n",
    "    \n",
    "    for first in keys(bigram_freq)\n",
    "        smoothed,_,p0 = simpleGoodTuring(bigram_freq[first])\n",
    "        k_bigrams[first] = smoothed\n",
    "        \n",
    "        backoff_keys = setdiff(keys(unigram_freq),keys(smoothed))\n",
    "        #share the p0 proability mass between them\n",
    "        total = sum([unigrams_freq[key] for key in backoff_keys])\n",
    "        for second in backoff_keys\n",
    "            k_bigrams[first][second]=p0.*unigrams_freq[second]./total\n",
    "        end\n",
    "    end\n",
    "    k_bigrams\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function dict2mat(bigrams::Dict, word_indexes::Dict{AbstractString,Int64}, dense=False)\n",
    "    mat  = (dense ? zeros: spzeros)(length(word_indexes),length(word_indexes))\n",
    "    for first in keys(bigrams)\n",
    "        for second in keys(bigrams[first])\n",
    "            mat[word_indexes[second], word_indexes[first]] = bigrams[first][second]\n",
    "        end\n",
    "    end\n",
    "    mat\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigram_freq, unigram_freq = collect_grams_stats(known_corpus);\n",
    "kbigrams=katz_bigrams(bigram_freq, unigram_freq)\n",
    "kbigrams_mat = dict2mat(kbigrams,word_indexes,true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using Gadfly\n",
    "using Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sent_lengths = map(length, known_corpus)\n",
    "plot(x=sent_lengths, Geom.histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sent_length_dist = fit_mle(Gamma, sent_lengths)\n",
    "plot(x=[round(rand(sent_length_dist)) for _ in 1:length(sent_lengths)], Geom.histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "length_prob=cdf(sent_length_dist,[1.5:1.0:50.5])-cdf(sent_length_dist,[0.5:1.0:49.5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function collect_cooccur_stats(sentences)\n",
    "    unioccur = counter(AbstractString)\n",
    "    bioccur = DefaultDict(()->counter(AbstractString))\n",
    "    \n",
    "    for sent in sentences\n",
    "        for ii in 1:length(sent)\n",
    "            push!(unioccur, sent[ii])\n",
    "            for jj in 1:length(sent)\n",
    "                if ii==jj\n",
    "                    continue\n",
    "                end\n",
    "                push!(bioccur[sent[ii]], sent[jj])    \n",
    "            end\n",
    "        end       \n",
    "    end\n",
    "    \n",
    "    [k=>v.map for (k,v) in bioccur], unioccur.map\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bioccur_freq, unioccur_freq = collect_cooccur_stats(known_corpus)\n",
    "\n",
    "bioccur_mat = dict2mat(bioccur_freq,word_indexes,true)\n",
    "bioccur_mat.+=1.0 # Add one smoothing\n",
    "bioccur_mat./=sum(bioccur_mat)\n",
    "\n",
    "unioccur = freq2prob(unioccur_freq)\n",
    "unioccur_vec = Float64[word in keys(unioccurs) ? unioccurs[word] : 0.0 for word in indexed_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unioccur_vec_smoothed = Float64[word in keys(unioccur_freq) ? unioccur_freq[word] : 0.0 for word in indexed_words]\n",
    "unioccur_vec_smoothed.+=1.0 # Add one smoothing\n",
    "unioccur_vec_smoothed./=sum(unioccur_vec_smoothed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(bioccur_mat,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "open(\"atis_data.jsz\",\"w\") do fh\n",
    "    data = Dict([\n",
    "        (\"bigrams\", kbigrams_mat),\n",
    "        (\"bioccur\", bioccur_mat),\n",
    "        (\"unioccur\", unioccur_vec),\n",
    "        \n",
    "        (\"length_prob\", length_prob),\n",
    "        (\"LL\",LL),\n",
    "        (\"word_indexes\", word_indexes),\n",
    "        (\"indexed_words\", indexed_words),\n",
    "        ])\n",
    "    serialize(fh, data)    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function likelyhood(sent, bigrams)\n",
    "    words = split(sent)\n",
    "    words = [START_MARKER; words; END_MARKER]\n",
    "    \n",
    "    p=1.0\n",
    "    for ii in 1:length(words)-1\n",
    "        p*=bigrams[words[ii]][words[ii+1]]\n",
    "    end\n",
    "    p\n",
    "end\n",
    "\n",
    "\n",
    "function select_word{S<:AbstractString,V}(unigrams::Dict{S,V})\n",
    "    cutoff = rand()\n",
    "    total = 0.0\n",
    "    for next_word in keys(unigrams)\n",
    "        total+=unigrams[next_word]\n",
    "        if total>=cutoff\n",
    "            return next_word\n",
    "        end\n",
    "    end\n",
    "    assert(False, \"Should never reach here\") \n",
    "end\n",
    "\n",
    "function random_walk(bigrams)\n",
    "    words=[]\n",
    "    cur = START_MARKER\n",
    "    while(cur!=END_MARKER)\n",
    "        cur = select_word(bigrams[cur])\n",
    "        push!(words,cur)\n",
    "    end\n",
    "    words = words[1:end-1]\n",
    "    join(words, \" \")\n",
    "end\n",
    "\n",
    "walk =random_walk(kbigrams) \n",
    "print(walk*\"\\t\")\n",
    "print(likelyhood(walk,kbigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frame's Magic Mass-Sharing Co-occurance PMF, Inspired by Bengio 2003\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "addprocs(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "immutable LU_NN{N<:Number}\n",
    "    C::Matrix{N} #lookup matrix\n",
    "    H::Matrix{N}\n",
    "    d::Vector{N}\n",
    "    U::Matrix{N}\n",
    "    b::Vector{N}\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prepare_cases (generic function with 1 method)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function prepare_cases(sentence)\n",
    "    Task() do\n",
    "        sentence_iis = Int[word_indexes[word] for word in sentence]\n",
    "        for n_givens in 1:length(sentence_iis)\n",
    "            given_prob = 2*1.0/(n_givens)\n",
    "            given_keep = rand(length(sentence_iis)).<given_prob\n",
    "            given_iis::Vector{Int} =  sentence_iis[given_keep]\n",
    "            cooccur_iis::Vector{Int} =  sentence_iis[~given_keep]\n",
    "            produce(given_iis, cooccur_iis)\n",
    "        end   \n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28-element Array{Tuple{Array{Int64,1},Array{Int64,1}},1}:\n",
       " ([4,1,2,11,5,17,9,3,12,17,13],Int64[])\n",
       " ([4,1,2,11,5,17,9,3,12,17,13],Int64[])\n",
       " ([4,1,2,5,17,9,3,12,17],[11,13])      \n",
       " ([1,11,17,12],[4,2,5,9,3,17,13])      \n",
       " ([4,1,3],[2,11,5,17,9,12,17,13])      \n",
       " ([4,17,3],[1,2,11,5,9,12,17,13])      \n",
       " ([2],[4,1,11,5,17,9,3,12,17,13])      \n",
       " ([4,9,12],[1,2,11,5,17,3,17,13])      \n",
       " ([1],[4,2,11,5,17,9,3,12,17,13])      \n",
       " (Int64[],[4,1,2,11,5,17,9,3,12,17,13])\n",
       " ([4,11,17,12],[1,2,5,9,3,17,13])      \n",
       " ([10,7,17,6,3,12,17,13],Int64[])      \n",
       " ([10,7,17,6,3,12,17,13],Int64[])      \n",
       " ⋮                                     \n",
       " ([12],[10,7,17,6,3,17,13])            \n",
       " ([10,3,17],[7,17,6,12,13])            \n",
       " (Int64[],[10,7,17,6,3,12,17,13])      \n",
       " ([4,1,2,11,8,3,12,17,13],Int64[])     \n",
       " ([4,1,2,11,8,3,12,17,13],Int64[])     \n",
       " ([4,1,2,8,12],[11,3,17,13])           \n",
       " ([4,1,11,3,12,17],[2,8,13])           \n",
       " ([1,12],[4,2,11,8,3,17,13])           \n",
       " ([4,1,8,3,12,13],[2,11,17])           \n",
       " ([8,3,12],[4,1,2,11,17,13])           \n",
       " ([1,3,12,17],[4,2,11,8,13])           \n",
       " ([4,2,11,8,13],[1,3,12,17])           "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_case_type = Tuple{Vector{Int64},Vector{Int64}}\n",
    "training_cases = @pipe (known_corpus\n",
    "                            |> map(prepare_cases, _) |> chain(_...)\n",
    "                            |> repeated(_, 5) |> chain(_...) \n",
    "                            |> collect(training_case_type,_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LU_NN{N<:Number}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function LU_NN(dEmb, dHidden, dOut)\n",
    "    LU_NN(\n",
    "        0.01*(randn((dEmb,dOut))), #C\n",
    "        0.01*(randn((dHidden,dEmb))), #H\n",
    "        0.01*(randn(dHidden)), #d\n",
    "        0.01*(randn((dOut,dHidden))), #U\n",
    "        0.01*(randn(dOut))#b\n",
    "    )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@everywhere function softmax(xs)\n",
    "    numer = exp(xs)\n",
    "    numer./sum(numer)\n",
    "end\n",
    "\n",
    "\n",
    "@everywhere function σ(xs)\n",
    "    1.0./(1+exp(-xs))\n",
    "end\n",
    "\n",
    "#########################################\n",
    "\n",
    "\n",
    "\n",
    "@everywhere function δ(δ_above, W)\n",
    "    (W'*δ_above)\n",
    "end\n",
    "\n",
    "@everywhere function δ_tanh(δ_above, a)\n",
    "    const dz = 1-a.^2\n",
    "    δ_above.*dz\n",
    "end\n",
    "\n",
    "@everywhere function δ_softmax_ce(actual, expected)\n",
    "    actual-expected\n",
    "end\n",
    "\n",
    "@everywhere function δ_σ(δ_above, a)\n",
    "    const dz = a .- a.^2\n",
    "    δ_above.*dz\n",
    "end\n",
    "\n",
    "@everywhere function δ_output_sq_loss(actual, expected) \n",
    "    -(expected-actual)\n",
    "end\n",
    "\n",
    "#############################################\n",
    "\n",
    "@everywhere function sq_loss(actual, expected)\n",
    "    0.5*sum((expected-actual).^2)\n",
    "end\n",
    "\n",
    "@everywhere function ce_loss(actual, expected)\n",
    "    -sum(expected.*log(actual))\n",
    "end\n",
    "\n",
    "@everywhere function forward(x,nn::LU_NN)\n",
    "    aa = tanh(nn.H*x+nn.d)\n",
    "    out = softmax(nn.U*aa + nn.b)\n",
    "    out, aa\n",
    "end\n",
    "\n",
    "@everywhere function feedforward_backprop(xx,nn::LU_NN, expected_output)\n",
    "    actual_output, aa = forward(xx,nn)\n",
    "    err = ce_loss(actual_output, expected_output)\n",
    "    δ_top = δ_softmax_ce(actual_output, expected_output)\n",
    "    ΔU  = δ_top*aa'\n",
    "    Δb  = δ_top\n",
    "    δ_hidden = δ_tanh(δ(δ_top, nn.U),aa)\n",
    "    ΔH  = δ_hidden*xx'\n",
    "    Δd  = δ_hidden\n",
    "    δ_bottom = δ(δ_hidden, nn.H)\n",
    "    Δx  = δ_bottom\n",
    "    Δx,ΔH,Δd,ΔU,Δb,err\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(t) == a_err = true\n",
      "findmax(abs(d_x .- a_x)) = (1.0842021724855044e-19,3)\n",
      "findmax(abs(d_H .- a_H)) = (1.0842021724855044e-19,12)\n",
      "findmax(abs(d_d .- a_d)) = (3.469446951953614e-18,12)\n",
      "findmax(abs(d_U .- a_U)) = (1.734723475976807e-18,69)\n",
      "findmax(abs(d_b .- a_b)) = (5.551115123125783e-17,10)\n"
     ]
    }
   ],
   "source": [
    "nn_outer = LU_NN(8, 16, length(indexed_words));\n",
    "\n",
    "xx=sum([nn_outer.C[:,g_ii] for g_ii in [1,2,3]])\n",
    "target = zeros(nn_outer.b)\n",
    "target[[10,11,12]]=1.0/3\n",
    "\n",
    "\n",
    "using ForwardDiff\n",
    "\n",
    "function f(θ)\n",
    "    x,H,d,U,b = unpack(θ,size(xx),(16,8),16,(19,16),19)\n",
    "    nn =  LU_NN(0.0*H, H,d,U,b)#using 0.0*H as a dummy value for C\n",
    "    \n",
    "    actual, _=forward(x,nn)\n",
    "    ce_loss(actual, target)\n",
    "end\n",
    "\n",
    "function calc_ag(θ)\n",
    "    x,H,d,U,b = unpack(θ,size(xx),(16,8),16,(19,16),19)\n",
    "    nn =  LU_NN(0.0*H, H,d,U,b) #using 0.0*H as a dummy value for C\n",
    "    Δx,ΔH,Δd,ΔU,Δb,err = feedforward_backprop(x,nn, target)\n",
    "end\n",
    "\n",
    "g = ForwardDiff.gradient(f)\n",
    "\n",
    "t=pack(xx,nn_outer.H,nn_outer.d,nn_outer.U,nn_outer.b)\n",
    "a_x, a_H, a_d, a_U, a_b, a_err = calc_ag(t)\n",
    "dg = g(t)  #Commented out so can't be run  \n",
    "d_x, d_H, d_d, d_U, d_b = unpack(dg,size(xx),(16,8),16,(19,16),19)\n",
    "\n",
    "\n",
    "@printval f(t) == a_err\n",
    "@printval findmax(abs(d_x .- a_x))\n",
    "@printval findmax(abs(d_H .- a_H))\n",
    "@printval findmax(abs(d_d .- a_d))\n",
    "@printval findmax(abs(d_U .- a_U))\n",
    "@printval findmax(abs(d_b .- a_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_U\t\tArray{Float64,2}\t(19,16)\n",
      "nn_outer.U\t\tArray{Float64,2}\t(19,16)\n"
     ]
    }
   ],
   "source": [
    "@pz d_U\n",
    "@pz nn_outer.U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "findmax(abs(nn_outer.H .- d_H)) = (0.023995581845296828,72)\n",
      "findmax(abs(nn_outer.d .- d_d)) = (0.02595172940401666,5)\n",
      "findmax(abs(nn_outer.U .- d_U)) = (0.029180588881421714,61)\n",
      "findmax(abs(nn_outer.b .- d_b)) = (0.293020737520177,10)\n"
     ]
    }
   ],
   "source": [
    "@printval findmax(abs(nn_outer.H .- d_H))\n",
    "@printval findmax(abs(nn_outer.d .- d_d))\n",
    "@printval findmax(abs(nn_outer.U .- d_U))\n",
    "@printval findmax(abs(nn_outer.b .- d_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_all (generic function with 1 method)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@everywhere function mysubarray(xs, id=myid(), nchunks=nworkers())\n",
    "    len = length(xs)\n",
    "    chunk_size = div(len, nchunks+1)\n",
    "    start_index = (id-2)*chunk_size + 1\n",
    "    end_index = start_index+chunk_size-1\n",
    "    print(start_index : end_index)\n",
    "    sub(xs, start_index : end_index)\n",
    "end\n",
    "\n",
    "@everywhere function train_one(given_iis, target_iis, C, W, b)\n",
    "    given_sowe = length(given_iis)>0 ? sum([C[:,g_ii] for g_ii in given_iis]) : zeros(C[:,1])\n",
    "    target = zeros(b) #just while we are testing use a one hot set rep\n",
    "    for t_ii in target_iis\n",
    "        target+=1.0/length(target_iis)\n",
    "    end\n",
    "        \n",
    "    Δx,ΔW,Δb, err = feedforward_backprop(given_sowe,W,b, target)\n",
    "    \n",
    "    ΔC = zeros(C)\n",
    "    for g_ii in given_iis\n",
    "        @inbounds ΔC[:, g_ii]+=Δx\n",
    "    end\n",
    "    ΔC,ΔW,Δb, err\n",
    "end\n",
    "\n",
    "\n",
    "function train_all(training_cases,C, W, b)\n",
    "    \n",
    "    function accumulate_training_over(cases,fun)\n",
    "        total_ΔC=zeros(C)\n",
    "        total_ΔW=zeros(W)\n",
    "        total_Δb=zeros(b)\n",
    "        total_err = 0.0\n",
    "        for case in cases\n",
    "            ΔC, ΔW, Δb,err = fun(case)\n",
    "            @inbounds total_ΔC+=ΔC\n",
    "            @inbounds total_ΔW+=ΔW\n",
    "            @inbounds total_Δb+=Δb\n",
    "            total_err+=err\n",
    "        end\n",
    "        total_ΔC, total_ΔW, total_Δb, total_err\n",
    "    end\n",
    "    \n",
    "    function train_remote()\n",
    "        accumulate_training_over(mysubarray(training_cases),\n",
    "                                 gt_iis -> train_one(gt_iis[1], gt_iis[2], C, W, b) )\n",
    "    end\n",
    "    \n",
    "    r_updates = [@spawnat(id, train_remote())  for id in workers()]\n",
    "        \n",
    "    totals = accumulate_training_over(r_updates, fetch)\n",
    "    ([tot./length(training_cases) for tot in totals]...)\n",
    "end\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function uncached_loss_and_loss_grad!(θ::Vector, grad::Vector)    \n",
    "    C, W, b = unpack!(θ, CC,WW,bb)\n",
    "    ΔC, ΔW, Δb, err = train_all(training_cases, C, W, b )\n",
    "    pack!(grad, ΔC, ΔW, Δb)\n",
    "    err\n",
    "end\n",
    "\n",
    "_loss_and_loss_grad=Dict{Vector{Float64},Tuple{Float64, Vector{Float64}}}()\n",
    "function loss_and_loss_grad!(θ::Vector, grad::Vector)    \n",
    "    if haskey(_loss_and_loss_grad,θ)\n",
    "        err, grad[:]= _loss_and_loss_grad[θ]\n",
    "    else\n",
    "        err = uncached_loss_and_loss_grad!(θ, grad)\n",
    "        _loss_and_loss_grad[θ] = (err, copy(grad))\n",
    "    end\n",
    "    err\n",
    "end\n",
    "\n",
    "function loss!(θ::Vector)  \n",
    "    dummy_grad = similar(θ) \n",
    "    loss_and_loss_grad!(θ, dummy_grad)\n",
    "end\n",
    "\n",
    "function loss_grad!(θ::Vector, storage::Vector) \n",
    "    #warn(\"loss_grad not defined\")\n",
    "    loss_and_loss_grad!(θ, grad)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using Optim\n",
    "push!(LOAD_PATH, \"../Optimisation\")\n",
    "using AdaDelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opt_func = DifferentiableFunction(loss!,loss_grad!,loss_and_loss_grad!)\n",
    "θ=pack(CC,WW,bb)\n",
    "#@time res = optimize(opt_func, θ, method=:l_bfgs, show_trace = true, store_trace = true, iterations = 10);\n",
    "@time res = adadelta(opt_func, θ, show_trace = true, iterations = 500);\n",
    "@printval res.f_calls \n",
    "@printval res.g_calls \n",
    "@printval res.iterations\n",
    "@printval res.f_minimum\n",
    "@printval res.gr_converged\n",
    "@printval res.x_converged                       \n",
    "@printval res.f_converged \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sowe = CC[:,word_indexes[\"ground\"]]\n",
    "ns = forward(sowe,WW,bb)\n",
    "indexed_words[findmax(ns)[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@printval res.gr_converged\n",
    "@printval res.x_converged                       \n",
    "@printval res.f_converged \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "var(CC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "var(bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "var(WW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.0-dev",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
