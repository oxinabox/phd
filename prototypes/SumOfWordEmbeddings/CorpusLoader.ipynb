{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{ByteString,1}:\n",
       " \"/home/ubuntu/build/julia-master/usr/local/share/julia/site/v0.5\"\n",
       " \"/home/ubuntu/build/julia-master/usr/share/julia/site/v0.5\"      \n",
       " \".\"                                                              \n",
       " \"../util\"                                                        "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Iterators\n",
    "using DataStructures\n",
    "using Pipe\n",
    "using Compat\n",
    "\n",
    "macro printval(ee)\n",
    "    ee_expr = @sprintf \"%s\" string(ee)\n",
    "    esc(:(println($ee_expr,\" = \", $ee)))\n",
    "end\n",
    "\n",
    "macro pz(ee)\n",
    "    ee_expr = @sprintf \"%s\" string(ee)\n",
    "    esc(:(println($ee_expr,\"\\t\\t\",typeof($ee), \"\\t\", size($ee))))\n",
    "end\n",
    "\n",
    "push!(LOAD_PATH, \".\")\n",
    "push!(LOAD_PATH, \"../util\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using Packing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "freq2prob (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using DataStructures\n",
    "\n",
    "function Base.sum(acc::Accumulator)\n",
    "    sum(values(acc.map))\n",
    "end\n",
    "\n",
    "function Base.sum(acc::Dict)\n",
    "    sum(values(acc))\n",
    "end\n",
    "\n",
    "function freq2prob{T,V<:Number}(acc::Union{Accumulator{T,V},Dict{T,V}})\n",
    "    \n",
    "    ret=Dict{T,Float64}()\n",
    "    total = sum(acc)\n",
    "    for (k,v) in acc\n",
    "        ret[k]=v/total\n",
    "    end\n",
    "    ret\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clean (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function clean(ss)\n",
    "    @pipe (ss \n",
    "    |> replace(_, r\"\\[.*?\\] ?\",\"\")  #Remove Nonword sounds\n",
    "    |> replace(_, r\"\\<.*?\\> \",\"\")  #Remove Verbal Deltions\n",
    "    |> replace(_, r\"\\*(.*?)\\*\",s\"\\1\") #Remove mispronounciation marks\n",
    "    |> replace(_,r\"\\:|\\-\\s\\.\\s\\-\", \"\") #remove intraword pauses\n",
    "    |> replace(_,r\"\\w+\\- \",\"\") #remove stuttered words\n",
    "    |> replace(_, r\"[!\\.,\\?]\",\"\")        #Remove punctation as it is not used traditionally (see sro spec)\n",
    "    \n",
    "    |> replace(_, r\"\\s+\",' ') #Remove repeated spaces\n",
    "    #|> replace(_, r\"([A-Z])\\s([A-Z])\", s\"\\1\\2\") #Merge len(2) abbrev\n",
    "    |> replace(_, r\".*[~\\(\\)\\-\\<\\>#'].*\",\"\")#Remove everything if anything unfixable found\n",
    "    |> lowercase\n",
    "    |> strip \n",
    "    )\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "collect_grams_stats (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const START_MARKER = \"**START**\"\n",
    "const END_MARKER = \"**END**\"\n",
    "\n",
    "function collect_grams_stats(sentences)\n",
    "    unigrams = counter(AbstractString)\n",
    "    bigrams = DefaultDict(()->counter(AbstractString))\n",
    "    \n",
    "    for sent in sentences\n",
    "        push!(bigrams[START_MARKER], sent[1])\n",
    "        for ii in 1:length(sent)-1\n",
    "            push!(unigrams,sent[ii])\n",
    "            push!(bigrams[sent[ii]], sent[ii+1])    \n",
    "        end\n",
    "        push!(unigrams,sent[end])\n",
    "        push!(bigrams[sent[end]], END_MARKER)\n",
    "    end\n",
    "    \n",
    "    \n",
    "    [k=>v.map for (k,v) in bigrams], unigrams.map\n",
    "end\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1131"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path=\"../../Resources/corpora/atis2_text/\"\n",
    "function valid(ss)\n",
    "    typeof(ss) <: ASCIIString  && length(ss)>0\n",
    "end\n",
    "    \n",
    "corpus = @pipe readdir(path) |> filter!(fn -> splitext(fn)[2]==\".sro\", _) |> map(_) do fn\n",
    "    try open(readall, path*fn) end\n",
    "    end |> filter!(valid,_) |> map(clean,_) |> filter!(valid,_) |> map(s->split(s),_);\n",
    "corpus_vocab = @pipe corpus |> map(Set,_) |> reduce(union,_)\n",
    "length(corpus_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using WordEmbeddings\n",
    "LL, word_indexes, indexed_words = load_word2vec_embeddings(\"word_emb_data/GoogleNews-vectors-negative300.bin\", length(corpus_vocab), corpus_vocab);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16-element Array{UTF8String,1}:\n",
       " \"and\"      \n",
       " \"a\"        \n",
       " \"respeak\"  \n",
       " \"nondirect\"\n",
       " \"maluso\"   \n",
       " \"of\"       \n",
       " \"panam\"    \n",
       " \"stapleton\"\n",
       " \"fokker\"   \n",
       " \"lufthansa\"\n",
       " \"to\"       \n",
       " \"laguardia\"\n",
       " \"nonjets\"  \n",
       " \"hartfield\"\n",
       " \"mcdonnell\"\n",
       " \"dulles\"   "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setdiff(corpus_vocab,indexed_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300x1119 Array{Float64,2}:\n",
       "  0.0529562  -0.00851202  -0.0123606    …  -0.0548293   0.0  0.0  0.0  0.0\n",
       "  0.0654598  -0.0342245   -0.0222299        0.0239878   0.0  0.0  0.0  0.0\n",
       "  0.0661953   0.0322839    0.0655398       -0.0190492   0.0  0.0  0.0  0.0\n",
       "  0.0470722   0.0458679    0.0394772        0.0826471   0.0  0.0  0.0  0.0\n",
       "  0.0522207  -0.0131429   -0.0866199        0.0620861   0.0  0.0  0.0  0.0\n",
       " -0.0820086  -0.0462207    0.0249128    …   0.0465646   0.0  0.0  0.0  0.0\n",
       " -0.0614145  -0.00094823  -0.0111628       -0.0786156   0.0  0.0  0.0  0.0\n",
       " -0.11621    -0.0522188   -0.0705224       -0.0516041   0.0  0.0  0.0  0.0\n",
       "  0.0156294   0.0465735    0.092369         0.00902063  0.0  0.0  0.0  0.0\n",
       "  0.0992929   0.0624509    0.0927522        0.0364857   0.0  0.0  0.0  0.0\n",
       " -0.0856861  -0.122785    -0.0563412    …   0.0395094   0.0  0.0  0.0  0.0\n",
       " -0.028133   -0.0287556   -0.0605572       -0.0588609   0.0  0.0  0.0  0.0\n",
       "  0.0522207   0.0515131   -0.0540416       -0.0903071   0.0  0.0  0.0  0.0\n",
       "  ⋮                                     ⋱               ⋮                 \n",
       " -0.0318105   0.0294613    0.0167682       -0.0199563   0.0  0.0  0.0  0.0\n",
       "  0.0181118   0.0211698    0.000958184      0.00942379  0.0  0.0  0.0  0.0\n",
       " -0.127242   -0.0163184   -0.00886321   …   0.0262052   0.0  0.0  0.0  0.0\n",
       " -0.0669308   0.00269033  -0.0122648       -0.00876866  0.0  0.0  0.0  0.0\n",
       " -0.060679   -0.0596282   -0.0262542        0.0336636   0.0  0.0  0.0  0.0\n",
       "  0.048911    0.0589226   -0.0161933        0.0701493   0.0  0.0  0.0  0.0\n",
       "  0.0461528   0.00573348  -0.0152351        0.0939355   0.0  0.0  0.0  0.0\n",
       " -0.0356719   0.00034456   0.0502089    …  -0.033462    0.0  0.0  0.0  0.0\n",
       " -0.0443141   0.0133193    0.01581         -0.0284225   0.0  0.0  0.0  0.0\n",
       " -0.0358558   0.0515131    0.00538979      -0.104821    0.0  0.0  0.0  0.0\n",
       "  0.0108946  -0.0252273    0.0479092       -0.0342683   0.0  0.0  0.0  0.0\n",
       " -0.0470722   0.0174651   -0.116515         0.0624893   0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Kind of the opposite of a stop word. This word has little meaning (So zero value), but much structural importance\n",
    "forcewords = [\"and\", \"a\", \"of\", \"to\"]\n",
    "for word in forcewords\n",
    "    @assert(!(word in indexed_words))\n",
    "    push!(indexed_words, word)\n",
    "    word_indexes[word] = length(indexed_words)\n",
    "end\n",
    "LL = [LL zeros(size(LL,1),length(forcewords))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300x1121 Array{Float64,2}:\n",
       "  0.0529562  -0.00851202  -0.0123606    …  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "  0.0654598  -0.0342245   -0.0222299       0.0  0.0  0.0  0.0  0.0  0.0\n",
       "  0.0661953   0.0322839    0.0655398       0.0  0.0  0.0  0.0  0.0  0.0\n",
       "  0.0470722   0.0458679    0.0394772       0.0  0.0  0.0  0.0  0.0  0.0\n",
       "  0.0522207  -0.0131429   -0.0866199       0.0  0.0  0.0  0.0  0.0  0.0\n",
       " -0.0820086  -0.0462207    0.0249128    …  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " -0.0614145  -0.00094823  -0.0111628       0.0  0.0  0.0  0.0  0.0  0.0\n",
       " -0.11621    -0.0522188   -0.0705224       0.0  0.0  0.0  0.0  0.0  0.0\n",
       "  0.0156294   0.0465735    0.092369        0.0  0.0  0.0  0.0  0.0  0.0\n",
       "  0.0992929   0.0624509    0.0927522       0.0  0.0  0.0  0.0  0.0  0.0\n",
       " -0.0856861  -0.122785    -0.0563412    …  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " -0.028133   -0.0287556   -0.0605572       0.0  0.0  0.0  0.0  0.0  0.0\n",
       "  0.0522207   0.0515131   -0.0540416       0.0  0.0  0.0  0.0  0.0  0.0\n",
       "  ⋮                                     ⋱  ⋮                        ⋮  \n",
       " -0.0318105   0.0294613    0.0167682       0.0  0.0  0.0  0.0  0.0  0.0\n",
       "  0.0181118   0.0211698    0.000958184     0.0  0.0  0.0  0.0  0.0  0.0\n",
       " -0.127242   -0.0163184   -0.00886321   …  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " -0.0669308   0.00269033  -0.0122648       0.0  0.0  0.0  0.0  0.0  0.0\n",
       " -0.060679   -0.0596282   -0.0262542       0.0  0.0  0.0  0.0  0.0  0.0\n",
       "  0.048911    0.0589226   -0.0161933       0.0  0.0  0.0  0.0  0.0  0.0\n",
       "  0.0461528   0.00573348  -0.0152351       0.0  0.0  0.0  0.0  0.0  0.0\n",
       " -0.0356719   0.00034456   0.0502089    …  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " -0.0443141   0.0133193    0.01581         0.0  0.0  0.0  0.0  0.0  0.0\n",
       " -0.0358558   0.0515131    0.00538979      0.0  0.0  0.0  0.0  0.0  0.0\n",
       "  0.0108946  -0.0252273    0.0479092       0.0  0.0  0.0  0.0  0.0  0.0\n",
       " -0.0470722   0.0174651   -0.116515        0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@assert(!(START_MARKER in indexed_words))\n",
    "push!(indexed_words, START_MARKER)\n",
    "word_indexes[START_MARKER] = length(indexed_words)\n",
    "\n",
    "@assert(!(END_MARKER in indexed_words))\n",
    "push!(indexed_words, END_MARKER)\n",
    "word_indexes[END_MARKER] = length(indexed_words)\n",
    "LL = [LL zeros(size(LL,1),2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "known_vocab = Set(indexed_words)\n",
    "known_corpus = filter(corpus) do sent\n",
    "    for word in sent\n",
    "        if !( word in known_vocab)\n",
    "            return false\n",
    "        end\n",
    "    end\n",
    "    true\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################LOADING Done, Now processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using StatsBase\n",
    "# modified from https://github.com/JoFrhwld/GoodTuring.jl/blob/master/GoodTuring.jl\n",
    "function simpleGoodTuring(speciesCountDict::Dict)\n",
    "    speciesCountVec = collect(values(speciesCountDict))\n",
    "        \n",
    "    totalCounts = sum(speciesCountVec)\n",
    "    cofcDict = countmap(speciesCountVec)\n",
    "    r = sort(collect(keys(cofcDict)))\n",
    "\n",
    "    N = size(r,1)\n",
    "    Nr = [cofcDict[r[i]] for i in 1:N]\n",
    "\n",
    "    p0 = haskey(cofcDict, 1.0) ? cofcDict[1.0] / totalCounts : 0.0\n",
    "    \n",
    "    Z = sgtZ(r,Nr)\n",
    "    logr = map(log,r)\n",
    "    logZ = map(log,Z)\n",
    "\n",
    "    X = hcat(ones(N), logr)\n",
    "    Y = copy(logZ )\n",
    "    coefs = X\\Y\n",
    "    intercept = coefs[1]\n",
    "    slope = coefs[2]\n",
    "\n",
    "    useY = false\n",
    "    rSmooth = Array{Float64}(N)\n",
    "    for i in 1:N\n",
    "        @inbounds thisr = r[i]\n",
    "        \n",
    "        #y = ((thisr+1.0)^(slope+1.0))/(thisr^slope)\n",
    "        #The above is the much simplified form of the below (Performance identical output differs by 10^-16)\n",
    "        y = (thisr+1.0) * exp(slope * log(thisr+1.0) + intercept) / exp(slope * log(thisr) + intercept)\n",
    "\n",
    "        if !in(thisr+1, r)\n",
    "            useY = true\n",
    "        end\n",
    "\n",
    "        if useY\n",
    "            rSmooth[i] = y\n",
    "        else\n",
    "            x = (thisr+1) * cofcDict[thisr + 1]/cofcDict[thisr]\n",
    "            thisNr = cofcDict[thisr]\n",
    "            thisNr1 = cofcDict[thisr+1]\n",
    "\n",
    "            t = 1.96 * ((thisr+1)^2) * (thisNr1 / thisNr^2) * (1 + (thisNr1 / thisNr))\n",
    "\n",
    "            if abs(x-y) > t\n",
    "                @inbounds rSmooth[i] = x\n",
    "            else\n",
    "                useY = true\n",
    "                @inbounds rSmooth[i] = y\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    smoothTot = sum(Nr.*rSmooth)\n",
    "    sgtProb  = (1.0 - p0) .* (rSmooth/smoothTot)\n",
    "    sgtProbDict = Dict([r[i] => sgtProb[i] for i in 1:N])\n",
    "    sgtDict = Dict([sp=>sgtProbDict[speciesCountDict[sp]] for sp in keys(speciesCountDict)])\n",
    "\n",
    "    sgtDict, sgtProbDict, p0\n",
    "end\n",
    "\n",
    "\n",
    "function sgtZ(r::Array, Nr::Array)\n",
    "    j = r\n",
    "    i = [0; j[1:end-1]]\n",
    "    lastK = 2*j[end] - i[end]\n",
    "    k = [j[2:end]; lastK]\n",
    "    Float64[(2*Nr[iter])/(k[iter]-i[iter]) for iter = 1:length(j)]\n",
    "end\n",
    "\n",
    "function simpleGoodTuring(speciesCountVec::Vector)\n",
    "    sgtD = simpleGoodTuring(Dict([ii=>v for (ii,vv) in enumerate(speciesCountVec)]))\n",
    "    [sgtD[ii] for ii in 1:length(speciesCountVec)]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function katz_bigrams(bigram_freq::Dict, unigrams_freq::Dict)\n",
    "    k_bigrams = Dict()\n",
    "    \n",
    "    for first in keys(bigram_freq)\n",
    "        smoothed,_,p0 = simpleGoodTuring(bigram_freq[first])\n",
    "        k_bigrams[first] = smoothed\n",
    "        \n",
    "        backoff_keys = setdiff(keys(unigram_freq),keys(smoothed))\n",
    "        #share the p0 proability mass between them\n",
    "        total = sum([unigrams_freq[key] for key in backoff_keys])\n",
    "        for second in backoff_keys\n",
    "            k_bigrams[first][second]=p0.*unigrams_freq[second]./total\n",
    "        end\n",
    "    end\n",
    "    k_bigrams\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function dict2mat(bigrams::Dict, word_indexes::Dict{AbstractString,Int64}, dense=False)\n",
    "    mat  = (dense ? zeros: spzeros)(length(word_indexes),length(word_indexes))\n",
    "    for first in keys(bigrams)\n",
    "        for second in keys(bigrams[first])\n",
    "            mat[word_indexes[second], word_indexes[first]] = bigrams[first][second]\n",
    "        end\n",
    "    end\n",
    "    mat\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigram_freq, unigram_freq = collect_grams_stats(known_corpus);\n",
    "kbigrams=katz_bigrams(bigram_freq, unigram_freq)\n",
    "kbigrams_mat = dict2mat(kbigrams,word_indexes,true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using Gadfly\n",
    "using Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sent_lengths = map(length, known_corpus)\n",
    "plot(x=sent_lengths, Geom.histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sent_length_dist = fit_mle(Gamma, sent_lengths)\n",
    "plot(x=[round(rand(sent_length_dist)) for _ in 1:length(sent_lengths)], Geom.histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "length_prob=cdf(sent_length_dist,[1.5:1.0:50.5])-cdf(sent_length_dist,[0.5:1.0:49.5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function collect_cooccur_stats(sentences)\n",
    "    unioccur = counter(AbstractString)\n",
    "    bioccur = DefaultDict(()->counter(AbstractString))\n",
    "    \n",
    "    for sent in sentences\n",
    "        for ii in 1:length(sent)\n",
    "            push!(unioccur, sent[ii])\n",
    "            for jj in 1:length(sent)\n",
    "                if ii==jj\n",
    "                    continue\n",
    "                end\n",
    "                push!(bioccur[sent[ii]], sent[jj])    \n",
    "            end\n",
    "        end       \n",
    "    end\n",
    "    \n",
    "    [k=>v.map for (k,v) in bioccur], unioccur.map\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bioccur_freq, unioccur_freq = collect_cooccur_stats(known_corpus)\n",
    "\n",
    "bioccur_mat = dict2mat(bioccur_freq,word_indexes,true)\n",
    "bioccur_mat.+=1.0 # Add one smoothing\n",
    "bioccur_mat./=sum(bioccur_mat)\n",
    "\n",
    "unioccur = freq2prob(unioccur_freq)\n",
    "unioccur_vec = Float64[word in keys(unioccurs) ? unioccurs[word] : 0.0 for word in indexed_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unioccur_vec_smoothed = Float64[word in keys(unioccur_freq) ? unioccur_freq[word] : 0.0 for word in indexed_words]\n",
    "unioccur_vec_smoothed.+=1.0 # Add one smoothing\n",
    "unioccur_vec_smoothed./=sum(unioccur_vec_smoothed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(bioccur_mat,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "open(\"atis_data.jsz\",\"w\") do fh\n",
    "    data = Dict([\n",
    "        (\"bigrams\", kbigrams_mat),\n",
    "        (\"bioccur\", bioccur_mat),\n",
    "        (\"unioccur\", unioccur_vec),\n",
    "        \n",
    "        (\"length_prob\", length_prob),\n",
    "        (\"LL\",LL),\n",
    "        (\"word_indexes\", word_indexes),\n",
    "        (\"indexed_words\", indexed_words),\n",
    "        ])\n",
    "    serialize(fh, data)    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function likelyhood(sent, bigrams)\n",
    "    words = split(sent)\n",
    "    words = [START_MARKER; words; END_MARKER]\n",
    "    \n",
    "    p=1.0\n",
    "    for ii in 1:length(words)-1\n",
    "        p*=bigrams[words[ii]][words[ii+1]]\n",
    "    end\n",
    "    p\n",
    "end\n",
    "\n",
    "\n",
    "function select_word{S<:AbstractString,V}(unigrams::Dict{S,V})\n",
    "    cutoff = rand()\n",
    "    total = 0.0\n",
    "    for next_word in keys(unigrams)\n",
    "        total+=unigrams[next_word]\n",
    "        if total>=cutoff\n",
    "            return next_word\n",
    "        end\n",
    "    end\n",
    "    assert(False, \"Should never reach here\") \n",
    "end\n",
    "\n",
    "function random_walk(bigrams)\n",
    "    words=[]\n",
    "    cur = START_MARKER\n",
    "    while(cur!=END_MARKER)\n",
    "        cur = select_word(bigrams[cur])\n",
    "        push!(words,cur)\n",
    "    end\n",
    "    words = words[1:end-1]\n",
    "    join(words, \" \")\n",
    "end\n",
    "\n",
    "walk =random_walk(kbigrams) \n",
    "print(walk*\"\\t\")\n",
    "print(likelyhood(walk,kbigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frames Magic Sharing Co-occurance PMF, Inspired by Bengio 2003\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dEmb = 32\n",
    "CC = 0.01*randn((dEmb, length(indexed_words)))\n",
    "WW = 0.01*randn((length(indexed_words),dEmb))\n",
    "bb = 0.01*randn((length(indexed_words)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CC\t\t"
     ]
    }
   ],
   "source": [
    "@pz CC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evaluate (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function evaluate(sentence)\n",
    "    sentence_iis = [word_indexes[word] for word in sentence]\n",
    "\n",
    "    for n_givens in 1:length(sentence_iis)\n",
    "        given_prob = 2* 1.0/n_givens\n",
    "        given_keep = rand(length(sentence_iis)).<given_prob\n",
    "        given_iis=  sentence_iis[given_keep]\n",
    "        cooccur_iis =  sentence_iis[~given_keep]\n",
    "        given_sowe = sum(CC[:,given_iis],2)\n",
    "        return given_sowe, cooccur_iis\n",
    "        input_iis\n",
    "    end\n",
    "    \n",
    "        \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train (generic function with 1 method)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function loss(actual, expected)\n",
    "    sum(0.5*(expected-actual).^2)\n",
    "end\n",
    "\n",
    "function forward(x,W,b)\n",
    "    tanh(WW*x+b)\n",
    "end\n",
    "\n",
    "function δ(a, δ_above, W)\n",
    "    #a is the ouput of this layer: a=tanh(z) where z is the input from layer below\n",
    "    #W is matrix to move to above layer, from this one\n",
    "    const dz = 1-a.^2 #Derivitive of a=tanh(z)\n",
    "    (W'*δ_above).*dz\n",
    "end\n",
    "\n",
    "function δ(actual, expected) \n",
    "    #Output Layer\n",
    "    const M = length(actual)# ==length(expected)\n",
    "    const dz = 1-actual.^2\n",
    "    const δ_above = -(expected-actual)\n",
    "    δ_above.*dz\n",
    "end\n",
    "\n",
    "function train(input,W,b, expected_output)\n",
    "    actual_output = forward(input,W,b)\n",
    "    δ_top = δ(actual_output, expected_output)\n",
    "    ΔW  = δ_top*actual_output'\n",
    "    Δb  = δ_top\n",
    "    δ_bottom = δ(input, δ_top, W)\n",
    "    Δx  = δ_bottom\n",
    "    Δx,ΔW,Δb\n",
    "end\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x,t_iis=evaluate([\"shortest\", \"flight\"])\n",
    "target = zeros(bb) #just while we are testing use a one hot bag rep\n",
    "target[t_iis]=1.0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       "32x1 Array{Float64,2}:\n",
       " -0.000867156\n",
       "  0.00313226 \n",
       "  0.00310955 \n",
       "  0.00641466 \n",
       "  0.000592477\n",
       " -0.00519664 \n",
       " -0.00149645 \n",
       " -8.56412e-5 \n",
       "  0.0037847  \n",
       " -0.00371514 \n",
       "  0.00364238 \n",
       "  0.00300397 \n",
       "  0.00187676 \n",
       "  ⋮          \n",
       "  0.00325599 \n",
       " -0.00169455 \n",
       " -0.00141891 \n",
       " -0.00579617 \n",
       "  0.00347054 \n",
       "  0.00469104 \n",
       " -0.0050027  \n",
       " -0.00414357 \n",
       "  0.00634323 \n",
       " -0.00441365 \n",
       " -0.00355065 \n",
       " -0.00642642 ,\n",
       "\n",
       "1121x1121 Array{Float64,2}:\n",
       "  3.1688e-5     3.64543e-5    3.16231e-5   …  -3.80822e-5    3.08786e-5 \n",
       "  3.64539e-5    4.19371e-5    3.63793e-5      -4.38099e-5    3.55229e-5 \n",
       "  3.16231e-5    3.63797e-5    3.15584e-5      -3.80043e-5    3.08154e-5 \n",
       "  1.61214e-5    1.85463e-5    1.60884e-5      -1.93745e-5    1.57097e-5 \n",
       " -2.56802e-5   -2.95429e-5   -2.56277e-5       3.08622e-5   -2.50243e-5 \n",
       " -5.64577e-6   -6.49498e-6   -5.63422e-6   …   6.78502e-6   -5.50157e-6 \n",
       "  8.49654e-6    9.77454e-6    8.47915e-6      -1.0211e-5     8.27953e-6 \n",
       "  3.53348e-5    4.06497e-5    3.52625e-5      -4.2465e-5     3.44324e-5 \n",
       "  0.000118226   0.000136009   0.000117985     -0.000142083   0.000115207\n",
       "  0.000100068   0.000115119   9.9863e-5       -0.00012026    9.75119e-5 \n",
       " -5.9471e-5    -6.84163e-5   -5.93493e-5   …   7.14716e-5   -5.79521e-5 \n",
       "  1.35314e-5    1.55667e-5    1.35037e-5      -1.62618e-5    1.31858e-5 \n",
       " -9.25562e-5   -0.000106478  -9.23667e-5       0.000111233  -9.01922e-5 \n",
       "  ⋮                                        ⋱                 ⋮          \n",
       "  3.68198e-5    4.23581e-5    3.67445e-5      -4.42496e-5    3.58794e-5 \n",
       "  7.50912e-5    8.6386e-5     7.49375e-5   …  -9.02437e-5    7.31733e-5 \n",
       " -3.46249e-5   -3.98329e-5   -3.4554e-5        4.16117e-5   -3.37405e-5 \n",
       "  6.40366e-5    7.36686e-5    6.39055e-5      -7.69584e-5    6.2401e-5  \n",
       "  2.573e-5      2.96002e-5    2.56773e-5      -3.0922e-5     2.50728e-5 \n",
       " -7.14472e-7   -8.21939e-7   -7.1301e-7        8.58644e-7   -6.96224e-7 \n",
       "  5.15999e-5    5.93612e-5    5.14943e-5   …  -6.20121e-5    5.0282e-5  \n",
       " -9.46113e-5   -0.000108842  -9.44177e-5       0.000113703  -9.21948e-5 \n",
       " -0.000136969  -0.000157571  -0.000136689      0.000164608  -0.000133471\n",
       "  1.56201e-5    1.79695e-5    1.55881e-5      -1.8772e-5     1.52211e-5 \n",
       " -3.80817e-5   -4.38097e-5   -3.80038e-5       4.57661e-5   -3.7109e-5  \n",
       "  3.08787e-5    3.55233e-5    3.08155e-5   …  -3.71096e-5    3.009e-5   ,\n",
       "\n",
       "1121x1 Array{Float64,2}:\n",
       "  0.00562912\n",
       "  0.00647575\n",
       "  0.0056176 \n",
       "  0.00286384\n",
       " -0.00456189\n",
       " -0.00100293\n",
       "  0.00150934\n",
       "  0.00627696\n",
       "  0.021002  \n",
       "  0.0177762 \n",
       " -0.0105646 \n",
       "  0.00240374\n",
       " -0.0164419 \n",
       "  ⋮         \n",
       "  0.00654075\n",
       "  0.0133394 \n",
       " -0.00615083\n",
       "  0.0113756 \n",
       "  0.00457073\n",
       " -0.00012692\n",
       "  0.00916631\n",
       " -0.0168069 \n",
       " -0.0243315 \n",
       "  0.00277478\n",
       " -0.00676491\n",
       "  0.00548535)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(x,WW,bb,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "g (generic function with 1 method)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using ForwardDiff\n",
    "\n",
    "function f(θ)\n",
    "    actual = forward(unpack(θ,size(x),size(WW),size(bb))...)\n",
    "    loss(actual, target)\n",
    "end\n",
    "\n",
    "# Using forwarddiff_jacobian\n",
    "g = forwarddiff_gradient(f, Float64, fadtype=:dual, n=length(pack(x,WW,bb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37025-element Array{Float64,1}:\n",
       " -0.000867328\n",
       "  0.00313256 \n",
       "  0.00310955 \n",
       "  0.00641479 \n",
       "  0.000592594\n",
       " -0.00519668 \n",
       " -0.00149691 \n",
       " -8.56524e-5 \n",
       "  0.00378514 \n",
       " -0.00371579 \n",
       "  0.00364245 \n",
       "  0.003004   \n",
       "  0.00187687 \n",
       "  ⋮          \n",
       "  0.00654075 \n",
       "  0.0133394  \n",
       " -0.00615083 \n",
       "  0.0113756  \n",
       "  0.00457073 \n",
       " -0.00012692 \n",
       "  0.00916631 \n",
       " -0.0168069  \n",
       " -0.0243315  \n",
       "  0.00277478 \n",
       " -0.00676491 \n",
       "  0.00548535 "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t=pack(x,WW,bb)\n",
    "dg = g(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1257794-element Array{Float64,1}:\n",
       " -0.000867156\n",
       "  0.00313226 \n",
       "  0.00310955 \n",
       "  0.00641466 \n",
       "  0.000592477\n",
       " -0.00519664 \n",
       " -0.00149645 \n",
       " -8.56412e-5 \n",
       "  0.0037847  \n",
       " -0.00371514 \n",
       "  0.00364238 \n",
       "  0.00300397 \n",
       "  0.00187676 \n",
       "  ⋮          \n",
       "  0.00654075 \n",
       "  0.0133394  \n",
       " -0.00615083 \n",
       "  0.0113756  \n",
       "  0.00457073 \n",
       " -0.00012692 \n",
       "  0.00916631 \n",
       " -0.0168069  \n",
       " -0.0243315  \n",
       "  0.00277478 \n",
       " -0.00676491 \n",
       "  0.00548535 "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ag = pack(train(x,WW,bb, target)...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "`git add ../util/Packing.jl` |> run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: DimensionMismatch(\"arrays could not be broadcast to a common size\")\nwhile loading In[45], in expression starting on line 1",
     "output_type": "error",
     "traceback": [
      "LoadError: DimensionMismatch(\"arrays could not be broadcast to a common size\")\nwhile loading In[45], in expression starting on line 1",
      "",
      " in broadcast_shape at broadcast.jl:41",
      " in .- at broadcast.jl:303"
     ]
    }
   ],
   "source": [
    "abs(dg.-ag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "`git commit -m=\"Working on neural cooccuance measure -a` |> run"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.0-dev",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
